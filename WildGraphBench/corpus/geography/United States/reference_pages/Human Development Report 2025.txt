# Human Development Report 2025

REPORT 2025 

# A matter of choice: 

# People and possibilities 

# in the age of AI Copyright @ 2025 

By the United Nations Development Programme 

1 UN Plaza, New York, NY 10017 USA 

All rights reserved. No part of this publication may be reproduced, stored in a 

retrieval system or transmitted, in any form or by means, electronic, mechanical, 

photocopying, recording or otherwise, without prior permission. 

Sales no.:  E.25.III.B.2 

Print ISBN:  9789211576092 

PDF ISBN:  9789211542639 

Print ISSN:  0969-4501 

Online ISSN:  2412-3129 

A catalogue record for this book is available from the British Library and Library 

of  Congress 

General disclaimers.  The designations employed and the presentation of the 

material in this publication do not imply the expression of any opinion whatsoever 

on the part of the Human Development Report Office (HDRO) of the United 

Nations Development Programme (UNDP) concerning the legal status of any 

country, territory, city or area or of its authorities, or concerning the delimitation 

of its frontiers or boundaries. Dotted and dashed lines on maps represent 

approximate border lines for which there may not yet be full agreement. 

The findings, analysis, and recommendations of this Report, as with previous 

Reports, do not represent the official position of the UNDP or of any of the UN 

Member States that are part of its Executive Board. They are also not necessarily 

endorsed by those mentioned in the acknowledgments or cited. 

The mention of specific companies does not imply that they are endorsed or 

recommended by UNDP in preference to others of a similar nature that are not 

mentioned. 

Some of the figures included in the analytical part of the report where indicated 

have been estimated by the HDRO or other contributors to the Report and are not 

necessarily the official statistics of the concerned country, area or territory, which 

may use alternative methods. All the figures included in the Statistical Annex are 

from official sources. All reasonable precautions have been taken by the HDRO to 

verify the information contained in this publication. However, the published material 

is being distributed without warranty of any kind, either expressed or implied. 

The responsibility for the interpretation and use of the material lies with the reader. 

In no event shall the HDRO and UNDP be liable for damages arising from its use. 

The signed contributions in boxes and spotlights represent the opinions of the 

authors and are the product of independent research of their responsibility. They 

do not represent necessarily the position or opinions of the Human Development 

Report Office or UNDP. Any errors or omissions are the authors’ responsibility. They 

are presented in the report to stimulate debate and to encourage further dialogue 

between researchers and decisionmakers. 

Printed in the USA, by AGS, an RR Donnelley Company, on Forest Stewardship Council 

certified and elemental chlorine-free papers. Printed using vegetable-based ink. 

The 2025 Human Development Report 

The cover and chapter images in the report 

feature portraits in the artistic styles of various 

historical periods and cultures, with subtle 

allusions to people’s use of technology. 

For example, the cover presents a modern 

woman with headphones, against a 

background with hints of technology in the 

style of prehistoric cave paintings—an echo of 

humanity’s earliest attempts to understand and 

shape the world. 

Combining history with symbols of modern 

technology, the images place humans at the 

centre and aim to bridge the past and future— 

positioning today’s breakthroughs in artificial 

intelligence (AI), and the media through which 

we interact with them, as part of humanity’s 

unfolding and open-ended journey towards 

advancing human development. 

Working with AI, a graphic designer created 

the images by guiding the system with ideas 

and creative direction, prompting the AI to 

produce a range of visual outputs that the 

graphic designer then edited, developed and 

finalized. The artworks themselves reflect how 

AI could reshape how we do things, unleashing 

new creative possibilities and augmenting what 

people can do. The cover and other images 

invite you to pause and reflect—as we navigate 

the uncertainties and possibilities of a world 

with AI. 

REPORT 2025 

A matter of choice: People and possibilities in the age of AI 

> A matter of choice
> People and possibilities in the age of AI

# A matter of choice 

# People and possibilities in the age of AI 

# H U M A N D E V E LO P M E N T 

# R E P O R T 2 0 2 5 i i i 

> HUMAN DEVELOPMENT REPORT 2025

# Team 

Director and lead author 

Pedro Conceição 

Research and statistics 

Joseph Bak-Coleman, Nabamallika Dehingia, Nicholas Depsky, 

Pratibha Gautam, Moumita Ghorai, Divya Goyal, Yu-Chieh Hsu, 

Christina Lengfelder, Brian Lutz, Tasneem Mirza, Prachi Paliwal, 

Josefin Pasanen, Antonio Reyes González, Som Kumar Shrestha, 

Ajita Singh, Heriberto Tapia, Yanchun Zhang and Zakaria Zoundi 

Digital, data and knowledge management, communications, operations, 

National Human Development Reports 

Nasantuya Chuluun, Seockhwan Bryce Hwang, Nicole Igloi, Admir 

Jahic, Fe Juarez Shanahan, Minji Kwag, Ana Porras, Qiamuddin 

Sabawoon, Stanislav Saling, Marium Soomro and Sajia Wais HUMAN DEVELOPMENT REPORT 2025 

# The 2025 Human Development Report 

# Advisory Board 

Co-chairs  Laura Chinchilla 

Former President of Costa 

Rica 

A. Michael Spence 

Philip H. Knight Professor 

Emeritus of Management, 

Graduate School of 

Business, Stanford 

University 

Members  Masood Ahmed 

President Emeritus, 

Center for Global 

Development 

Deemah AlYahya 

Secretary-General, Digital 

Cooperation Organization 

Kaushik Basu 

Professor of Economics and 

the Carl Marks Professor 

of International Studies, 

Cornell University 

Haroon Bhorat 

Professor of Economics and 

Director of the Development 

Policy Research Unit, 

University of Cape Town 

Diane Coyle 

Bennett Professor of 

Public Policy, University of 

Cambridge; Co-Director, 

Bennett Institute for 

Public Policy, University of 

Cambridge 

Gretchen C. Daily 

Director, Natural Capital 

Project and Bing Professor 

of Environmental Science, 

Stanford University 

Marc Fleurbaey 

Research Director, CNRS; 

Professor, Paris School 

of Economics; Associate 

Professor, Ecole normale 

supérieure, Paris 

Paula Ingabire 

Minister, ICT and Innovation, 

Republic of Rwanda 

Sheila Jasanoff 

Pforzheimer Professor of 

Science and Technology 

Studies, Harvard Kennedy 

School 

Ravi Kanbur 

T. H. Lee Professor 

of World Affairs, 

International Professor of 

Applied Economics and 

Management and Professor 

of Economics, Cornell 

University 

Luis Felipe López-Calva 

Global Director, Poverty 

and Equity Global 

Practice, World Bank 

Group 

J. Nathan Matias 

Assistant Professor, 

Department of 

Communication, Cornell 

University 

Arvind Narayanan 

Professor of Computer 

Science, Princeton 

University; Director, 

Center for Information 

Technology Policy 

Rapelang Rabana 

Co-CEO, Imagine 

Worldwide 

Francesca Rossi 

IBM Fellow and the IBM AI 

Ethics Global Leader, TJ 

Watson Research Center 

Emma Ruttkamp-Bloem 

Head, Department of 

Philosophy and AI Ethics 

Lead, Center for AI 

Research, University of 

Pretoria 

Zeynep Tufekci 

Henry G. Bryant Professor 

of Sociology and Public 

Affairs, Princeton 

University 

Krushil Watene 

Peter Kraus Associate 

Professor in Philosophy, 

University of Auckland 

Waipapa Taumata Rau 

Linghan Zhang 

Professor, Institute of Data 

Law, China University of 

Political Science and Law FOREWORD  vForeword 

Artificial intelligence (AI) is racing ahead at lightning 

speed. Yet as AI surges forward, human development 

stalls. Decades of progress, reflected in the Human De -

velopment Index, have flatlined, with no clear recovery 

from the blows dealt by the Covid-19 pandemic and 

subsequent crises. We are at a crossroads: while AI 

promises to redefine our future, it also risks deepening 

the divides of a world already off balance. Are we on the 

verge of an AI-powered renaissance—or sleepwalking 

into a future ruled by inequality and eroded freedoms? 

Too often, headlines, policies and public debates fixate 

on what AI might achieve in some distant future—utopian 

or dystopian. These deterministic views are not only 

disempowering; they are profoundly misleading. They 

obscure the fact that the future is being shaped now, by 

the choices we make today. The 2025 Human Develop -

ment Report, A Matter of Choice: People and Possibilities 

in the Age of AI, reminds us that it is people—not ma -

chines—who determine which technologies thrive, how 

they are used and whom they serve. AI’s impact will be 

defined not by what it can do but by the decisions we 

make in its design, development and deployment. 

Central to these decisions is how we view the role 

of people in an AI-driven world. Assuming that AI will 

inevitably sideline humanity overlooks the very force 

driving its progress: us. AI’s capacity to automate 

nonroutine tasks has stoked fears of human replace -

ment—but this is only when we reduce people to mere 

task-performers. This Report challenges that view. It 

argues that humans, “the true wealth of nations,” are far 

more than the sum of the tasks we perform. Rather than 

measuring AI by how closely it mimics us, the Report 

emphasizes how the differences between humans and 

machines can create powerful complementarities that 

expand human potential. 

This people-centred perspective becomes even 

more critical in a moment of overlapping global crises. 

It is tempting to believe that AI alone can solve our de -

velopment challenges. But that belief invites compla -

cency. It asks us to surrender responsibility and ignore 

the political, social and systemic barriers that have long 

impeded progress. The 2023/2024 Human Develop -

ment Report,  Breaking the Gridlock , made it clear: 

our limitations are not technological but sociological. 

Many of the crises and inequalities we face persist not 

because solutions are lacking but because we have 

failed to act. With AI we must choose differently—and 

we must choose now. 

We might resist the temptation to anthropomorphize 

AI, yet in many ways it acts like a mirror—reflecting and 

amplifying the values, structures and inequalities of the 

societies that shape it. AI does not act independently 

of us; it evolves through our decisions and our priori -

ties. If we fail to address the injustices and divides that 

persist today, AI will only entrench them further. But if 

we invest in human capabilities and commit to greater 

equity, AI can magnify the best of what humanity can 

achieve. Ultimately, the 2025 Human Development Re -

port on AI is not about technology—it is about people, 

and our ability to reinvent ourselves in the face of pro -

found change. 

Achim Steiner 

Administrator 

United Nations Development Programme v i HUMAN DEVELOPMENT REPORT 2025 

# Acknowledgements 

Every Human Development Report is a 

voyage of discovery, exploring how the 

human development approach helps navi -

gate pressing challenges and emerging 

opportunities. That navigation proved par -

ticularly challenging for this Report, given 

the rapidly changing context of artificial 

intelligence (AI). AI continues to astonish 

every day. It engenders a mix of hype and 

hope, along with fear and trepidation. It is 

attracting financial investment and human 

talent towards its continuing evolution, but 

it is also becoming a source of geopoliti -

cal tensions. There was really no roadmap 

helping us navigate what seemed like a 

new and constantly moving AI frontier. A 

technology that is in many ways just one 

more like many others that preceded it 

also felt at times different, in its ability to 

simulate and replicate features that are 

so distinctively human. Therefore, this is a 

Report that captures the spirit of a particu -

lar moment in time, with much uncertainty 

about what might follow in terms of both 

AI as a technology and its ultimate impact 

on people’s lives. Joining in this journey of 

exploration are the many individuals and 

organizations recognized here that con -

tributed their expertise, wisdom and ex -

pectations, as well as doubts, about what 

AI might mean for human development. 

The  Advisory Board , always a crucial 

source of advice and guidance, was partic -

ularly relevant this year and is recognized 

next to the Report team not to implicate 

them in the findings but to show apprecia -

tion for their fundamental contribution to 

the Report’s framing and analysis . 

Complementing the advice from the 

Advisory Board, the  Statistical Advi -

sory Panel  provided guidance on several 

methodological and data aspects of the 

Report—particularly those related to cal -

culating its human development metrics. 

We are grateful to all the panel members: 

Ola Awad, Oliver Chinganya, Koen Decan -

cq, Shatakshee Dhongde, Patrick Gerland, 

Aishath Hassan, Ivo Havinga, Richard 

Heys, Solomon Hsiang, Doho Latif Kane, 

Steven Kapsos, Milorad Kovacevic, Jaya 

Krishnakumar, Christoph Lakner, Steve 

Macfeely, Silvia Montoya, Anu Peltola, 

Iñaki Permanyer, Andrew Rzepa, Michaela 

Saisana, Claudia Sanmartin, Hany Torky 

and Andrew Zolli. 

We are also thankful to colleagues who 

provided data assistance to the  Statistical 

Annex , specifically, Jenny Cresswell, Ad -

olfo Gustavo Imhof, Vladimíra Kantorová, 

Olivier Labé, Jong-Wha Lee, Stephan 

Lutter, Alasdair McWilliam, Eric Roland Me -

treau, Oscar Milafu Onam, Damien Sass, 

Leo Tornarolii and Yanhong Zhang. 

Appreciation is also extended for all the 

data, written inputs and peer reviews 

of the Report’s draft chapters, including 

those by PB Anand, Paul Anand, Joel An -

derson, Uğur Aytaç, Klaus Bruhn Jensen, 

Yi Bu, Leonardo Bursztyn, Miriam Car -

rera Manzano, Maria-Louise Clausen, Nick 

Couldry, Andrew Crabtree, Fabien Curto 

Millet, Christiaan De Neubourg, Virginia 

Doellgast, Kevin Donovan, Pablo Egaña 

del Sol, Frank Esser, Adam Fejerskov, 

Rana Gautam, Anne Marie Goetz, David 

Hammond, Benajmin Handel, Tomasz 

Hollanek, Jeroen Hopster, Johannes Jae -

ger, Rafael Jimenez Duran, Julia Karpati, 

Marie Kolling, Anton Korinek, Seth Lazar, 

Margauz Luflade, Michael Muthukrishna, 

Rose Mutiso, Kruakae Pothong, Stiene 

Praet, Carina Prunkl, Mitsy Barriga Ramos, 

Christoph Roth, Anna Salomons, Stefka 

Schmid, Tobia Spampatti, Tara Thiagara -

jan, Luis Hernán Vargas, Manuela Veloso, 

Juri Viehoff, Zi Wang, Åsa Wikforss, Kuan -

song Victor Zhuang and David Zuluaga 

Martínez. 

We are especially thankful to our close 

collaborations with our  partners : Mario 

Biggeri, Enrica Chiappero-Martinetti, Fla -

vio Comim, Carlos Alberto Garzon, Ann 

Mitchell and Kathy Rosenblum at the 

Human Development & Capability Orga -

nization; Stefano Calcina, Valentina Caliri, 

Giuseppe Diglio, Gerardo Filippo, Marina 

Kodric, Fabio Marchetti, Bianca Mihalcea, 

Marco Presenti and Andrea Sironi at Gen -

erali; Jon Clifton, Kiki Papachristoforou 

and Andrew Rzepa at Gallup; Suela Aksoy, 

Nancy Hey and Ed Morrow at the Lloyd 

Register Foundation; Antonio Corcoles, 

Ismael Faro, Zaira Nazario and Kush 

Varshney at IBM; David G. Blanchflower at 

Dartmouth College and Alexander Bryson 

from University College London; Beata 

Javorcik and Zoe Russo at the European 

Bank for Reconstruction and Develop -

ment; Nino Naderashvili and Charlie Zong 

at South-North Scholars; Juliana Alves 

Soares, Paul Anthony, Kimberley Blair 

Bolch, Nicholas Nam and Leslie J Yun 

at the World Bank; Sabina Alkire at the 

Oxford Poverty and Human Development 

Initiative; Stijn Broecke at the Organisation 

for Economic Co-operation and Develop -

ment; Lucas Chanel at the World Inequal -

ity Lab; Ketan Patel at the Force for Good; 

Jonathan Richard Schwarz at the UK AI 

Security Institute/Thomson Reuters; Phil -

lip Howard and Sebastian Valenzuela at 

the International Panel on the Information 

Environment; José M. Tavares at the Nova 

School of Business and Economics; and 

Hannah Hess at the Climate Impact Lab. 

Our thanks are also extended to Olimpia 

Dubini, Olivia Lempa and Richard Steinert 

at the Nova School of Business and Eco -

nomics working on the Capstone Project. 

Several  consultations and seminars 

with thematic and regional experts and nu -

merous informal consultations with many 

individuals without a formal advisory role 

were held in the process of preparing this 

year’s Report. We are grateful for input in 

# Acknowledgements ACKNOWLEDGEMENTS  v i i 

these consultations from Siri Aas Rustad, 

Tayma Abdalhadi, Alexandra Abello Colak, 

Elena Abrusci, Adedji Adeniran, Fabrizio 

Andreuzzi, Anatola Araba, Vesa Arponen, 

Victoria Austin, Gifty Ayoka, Joon Baek, 

Maha Bahou, Onur Bakiner, Pallavi Bansal, 

Roxana Barrantes, Gustavo Béliz, Eliot 

Bendinelli, Cynthia Bennett, Rahul Bhar -

gava, Nidal Bitar, Karl Blanchet, Joshua 

Blumenstock, Joanna Bryson, Romina Ca -

chia, Hailey Campbel, Maria Paz Canales, 

Michele Candotti, Michela Carlana, Dante 

Castillo, Han Sheng Chia, Zhang Chunfei, 

Paul Anthony Clare, Daniella Darlington, 

Erika Deserranno, Arkan El Seblani, 

Ethar Eltinay, Alberto Fernández Gibaja, 

Elenore Fournier-Tombs, Victor Galaz, 

Helani Galpaya, Daniela Garcia Villamil, 

Michael Gibson, Gabriel Gomes Couto, 

Piers Gooding, Andrea Guariso, Anita 

Gurumurthy, Jinhwa Ha, Jungpil Hahn, 

Hamza Hameed, Corinne Heckmann, 

Catherine Holloway, Marie Humeau, Ghis -

lain Irakoze, Natalie Jabangwe, Parminder 

Jeet Singh, Yu Jianjun, Priscilla Ege 

Johnson, Seong Hwan Ju, Ma Jun, Zubair 

Junjunia, Frederike Kaltheuner, Ozge 

Karadag, Mary Kawar, Harttgen Kenneth, 

Jungwook Kim, Niki Kim, Taeho Kim, Yoon 

Ko, Sengmeng Koo, Adithi Kumar, Nagesh 

Kumar, Protiva Kundu, Cheol Lee, Dong 

Hoon Lee, Hyun-kynung Lee, Emmanuel 

Letouze, Nicola Limodio, Björn-Ola Linner, 

Sonia Livingstone, Yu Lu, Jean Luc Mas -

taki, Ke Luoma, Luísa Franco Machado, 

Anu Madgavkar, Izhar Mahjoub, Joan 

Manda, Jenifer Mankoff, Audrin Mathe, 

Francesca Mazzi, Lena Menge, Saurabh 

Mishra, Hélène Molinier, Nusrat Molla, 

Amal Mowafy, Ava Nadir, Yushi Nagano, 

Daniel Naoujoks, Fabio Nascimbeni, Alain 

Ndayishimiye, Megan O’Neill, Toby Ord, 

Gudrun Østby, Nikolas Ott, Nikhil Pahwa, 

Yuhun Park, Balaji Parthasarathy, Pratik 

Patil, Laurel Patterson, Jason Pielemeier, 

Fillippo Pierozzi, Carina Prinkl, Raphaëlle 

Rafin, Rebeca Robboy, Yurii Romashko, 

Ilana Ron Levy, Asma Rouabhia, Satyaki 

Roy, Tiffany Saade, Dong-Pyoung Sheen, 

Bahja Ali Shuriye, Rita Singh, Sebastian 

Smart, Sang Hyo Song, Tong Song, Paul 

Spiegel, Serge Stinckwich, Jaimee Stuart, 

Inkyoung Sun, Yash Tadimalla, Zhou Taid -

ong, Toshie Takahashi, Ma Tianyue, Jutta 

Treviranus, Chi-Chi Undie, Ott Velsberg, 

Stefaan Verhulst, Anna Walch, Skyler 

Wang, Zi Wang, Achim Wennmann, Olivia 

White, Isaac Wiafe, Kellee Wicker, Kebene 

Wodajo, Wang Xiaolin, Wan Xiaoyan, 

Yang Xingli, Nobuo Yoshida, Zhou Yu-Ya, 

Muhammad Zaman, Liang Zheng, Shen 

Zhou and Enrique Zuleta Puceiro. Further 

support was also extended by others too 

numerous to mention here. Consulta -

tions are listed at  https://hdr.undp.org/ 

towards-hdr-2025 .

Contributions, support and assistance 

from many colleagues across the  UN fam -

ily  are gratefully acknowledged: the 

International Telecommunication Union, 

including Jin Cui, Fredrik Ericsson, Thierry 

Geiger, Youlia Lozanova, Jose Luis, Rosie 

McDonald, Martin Shaaper and Caroline 

Troein; the International Labour Orga -

nization, including Janine Berg, David 

Bescond, Ekkehard Ernst, Andrea Mari -

nucci, Uma Rani, Olga Streitska-Ilina and 

Dagmar Walter; the Office of the High 

Commissioner of Human Rights, including 

Scott Campell, Isabel Ebert, Peggy Hicks 

and Nathalie Stadelmann; the United Na -

tions Office for South-South Cooperation, 

including Zanofer Ismalebbe and Nav -

eeda Nazir; the United Nations Entity for 

Gender Equality and the Empowerment 

of Women, including Hélène Molinier 

and Raphaëlle Rafin; the United Nations 

Educational, Scientific and Cultural Orga -

nization, including Priyadarshani Joshi, 

Iaroslava Kharkova, Irakli Khodeli, Karalyn 

Monteil, Claudia Roda and Prateek Sibal; 

the United Nations University, including El -

enore Fournier-Tombs, Tshilidzi Marwala, 

Serge Stinckwich and Shen Xiamomeng; 

the UN Secretary-General’s Special Envoy 

for Digital and Emerging Technologies’ 

Mehdi Snene; and the United Nations 

Industrial Development Organization Re -

gional Office, including Shraddha Srikant. 

Colleagues in at the  United Nations 

Development Programme (UNDP)  pro -

vided advice and input and organized 

consultations. We are grateful to Tehmina 

Akhtar, Abdallah Al Dardari, Fabrizio An -

dreuzzi, Iffat Anjum, Jacob Assa, Estefania 

Asturizaga, Marcos Athias Neto, Walid 

Badawi, Rodrigo Barraza, Iram Batool, 

Fiona Bayat-Renoux, Yakup Beris, Robert 

Bernado, Benjamin Bertelsen, Jeremy 

Boy, Susan Brown, Camilla Bruckner, Mi -

chele Candotti, Yu Ping Chan, Gary Chew, 

Hojin Chung, Enrique Crespo, Pauline 

Deneufbourg, Roqaya Dhaif, Violante di 

Canossa, Mirko Ebelshaeuser, Ahunna 

Eziakonwa, Almudena Fernandez, Kumiko 

Fukagawa, Arvinn Gadgil, Victor Garrido, 

Herte Gebretsadik, Raymond Gilpin, Kiri 

Ginnerup, Carolina Given Sjölander, Carla 

Gomez, Janil Greenaway, George Gray 

Molina, El Hadji Fall, Joe Hooper, Caro -

line Hopper-Box, Alexander Hradecky, 

Vito Intini, Ghida Ismail, Giulia Jacovella, 

Zulkarin Jahangir, Anne Juepner, Hurshid 

Kalandarov, Tomohiro Kawase, Antonin 

Kenens, Sujin Kim, Sharon Kinsley, Yuna 

Koh, Adithya Kumar, Alexis Laffittan, Julie 

Lee, Regina Lio, Jennifer Louie, Linda 

Maguire, Joan Manda, Michelle Muschett, 

Debashis Nag, Steliana Nedera, Liwen 

Ng, Keyzom Ngodup, Shoko Noda, Camila 

Olate, Robert Opp, Anna Ortubia, Hye-Jin 

Park, Gayan Peiris, Isabella Rosso, Jelena 

Ruzicic, Pratyasha Saha, Sebnem Sahin, 

Turhan Saleh, Philip Schellekens, Anca 

Stoica, Helin Su Aslan, Hyunjee Sung, 

Ludmila Tiganu, Riccardo Trobbiani, Ramiz 

Uddin, Georges Van Montfort, Agi Veres, 

Kanni Wignaraja, Lesley Wright, Qu Xinyi, 

Haoliang Xu, Shinobu Yamaguchi, Weijing 

Ye, Vitali Zakhozhyi and Ivana Zivkovic. 

We were fortunate to have the support 

of talented  interns  and  fact checkers : Id -

ris-Alaba Aderinto, Natalia Aguilar, Komla 

Amega, Raiyan Arshad, James Chabin, 

Andrea Davis, Jessica Karki, Danielle Mal -

lon, Chiara Marcoccia, Nazifa Rafa, Yu-Ya 

Rong, Laura Sanzarello and Xiqing Zhang. 

The Human Development Report Office 

(HDRO) also extends its sincere gratitude 

to the governments of Japan and the Re -

public of Korea for their financial contribu -

tions. Their ongoing support is very much 

appreciated and remains essential. 

We are grateful for the highly pro -

fessional work of our editors and 

layout artists at Communications De -

velopment Incorporated—led by Bruce 

Ross-Larson, with Joe Caponio, Meta de 

Coquereaumont, Mike Crumplar, Chris -

topher Trott and Elaine Wilson. It was a 

communal experience learning together, 

especially with Bruce, about how regular v i i i HUMAN DEVELOPMENT REPORT 2025 

spoken language (natural language  in 

the computer science jargon) is becom -

ing a new interface to communicate with 

computational machines, as well as how 

artificial intelligence can support the 

preparation of these reports. That experi -

ence extended to the collaboration with 

Therese Severinsen Marques and the 

team at Studio Mnemonic in preparing the 

cover and images in the Report. Therese 

was given a difficult challenge—to come 

up with options that centred artificial intel -

ligence on the human and avoid clich és 

of  robots or digital circuits—and she suc -

ceeded in creating beautiful images with 

the help of artificial intelligence that met 

this brief. 

Over several years now the Human 

Development Report owes a deep debt 

of gratitude to UNDP Administrator 

Achim Steiner. This gratitude has ac -

cumulated over the years because he 

has not only scrupulously preserved and 

protected HDRO’s editorial independence 

but has always been generous with his 

time and wisdom. He has provided us with 

guidance and, on more than one occa -

sion, challenged us to be more and more 

ambitious, so that we could make a differ -

ence in advancing human development. 

We only hope to have been worthy of the 

trust and confidence that he has depos -

ited in our team. 

Pedro Conceição 

Director 

Human Development Report Office Contents 

CONTENTS 

Foreward  v

Acknowledgements  vi

Overview  2

Terms and concepts  12 

CHAPTER 1 

Empowering people to make artificial intelligence work for 

human development  16 

Examining the demand side of AI  17 

Looking back — a digital transformation going from creator 

to destroyer?  24 

Attention is all you need — for tasks that AI may do well in the future  26 

Envisioning the human development opportunity of AI  34 

CHAPTER 2 

From tools to agents: Rewiring artificial intelligence to 

promote human development  46 

From doing what we do to choosing what we choose  47 

Entering a brave new (digital) world  49 

Embedding AI into our social fabric  54 

AI-infused social networks: What happens when AI makes choices 

for, between and among us?  59 

Preserving and expanding human agency across scales  62 

CHAPTER 3 

Artificial intelligence across life stages: Insights from a people-

centred perspective  66 

Early childhood — too little, too much, too risky  69 

School age  —  access, regulation and ownership  72 

Adolescence — smartphones, AI-powered apps and mental 

wellbeing, much ado about nothing?  75 

Semi- autonomous adulthood  —  with overlapping identities  79 

Older age  —  trained, empowered and healthier?  83 

Multistakeholder action for people-centred AI  86 

CHAPTER 4 

Framing narratives to reimagine artificial intelligence to 

advance human development  102 

Beyond techno- determinism: Technological change shapes and is 

shaped by society  103 

AI’s potential for people with disabilities: Framing a more nuanced 

narrative to expand human development  105 

Narratives about care technologies overlook the profoundly 

human and relational nature of care  109 

Narratives about gender digital divides paint an incomplete picture  113 

Technical solutions are not enough: Biases in AI are deeply 

intertwined with social norms and societal inequalities  119 

Framing a narrative on AI to advance human development  121 

CHAPTER 5 

Power, influence and choice in the Algorithmic Age  136 

Algorithms shape social choices and power  139 

Who has the power? Divides and dependencies are evolving 

amid furious AI races  146 

CHAPTER 6 

Reimagining choices: Towards artificial intelligence– 

augmented human development  162 

Building a complementarity economy to expand development frontiers  164 

Driving innovation with intent: Aligning socially and privately 

valuable AI research  172 

Investing in capabilities that count: Can AI enhance education and 

health outcomes?  179 

The road ahead: AI’s promise to advance human development  185 

Notes  201 

References  221 

BOXES 

1.1  The many ways generative artificial intelligence differs from 

classical programming  27 

1.2  The perils and affordances of artificial intelligence  30 

S1.2.1  Human intelligence is not defined by that of a single human but of 

many: Could artificial intelligence get there?  42 

2.1  Artificial intelligence revolutionizing biomedicine  51 

3.1  Artificial intelligence can violate children’s rights — or protect them  71 

3.2  Levelling the playing field for disadvantaged students  73 

3.3  Artificial intelligence on social media undermines agency and 

drives emotions — but only for some young people so far  77 

3.4  Harmful friends without benefits  81 

S3.1.1  Connected or disconnected? Exploring possible mechanisms 

between smartphones and mental wellbeing  90 

4.1  Going beyond access: Women’s disproportionate care 

responsibilities drive their lower digital skills  116 

4.2  As technologies advance, so do new ways of perpetrating 

violence against women  118 5.1  Recommendations in digital platforms and human development: 

Artificial intelligence as part of the problem, part of the solution?  142 

5.2  The UN Global Digital Compact for addressing power imbalances 

and fostering inclusive artificial intelligence  153 

5.3  More subtle manifestations of power emerge in artificial 

intelligence models’ behaviour  154 

5.4  The potential for artificial intelligence audit protocols  155 

6.1  Assessing artificial intelligence’s productivity effects  168 

6.2  Smart systems, shared goals: The complementarity of artificial 

intelligence and digital public infrastructure  170 

6.3  Who’s the boss? The rise of algorithmic management in the 

automobile manufacturing sector  173 

6.4  Bridging bytes and governments: Artificial intelligence 

ecosystems through partnerships  178 

FIGURES 

O.1  About two- thirds of survey respondents in low, medium and high 

Human Development Index (HDI) countries expect to use artificial 

intelligence in education, health and work within one year  3

O.2  Global progress in human development is losing steam, with the 

weakest and most vulnerable being left farther behind  4

O.3  The post-2020 slowdown in human development progress 

affects every region of the world  5

O.4  People at each life stage use artificial intelligence (AI) for different 

purposes  7

O.5  Young internet users are struggling — everywhere  8

O.6  Younger people expect to lose control over their lives due to 

artificial intelligence (AI) less than older people do  9

O.7  Across occupations and Human Development Index levels, 

respondents expect that artificial intelligence will both automate 

and augment their work — with higher expectations of augmentation  10 

O.8  ChatGPT answers are culturally closer to those of humans in very 

high Human Development Index (HDI) countries  10 

1.1  About two- thirds of survey respondents in low, medium and high 

Human Development Index countries expect to use artificial 

intelligence (AI) in education, health and work within one year  18 

1.2  Low Human Development Index countries are being left further 

behind  19 

1.3  Most survey respondents are confident that artificial intelligence 

(AI) will make them more productive at work, and the more AI is 

used, the higher the share of respondents reporting feeling confident 20 

1.4  The majority of monthly ChatGPT web traffic came from middle-

income countries by mid-2023  24 

1.5  With classical programming, machines can execute routine tasks  25 

1.6  The cost of computing declined by 12 orders of magnitude in the 

classical programming age  26 

1.7  Beyond the routine–nonroutine tasks dichotomy: What artificial 

intelligence (AI) can automate depends on the stakes and on the 

range of potential implications  29 

1.8  The lower the level of skill and experience, the more workers 

benefit from artificial intelligence (AI)  32 

S1.2.1  A human development interpretation of the evolution of 

computational machines—more tasks helpful to humans with less effort  41 

2.1  Sense of agency now and in an artificial intelligence (AI)–defined 

future  47 

2.2  Simpler forms of artificial intelligence (AI) may more easily 

promote human agency, whereas AI with high agenticity can have 

a broader range of more dramatic impacts  48 

2.3  Interactions between and among humans and artificial intelligence  55 

2.4  Cultural differences from the United States explain the use of 

ChatGPT  62 

3.1  People at each life stage use artificial intelligence (AI) with varying 

frequency and for different purposes  68 

3.2  Invest, inform and include for people-centred artificial intelligence (AI)  69 

3.3  Excessive screen time in early childhood is related to 

changes in the brain structure — and to reduced language 

capacity and understanding  70 

3.4  Mathematics achievement in the United States did not decline 

after calculators became available in the classroom  74 

3.5  Pandemic-related stress is a complementary explanation for 

adolescents’ mental illbeing  76 

3.6  Multidimensionally poor people with little education lack access 

to the internet  79 

3.7  Disentangling autonomy, authenticity and agency in the digital space  80 

3.8  Automated systems may cut costs but distress customers  82 

3.9  Very little internet use among older people  84 

3.10  Stark variance in internet use among older people across 

countries with different Human Development Index levels  85 

3.11  Across world regions older people who use the internet are less 

distressed than younger ones  86 

3.12  Social, algorithmic and data- driven biases in older people’s 

healthcare  87 

3.13  Harnessing artificial intelligence (AI) for human development —

invest, inform, include  87 

S3.1.1  Declining wellbeing, rising despair among young people in the 

United States  89 

S3.1.2  Increase in despair in the United States since 2010, especially 

among women  90 

S3.1.3  Young internet users are struggling everywhere  91 

S3.1.4  The age at first smartphone ownership appears to matter for 

mental wellbeing  92 

S3.2.1  Respondents who prefer to live in a world without the platform  94 

S3.2.2  Consumer surplus across welfare measures  95 

4.1  People with disabilities also face inequalities in internet use  106 

4.2  Most patents for conventional assistive technology are filed in just 

a handful of countries…  107 

4.3  …as are most patents for emerging assistive technology  108 

4.4  Older people expect to have less choice and control over 

their lives as artificial intelligence technologies become more 

integrated into daily life  111 

4.5  On average, only 35 percent of graduates in science, technology, 

engineering and mathematics are women  114 

4.6  The share of graduates in science, technology, engineering and 

mathematics who are women has changed little since 2010–2011  115 

5.1  The market structure of the artificial intelligence (AI) supply chain 

is concentrated  138 

5.2  Artificial intelligence transforming the way people retrieve 

information  140 

5.3  Recommender algorithms show how artificial intelligence is 

shaping social, economic and political processes  141 

5.4  Artificial intelligence (AI) outperforms human mediators in finding 

common ground  145 

5.5  The majority of today’s large-scale artificial intelligence models 

are developed by organizations based in the United States, 

followed by China and the United Kingdom  150 

5.6  Most global investment in artificial intelligence (AI) flowed to the 

United States in 2024  150 CONTENTS  x i 

5.7  Artificial intelligence (AI) talent has been flowing towards high-

income countries  151 

5.8  India has the highest self-reported artificial intelligence (AI) skills 

penetration  151 

5.9  The artificial intelligence (AI) race today can be conceptualized as 

unfolding along a spectrum spanning innovation to arms  152 

6.1  Across Human Development Index (HDI) groups the largest share 

of jobs exposed to artificial intelligence (AI) falls into “a big unknown” 165 

6.2  Men and people with greater levels of education report higher 

use of artificial intelligence (AI) for work—across all Human 

Development Index groups  166 

6.3  More respondents in low and medium Human Development 

Index (HDI) countries expect labour market changes—through 

augmentation, automation and productivity boosts—with artificial 

intelligence  166 

6.4  Across occupations and Human Development Index levels, 

respondents expect that artificial intelligence will both automate 

and augment their work — with higher expectations of augmentation  167 

6.5  Across occupations respondents expect transformational change 

to their work  168 

6.6  Disruptive science and technological innovation was on a steady 

decline through 2010  175 

6.7  Artificial intelligence can inspire humans to reach new heights in 

creativity  175 

6.8  Education—convergence in basic capabilities, divergence in 

enhanced capabilities  179 

6.9  Critical thinking mitigates students’ propensity towards extreme 

trust or distrust of online content  180 

6.10  The benefits of digital resources for learning critical thinking 

diminish with excessive use  181 

6.11  Mind the context—initial conditions can compound development 

challenges  185 

S6.1.1  Computing performance has evolved at roughly the same pace 

as warming temperatures in recent decades  189 

SPOTLIGHTS 

1.1  Humans have agency, algorithms do not  36 

1.2  A human development perspective on the pursuit of artificial 

general intelligence  39 

3.1  The decline in young people’s mental wellbeing in some parts of 

the world  88 

3.2  The social media trap  94 

3.3  Worker agency in the digital age  97 

4.1  Narratives in economic decisionmaking  125 

4.2  Caring through digital platforms  127 

5.1  Threats to democratic reason in a high -choice information 

environment  157 

6.1  The promise and peril of leveraging artificial intelligence to 

address dangerous planetary change  188 

6.2  Universal and meaningful connectivity and artificial intelligence  193 

6.3  Global case studies of social dialogue on artificial intelligence and 

algorithmic management  195 

TABLES 

1.1  Machine learning has extended the use of machines to many 

tasks that classical programming struggled with  23 

2.1  Comparing characteristics of digital tools and artificial intelligence 

(AI) agents  50 

S3.2.1  The CARE framework  99 

5.1  When do we confront high stakes? When “power over” is 

concentrated and impacts deeply or across many dimensions of 

people’s lives  139 

5.2  Gaps across country income groups based on popular artificial 

intelligence (AI) metrics  149 

5.3  Where there is a stronger case for international policy 

coordination on artificial intelligence  155 

STATISTICAL ANNEX 

Readers guide  273 

HUMAN DEVELOPMENT COMPOSITE INDICES 

1 Human Development Index and its components  278 

2 Human Development Index trends, 1990–2023  283 

3 Inequality-adjusted Human Development Index  287 

4 Gender Development Index  292 

5 Gender Inequality Index  297 

6 Multidimensional Poverty Index: developing countries  302 

7 Planetary pressures-adjusted Human Development Index  305 

Developing regions  310 

Statistical references  311 A matter of choice 

# People and possibilities in the age of AI 

# OV E R V I E W 

> 12HUMAN DEVELOPMENT REPORT 2025
> OVERVIEW

# A matter of choice: People and 

# possibilities in the age of AI OVERVIEW  — A  MATTER  OF  CHOICE : P EOPLE  AND  POSSIBILITIES  IN  THE  AGE  OF  AI  3

Artificial intelligence (AI) has broken into a dizzy -

ing gallop. Each day seems to herald some new AI-

powered algorithmic wonder. As a general-purpose 

technology, AI has been dubbed “the new electric -

ity.” Regardless of whether the utopian, techno-

solutionist 1 visions of AI’s most ardent advocates 

come to fruition or fizzle as snake oil (or worse), the 

world is pulsing with a powerful new technology, a 

new kind of dynamism or vitality, that differs from 

technologies of the past. 

Yet, the AI zeitgeist is awfully blinkered. Headlines 

fixate on arms races, policymaking on risks. These are 

real. But they are not —and should not be —the whole 

story. We need to go beyond races and risks to possibili -

ties for people, possibilities shaped by people’s choices. 

The choices that people have and can realize, with -

in ever expanding freedoms, are essential to human 

development, whose goal is for people to live lives 

they value and have reason to value. A world with 

AI is flush with choices the exercise of which is both 

a matter of human development and a means to ad -

vance it. The future is always up for grabs, even more 

so now. Trying to predict what will happen is self-

defeating, privileging technology in a make-believe 

vacuum over the frictional realities and messier 

promises of people’s agency and their choices. From 

a human development perspective the relevant ques -

tion instead is what choices can be made so AI works 

for people. 

This year’s Human Development Report examines 

what distinguishes this new era of AI from previous 

digital transformations and what those differences 

could mean for human development (chapter 1), in -

cluding how AI can enhance or subvert human agen -

cy (chapter 2). 2 People are already interacting with 

AI in different ways at different stages of life, in ef -

fect scoping out possibilities good and bad and un -

derscoring how context and choices can make all the 

difference (chapter 3). Human agency is the price 

when people buy into AI hype, which can exacerbate 

Figure O.1  About two- thirds of survey respondents in low, medium and high Human Development Index (HDI) countries 

expect to use artificial intelligence in education, health and work within one year 

14.4 23.6 19.0 66.1 68.9 45.9 0 20 40 60 80 Actual use of AI in the past month Expected use of AI in one year Expected increase in use 

HDI group 

Low and medium High Very high Share of population (%)     

> Note: Based on pooled data for 21 countries. For actual use in the past month, the following responses to the question, “In the past 30 days, have you ever
> interacted with artificial intelligence, such as chatbots, in any of the following ways?” were used to calculate the average use of AI for education, health and
> work: “education” is based on the response “educational platforms of learning apps,” “health” is based on the response “health care services or applications”
> and “work” is based on the response “work-related tools or software.” For expected use in one year, the following responses to the question, “Over the next 12
> months, how likely are you to use an artificial intelligence tool for the following?” were used to calculate the average use of AI for education, health and work:
> “education” is based on the response “for education and training,” “health” is based on the response “for medical advice” and “work” is based on the response
> “for work tasks.” Expected increase in use is the difference between expected use in one year and actual use in the past month.
> Source: Human Development Report Office based on data from the United Nations Development Programme Survey on AI and Human Development. 4HUMAN DEVELOPMENT REPORT 2025

exclusion (chapter 4) and harm sustainability. 3 And, 

of course, who produces AI and for what matter a lot 

for everyone (chapter 5). 

Letting people take the reins makes good sense, 

because they expect AI to be a growing part of their 

lives. A global survey 4 for this Report found that, at 

all levels of the Human Development Index (HDI), 

AI use is already substantial (for about 20 percent of 

respondents) and is expected to shoot up fast. About 

two-thirds of respondents in low, medium and high 

HDI countries expect to use AI in education, health 

and work —the three HDI dimensions  —within one 

year (figure O.1). 

## Human development gaps are 

## widening, and global progress 

## may be losing steam 

Focusing on people can help many countries feel -

ing caught in a human development pinch between 

Figure O.2  Global progress in human development is losing steam, with the weakest and most vulnerable being left 

farther behind 

0.805 0.785 eulav)IDH(xednItnempoleveDnamuHlabolG0.825 2015 2010 2005 2000 .0 765 0.745 0.725 0.705 0.685 .0 665 0.645 2023–2024 Pre-2020 trend 2021–2024 trend trend (projected) (extrapolated trend) 0202 4202 2030 Threshold for very high HDI group: 0.800 

0.000 0.001 0.002 0.003 0.004 Change in HDI value, 1990–2024 (excluding 2020–2022) 0.008 0.007 0.006 0.005 2020 2015 2010 2005 2000 1995 1990 Mean change (excluding 2020–2022) ~4.5× lower than the 1990–2024 mean change (excluding 2020–2022) 2024 (projected) 

Difference in HDI value between very high and low HDI countries 0.380 0.400 0.420 0.440 0.460 2024 2020 2015 2010 2005 2000 1995 1992 2016 2020 2024 (projected) 0.410 0.400 0.390              

> Source: Human Development Report Office calculations based on data from Barro and Lee (2018), IMF (2024), UNDESA (2024), UNESCO Institute for Statistics
> (2024), United Nations Statistics Division (2025) and World Bank (2024). OVERVIEW — A MATTER OF CHOICE : P EOPLE AND POSSIBILITIES IN THE AGE OF AI 5

sky-high expectations for AI and sobering develop -

ment realities, including ongoing violent conflicts and 

stresses on human security. Wounds from the 2020– 

2021 declines in global HDI value have not healed, 

and the rebound since may be losing steam. Just a few 

years ago we were on course to live in a very high HDI 

world by 2030. 5 That world was delayed by a few years 

based on the 2021–2024 trend. Now it is projected to 

be delayed by decades (top left panel of figure O.2). 6

While the global HDI value is projected to reach a 

record high in 2024, the increase would be the low -

est since records began 35 years ago (top right panel 

of figure O.2). Gaps between very high and low HDI 

countries, which for decades had been shrinking, have 

been widening over the past four years (bottom panel 

of figure O.2). The dramatic slowdown in HDI pro -

gress cuts across all developing regions (figure O.3). 

Development pathways that have created jobs at 

scale and reduced poverty, thanks to expanded man -

ufacturing and exports to international markets, are 

narrowing. 7 A triple squeeze results from inadequate 

external financing, fewer opportunities in manufac -

turing due in part to automation and trade tensions 

limiting export options. 8

Now enter AI, a development wildcard. 9 If AI is 

seen simply as a supercharged extension of earlier 

digital technologies deployed to automate work, la -

bour is condemned to cede the remaining ground to 

machines, further eroding development options. Is 

this what is in the cards? 

It is a matter of choices. Development depends less 

on what AI can do  —not on how human it appears  —

and more on mobilizing people’s imaginations to re -

shape economies and societies to make the most of it. 

Figure O.3  The post-2020 slowdown in human development progress affects every region of the world 

0.600 1999 

Arab States 

Regional Human Development Index value 0.750 0.700 0.650 2007 2015 2023 0.600 0.650 0.700 0.750 0.800 0.850 1999 2007 2015 2023 0.600 0.650 0.700 0.750 0.800 0.850 0.900 1999 2007 2015 2023 0.690 0.710 0.730 0.750 0.770 0.790 1999 2007 2015 2023 0.500 0.550 0.600 0.650 0.700 1999 2007 2015 2023 0.400 0.450 0.500 0.550 0.600 1999 2007 2015 2023 

East Asia and the Pacific South Asia Sub-Saharan Africa Europe and Central Asia Latin America and the Caribbean  

> Pre-2020 trend
> Source: Human Development Report Office calculations based on data from Barro and Lee (2018), IMF (2024), UNDESA (2024), UNESCO Institute for Statistics
> (2024), United Nations Statistics Division (2025) and World Bank (2024). 6HUMAN DEVELOPMENT REPORT 2025

## Making AI work for people 

## is a matter of choices 

AI does some things uniquely well, such as seeing pat -

terns in huge datasets that are difficult or impossible 

for humans to discern. 10  It does other things poorly, 

sometimes making things up. 11  It cannot frame prob -

lems, as humans can do. Whatever new algorithmic 

feats are in store, there will always be spaces, howev -

er in flux, where humans shine  —where humans do 

things that machines cannot do or are bad at, where 

societies value people rather than machines doing 

things and where people and machines go farther and 

faster together than separately. 

Evolving overlaps and complementarities between 

humans and AI-powered machines land societies at 

inflection points, after which trajectories will depend 

largely on two factors: what access societies have to 

AI and how they view and use it. These are choices, 

by the few or the many. Is the focus on overlaps, pit -

ting what Daron Acemoğlu calls so-so AI against peo -

ple, which could cut jobs without productivity gains? 12 

Or is it instead on complementarities and collabora -

tion to envision new development pathways? 13  Entire -

ly new roles, markets and industries could be in the 

offing. If anything, then, AI can be seen as adding 

hazy pages to the development playbook instead of 

stripping them away. Possible paths become wider, if 

less clear, given that much is yet unknown about what 

AI can do and how it will affect human decisions. 

# “ AI can be seen as adding hazy pages to the 

development playbook instead of stripping them 

away. Possible paths become wider, if less clear, 

given that much is yet unknown about what AI 

can do and how it will affect human decisions 

People seem to expect as much: a cloudy glass half 

full. Nearly 4 in 10 respondents 14  in the survey for 

this Report expect AI to automate and augment jobs. 

Overall expectations for augmentation (61 percent) 

just edge those for automation (51 percent). 15  And the 

more that people use AI, the more confident they feel 

in its ability to increase productivity. Expectations 

in developing countries are particularly high. 16  With 

so much promise and expectation, the bar for AI is 

higher than simply being useful or “doing good”; it is 

avoiding development disappointment. 

It is time to break the spell of technological inevita -

bility: no path forward is about technology in isolation 

but rather how it is deployed —by whom, with whom, 

for whom —and with what kind of accountability. Dif -

ferent choices can help turn things around, and the lens 

of this year’s Human Development Report, focused on 

people and possibilities, identifies three areas of action 

for AI-augmented human development (chapter 6): 

1.  Building a complementarity economy,  so people and 

AI find more opportunities to collaborate rather 

than compete. 

Rather than try to predict the future, policy makers 

should shape it, breaking away from trying to guess 

how humans will be replaced by AI, to see the poten -

tial of what humans can do with AI. That includes 

driving productivity gains through intelligence aug -

mentation, leveraging the complementarities be -

tween AI and people. Ensuring that AI is proworker, 

limiting curbs on agency and empowering workers to 

use AI to augment what they can do. Deploying AI in 

sectors where positive spillovers to other sectors and 

across the economy can be leveraged, helping with 

economic diversification and job-creating structural 

transformation. Implementing fiscal measures and 

strengthening social dialogue that incentivize AI to 

safeguard decent work and supporting incumbent 

workers displaced by AI. 

2.  Driving innovation with intent,  so opportunity for 

people is not an afterthought but a built-in integral 

part of AI design and deployment. 

AI should be harnessed to accelerate science 

through curiosity-driven basic research, as well 

as technological innovation —not by automating 

creative processes but by augmenting them. 17 

AI innovation can be steered through incentives 

that embed human agency in AI from design to 

deployment — by aligning socially desirable and 

privately profitable innovation and supplementing 

existing AI benchmarks with new ones that capture 

AI’s potential to advance human development. 

3.  Investing in capabilities that count,  so people have 

the capabilities to make the most of AI in their lives 

and to thrive in a world with AI. 

AI’s flexibility and adaptability should be lev -

eraged to personalize education and healthcare OVERVIEW  — A  MATTER  OF  CHOICE : P EOPLE  AND  POSSIBILITIES  IN  THE  AGE  OF  AI  7

in different contexts, while attending to risks and 

concerns related to bias, privacy, affordability and 

equity. 18  By tailoring learning or expanding health 

care, AI can also generate demand for complemen -

tary human labour. 19 

Together, the three areas invite policymakers at dif -

ferent levels to shake off unhelpful narratives that swing 

between utopia and dystopia, to depart from disem -

powering trends that sideline most people or put bull -

seyes on their backs and instead to embolden people to 

reimagine their choices and expand their freedoms. 

## Who, where, when and how? AI’s 

## possibilities depend on context 

The possibilities of AI depend on context: who, 

where, when, how? AI is more than just an opportuni -

ty for people’s choices; it requires them. People of dif -

ferent ages use AI for different purposes (figure O.4). 

AI has shown promise for helping students by provid -

ing study assistance when educators or parents have 

time or resource constraints 20  or by improving per -

sonalized, adaptive learning. 21  AI could bridge gaps in 

the light of constrained education resources and help 

level the field for disadvantaged students. 22  This is in 

addition to  —not in lieu of —teachers, who uniquely 

provide, among other things, necessary social inter -

actions critical to students’ overall development. 

Until recently, one of the most well-established em -

pirical regularities across countries was that subjec -

tive measures of wellbeing (such as life satisfaction) 

followed a U-shaped pattern with age: younger and 

older people reported higher wellbeing than those in 

middle age (late 40s to early 50s). 23  About 10–15 years 

ago that began to change in some countries. Despair 

among young people shot up, and life satisfaction 

tanked. 24  Young women fare worse than young men. 25 

What explains the dramatic declines among 

young people? The picture is complex and evolving. 

That the trend is most evident in some very high 

HDI countries and parallels the broader diffusion of 

smartphones has implicated digital technologies. In 

a global survey of people with access to the internet, 

the typical U-shape curve is completely absent. In its 

place is essentially a diagonal line, with young peo -

ple’s mental wellbeing at the bottom (figure O.5). 26 

The opportunities for and risks to young peo -

ple from digital technologies, including AI, are 

Figure O.4  People at each life stage use artificial 

intelligence (AI) for different purposes 

Purpose of AI use by occupation group Student Nonworkforce Workforce Retired 0 10 20 30 50 60 40 Share of survey respondents (%) 

Education Work Health Entertainment    

> Note: Based on pooled data for 21 countries. For purpose of AI use, the follow -
> ing responses to the question, “In the past 30 days, have you ever interacted
> with artificial intelligence, such as chatbots, in any of the following ways?” were
> used to calculate the average use of AI for work, education, entertainment and
> health: “work” is based on the response “work-related tools or software,” “ed -
> ucation” is based on the response “educational platforms of learning apps,”
> “entertainment” is based on the response “entertainment (e.g. streaming serv -
> ices/gaming)” and “health” is based on the response “health care services or
> applications.” For occupation group the following responses to the question
> “What best describes you? Are you…?” were used: “working” includes self-
> identified full- and part-time employees and self-employed respondents, and
> “not working” includes homemakers and unemployed respondents.
> Source: Human Development Report Office based on data from the United
> Nations Development Programme Survey on AI and Human Development. 8HUMAN DEVELOPMENT REPORT 2025

particularly relevant for many lower HDI countries, 

where age structures skew young and digital pene -

tration has farther to go. That is itself an opportuni -

ty to chart a path informed by lessons elsewhere. The 

age structures of many higher HDI countries lean the 

other way, towards the old. Although patterns dif -

fer across countries, the world as a whole is greying 

quickly, with 1.4 billion people age 60 or older ex -

pected by 2030. 27  At the same time younger people 

expect to lose control over their lives due to AI less 

than older people do (figure O.6). 

AI has enabled pathbreaking innovations in as -

sistive and accessible technologies that can expand 

choices and opportunities for people with disabili -

ties, technologies such as live captioning, image de -

scriptions and translation of sign language into voice 

or text. 28  But achieving the full reach and potential 

of these and other applications depends on more 

than technology alone. Social choices and contexts 

matter, too, 29  including, at the most fundamental 

level, whether these applications are accessible and 

affordable. Likewise, gender inequalities permeate 

both the production and consumption of AI. The sur -

vey for this Report finds that irrespective of educa -

tion qualifications, men are more likely than women 

to use generative AI for work. 30 

## Building a complementarity economy 

Seemingly every day, a new AI model exceeds human 

scores on a narrowly defined benchmark, often bear -

ing apocalyptic sobriquets such as Humanity’s Last 

Exam. From this supply-side view humans are framed 

as one- dimensional benchmarks in a zero-sum com -

petition for finite spots in our future economy —an 

economy of human replacement. Yet incorporating 

the demand side reveals how policy choices and 

strategies can promote a complementarity economy, 

where AI could augment and extend existing human 

labour, 31  yield a more inclusive labour market 32  and 

lead to new industries, jobs and tasks. 33 

AI can automate tasks that have long remained 

resistant —nonroutine tasks that cannot be accom -

plished by some industrial machine. Yet rarely do 

jobs comprise solely what can be readily delegated to 

machines. Consider radiologists, who were viewed a 

decade ago as at risk of no longer being needed fol -

lowing the success of AI in interpreting radiological 

imagery. Today, demand for radiologists remains as 

high as ever. 34  AI diagnosis is a far cry from deploy -

ing medical knowledge in a clinical setting —which, 

even if it were feasible, patients might reject. 35  A

decade on, the story of AI in radiology is one of 

complementarity —improving diagnostics through AI 

that augments rather than replaces radiologists. 36 

AI’s capacity for augmenting human abilities can 

likewise serve as a vital onramp for economic inclu -

sion. For example, AI tends to improve the perfor -

mance of newly hired call centre workers but has 

lesser effects for seasoned veterans. 37  Similar results 

have been documented in writing tasks, 38  software 

development 39  and management consultancy, 40 

among others. 41  Firms are adopting AI for product in -

novation more than for process automation and see -

ing higher sales, revenue and employment through 

better outputs. 42 

Figure O.5  Young internet users are struggling —

everywhere 

> 020 40 60 80 100 120 140 75 and older 65–74 55–64 45–54 35–44 25–34 18–24

Average Mental Health Quotient score Middle East and North Africa Western Europe North America Age group (years) South Asia Sub-Saharan Africa Latin America Oceania               

> Note: Data are from the Global Mind Project at Sapien Labs. The Mental Health
> Quotient score is a tool that encompasses 47 aspects of mental function as -
> sessed on a life impact scale that span the dimensions of Mood & Outlook, the
> Social Self (or relational aspects), Adaptability & Resilience, Drive & Motiva -
> tion, Cognition and Mind-Body Connection. The higher the score, the better
> perceived mental wellbeing. The survey was conducted during 2020–2024.
> Source: Thiagarajan, Newson and Swaminathan 2025. OVERVIEW — A MATTER OF CHOICE : P EOPLE AND POSSIBILITIES IN THE AGE OF AI 9

As AI systems are integrated into jobs, working 

effectively alongside AI — understanding its limita -

tions, interpreting its outputs and applying human 

judgement —will be critical. New kinds of tasks and 

related expertise will be needed at the nexus of peo -

ple and machines. Some envision three new roles: ex -

plainer, trainer and sustainer. 43 

Yet AI can disrupt and displace work. Robust social 

protection systems alongside adaptive skills building 

aligned with emerging needs can improve employ -

ment prospects, 44  while on-the-job training may sup -

port those whose jobs and tasks are reshaped by AI. 45 

AI systems rely heavily on human labour throughout 

the supply chain, from development and design to data 

labelling and annotation. 46  As an AI-enabled economy 

expands, social dialogue and collective bargaining are 

key for new meaningful decent work opportunities. 

Labour augmentation opportunities, despite their 

big potential, are not inevitable. The digital divide 

persists, such that access and relevant skills are lim -

iting factors for using technology more broadly, and 

these challenges apply equally to AI in the workplace. 

Starting nearly a generation ago, digital technolo -

gies began suffusing high-income countries, whose 

workforces today typically enjoy widespread access 

to digital devices and have extensive experience 

using them. 47  Elsewhere the persistent digital divide 

is likely to be a major barrier to realizing the positive 

effects of AI on jobs and beyond. 48 

Looking ahead, people expect AI to both automate 

and augment their work, but they expect the balance 

to tilt towards augmentation (figure O.7). 

Whether the expectations for augmentation will be 

met depends on policies and incentives to catalyse 

complementary between people and AI. Getting this 

wrong will lead to development disappointment in the 

short term and possibly wider economic divergence in 

the coming decades. One possibility is averting hasty 

worker replacement caused by deployment of so-so 

AI that destroys jobs without generating productivity 

gains and instead promoting fiscal policies that en -

courage augmentation. 49 

## Driving innovation with intent 

AI can accelerate discovery and innovation and trig -

ger new frontiers of creativity, 50  potentially becom -

ing a method of invention. 51  That is, a new tool to 

Figure O.6  Younger people expect to lose control over their lives due to artificial intelligence (AI) less than older people do     

> –20 –15 –10 –5 0510 15–24 25–34 35–44 45–59 60 and older

Change (%) Age group High HDI Low and medium HDI Very high HDI   

> Note: Based on pooled data for 21 countries. Data show, for each age group, the change in perceived agency as measured by the difference in the percentage
> of respondents who feel they have a high level of control over their lives today and the percentage who expect to feel a high level of control five years from now,
> as AI becomes more integrated into everyday life.
> Source: Human Development Report Office based on data from the UNDP Survey on AI and Human Development. 1 0 HUMAN DEVELOPMENT REPORT 2025

empower people to fulfil the deeply human aspira -

tions to understand and create. Rather than auto -

mating tasks in creative processes associated with 

scientific and technological innovation, the key is 

augmenting human intelligence 52  by leveraging the 

complementary capabilities of AI and humans to ac -

celerate innovation 53  and creativity more broadly. 54 

The direction of AI innovation could be steered in 

ways that align with socially desirable and privately 

profitable outcomes. 55  AI benchmarks have become 

fundamental tools for evaluating the performance, 

capabilities and safety of AI models. 56  Supplement -

ing the current lot with new standards that assess AI’s 

contribution to human development could help steer 

AI innovation in that direction. 57 

The complex intersection of different country pri -

orities with global and local constellations of tech 

firms is fuelling a geopolitical innovation race that 

risks leaving many countries and people behind. 58 

The mismatch between suppliers and users matters 

for many reasons. One is cultural. AI models reflect 

the cultures where they were developed. ChatGPT 

responses are closer culturally to those of humans in 

very high HDI countries and most distant from those 

in low HDI countries (figure O.8). 

Combatting cultural and linguistic bias is one 

reason many countries desire to be part of the AI 

supply chain. AI supply depends on three key inputs 

— computing power, data and talent —some of which 

are highly concentrated, posing unique challenges to 

many lower HDI countries. Only a handful of voic -

es wield power over and through AI. Few of us have 

much direct say over it. What choices trickle down 

to us may seem atomizing and binary: buy the latest 

gadget or not, accept the cookies or not. Take-it-or-

leave-it terms of service agreements can boil down 

to granting powerful firms carte blanche access to 

our daily lives or to being excluded from digital plat -

forms, where for better or worse ever more of our 

lives, interactions and relationships take place. 

Figure O.7  Across occupations and Human Development 

Index levels, respondents expect that artificial intelligence 

will both automate and augment their work — with higher 

expectations of augmentation 

Expected automation (%) 0 80 100 Expected augmentation (%) 100 80 20 40 60 60 40 20 0  

> Note: Based on pooled data for 21 countries. Each dot represents the per -
> centages of respondents in an occupation group in a country who expect au -
> tomation and augmentation from AI to affect their occupation. The following
> occupational groups are used: professional/higher administrative, skilled, un -
> skilled/semi- skilled, services, clerical, farm and other. The shaded area repre -
> sents a higher share of respondents expecting augmentation than automation.
> Source: Human Development Report Office based on data from the United
> Nations Development Programme Survey on AI and Human Development.

Figure O.8  ChatGPT answers are culturally closer to those 

of humans in very high Human Development Index (HDI) 

countries 

HDI group Low Medium High Very high Correlation between ChatGPT answers and human responses 0.90 0.85 0.80 0.75 0.70 0.65 0.60               

> Note: Higher values on the vertical axis indicate greater cultural and values
> similarity between ChatGPT and respondents in a given country (indicated
> by a dot).
> Source: Based on data from Atari and others (2025), who compared results
> across 65 countries from the World Values Survey. OVERVIEW — A MATTER OF CHOICE : P EOPLE AND POSSIBILITIES IN THE AGE OF AI 1 1

Narratives that focus on and reinforce only zero-

sum thinking crowd out opportunities where coop -

eration could add a lot of value. At the global level 

opportunities for international cooperation on AI 

exist, not necessarily on everything but certainly in 

some specific and important areas. The rationale is 

especially compelling in computer-provided over -

sight, content provenance and model evaluations. 59 

Indeed, important work across many internation -

al institutions and fora are well under way. The UN 

Global Digital Compact, which encourages cross-

jurisdiction and science-informed dialogue can ena -

ble countries to learn from each other and fine-tune 

regulatory approaches, as well as level the playing 

field so all countries can meaningfully participate in 

and benefit from AI’s potential. 

## Investing in capabilities that count 

To prepare young people to strive with AI, education 

needs to focus on learning outcomes, as well as criti -

cal, creative and relational thinking, moving beyond 

simply increasing years of schooling. When integrat -

ing AI in education, avoid using AI as a crutch, by 

teachers or students, and treat it as a companion to 

unleash new ways of learning. This involves deploy -

ing AI to scale interventions known to enhance edu -

cation outcomes, such as customized learning, rather 

than deploying it for its own sake. 

In healthcare AI should be deployed to comple -

ment expertise, particularly when it is scarce, as 

in lower-income countries and settings, empower -

ing healthcare workers to do more in resource- and 

expertise- constrained contexts. 60  Healthcare sys -

tems and organizations should safely and trans -

parently integrate AI technologies—  strengthening 

both institutional and frontline provider capacity to 

use these systems, while clearly communicating to 

patients how the systems are employed in clinical 

decisionmaking to build trust. Because the unintend -

ed side effects of AI in health services may change 

over time, monitoring AI biases and health inequali -

ties needs to be seen as continuous. 61 

## New horizons for human development 

Scientific and technological progress propel develop -

ment. 62  Waves of technological innovation have made 

us healthier, wealthier and more knowledgeable, while 

shifting patterns of economic opportunity and redraw -

ing inequalities. 63  Not because of inherent features 

of the technologies, but because of active decisions 

by people, firms and governments and the incentives 

shaped by newly created institutions. As AI moves 

from a niche technology to a cornerstone of people’s 

lives across multiple domains, its potential to advance 

human development has to be seized. That depends 

on more than algorithms; it depends on our choices. 

The potential everywhere is big, including in lower 

HDI countries, whose narrowing development path -

ways feel more and more like a development tightrope 

over a widening chasm. AI can act as a bridge — to other 

advanced technologies that can facilitate industrial up -

grading, 64  to greater diversification and integration up 

and down global value chains, 65  to better markets for 

self-employed workers such as freight drivers 66  and to 

new knowledge, skills and ideas that can help every -

one, from farmers 67  to small business owners. 68 

Of course, that depends on access not just to “the 

new electricity” —AI —but also to the old. Yet tapping 

AI’s potential goes well beyond access, however im -

portant it may be. In a world of AI, divides will also 

spin along another axis: which societies can make the 

most of a game-changing technology, focusing on how 

AI complements and augments what people do, and 

which societies cannot, by either mistaking for it su -

percharged extensions of earlier computing technolo -

gies or deploying it in ways that compete with people. 

# “ The future is in our hands. By building 

a complementarity economy, driving 

innovation with intent and investing in 

capabilities that count, societies can use AI to 

expand people’s choices and possibilities. 

The future is in our hands. Technology is about 

people, not just things. Beneath the razzle- dazzle of 

invention lurk important choices, by the few or the 

many, whose consequences will reverberate across 

generations. By building a complementarity econo -

my, driving innovation with intent and investing in 

capabilities that count, societies can use AI to expand 

people’s choices and possibilities. In doing so, new 

development pathways for all countries will dot the 

horizon, helping everyone have a shot at thriving in a 

world with AI. 1 2 HUMAN DEVELOPMENT REPORT 2025 

# Terms and concepts 

Agency (human):  People’s ability to hold values, set 

goals and make commitments that may, or may not, 

advance their wellbeing. 1

Agent (AI):  An artificial intelligence (AI) system that 

can autonomously process information, makes deci -

sions and complete tasks. 2

Agenticity (AI):  The degree to which an AI agent can 

autonomously and proactively execute tasks and act as 

an agent (see above) over extended periods of time. 3

Algorithmic bias:  Systematic errors in AI 

decisionmaking, often discussed in the context of er -

rors that lead to inequitable outcomes, exacerbate dis -

parities or reinforce existing patterns of discrimination. 4

Algorithms:  A specified process or set of steps that 

accomplishes a task, with roots in early mathematics 

but often used to describe sets of formal instructions 

provided to a computer. 5

Alignment:  The degree to which an AI system ex -

hibits consistency with human values, ethics and in -

tended outcomes. 6

Artificial general intelligence:  A catchall term for 

hypothetical AI that exhibits intelligence that gener -

alizes across a wide range of contexts. 7 However, defi -

nitions, feasibility and coherence of the concept itself 

remain a subject of scientific debate. 8

Artificial intelligence:  Software developed to ac -

complish things typically associated with human 

intelligence, from simple rules-based systems to 

modern generative AI and large language models. 9

Benchmarks (AI):  Quantitative assessments of AI 

to enable evaluation of its performance, efficiency, 

capabilities, safety, bias, impacts and other features. 10 

Chatbots:  AI designed to have conversations, ranging 

from early approaches that relied on explicit rules to 

more modern large language models and generative AI. 

Computational machines:  Devices that perform 

mathematical operations ranging from simple tabu -

lation and physical computation to advanced modern 

forms of AI. 

Computer vision:  Techniques, ranging from clas -

sical computing to machine learning, for enabling 

computers to accomplish image-based tasks. 11 

Fine-tuning:  Taking an existing model and provid -

ing additional training to adjust, extend or improve 

its performance. 12 

Frontier models:  Although not well defined, often 

used to refer to cutting-edge, recently developed, ex -

citing or particularly capable AI models. 13 

Generative artificial intelligence (including 

large language models):  AI specifically designed to 

generate information and content such as text, imag -

es, videos and protein structures. 14 

Generative pretrained transformers:  An ap -

proach to developing AI that relies on a pretraining 

step on large, unlabelled datasets (such as text from 

the internet) to train a family of models known as 

transformers. After the initial pretraining, the model 

is subsequently refined on labelled data. 15 

Hallucination:  A term used to describe the possibility 

of AI generating false information, generating factual -

ly correct outputs that are irrelevant to what the user is 

asking for or generating statements that contradict each 

other. In general, it refers to making statements without 

regard to the truth. 16  For example, AI may create a false 

fact and trace it to a reference that does not exist. 

(Human) intelligence augmentation:  An approach 

to developing or using AI that improves humans’ abili -

ty to leverage their own cognitive capabilities. 17 

Labelling:  Detecting and tagging training data with 

additional information to facilitate machine learning. 18 OVERVIEW  — A  MATTER  OF  CHOICE : P EOPLE  AND  POSSIBILITIES  IN  THE  AGE  OF  AI  1 3 

Large language model:  Forms of AI trained on very 

large datasets of human-generated text. 19 

Machine learning:  An approach to developing AI 

in which the system’s behaviour is not a result of ex -

plicit instructions but instead is learned from data or 

experience. 20 

Model collapse:  A phenomenon that occurs when 

AI is recursively trained on AI-generated data, even -

tually resulting in degradation or outright failure of 

the model’s performance. 21 

Multimodal (AI):  Forms of AI that can process or 

generate information across multiple modalities, 

such as audio, text and images. 22 

Neural networks:  An approach to machine learning 

in which computers interact with networks of individ -

ual units (neurons) that learn by altering their con -

nections to one another over time. 23 

Open source, open data:  Software (or perhaps data) 

for which the code is made publicly available under 

a copyright licence that enables others to use, study 

and change the code for any purpose. 

Parameters:  The variables that a machine learning 

AI model adjusts throughout the course of training. 

Prompt:  Instructions provided to generative AI to 

shape or determine its output. 

Prompt engineering:  The process of developing 

more complex prompts that better enable AI to pro -

duce a desired response. 

Reasoning or chain-of-thought (AI):  A technique 

for developing large reasoning models that, rather 

than simply generating output, are trained to gener -

ate a series of intermediate steps between the task 

specification and final output. This approach im -

proves performance on some benchmark, but debate 

lingers as to whether these systems are engaging in 

true reasoning or merely mimicking or hallucinating 

the process of reasoning. 24 

Reinforcement learning:  A method of training in 

which various decisions the system (here, AI) makes 

are associated with different levels of reward. Learn -

ing is achieved by adjustments that enable larger re -

ward in subsequent steps. 

Retrieval augmented generation:  A technique 

for improving AI responses that enables it to re -

trieve information from elsewhere (such as the in -

ternet or a dataset) in the process of generating its 

response. 

Small models:  AI models that are smaller in terms 

of parameter counts or complexity, often cheaper to 

train, modify and use. 

Training data:  Images, text, video or any other type 

of data used for machine learning and AI. 

Turing machine:  An abstract model of a computa -

tional system proposed by Alan Turing that applies 

rules to stored information such that it can imple -

ment any possible algorithm. 

NOTES                         

> 1. UNDP 2024.
> 2. Mukherjee and Chang 2025.
> 3. Mukherjee and Chang 2025.
> 4. Kordzadeh and Ghasemaghaei 2022.
> 5. Chabert and Barbin 1999.
> 6. Ji and others 2023.
> 7. Goertzel 2014.
> 8. Mitchell 2024.
> 9. McCarthy and others 2006.
> 10 Raji and others 2021.
> 11. Ballard and Brown 1982.
> 12. Ding and others 2023.
> 13. Cottier and others 2024.
> 14. Banh and Strobel 2023.
> 15. Achiam and others 2023.
> 16. Hicks, Humphries and Slater 2024.
> 17. Jarrahi, Lutz and Newlands 2022.
> 18. Kotsiantis, Zaharakis and Pintelas 2006.
> 19. Naveed and others 2023.
> 20. Jordan and Mitchell 2015.
> 21. Shumailov and others 2024.
> 22. Zhang and others 2020.
> 23. McCulloch and Pitts 1943.
> 24. Mitchell 2025. 1 5

# Empowering people 

# to make artificial 

# intelligence work for 

# human development 

# C H A P T E R 

# 11 6 HUMAN DEVELOPMENT REPORT 2025 

# As artificial intelligence (AI) races ahead, this chapter 

# turns the focus to people—not just to those who 

# build AI but to how people everywhere can use it to 

# improve their lives. This is the most relevant question 

# from a human development perspective. Used in the 

# right way, AI offers an opportunity to expand human 

# capabilities. The chapter challenges unhelpful myths 

# about AI replicating humans and calls for reimagining 

# the relationship between people and this powerful 

# new technology. Despite all the things that AI can 

# do, it cannot replace human judgement. Thinking 

# beyond replacing humans reveals opportunities for 

# AI to augment human development and enhance the 

# unique contributions of human intelligence, including 

# expanding human scientific and expressive creativity. 

> CHAPTER 1

# Empowering people to make artificial 

# intelligence work for human development CHAPTER  1 — E MPOWERING  PEOPLE  TO  MAKE  ARTIFICIAL  INTELLIGENCE  WORK  FOR  HUMAN  DEVELOPMENT  1 7 

# “Both the technologies developed and the 

manner in which they are used —for exploitation 

or emancipation, for broadening prosperity 

or concentrating wealth —are determined 

foremost not by the technologies themselves 

but by the incentives and institutions in 

which they are created and deployed.” 

— National Academies of Sciences 

and Medicine 2024, p. 84 

As artificial intelligence (AI) reaches ever more 

stunning abilities, how will it shape our work, our re -

lationships, our lives? With AI appearing to “reason,” 1

will it come after our jobs? Could artificial general 

intelligence, the pursuit of which is one of humani -

ty’s most ambitious technological endeavours, make 

people worse off? 2 Should we fear that something like 

artificial superintelligence might wipe out human 

civilization? 3

Rather than try to answer these questions by pre -

dicting what  will  happen, this Report asks what choic -

es  can  make AI work for people. It proposes a human 

development framework to see how AI differs from 

previous digital technologies and to navigate the fu -

ture of this rapidly changing technology, wherever it 

may go. 4 Instead of looking to the future through a 

foggy fear of the unknown, this chapter invites us to 

shape that future by knowing more about what AI can 

and cannot do now and what might be possible as AI 

evolves. 5

## Examining the demand side of AI 

Much policy and media attention focuses on the 

supply side of AI —which firms and countries will 

get ahead in the AI race 6 and how to ensure that the 

production and deployment of AI are free from ac -

cidents, misuse or systemic negative social impacts 7

and grounded in human rights. 8 Supplementing these 

crucial considerations, the main focus here is on the 

demand side of AI, its use across society, examining 

how it can either enhance or subvert human agency 

(chapter 2), 9 how it is already changing people at dif -

ferent life stages, often in harmful ways (chapter 3), 

and how succumbing to AI hype can exacerbate ex -

clusion (chapter 4) . 

The key reason to consider the user side of AI is that 

historically the impact of technological innovation on 

improving productivity and increasing living stand -

ards has depended on complementary changes in the 

organization of economic activity, not simply replac -

ing older technologies with newer ones. The chang -

es in the organization of economic production during 

the transition from steam power to electricity are a 

well-studied example that has been invoked to ex -

plain the lag between the adoption of digital technol -

ogies and productivity gains. 10  Moreover, only a small 

fraction of the social value of innovation has been 

appropriated by the innovators. 11  By one estimate 

digital entrepreneurs of the late 1990s appropriated 

only about 7 percent of the additional value created 

by new digital firms in the United States alone. 12  Ac -

counting for the value of digital goods in 13 countries 

added $2.5 trillion in consumer welfare (or 6 percent 

of their combined GDP), with larger welfare gains 

accruing to lower income countries and individuals 

within countries. 13 

Another reason is that people expect AI to be a 

growing part of their lives. A global survey for this Re -

port found that AI use is already substantial for about 

20 percent of respondents at all Human Develop -

ment Index (HDI) levels. 14  But even more stunning, 

at least two-thirds of respondents in low, medium 

and high HDI countries expect to use AI in education, 

health and work —the three HDI dimensions —within 

one year (figure 1.1). 15 

The chapter argues that AI represents a technolog -

ical inflection point beyond simply having more pow -

erful digital tools. AI invites new ways of exploring 

how economies at all income levels can harness its 

potential to advance human development. 16  But the 

task is particularly urgent for low-income and many 

middle-income countries, given that the pathways 

that created jobs at scale and reduced poverty over 

the past two to three decades, based on expanding 

manufacturing industries and exporting to interna -

tional markets, are narrowing. 17  Low HDI countries 

continue to diverge from very high HDI countries 

(figure 1.2), with many skipping the kinds of structur -

al transformation that run through manufacturing, by 

having employment move straight from agriculture 

to services rather than shifting to manufacturing in 

between. 18  The narrowing of pathways for low- and 

middle-income countries is related in part to the 

automation bias of the ongoing digital transforma -

tions, but AI offers new options if opportunities to 1 8 HUMAN DEVELOPMENT REPORT 2025 

complement rather than replace work are explored. 19 

AI on its own is not a panacea. 20  Its impact will de -

pend ultimately on whether people, firms and gov -

ernments adjust and reorganize to make the most of 

it. That includes accelerating the transition to low-

carbon economies and supporting the multiple trans -

formations historically associated with development 

(from rural to urban, from home production to mar -

ket, from informal to formal, from self- employment 

to wage work). 21 

The chapter’s three key messages: 

• The value of AI for human development lies not in 

whether computational machines (machines, for 

short) are intelligent but in the ways they can augment 

human intelligence. 22 

AI does some things very well, things that no 

machine or human has ever done before. But one 

must avoid anthropomorphic generalizations that 

could mislead people into thinking that AI can do 

everything more capably. 23  Some things are best 

left either to humans or to other pre-AI digital 

tools. 24 

Comparisons of human and artificial intelligence 

are fraught with fear, uncertainty and false hope 

(spotlight 1.1). 25  Whether machines are close to 

being humanlike (writing a poem) distracts from 

identifying how to use AI to augment what humans 

wish to do (helping with poetic expression). 26  AI is 

better than any human at chess, but people still play 

against each other —and are getting better at it with 

AI. 27  AI algorithms have increased music streaming, 

which has stimulated demand for live performanc -

es. 28  This suggests that the authenticity of human 

connections and the need to identify with other hu -

mans will remain important, even if machines can 

Figure 1.1  About two-thirds of survey respondents in low, medium and high Human Development Index countries expect 

to use artificial intelligence (AI) in education, health and work within one year 

14.4 23.6 19.0 66.1 68.9 45.9 0 20 40 60 80 Actual use of AI in the past month Expected use of AI in one year Expected increase in use 

HDI group 

Low and medium High Very high Share of population (%)              

> Note: Based on pooled data for 21 countries. For actual use in the past month, the following responses to the question, “In the past 30 days, have you ever
> interacted with artificial intelligence, such as chatbots, in any of the following ways?” were used to calculate the average use of AI for education, health and
> work: “education” is based on the response “educational platforms of learning apps,” “health” is based on the response “health care services or applications”
> and “work” is based on the response “work-related tools or software.” For expected use in one year, the following responses to the question, “Over the next 12
> months, how likely are you to use an artificial intelligence tool for the following?” were used to calculate the average use of AI for education, health and work:
> “education” is based on the response “for education and training,” “health” is based on the response “for medical advice” and “work” is based on the response
> “for work tasks.” Expected increase in use is the difference between expected use in one year and actual use in the past month.
> Source: Human Development Report Office based on data from the United Nations Development Programme Survey on AI and Human Development. CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 1 9

surpass humans in some tasks. 29  In fact, it has been 

argued that the value of the real, the authentic, may 

increase as AI is more widely deployed. 30 

• Harnessing the human-augmenting power of AI to em -

power people requires questioning misleading narratives 

that AI can replicate and replace human intelligence. 

AI goes beyond what earlier digital tools can do. 

Pre-AI digital tools faithfully executed sequenc -

es of steps to automate routines but struggled 

with things such as recognizing a cat in an image, 

which AI can now do. As a result, the scope for 

potential automation expanded. 31  But focusing 

on automation sells short the potential of humans 

and machines alike. 32  It can lead to deploying what 

Daron Acemoğlu called so-so AI 33  for things people 

already do very well, with few if any productivity 

benefits 34  but with job losses 35  and other downsides 

of AI, including exploitative labour practices in 

data labelling 36  and environmentally stressing en -

ergy and material requirements. 37 

More generally, focusing exclusively on automa -

tion ignores humans’ complex multifaceted roles. 

Passing a medical test, which AI can now do, is far 

different from applying medical knowledge in a 

clinical setting, where contextual awareness and 

subjective human interactions are critical. 38 

Even if some automation takes hold, AI is also 

creating new tasks for people, given, for example, 

its potential to personalize services, as in med -

icine. 39  AI’s wide availability makes advanced 

expertise more accessible, 40  and open-source AI 

allows customizing AI to varied local contexts. 41 

Seeing AI as a new way for humans to take advan -

tage of the knowledge others have accumulated 

over generations 42  opens windows for people 

anywhere to solve problems and pursue new ven -

tures. 43  At the same time it creates new challenges, 

ranging from intellectual property management 44 

and the compensation of creative workers that gen -

erate content used to train AI models 45  to concerns 

over privacy and human rights, which may be made 

vulnerable in new ways. 46 

• Despite the many ways AI is useful, its inability to bear 

responsibility leaves it unable to fulfil many roles in 

society, creating further demand for AI-augmented 

human roles. 

AI can be very good at seeing data patterns that 

are hard for humans to discern, 47  but it is not an 

oracle that can predict the future. 48  In a courtroom 

even seemingly accurate AI tools for deciding who 

should receive bail cannot know whether a given 

individual truly poses a flight risk. 49  Assuming that 

AI knows that can lead to excessive deference to 

AI, risking ceding human agency (chapter 2). 50 

Another key reason AI cannot replace humans 

in many contexts is that it bears no responsibility 

for its actions. 51  Knowing that some decisions 

affecting our lives are made by a real person who 

is accountable is an irreplaceable feature of so -

cial arrangements  —and one reason people react 

against automated enforcement of government 

regulations. 52 

Thinking beyond replacing humans reveals op -

portunities for AI to augment the unique contribu -

tions of human intelligence, including expanding 

human scientific and expressive creativity. Human 

evaluation of AI outputs is often required, particu -

larly in high-stakes situations, further expanding 

the scope of AI augmentation. For example, in legal 

and medical applications, given that AI can hallu -

cinate (including by producing plausible sounding 

Figure 1.2  Low Human Development Index countries are 

being left further behind 

Difference in HDI value between very high and low HDI countries 0.380 0.400 0.420 0.440 0.460 2024 2020 2015 2010 2005 2000 1995 1992 2016 2020 2024 (projected) 0.410 0.400 0.390  

> Source: Human Development Report Office calculations based on data from
> Barro and Lee (2018), IMF (2024), UNDESA (2024), UNESCO Institute for Sta -
> tistics (2024), United Nations Statistics Division (2025) and World Bank (2024). 2 0 HUMAN DEVELOPMENT REPORT 2025

but factually wrong statements or generating 

statements that contradict each other). 53  Moreover, 

having humans interact with AI using regular spo -

ken language may introduce ambiguity in what 

people are trying to achieve. 54  What is high stakes 

(elaborated in chapter 5) is a matter of individual 

and social choice, so there is much scope to expand 

AI augmentation as a result of the need for human 

evaluation of AI outputs in many situations. 

In sum, both humans and AI are sold short by no -

tions of replacing humans simply because AI can 

automate some tasks. Instead, AI’s potential is best 

leveraged to augment human strengths, such as intel -

ligence and agency. Automation and augmentation 

are twin features of the relationship between humans 

and AI that will determine AI’s impact on human de -

velopment. In the world of work, the net effect on em -

ployment will depend on how the two forces balance 

out in the short term, on what new tasks are created 

on longer time scales and on how demand for more 

efficiently produced goods and services evolves —all 

uncertain but the result of deliberate policy, firm and 

individual choices. 55  The role of choices represents 

opportunities to make AI work for people. This is par -

ticularly important because most survey respondents 

are confident that AI will make them more productive 

at work, and this confidence increases as AI use rises 

(figure 1.3). 

An alien intelligence is becoming part of our lives 

The novel capabilities of AI —particularly generative 

AI, which showcases remarkable advances in content 

generation and creative tasks  —require recognizing 

that something new has entered people’s lives. That 

Figure 1.3  Most survey respondents are confident that artificial intelligence (AI) will make them more productive at work, 

and the more AI is used, the higher the share of respondents reporting feeling confident 

Index of use of AI for Human Development (last month) Share of population that is confident that AI will increase their work productivity (%) 40 50 60 70 80 0 80 20 40 60 100 Age group 15–24 25–34 35–44 45–59 60 and older              

> Note: Based on pooled data for 21 countries. For actual use in the past month, the following responses to the question, “In the past 30 days, have you ever in -
> teracted with artificial intelligence, such as chatbots, in any of the following ways?” were used to calculate the average use of AI for education, health and work:
> “education” is based on the response “educational platforms of learning apps,” “health” is based on the response “health care services or applications” and
> “work” is based on the response “work-related tools or software.” Confidence that AI will increase productivity is based on respondents who answered “likely”
> or “very likely” to the question, “You believe ‘AI will increase your productivity at work.’”
> Source: Human Development Report Office based on data from the United Nations Development Programme Survey on AI and Human Development. CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 2 1

something is raising fresh questions because so much 

about it is unknown —and perhaps unknowable. Neu -

roscientist Terrence Sejnowski described the appear -

ance of large language models such as ChatGPT, a 

kind of generative AI, 56  in this way: 

A threshold was reached, as if a space alien sudden -

ly appeared that could communicate with us in an 

eerily human way. Only one thing is clear —LLMs 

[large language models] are not human.... Some 

aspects of their behaviour appear to be intelligent, 

but if not human intelligence, what is the nature of 

their intelligence? 57 

In the near future, and perhaps forever, we will 

have to grapple with Sejnowski’s question. Scientists, 

philosophers and people in general continue to de -

bate whether AI is approaching, or has even already 

achieved, some degree of human understanding. 58  In 

Sejnowski’s framing it seems only right to mix con -

cern and optimism for sharing the planet with arte -

facts that exhibit intelligence once squarely in our 

purview. How will AI change us as individuals? As so -

cieties and cultures? As a planet? 

# “ There are many opportunities for AI to advance 

innovation and creativity and many options to 

explore new complementarities between AI and 

humans without having machines replace humans 

There are many opportunities for AI to advance 

innovation and creativity and many options to ex -

plore new complementarities between AI and hu -

mans without having machines replace humans. 59  AI 

has the potential to generate demand for new exper -

tise and new tasks. 60  But using AI may imply difficult 

tradeoffs. 61  For example, how much does society gain 

from improved scientific output from individual sci -

entists using AI compared with the potential loss of 

variation across these outputs? 62  What moral and eth -

ical frames do we need to consider if machines can 

act as moral proxies? 63  The interactions between AI 

and humans will play out differently in different cul -

tural contexts, 64  but large language model responses 

converge towards particular cultural frames, often 

those first and fastest across the digital divide. 65 

Amid the myriad ways AI might affect our world 

—mundane, absurd or extreme  —it can be easy to 

feel adrift in the possibilities. Yet Sejnowski firm -

ly anchors us: large language models, and AI more 

broadly, are not human, not even living organisms 

(spotlight 1.1). From a human development perspec -

tive choices should be guided by how to combine 

uniquely human characteristics with AI’s unique 

complementary abilities. This will not be effortless. 

Building and maintaining an augmentative relation -

ship with AI are hard. 66  Augmentative relationships 

require moving beyond easy applications that lev -

erage AI as a crutch, undermining human intellect 

rather than augmenting it. 67  The rest of this chapter 

explores how to do this. 

AI is better at helping people than replacing them 

The vocabulary around AI often misleads —starting 

with the term “intelligence.” While useful for de -

scribing AI abilities, intelligence should not imply 

that machines are acquiring human traits. 68  AI is 

not able to frame problems or act on its own behalf 

(spotlight 1.1). Because AI can do some things so well, 

some people assume that humans will not be needed 

to do those things. It was predicted in 2016 that with -

in a decade advances in AI medical imaging would 

lead to the disappearance of radiologists. 69  Extrap -

olations along the same lines continue to posit that 

artificial general intelligence will leave no work for 

people. 70 

AI deployment need not replace humans 

A decade later the prediction about radiologists has 

been proven wrong. 71  By contrast, demand for radi -

ologists is growing, with a global shortage at the time 

of writing. 72  Using AI in a task (reading and classify -

ing medical images) did not mean that AI replaced 

radiologists for many reasons, three of which merit 

close consideration. 73  First, even though AI could exe -

cute one task of radiologists, it was useless for several 

others, including those that are inherently social and 

require interacting with people 74  and those that are 

constrained by the institutional and organizational 

features of radiologists’ work context. 75  Second, in -

troducing AI to help read medical images created 

tasks that did not exist before, requiring new skills 

such as the ability to understand and interpret the 2 2 HUMAN DEVELOPMENT REPORT 2025 

recommendations from AI. 76  So, using a machine 

to execute a task can replace but also create tasks. 77 

Third, having AI classify medical images liberated 

radiologists’ time to devote more attention to other 

tasks, making them more efficient and effective. 78  AI 

not only failed to replace radiologists; it also failed to 

reduce the value of their work. 79  In the future AI may 

replace tasks and even occupations — digital technolo -

gies have reshaped the world of work by doing exact -

ly that, and automation tends to reduce employment 

and wages for incumbent workers even when the 

economy as a whole is better off, as we will see later. 80 

Who gets to decide how AI is deployed? 

AI technical affordances alone do not determine wheth -

er AI will be deployed; there must be an organizational 

reason as well —and for firms, a business reason. For 

example, a recent study found that while 36 percent 

of US private sector jobs were exposed to automation 

through AI advances in computer vision capabilities, 

the economic case made sense for only 8 percent. 81  But 

new forms of generative AI are much more accessible 

and provide greater opportunities for use in a more de -

centralized way. For example, even though only 18 per -

cent of US school districts provide any guidance on AI, 

60 percent of principals and 40 percent of teachers 

used AI in the 2023/2024 school year. 82  Among work -

ers in 27 countries, almost half used AI every day in 

2024, up from about 30 percent in 2023. 83 AI could thus 

be accessible to the many self-employed workers in 

low- and middle-income countries. 84 

# “ The ladder of generality describes the evolution 

of computational machines as the pursuit of 

machines that can execute an ever-wider range of 

tasks (their generality) with less and less human 

input, direction or intervention (human effort) 

While workers may now have more agency in using 

generative AI, firms seeking to increase revenue and 

decrease costs will play a central role in how AI is de -

ployed. Deploying technological innovation to reduce 

labour costs tends to worsen wages and employment 

for incumbent workers, even when overall employ -

ment and labour productivity rise. 85  AI can be de -

ployed to automate tasks, much like previous digital 

technologies, but the economic impact of AI at the firm 

level appears to come more from greater product inno -

vation than lower production costs. 86  Perhaps that is 

why a recent survey found that about a quarter of US 

firms using AI did so in part to replace worker tasks but 

two-thirds were not pursuing task replacement. 87 

However, firms might still deploy AI to reduce op -

erating costs, including labour costs, particularly if 

prevailing narratives focus on the better-than-human 

abilities of AI and if AI-producing firms emphasize 

the benefits of replacing people. 88  Seizing on AI’s po -

tential to augment rather than replace people will not 

be automatic. 89  It will require deliberate choices to re -

shape incentives and provide information on what AI 

can and cannot do. 

We are on a road to nowhere; come on inside: 

Taking that ride to intelligence augmentation 

The case of AI and radiologists shows that AI has 

reduced the human effort needed to get a machine 

to execute a task. At the same time the underlying 

AI that enhances medical image reading has many 

other applications, such as recording of vehicle li -

cense plates and automation of industrial and agri -

cultural processes. AI expands the range of tasks that 

machines can execute. This borrows from Arvind 

Narayanan and Sayash Kapoor’s ladder of general -

ity, a description of the evolution of computational 

machines as the pursuit of machines that can execute 

an ever-wider range of tasks (their generality) with 

less and less human input, direction or intervention 

(human effort). 90  But where are we now? And what 

comes next in the evolution of computational ma -

chines? We briefly describe four stages, each marked 

by higher generality and lower human effort than the 

preceding one (spotlight 1.2): 

1.  Machines  with hardware designed for one task 

(such as  digital cameras) 

• Each task requires separate hardware. 

• Low generality (machine designed for one task 

only) and high human effort (build and operate 

hardware for each task). 

2.  General-purpose hardware (classical programming) 91 

• One general-purpose computer can handle mul -

tiple tasks thanks to software. CHAPTER  1 — E MPOWERING  PEOPLE  TO  MAKE  ARTIFICIAL  INTELLIGENCE  WORK  FOR  HUMAN  DEVELOPMENT  2 3 

• Generality increases substantially but still re -

quires writing explicit instructions for each task 

or domain of tasks; human effort to have the 

machine execute tasks is reduced to the need to 

operate the software. 

3.  Machine learning (pre–generative AI) 

• Instead of coding tasks in full detail, feed the 

machine data from which it can learn a task, or 

let the machine learn from known rules by inter -

acting with itself. 

• Generality expands further to tasks that are 

hard to specify with instructions; human effort 

declines because of the greatly reduced need to 

operate software. 

4.  Generative AI 

• Leverages large datasets spanning text, video, 

images and sound. 

• Generality is so broad that it spans drafting texts, 

writing computer code, composing music and 

translating languages; human effort is lower be -

cause minimal user direction using regular writ -

ten or spoken language is required for the task to 

be executed. 92 

Humans have long imagined computational ma -

chines. Talos, an automated guardian robot was ide -

alized in Greek mythology more than 2,500 years 

ago. 93  We began to bring such science fictions to 

life at the dawn of the electric age in the 19th cen -

tury, enabling automation of once uniquely human 

information-processing tasks by constructing com -

putational machines, such as the Hollerith tabula -

tion machine that helped process the 1890 US census 

(spotlight 1.2). 94  That machine was characteristic of 

the first stage: computational devices built with spe -

cific hardware from scratch to execute a single task. 

Generality is low, and the corresponding human ef -

fort to automate a given task high, because hardware 

needs to be built for each task. Such hardware is still 

with us — digital cameras, automated teller machines, 

many medical devices and internet switches. 

Today’s programmable computers, in which a com -

puter (one piece of hardware) can be preprogrammed 

to execute many different tasks, correspond to classi -

cal programming, the second stage (spotlight 1.2). 95 

This vastly increased the generality of tasks that a 

machine can execute and reduced the human effort 

required to do so. 

With AI the nature of effort to offload tasks to a ma -

chine has changed yet again, reaching a third stage, 

extending generality further to tasks difficult for clas -

sical programming to execute. Rather than relying on 

written code, systems learn their functionality from a 

corpus of data (think of data as examples that train the 

machine): this is the basic idea of machine learning, 

which has yielded multiple applications (table 1.1). 

The most recent stage is the availability of large 

language models and other forms of generative AI. 96 

AI already pervaded human lives before this fourth 

stage but worked mostly invisibly in the background, 

deployed by governments and firms. 97  Generative AI 

brought it to any person in the world with a comput -

er or smartphone and internet access. 98  Work use of 

generative AI is spreading far faster than the use of 

computers or the internet. 99  Just after its release at 

the end of 2022, more than 90 percent of web traffic 

through ChatGPT came from high-income countries, 

but within a few months the majority was coming 

from middle-income countries (figure 1.4). 

Table 1.1  Machine learning has extended the use of machines to many tasks that classical programming struggled with         

> Objective Why hard for classical programming Training data Practical applications
> Image classifiers Easy for people to recognize a chair,
> very hard to specify with instructions
> what it is
> Images and labels Radiology, recording of vehicle
> license plates, automation of
> industrial and agricultural processes
> Recommendations in
> digital platforms
> Very hard to flexibly accommodate
> diverse and changing interests with fixed
> instructions
> User behaviour on the digital
> platform
> Social media, streaming services,
> internet searches, targeted
> advertising
> Financial fraud detection Hard to specify all possible
> characteristics of perpetrators or fraud
> modalities
> Financial transaction records Credit card platforms, banking
> services
> Source: Human Development Report Office. 24 HUMAN DEVELOPMENT REPORT 2025

The range of tasks that generative AI can execute 

has even greater generality than earlier iterations of 

machine learning. And the human effort to get the 

machine to execute a task is very low, since it can be 

specified using regular spoken or written language. 

The discussion of AI in the rest of the chapter consid -

ers primarily the affordances enabled by this fourth 

stage in the evolution of computational machines. 

Discussions of artificial general intelligence often 

obscure whether, where and when humans could 

benefit from whatever comes next. 100  The ultimate 

destination is not an inevitability simply because 

we have come so far but a human choice, possibly 

bounded by what is socially valuable only if execut -

ed by humans or reserved for human interaction (cer -

tain forms of art, high-stakes decisions). 101 

This framework helps in interpreting future AI 

developments as the continuation of the pursuit of 

greater generality with less human effort From a 

human development perspective what matters are 

the choices shaping the direction of technological 

innovations and their applications in ways that aug -

ment human capabilities and agency: if anything, 

a ride towards open- ended human intelligence 

augmentation. 102  Navigating this ride, today and 

going forward, implies appreciating how AI differs 

from classical programming, starting with how classi -

cal programming drove the digital transformation of 

the past, before envisioning ways AI can be leveraged 

to advance human development in the future. 

## Looking back — a digital transformation 

## going from creator to destroyer? 

Classical programming and AI are sometimes de -

scribed as simply an evolution towards machines be -

coming more humanlike. 

But classical programming and AI are better seen 

as having different strengths and weaknesses. A 

sharp demarcation is hard to define, but it is still use -

ful to examine key differences. Hopes and fears that 

AI will simply supercharge the automation of classi -

cal programming fail to consider some AI character -

istics that may constrain automation. Conversely, 

tasks beyond the reach of classical programming may 

now be ripe for automation with AI. Appreciating 

these differences is key to having agency to shape the 

direction and application of AI in ways that advance 

human development. 

In classical programming explicit and rule-based 

instructions are loaded on hardware to enable ma -

chines to execute tasks predictably. 103  Classical pro -

gramming machines execute tasks described as 

sequences of precise and replicable steps specifiable 

fully in advance. Economists classify these tasks as 

routine. 104  In classical programming much of the past 

half century has focused on discerning the routine 

tasks that could be done by machines —both manual 

and cognitive (figure 1.5). 

The automation of many routine tasks has reshaped 

the world of work, 105  as with robots in manufactur -

ing, 106  often hurting incumbent workers’ employment 

and wages. 107  Some occupations with purely automat -

able tasks have disappeared, but that is rare. 108 

The digital transformation that has unfolded since 

the advent of classical programming around the mid -

dle of the 20th century has been driven in part by 

the steady decline in the cost of computing, which 

fell by 12 orders of magnitude (equivalent to going 

from taking a century to execute a task to taking less 

than a second) between the middle of the 20th cen -

tury and the dawn of deep learning in the late 2000s 

Figure 1.4  The majority of monthly ChatGPT web traffic 

came from middle-income countries by mid-2023               

> 010 20 30 40 50 60 70 80 90 100 Upper-middle-income countries High-income countries Low-income countries Lower-middle-income countries 2023m1 2023m4 2023m7 2023m10 2024m1
> Source: Liu and Wang 2024. CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 2 5

(figure 1.6). The massive reduction in cost has provid -

ed strong incentives to use more and more classical 

programming machines for more and more routine 

tasks. 109 

The digital transformation enabled by classical 

programming changed the world of work, creating 

many new tasks, occupations, firms and even whole 

industries, as with software development, includ -

ing software engineers and developers. India alone 

employs more than 5 million software developers, 

roughly the population of Ireland, with demand ex -

pected to continue to grow. 110  In the United States 

60 percent of employment in 2020 was concentrat -

ed in occupations that did not exist 80 years earlier, 111 

and more than 85 percent of this employment growth 

was driven by technology-related new tasks (the Digi -

tal Revolution was a major part). 112 

At the same time occupations with many routine 

tasks eventually had machines deployed to execute 

more and more of the tasks, depressing demand for 

those occupations. 113  For the first 40 or so years since 

the advent of classical programming, the rate of task 

displacement due to task automation was roughly 

the same as the rate of task creation in high-income 

countries in which the digital transformation pro -

gressed rapidly. But since the late 1980s task dis -

placement has happened at a higher rate than task 

reinstatement in some of these countries. 114 

The impact of automating routine tasks extend -

ed to low- and middle-income countries. 115  In most 

countries occupations intensive in nonroutine tasks 

have gained more employment since 2006 than oc -

cupations intensive in routine tasks, regardless of 

income level or economic structure, pointing to the 

global impact of the digital transformation in auto -

mating routine-intensive work. 116  There are multiple 

channels through which this happened. Automation 

in high-income countries became a substitute for 

globalization, in that firms based in these coun -

tries had lower incentives to seek less expensive la -

bour in lower income countries. 117  Integration into 

global value chains by firms in low- and middle-

income countries increasingly required capital- and 

technology-intensive machinery (such as computer-

aided manufacturing and industrial robots) to remain 

globally competitive, resulting in what economist 

Dani Rodrik called jobless industrialization. 118 

This shift in labour shares from routine to 

nonroutine tasks further disadvantaged many low-

and middle-income countries because it increased 

the value of advanced expertise, which is required 

for many nonroutine cognitive and interperson -

al tasks 119  and is scarcer in lower income countries 

than in higher income ones. 120  Advanced expertise 

is not widely available because it typically requires 

apprenticeships or formal higher-level education. 121 

In high-income countries and some middle-income 

countries a bias against unskilled work contributed to 

wage polarization, 122  with gains for those at the very 

bottom and very top of the earnings distribution but 

a hollowing- out of the middle. 123  This reflects the de -

cline in the economic value of expertise needed for 

occupations such as factory and office workers, situ -

ated in the middle of the wage distribution. 124  Shifting 

from occupations intensive in routine tasks to occu -

pation intensive in nonroutine tasks has a geograph -

ic element because the places with opportunities and 

the places with obsolescence rarely coincide, pre -

cluding reskilling. 125  The way skills are acquired may 

make those acquired in routine tasks largely irrele -

vant to nonroutine tasks. Reskilling from the ground 

up is not easy. 126 

Figure 1.5  With classical programming, machines can 

execute routine tasks   

> PLUMBERS, ELECTRICIANS DOCTORS, LAWYERS SEQUENCES OF PRECISE AND REPLICABLE STEPS THAT CAN BE SPECIFIED FULLY IN ADVANCE COGNITIVE MANUAL NONROUTINE ROUTINE
> Note: The red oval represents tasks that classical programming can automate.
> Source: Human Development Report Office. 2 6 HUMAN DEVELOPMENT REPORT 2025

The digital transformation unleashed by classi -

cal programming did not determine the rates of task 

displacement and reinstatement on its own, even if 

economic incentives for automating tasks are strong: 

institutions and policies had a crucial role. 127  The 

digital transformation and the choices made on its 

direction and deployment redefined the skills and 

expertise that command higher wages, contributing 

to a decline in the economic value of the low-level 

expertise of factory and office workers and an in -

crease in the economic value of advanced expertise 

for nonroutine cognitive and interpersonal tasks and 

for nonroutine manual tasks. So, while the digital 

transformation had many positive impacts, its bias 

towards automation has also created challenges. If AI 

is seen only as more of the same automation that we 

saw with the digital transformation, there would be 

little reason to expect different outcomes going for -

ward. However, understanding how AI differs from 

classical programming suggests that it is important 

to supplement the frame of analysis of routine versus 

nonroutine tasks with new elements associated with 

the distinct characteristics of AI that offer new oppor -

tunities to envision a more augmentative relationship 

with human development. 

## Attention is all you need — for tasks 

## that AI may do well in the future 

One of the key strengths of classical programming 

is the ability to master and execute routine tasks. 

In contrast, AI can master and execute nonroutine 

tasks, including things that people know only tacitly 

without following explicit rules. 128  This opens the pos -

sibility of automating more tasks currently out of the 

reach of classical programming, particularly with the 

advent of generative AI (box 1.1). 129 

If the impact of AI simply followed the path of clas -

sical programming in automating routine tasks, occu -

pations exposed to one would also be exposed to the 

Figure 1.6  The cost of computing declined by 12 orders of magnitude in the classical programming age        

> 1.E–11 1.E–10 1.E–09 1.E–08 1.E–07 1.E–06 1.E–05 1.E–04 1.E–03 1.E–02 1.E–01 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 2010 1850 1870 1890 1910 1930 1950 1970 1990 Price per unit of computing power (2006 $)

PRETURING MACHINES TURING MACHINES             

> Manual Thomas arithmometer Abacus (novice) IBM PC Burroughs 9 EDSAC Dell XPS Dell PW380 IBM 360
> Source: Nordhaus 2007. CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 2 7

other. But the exposure of agricultural occupations to 

robotization (which can automate routine tasks) and 

large language models are inversely correlated. 130  This 

suggests that AI cannot be seen merely as an expansion 

of existing automation but instead must be interpreted 

as a qualitatively distinct landscape for automation. 

Box 1.1  The many ways generative artificial intelligence differs from classical programming 

Generative AI differs from classical programming in many subtle ways. Outputs in classical programming follow from 

instruction to the machine in a sequence of specific and fully certain actions that lead the machine to always produce 

the same output given the same inputs (deterministic outputs). But with generative artificial intelligence (AI), for each 

input the machine probabilistically predicts an output that is based on its training data and what its algorithm was 

optimized to do and that cannot be known in advance with full certainty in most current generative AI applications 

(stochastic outputs). 1

Using the same prompt to a large language model will not always generate the same output. 2 Making the most out 

of tasks performed by a large language model depends on the prompt — with, as a result, prompt engineering emerg -

ing as a new task for humans. 3 Other approaches supplement prompt engineering, such as retrieval-augmented 

generation (in which external knowledge — retrieved through a web search engine, for instance — helps the model 

generate more accurate and reliable responses). 4 Or chain-of-thought prompting, which instructs large language 

models to “think” step-by-step. 5 But even if these approaches improve large language model performance in some 

tasks, they also reduce it in others. 6

Generative AI often hallucinates (yielding plausible sounding but factually wrong outputs, contradictory statements 

or factually correct but irrelevant statements). 7 Generative AI outputs do not emanate from causal sequencing based 

on things such as basic logic 8 and so often fail to give correct answers to slightly changed prompts. 9 Large language 

models also struggle with simple tasks such as counting words or reversing a list. 10  Models often lack awareness 

of their limitations 11  and, more worryingly, express overconfidence in their abilities. 12  It is difficult to understand how 

generative AI generates its outputs, whether truthful or not. 13 

Generative AI lacks knowledge recency beyond its training data, so it may struggle with tasks that require updated 

information. 14  One obvious solution is to update the data and retrain the model, but that gives rise to another chal -

lenge: catastrophic forgetting. Since AI does not retain memory when it is trained on new data or for a new task, that 

creates challenges. 15 

There are many efforts to address these limitations, 16  and there has been tremendous progress since early itera -

tions of generative AI. 17  Some involve enabling large language models to invoke other tools to improve their outputs 

(such as a calculator for arithmetic tasks or a web search engine to access more recent information beyond their train -

ing data). 18  Other approaches imply “editing” the models through different mechanisms. 19  But it might not be possible 

to eliminate limitations entirely, 20  particularly given current algorithmic architectures and approaches, because these 

models have no representation of ground truths against which they can assess the veracity of outputs. 21  At the time of 

writing, the hallucination rate of the most advanced large language model released by OpenAI, GPT-4.5, was 37 per -

cent, down from the 60 percent of its predecessor (GPT-4o) — great progress, but far from eliminating hallucinations. 22                                            

> Notes
> 1. Banh and Strobel (2023) focus on generative AI. Some challenges relate more broadly to machine learning, which often reflects “shortcut
> learning,” where the model identifies spurious correlations in the data that allow it to perform well on some benchmarks without understand -
> ing why it does so (Geirhos and others 2020). 2. Minaee and others 2024b; Santu and Feng 2023. 3. Cao and others 2024; Polverini and
> Gregorcic 2024; White and others 2023. Beurer-Kellner, Fischer and Vechev (2023) suggest that prompting is programming. 4. For a combi -
> nation of retrieval-augmented generation and in-context learning to integrate diverse cultural knowledge in large language model outputs,
> see Seo, Yuan and Bu (2025). 5. Liu and others 2024b. This can elicit reasoning in large language models (Wei and others 2022). 6. Chen
> and others 2024. 7. Huang and others 2025; Li and others 2023. Dahl and others (2024) found hallucinations in more than half the legal ap -
> plications studied. Haltaufderheide and Ranisch (2024) document hallucinations in health applications. Lauscher and Glavaš (2025) show that
> hallucinations are pervasive across different languages, both high and low resource. 8. Barassi 2024; Chakraborty, Ornik and Driggs-Campbell
> 2025; Jesson and others 2024; Jesson and others 2024; Maleki, Padmanabhan and Dutta 2024. 9. Berglund and others 2024. 10. McCoy
> and others 2024. 11. Ren and others 2025. 12. Nezhurina and others 2024. 13. Biecek and Samek 2024; McGrath and others 2022; Mumuni
> and Mumuni 2025; Song, Xu and Zhong 2025; Vafa and others 2024. 14. Zhao and others 2023. 15. Alzubaidi and others 2021, 2024. Efforts
> are ongoing to improve algorithms to address catastrophic forgetting (Alammar and others 2024; Kirkpatrick and others 2017). 16. Chen, Za -
> haria and Zou 2024; Du and others 2023; Hagos, Battle and Rawat 2024; McDonald, Papadopoulos and Benningfield 2024; Wei and others
> 2024; Yang and others 2024; Yenduri and others 2024. 17. Bender and others 2021. 18. On calculators, see Schick and others (2023); on
> web search engines, see Nakano and others (2021). 19. Lazaridou and others 2022; Lu and others 2023; Peng and others 2023a. 20. Pearl
> (2018) argues that there are inherent limitations to purely statistical models. 21. Bigoulaeva, Madabushi and Gurevych 2025; Kalai and Vem -
> pala 2024; Kirk and others 2023b; Treiman, Ho and Kool 2024; Xu, Jain and Kankanhalli 2024; Zhou and others 2024. 22. Criddle 2025. 2 8 HUMAN DEVELOPMENT REPORT 2025

As we increasingly interact with AI through mo -

dalities once reserved for human interaction, we 

need to understand how these new interactions with 

machines differ from those in the classical program -

ming era. For example, AI outputs are not always the 

same, even with the same inputs, and even subtle dif -

ferences in inputs may lead to drastic differences in 

outputs (see box 1.1). Even if AI were predictable, hu -

mans have ambiguous goals, which alongside the im -

precision of regular spoken language compared with 

programming language may result in model misinter -

pretations and communication breakdowns. 131  This 

risks amplifying harms, given the constraints on ac -

curacy and reliability that may emerge from human– 

AI interaction. 132 

Many tasks in which AI is deployed 

require a human presence 

Just because AI —and particularly generative AI such 

as large language models —is very proficient at some 

tasks — or aspects of tasks — does not mean it can serve 

as a surrogate for humans in those tasks. One key 

reason: many tasks that can nominally be automat -

ed require, on closer inspection, a human presence. 

For instance, AI is often touted for its ability to write 

code. Yet code is only the tangible output of the intan -

gible process of software development. Before code 

is written, software development teams must find 

ways to manage stakeholder interests, needs, values 

and more. Code comes together throughout an itera -

tive and dynamic social process of lengthy conversa -

tions, negotiations, (human) user experience testing 

and vision of the values and needs underlying these 

processes. All of this is far beyond the reach of AI be -

cause nominal task performance is a far cry from dy -

namic social processes. This is just one example, but 

many jobs reveal these complex, human, social pro -

cesses that will likely remain beyond the reach of AI. 

In addition, occupations may seem in the abstract to 

be decomposable by tasks, but this is often more dif -

ficult in practice. 133  Moreover, even if it is technical -

ly feasible for AI to execute some tasks, people may 

not value it doing so if they seek authenticity, human 

connection or identification with other humans. 134 

A more nuanced understanding of human–AI in -

teraction goes beyond assuming that AI is just an 

extension or deepening of the automation enabled 

by classical programming. The human effort to use 

or adapt a large language model for a specific task 

must be weighed not in isolation but alongside the 

externalities (including energy consumption and 

environmental impacts), 135  as well as long-tail risks 

of unpredictability and misunderstanding. In many 

cases even nominally easy tasks assignable to a large 

language model may be better served using classical 

programming, mechanical machines or humans. 136 

In many instances relying on AI means not simply 

automating tasks but also having humans inspect 

and evaluate AI outputs. 137  For example, deploying 

AI in public health while ignoring human-mediated 

knowledge may be counterproductive. 138  Even if we 

reach a point where AI-powered clinicians can auto -

mate most of the clinical workflow, patients could be 

less willing to accept medical advice from an  in silico 

doctor — demonstrating AI aversion. 139  Indeed, cur -

rent evidence suggests that information assumed to 

have been fully automated through AI is less valued 

by people and has less impact on their beliefs and ac -

tions. 140  Although increased familiarity with AI and 

newer and better AI abilities may alter these dynam -

ics, we cannot assume that the result will, or should, 

be widespread embrace of AI-generated information 

and decisions across all domains. 

Complementarity of AI and humans 

Human input may be particularly valuable in situa -

tions where even small deviations in AI outputs have 

a wide range of implications (from extraordinarily 

good to catastrophic) 141  and high stakes (which chap -

ter 5 defines in more detail). Of course, humans also 

make mistakes, and it may be better to offload some 

tasks to reliable machines, given that they are often 

capable of tirelessly, dispassionately and consist -

ently engaging in tasks. 142  But unlike AI, humans have 

“skin in the game” and a unique capacity to contex -

tually appreciate and weigh the value of risks and 

benefits —something they can uniquely contribute to 

high-stakes contexts. These features present a key 

opportunity for complementarity between humans 

and AI. In the top right quadrant of figure 1.7 the role 

of people is central to defining priorities, assessing 

choices and taking responsibility. Some high-stakes CHAPTER  1 — E MPOWERING  PEOPLE  TO  MAKE  ARTIFICIAL  INTELLIGENCE  WORK  FOR  HUMAN  DEVELOPMENT  2 9 

situations are self- evident (life or death), but ulti -

mately humans determine what decisions are high 

stakes and will need to decide which contexts require 

machines alone, humans alone or some combination 

of the two. 143  Critically, these valuations depend on, 

but are not defined by, the state of AI and its abilities 

—so no manifestation of AI will obviate the need for 

careful consideration of when human evaluation of 

AI is required. That implies the undesirability of fully 

automating many decisions but opens an unbounded 

set of opportunities for human augmentation. 

For example, tasks in medicine related to clinical 

practice, medical research or medical education are 

high stakes, and even tiny differences in AI outputs 

can lead to vastly different outcomes for people. To 

see how this matters, consider that people who ex -

perience mental health challenges are more likely to 

express what they think on social media than with doc -

tors, opening the possibility of relying on AI to assign 

emotional labels, including suicidal ideation, to the 

vast amount of content that people express on social 

media. 144  But there is little agreement on labelling 

suicide-related content between AI and humans (in 

particular, AI cannot distinguish mentions of suicide 

in a humorous context from those that correspond to 

genuine ideation). 145  Moreover, when, whether and 

how emotional surveillance through AI is warranted 

are important and likely culturally varying questions. 

Relying on AI outputs without human evaluation in 

high-stakes contexts is dangerous, even if it might be 

helpful to have AI cull from social media references to 

suicidal ideation that a human can evaluate. 

While large language models have the potential 

to ease access to medical knowledge and facilitate 

access to healthcare, risks of scientific misconduct, 

distribution of misinformation and simple hallucina -

tions imply the need for humans with at least some 

medical knowledge to evaluate the models’ outputs 

for these high-stakes tasks. 146  A concrete illustration 

of the limitations of large language models in medi -

cine is that they are error-prone in a simple task such 

as mapping medical diagnoses to clinical codes, 

Figure 1.7  Beyond the routine–nonroutine tasks dichotomy: What artificial intelligence (AI) can automate 

depends on the stakes and on the range of potential implications 

AI CAN AUTOMATE AI REQUIRES HUMAN EVALUATION COMPLEMENT WIDE NARROW HIGH LOW STAKES RANGE OF POTENTIAL IMPLICATIONS PLUMBERS, ELECTRICIANS DOCTORS, LAWYERS COGNITIVE MANUAL NONROUTINE ROUTINE SEQUENCES OF PRECISE AND REPLICABLE STEPS THAT CAN BE SPECIFIED FULLY IN ADVANCE   

> Note: The red ovals represent tasks that can be automated with classical programming and AI. The red oval in the graph on the left is larger than the
> one in the graph related to classical programming (figure 1.5) because the potential for automation with AI extends to some nonroutine tasks. The teal
> oval represents tasks where AI presents new opportunities for augmentation.
> Source: Human Development Report Office. 3 0 HUMAN DEVELOPMENT REPORT 2025

limiting AI’s ability to automate this task and requir -

ing human evaluation of the models’ outputs. 147  Sim -

ilarly, large language models are “unaware” of their 

medical knowledge limitations and provide confident 

answers to multiple- choice questions even when no 

correct answers were available: these outputs pose 

risks when relying on large language models without 

human evaluation in clinical settings. 148 

The major implication emerging from this argu -

ment, along with a consideration of the character -

istics of AI (box 1.2), is that the patterns of labour 

displacement and reinstatement, and the expertise in 

demand to take advantage of AI, require supplement -

ing the analysis of the dichotomy between routine 

and nonroutine tasks that was so useful in the classi -

cal programming stage. 149 

Box 1.2  The perils and affordances of artificial intelligence 

Recent artificial intelligence (AI) developments have generated much interest about safety, both in the potential for 

misuse of AI and in the accidental risks that may emerge as unintended consequences. 1 Some evidence suggests that 

even when designed to mitigate these risks (sometimes referred to as aligning AI with human values), large language 

models are capable of mimicking or faking this alignment, 2 covertly pursuing misaligned goals, 3 posing security and 

privacy risks 4 and disclosing sensitive, private or illegal information. 5 At the same time human limitations (such as 

difficulty distinguishing between human- and AI-generated text), along with the expansion of content generated by 

AI, 6 pose new risks of misuse 7 or accidents. 8

AI has been around for a long time, so where does the renewed interest in safety come from? In part, from the new 

affordances of AI and four notable features. 

First, AI can exhibit abilities in areas outside those intended or considered in its design. Unlike classical program -

ming, where machines excelled at the task they were programmed to perform, large language models trained to pre -

dict the next word in a text sequence have proved helpful in tasks ranging from translation to writing computer code. 9

Second, AI can be generative, producing novel output based on descriptive prompts expressed in everyday lan -

guage, unlike classical computer machines that execute instructions only from prespecified scripts. In early 2024 it 

was reported that ChatGPT alone was generating 100 billion words a day: 10  within one year this would be roughly 

equivalent to the amount of high-quality text available on the internet. 11 

Third, AI can personalize and customize outputs adaptively and iteratively — and do it quickly and at scale, unlike 

classical programming’s outputs in the form of one size fits all, with limited opportunities for rapid and dynamic 

customization at scale. 12  Applications for personalization hold particular promise in education and healthcare. 13 

Fourth, AI is very efficient at discerning useful patterns in data that are hard for people to do, while classical program -

ming can provide insights only from data guided by human intuition. 14  One practical application of this feature of AI is 

the rapid progress in predicting protein folding in biology, something that used to take humans much time and effort. 15 

As such, the same features that motivate concern for AI safety underlie much of its potential for augmentation. 

Excising these features is thus a simple but limiting solution, requiring alternatives that guide AI implementation away 

from harm and towards opportunities.                                         

> Notes
> 1. The debate has been particularly heightened for open foundational models. Foundational models are the cornerstone of the current
> AI boom, spanning technological advances, deployment and adoption and sustaining the latest stage of development of computational
> machines identified earlier in the chapter (Bommasani and others 2021). Open foundational models release more information to the public,
> which allows for greater customization (even if the designation of what open means is disputed; Widder, Whittaker and West 2024). For risks
> associated with open foundational models, see Bommasani and others (2024) and Kapoor and others (2024). For risks associated with large
> language models more broadly, see Chua and others (2024) and Wang and others (2023a). For the specific risk of data poisoning in medi -
> cal large language models, see Alber and others (2025). 2. Greenblatt and others 2024. 3. Meinke and others 2024. 4. Das, Amini and Wu
> 2025. 5. Liu and others 2025. 6. Martínez and others 2024. 7. Hackenburg and Margetts 2024a, 2024b; Ibrahim and others 2023; Jakesch,
> Hancock and Naaman 2023. 8. Gans 2024; Kidd and Birhane 2023. 9. Technically referred to sometimes as out-of-distribution generalization
> (Song, Xu and Zhong 2025; Yang and others 2023a). 10. Griffin 2024. 11. Specifically, available on Common Crawl, based on the estimates
> by Villalobos and others (2024). 12. Zhang and others 2024d. 13. On health applications, see Adapa and others (2025) and Delanerolle
> and others (2021). On education, see Bewersdorff and others (2025), Labadze, Grigolia and Machaidze (2023), Mollick and others (2024),
> Moundridou, Matzakos and Doukakis (2024), Rudolph and others (2024) and Tan and others (2024). 14. More rigorously, machine learning
> excels at eliciting mathematical structure in unstructured data (Dell 2024; Kwon and others 2024). 15. Baek and others 2021; Jumper and
> others 2021; Kovalevskiy, Mateos-Garcia and Tunyasuvunakool 2024; Shimanovich and Hartl 2024. This enables advances in many areas of
> medicine and beyond (Mifsud and others 2024; Topol 2024) and progress towards understanding the cognitive and biology of smell (Smith
> 2024). For an application of using large language models to elicit political latent positions, see Wu and others (2023). CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 3 1

Expanding science and creativity 

The characteristics of AI also create new opportu -

nities for humans to interact with AI in ways that 

can accelerate discovery and innovation and trig -

ger new frontiers of creativity. 150  Like any other 

general-purpose technology, such as electricity or 

the internet, AI will spread in multiple applications 

across the economy and society, continuing to im -

prove, 151  ideally increasing productivity, 152  a key 

determinant of standards of living. 153  But AI is, ac -

cording to economic historian Nicholas Craft, an 

invention of a method of invention (chapter 6). 154 

The US National Academy of Sciences went further 

in saying that AI is “arguably the most general of all 

general-purpose technologies.” 155  AI can increase 

the level and potentially the rate of innovation 

productivity. 156 

# “ AI also creates new opportunities for 

humans to interact with AI in ways that 

can accelerate discovery and innovation 

and trigger new frontiers of creativity 

Rather than automating tasks in creative pro -

cesses associated with scientific and technological 

innovation, the key here is human intelligence aug -

mentation. 157  Automating some nonroutine creative 

tasks can erode demand for creative occupations. 158 

Offloading cognitive effort to AI can reduce critical 

thinking. 159  AI can increase scientific output but de -

crease human scientific understanding 160  and vari -

ation in scientific outputs. 161  In contrast, leveraging 

the complementary capabilities of AI and humans to 

accelerate innovation 162  and creativity more broad -

ly 163  could boost the rate of innovation without these 

harmful effects. For example, AI models that trained 

themselves to play chess not only consistently beat 

humans but also make chess moves that have never 

been documented as being used by humans before, 

which in turn inspires top players to improve their 

performance. 164  Finding ways of bridging the human-

AI knowledge gap beyond games could expand cre -

ativity across many fields. 165  Creativity involves 

novelty, surprise and value  — even if AI can help with 

the first two features, value will always be up to us to 

determine. 166 

Augmenting human intelligence 

Beyond the potential to enhance creativity, a key bar -

rier that modern AI can overcome is that nonroutine 

tasks often rely on tacit or difficult to codify 

knowledge  —largely out of reach of machines in clas -

sical programming. 167  What will the increase in the 

range of tasks and types that can be automated imply 

for labour demand? 

The novel landscape can be intuited by careful -

ly considering the types of nonroutine tasks that are 

not possible or desirable to automate. 168  For example, 

some tasks of primary school teachers can be partial -

ly automated with generative AI, such as preparing or 

refining lessons and grading some forms of assign -

ments. 169  Yet others are clearly beyond the practi -

cal and normatively acceptable scope of AI, such as 

implementing discipline or intuiting when students’ 

home lives may require intervention. 

The scope of AI’s potential for augmentation re -

lates to qualitative changes that intelligence augmen -

tation can yield for human tasks. 170  Three salient but 

nonexhaustive ways for such augmentation include 

making advanced expertise more accessible; requir -

ing human evaluation of AI outputs, which creates 

the need for new types of expertise; and personaliz -

ing and customizing rapidly and at scale. 

AI makes advanced expertise more accessible 

Building on the internet as a repository of knowledge, 

AI provides a novel means of accessing and recombin -

ing that information in a way that can reduce barriers 

to accessing advanced expertise. 171  Historically, the 

supply of experts is limited because advanced exper -

tise requires education, training and accumulation of 

experience through learning-by-doing, which takes 

time, effort and resources. Although classical pro -

gramming can often retrieve information produced by 

experts, consuming this information and applying it 

to a given task has typically required expertise. 172 

While there is no reason to expect that demand 

for advanced expertise will decline, constraints on 

the supply side could be eased given that AI can as -

sist in tasks ranging from computer coding to help -

ing a struggling student understand a math problem 

to using regular spoken language as a universal 3 2 HUMAN DEVELOPMENT REPORT 2025 

interface in healthcare. 173  For example, a recent sur -

vey of AI startups found that only 10 percent of their 

products required users to have expert coding or data 

skills. 174  A potential implication is that an expanding 

pool of “functional experts” with advanced exper -

tise could depress the expertise wage premium that 

emerged during classical programming as a result 

of the automation of routine tasks. This potential 

downward wage pressure on high-paying occupations 

could counter the wage polarization that emerged in 

many countries, if advanced expertise jobs no longer 

command outsized premiums —but remain well-paid 

nonetheless. 175  The US labour market, for instance, 

appears not to be polarizing anymore. 176 

Reducing the barriers to accessing advanced ex -

pertise does not mean that advanced experts do not 

benefit from AI. For creative tasks higher skilled em -

ployees do benefit, consistent with the argument that 

AI can augment creativity. 177  Early evidence suggests 

that using AI to accomplish creative tasks reduces the 

value of domain-specific expertise relative to broad -

er cognitive adaptability. 178  But while AI elevates the 

performance of professional artists, it also makes the 

output of laypeople worse by a smaller margin than 

would have been the case without AI. 179 

However, expanded access to expertise is not whol -

ly without risks. It could result in AI “experts” whose 

responses merely mimic expertise, ultimately provid -

ing none at all and merely justifying whatever answer 

the requester sought — effectively decoupling apti -

tude from understanding. 180  Similarly, distillation of 

some concepts can go only so far or require human 

subjective judgement, such that decisions based on 

AI-acquired expertise may be riskier than those from 

veritable human experts. 181 

Yet tangible benefits of access to expertise through 

AI already exist. For example, access to AI improves 

the performance of the least experienced and lower 

skilled call- centre workers. The benefits decline to 

undetectable among the most experienced workers 

(figure 1.8). Similar results have been documented in 

writing tasks, 182  software development 183  and man -

agement consultancy, 184  among others. 185  Younger 

and less experienced workers appear to be adopting 

AI at a faster rate, across a range of occupations, po -

tentially enabling them to achieve higher perfor -

mance more quickly. 186  Those more aware of their 

own limitations in ability benefit the most from 

working with AI. 187  These effects may also appear as 

changes in organizational structures: firms that invest 

Figure 1.8  The lower the level of skill and experience, the more workers benefit from artificial intelligence (AI) 

Change in resolutions per hour 

Skill 

Change in resolutions per hour 

Tenure 

Agent tenure at AI deployment (months) Agent skill at AI deployment Q1 (lowest) Q2 Q3 Q4 Q5 (highest) 0.4 0.2 0.0 0.6 –0.2 0.6 –0.2 0 3–6 7–12 12 or more 1–2 0.4 0.2 0.0 0.8              

> Note: Impact on the performance of consumer representative agents after AI is deployed, measured as the change in the number of case resolutions
> per hour.
> Source: Brynjolfsson, Li and Raymond 2025. CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 3 3

more in AI show a flattening hierarchy, with a rise in 

the share of workers at junior levels and a drop in the 

share of middle and senior management workers. 188 

Whether these sector-specific findings apply to a 

broader set of tasks and more complex occupations 

— and can thus extend to society as a whole  — and 

whether they persist over time remain unknown. 189 

If they do, or choices are made such that they do, AI 

adoption may not polarize the labour market the way 

the diffusion of classical programming did. 

At the same time new gaps may emerge as a result 

of differences in ability or willingness to use AI, so it 

is not a given that AI adoption will always have a lev -

elling effect. This is particularly concerning given 

the evidence of deep gender gaps in the use of gen -

erative AI, which persist even when access to AI is 

enhanced. 190 

AI outputs demanding human evaluation 

require new types of expertise 

Even if advanced expertise is available through AI, 

some translational expertise may be required to in -

terpret and evaluate AI outputs in many situations. 191 

The risk of AI giving bad advice implies, particular -

ly in high-stakes situations, the need for humans to 

evaluate AI outputs 192  and use AI more as a collabo -

rator than as something that automates tasks in these 

situations. 193 

# “ Taking advantage of AI–human 

complementarity will probably require new 

types of tasks and related expertise, in three 

new roles: explainer, trainer and sustainer 

So, taking advantage of AI–human complementa -

rity will probably require new types of tasks and re -

lated expertise, in three new roles: explainer, trainer 

and sustainer. 194  Explainer  calls for translational ex -

pertise, so that outputs from AI can be evaluated and 

assessed before being incorporated into decision -

making. 195  Trainer  encompasses new tasks such as 

prompt engineering and augmented generation re -

trieval to get the most out of AI. It can extend to more 

upstream tasks of customizing AI models for domain-

specific applications  — ChatGPT already has hun -

dreds of thousands of user- created domain-specific 

applications. 196  This is about ensuring that AI works 

better for intended applications.  Sustainer  encom -

passes tasks associated with keeping up with AI pro -

gress and ensuring that both skills and organizational 

processes make the most of opportunities as they 

evolve over time. 

AI can personalize and customize services 

to unique community or individual needs 

As the past decade has demonstrated, for better and 

for worse, AI can personalize and customize servic -

es quickly and at scale. Much of the focus so far has 

been on the ability to personalize messages that can 

microtarget political and marketing persuasion. 197 

But personalization well leveraged can open new op -

portunities to make bespoke education 198  and health -

care. 199  Indeed, the nonhuman yet personalizable 

features of AI may similarly allow people facing em -

barrassing or stigmatizing circumstances to interact 

with it more easily. 200 

If these personalization possibilities are deployed 

in ways that substantially improve quality, they could 

increase productivity in service sectors such as health -

care and education that have lagged the rest of the 

economy in productivity gains. 201  This may be impor -

tant in low- and middle-income countries, where em -

ployment is expanding more rapidly in services than in 

other sectors, particularly in settings where the transi -

tion through manufacturing jobs is muted or difficult, 

as discussed earlier. In addition, personalization can 

also improve the effectiveness of learning and access to 

healthcare in low-income countries and low-resource 

settings. 202  Deploying AI to boost personalization of 

healthcare and education could, over time, increase, 

rather than depress, demand for healthcare workers 

and teachers.  203  However, personalization brings new 

risks, associated with the potential for large-scale pro -

filing, privacy violations and exploitation of vulnerable 

people, requiring carefully calibrated bounds so that 

these risks do not outweigh benefits. 204 

Personalization should not be taken so far as to as -

sume AI is a soothsayer able to predict or determin -

istically alter individual outcomes. AI tools (many of 

which are machine learning based but not genera -

tive AI) that provide predictive information are often 

sold with the promise of being able to automate de -

cisions, replacing human decisionmaking. 205  In par -

ticular, predictive optimization —AI that both predicts 3 4 HUMAN DEVELOPMENT REPORT 2025 

future outcomes and makes decisions about individ -

uals based on those predictions (examples include 

predictions for pretrial risk, child maltreatment, job 

performance and dropping out of school) —risks sys -

tematically failing on its own terms. 206  Recognizing 

AI’s inability to function as an oracle can instead ena -

ble it to be a source of informed decisionmaking rath -

er than a substitute. 207 

## Envisioning the human 

## development opportunity of AI 

Understanding what AI can do, what is new and dif -

ferent from previous digital tools, gives us a way of 

imagining pathways through which it could advance 

human development. An important element will be 

to design and implement adequate policy and regula -

tory environments adapted to each country’s unique 

characteristics. 208  All countries confront this chal -

lenge, but lower HDI countries face the addition -

al challenge that previously available development 

pathways through export-led manufacturing are nar -

rowing. So how could AI help? Without being exhaus -

tive, here are some possibilities. 

# “ AI does more than offer access to information, 

which still requires someone to know what to look 

for through a query on a web search engine. AI can 

work more as a resource that enables access not 

only to better information but also to better ways 

of using that information through interaction 

with AI and collaboration with other people 

First, AI can enable people, organizations and firms 

to access not only information but also know-how. The 

internet has provided access to vast amounts of infor -

mation and new means for global communication, 

which have created many opportunities and social 

dividends in low-income settings. 209  But AI does more 

than offer access to information, which still requires 

someone to know what to look for through a query on a 

web search engine. AI can work more as a resource that 

enables access not only to better information but also 

to better ways of using that information through inter -

action with AI and collaboration with other people. 210 

AI enables access to something that resembles know-

how. It allows for questions that are more open ended 

and unstructured, in multiple languages and through 

multiple media (writing, voice) and for responses that 

organize and interpret information, as well as for sug -

gestions about what else to ask and do. 211  A key con -

straint in enabling firms in low- and middle-income 

countries to engage in industrial upgrading (using ad -

vanced technologies and products already developed 

elsewhere) is lack of know-how, which AI could allevi -

ate. 212  Similarly, AI can facilitate the engagement of re -

search institutions in low-income countries with global 

scientific endeavours. 213 

Second, there are more opportunities to generate 

positive spillovers from AI investments that spread 

across the economy. Even when countries succeed in 

one type of exports to global markets, it is an ongoing 

challenge to generate employment along the value 

chain or in other sectors. For example, manufacturing 

firms in Bangladesh have been successful in exporting 

garments, generating a lot of employment in that ac -

tivity, but have had limited success in translating this 

to activities upstream (design) or downstream (mar -

keting) from garment production or to other sectors. 214 

Even the most successful firms in low- and middle-

income countries face challenges with established 

backward and forward links in the country, given 

that global value chains are, in a sense, premised on 

those links not being available in the country. 215  And, 

as shown above, to remain competitive in global value 

chains, firms in low- and middle-income countries 

often need to invest more in capital- and technology-

intensive production, in contexts where labour supply 

or high costs are not firm constraints, so gains in firm 

productivity stay largely within the firm. 216  Investment 

in AI appears to have greater potential to generate 

spillovers across sectors, which opens new opportuni -

ties for economic diversification (chapter 6). 217 

Third, AI opens new opportunities to expand trade 

in and increase the productivity of services. On trade 

AI lowers the language and culture barriers in inter -

national communication. 218  On productivity and em -

ployment in services, strategies could include: 

• Working with large incumbent firms to increase 

local employment. 

• Enabling smaller firms to access and use AI to en -

hance their productive capabilities. 

• Empowering workers directly, in firms or when 

self- employed, with access to AI in ways that com -

plement low-skilled workers to make them more 

productive. 219 CHAPTER  1 — E MPOWERING  PEOPLE  TO  MAKE  ARTIFICIAL  INTELLIGENCE  WORK  FOR  HUMAN  DEVELOPMENT  3 5 

More-productive and cheaper services can boost 

demand when lower service prices allow more people 

to consume those services, expanding employment 

further. 220 

Many workers in low- and middle-income coun -

tries are self- employed (even outside agriculture) 

and thus do not benefit from being part of an organ -

ization that can specialize tasks, organize the division 

of labour and invest in technology. 221  For example, 

two-thirds of the 1 million freight drivers in Brazil are 

self- employed, but the recent emergence of locally 

developed digital platforms has enabled productivity 

increases in this crucial sector by matching workers 

and freight tasks and improving routing. More than 

half of road freight in Brazil is intermediated through 

these homegrown platforms. 222  One tends to think of 

transport services as being nontradable, but a task-

based (rather than product-based) analysis of trade 

shows that this sector accounts for about 10 percent 

of exports for countries at all income levels. 223 

# “ AI does not require additional physical 

infrastructure; it is immediately accessible 

to those online. The drawback is that people 

who cannot be online face an even bigger 

disadvantage—even more reason to increase 

electricity access and close digital divides 

Fourth, AI’s flexibility can empower people to seek 

and iterate solutions to their problems or pursuits that 

are tailored to diverse and local contexts and even to 

the unique specificity of individual firms. One chal -

lenge of policy advice and development interventions 

is that they can be overly rigid, as with efforts to pro -

mote entrepreneurial activity that do not adapt to dif -

ferent settings or dynamic changes in the economy or 

society. 224  AI allows for continual experimentation and 

accumulation of learning over time, further expand -

ing the opportunities already afforded by digital tools 

for entrepreneurial and small and medium enterprise 

growth. 225  Small and medium enterprises are often 

resource-constrained but can deploy AI to identify cost-

effective approaches to optimize operations. 226  AI can 

also be used to improve the supply of goods and servic -

es from small and medium enterprises by augmenting 

the creativity of business owners and employees. 227 

The potential is also vast in agriculture, a sec -

tor that still employs substantial shares of people in 

low- and middle-income countries, many of whom 

are self-employed and engaged in home rather than 

market production. 228  AI applications range from 

making cutting-edge agricultural knowledge more ac -

cessible by providing location-specific advice (large 

language models are sometimes seen to even outper -

form traditional agricultural extension workers) 229  or 

more-accurate and real-time weather information (par -

ticularly important in rainfed agriculture, as climate 

change makes this practice ever more challenging). 230 

Fifth, unlike electricity or the internet, access to AI 

does not require additional physical infrastructure; it 

is immediately accessible to those online. The draw -

back is that people who cannot be online face an even 

bigger disadvantage 231 — even more reason to increase 

electricity access and close digital divides. 232  In rural 

areas of low-income countries, electricity has com -

pounding benefits for human development when 

paired with complementary things people can do 

with it, so AI can empower these communities in new 

ways. 233  Equally important are the risks of exclusion 

from the producer side of AI, which being far from 

AI-producing hubs and lacking access to computing 

power can exacerbate. 234  Human capabilities to use 

AI are also crucial, starting with basic achievements 

in numeracy and literacy. Only 6 percent of young 

people in Sub- Saharan Africa, 10 percent in South 

Asia and 35 percent in Latin America and the Carib -

bean meet a global standard of basic skills in math 

and science. 235  But AI can also be deployed to bridge 

these gaps, with recent evidence showing how AI can 

be more efficient than the web by helping teachers 

in Sierra Leone in ways that are 90 percent cheaper 

than relying on traditional search engines. 236 

There are many potential pathways in which AI can 

enhance human development, and those outlined 

above may not pan out. Along with the potential, 

there are the risks that AI’s deployment will follow 

the path of classical programming, which was often 

not pro-worker, given its bias towards automation. 237 

Whatever the future holds, development policy needs 

to be informed by the distinctive nature of AI and 

what it can do for human development. Envisioning 

how AI can advance human development can inspire 

the general direction to aim towards, leaving flexibili -

ty to adapt to unique national and local contexts. The 

remainder of the Report further fleshes out the ways 

AI can be made to work for people. 3 6 HUMAN DEVELOPMENT REPORT 2025 

Is humanity’s future still in our own hands? Or will we 

soon be outcompeted and replaced by machines? Re -

cent developments in artificial intelligence (AI) and 

the public discussions that surround it can make one 

doubt. The dominant narrative is that of imminent 

artificial general intelligence. There is a widespread 

expectation (or fear) that machines will soon surpass 

human thinking capacity to achieve some kind of su -

perintelligence. 1 This pursuit of artificial general in -

telligence goes back to the very roots of AI research. 

Famously, Alan Turing postulated a test in 1950 (he 

called it the “imitation game”) 2 that would reveal 

when a machine exhibits intelligence equivalent to 

that of a human being. However, what this means 

precisely remains undefined and, on close inspection, 

undefinable. 

Algorithms cannot frame problems 

Intelligence, counter to widespread intuition, relies 

not only on our ability to solve problems (to com -

pute) but also, crucially, on our ability to frame them 

(to pass judgement on what a relevant problem is in 

the first place). Evidently, the two are not the same. 3

This is why artificial “intelligence” is such a terrible 

misnomer: algorithms cannot frame problems. They 

always operate within a fixed frame. The problems 

they solve must be defined for them (however flexibly 

and indirectly) by the human agent who designed the 

hardware, programmed them, specified their target 

functions and annotated their training data. It is in 

this precise sense that algorithms are not intelligent 

at all! Indeed, as a best-case scenario, the technolo -

gy we call AI is employed as intelligence augmenta -

tion, not to replace us but to increase our own human 

thinking capabilities. 

We may now ask: what is it that enables a human 

being to be intelligent? What allows us to frame our 

own problems? And is this something only humans 

can do? As it turns out, the ability to realize what is 

relevant for oneself is common and exclusive to all 

living beings—from a simple bacterium to a sophis -

ticated human being. 4 Obviously, there are huge dif -

ferences in the degree to which different organisms 

engage in framing problems and in the complexity of 

the problems framed. But the fact remains: even the 

simplest bug can do things that our most sophisticat -

ed AI cannot do (and will never be able to) because 

they lie outside the algorithms’ design specifications. 

Living organisms manufacture themselves 

This special organismic power is called basic agency, 5

and there is nothing mysterious about it. It is entirely 

compatible with what we know about thermodynamics 

and the physics of living systems. Agency arises from 

the peculiar organization of material and energetic 

flows in a living organism that enable it to manufacture 

itself. Biologists call this autopoiesis—self-production. 6

No machine that humans have built so far can do this. 

And it looks unlikely that we will acquire the capability 

to build any truly autopoietic artefacts anytime soon. 

The basic idea behind self-manufacture is a little 

counterintuitive but not extremely difficult to grasp. 

The counterintuitive part is that the organization of 

an organism folds in on itself, like a snake that bites 

its own tail. It is self-referential or reflexive in a way 

that our mechanistic machine designs generally are 

not. In particular, the reflexivity of an organism’s or -

ganization is different from mere feedback regulation, 

which we do use a lot in engineering. Feedback occurs 

between processes that could also exist independent 

of each other. In contrast, the capacity to self-manu -

facture implies a living system consisting of physical 

and chemical processes that not only regulate but 

also construct each other. Each one could not even 

exist without the others being present and involved 

in its own generation while in turn contributing to the 

> SPOTLIGHT 1.1

# Humans have agency, algorithms do not 

Johannes Jaeger,  Department of Philosophy, University of Vienna; Complexity Science Hub, Vienna, Austria CHAPTER  1 — E MPOWERING  PEOPLE  TO  MAKE  ARTIFICIAL  INTELLIGENCE  WORK  FOR  HUMAN  DEVELOPMENT  3 7 

generation of other processes. This peculiar way of 

collective co-construction is called organizational clo -

sure. 7 It is the generative principle behind autopoiesis. 

In such an organizationally closed system, the 

causal control over what gets built next lies (at least 

to some extent) within the circular organization of 

the system itself. In other words, as a living organ -

ism, your future is yours to decide. Within limits, 

of course: you cannot break the laws of physics, nor 

should you behave in a way that jeopardizes the in -

tegrity of your own organization, as this would mean 

death. Nonetheless, you have a basic kind of agency 

because your future actions are (to some degree) au -

tonomous of what is going on in your surroundings. 

You not only manufacture yourself, but you ultimate -

ly also determine the rules of your own behaviour. 

Can a piece of software build the hardware 

it is running on while running on it? 

An apt machine analogy would be a piece of soft -

ware that builds the hardware it is running on while 

running on it. Or in mathematical terms a model of 

a whole living organism would have to be based on a 

system of equations that somehow writes itself. We 

have very few formal tools today that can help us ana -

lyse and understand the behaviour of such self-man -

ufacturing systems. 

You may also have noticed the use of “should” 

above. It means that autopoiesis brings some sort of 

normativity to an organism’s existence: rules accord -

ing to which it ought to behave to stay alive. These 

rules are the precursors to our familiar human values: 

a bacterium “should” go for the sugar and avoid the 

toxin in order to survive and reproduce. Such norms 

are not a matter of thoughtful intention in the case of 

the bacterium but are automatisms shaped through 

evolution by natural selection. Still, the basic drive to 

survive, which we presuppose for such rules to exist, 

is something that comes from within any kind of liv -

ing system. 

And from this drive we also get the idea of rele -

vance: life is precarious, and living beings need to 

constantly invest physical work into staying alive. 

This is another aspect that distinguishes them from 

machines: a chatbot does not get bored between 

queries because it literally pauses its existence as a 

computational process when it does not receive or 

process any input. An organism cannot do that. It 

needs to constantly work to continue existing—every 

single moment of its life. 

To survive means to preserve your self-manufac -

turing organization. Accordingly, there are good and 

bad ways to invest your efforts in survival, some that 

succeed and some that fail to keep you alive. And with 

this basic distinction, there come problems that are 

either relevant or not for you in your particular situ -

ation. But if you do not have to invest work into man -

ufacturing yourself, if you cannot perish (because you 

are not alive and you are not a self), nothing is rele -

vant to you. Algorithms are not alive. Therefore, they 

cannot solve the problem of relevance, they cannot 

frame their own problems, because the concept of 

relevance simply does not exist for them, as they have 

no self to be manufactured and maintained under 

precarious circumstances. 

Algorithms can only help us grow—and cannot 

grow beyond what they already are 

It should be obvious that this has immediate and pro -

found consequences for policies concerning human 

development. The basic autonomous agency out -

lined above opens the path for continued growth and 

open-ended evolution in the living world. In contrast, 

an algorithm, operating within its fixed frame, always 

remains at its characteristic level of complexity. Only 

autopoietic organisms can transcend themselves. 8

Only they can evolve or learn to exist and behave in 

more complex ways than they used to, up until now. 

Algorithms can only help us grow. They cannot grow 

beyond what they already are. Humans are creative 

in a way that algorithmic AI can never be. 

And this is how, from basic agency, we get the 

emergence of cognition and thinking in animals with 

a nervous system and, much later in evolution, con -

sciousness and the whole human experience of inten -

tion and reflexive self-awareness. The details of this 

evolutionary process (and the very nature of many of 

these higher-level phenomena) are still poorly under -

stood. But it seems highly plausible that autopoiesis, 

self-production, is a basic prerequisite for all of them. 9

This should give us a new appreciation of ourselves 

and everything else that is alive on this planet. Our 3 8 HUMAN DEVELOPMENT REPORT 2025 

ability to act autonomously, to be truly creative and 

to grow beyond our present selves can only be imi -

tated by algorithmic AI technology. This leads us to 

fundamentally reassess the limitations of AI, as well 

as other social and cognitive technologies that aim to 

mimic human thinking and behaviour. For instance, 

talk of AI agents is grossly misleading. These tech -

nologies are sophisticated tools that should enhance 

our agency and intelligence, but they are not agents 

in themselves. They cannot replace our creativity, our 

thinking; they can only supplement it. 

Unfortunately, both the prevalent business model 

for AI and the discussion of its capacities (in particu -

lar, claims about artificial general intelligence) are un -

helpful in this regard. They misleadingly project (and 

often actively aim to bring about) a future where it is 

inevitable that humans will be outcompeted and per -

haps even replaced by “superintelligent” technology. 

Yet, as we have seen, no robust argument supports this 

view. Machines do not want to take over the world. Al -

gorithms (by their very nature) do not want anything. 

If machines conquer the world, it is because we, their 

human creators, have instructed them to do so. 

This puts the responsibility straight back into our 

own courtyard. The buck stops with us. AI by itself may 

not take agency from us, but humans can employ it in 

very destructive ways. We can be induced or forced to 

give away our autonomy, for instance, when algorithms 

automate creative tasks (AI “art”) or decisionmaking 

processes (including expressing our democratic rights). 

Applications in surveillance and automated warfare, 

or the disruption of our social fabric, are also highly 

problematic aspects of AI—posing potentially existen -

tial risks—that should not be underestimated. Yet, truly 

recognizing the difference between human agency and 

the lack thereof in algorithmic systems also means that 

a different future is possible and well within our reach, 

exactly because we carry our fate in our own hands as 

autonomous agents. 

Algorithms can augment our 

autonomy, agency and freedom 

Instead of voluntarily giving our agency away to al -

gorithms that have a mere semblance of it, we should 

focus on novel ways of designing and interacting with 

our technological tools that augment our autonomy, 

agency and liberty—our ability to take responsibili -

ty for our own future—instead of diminishing them. 

The choice remains ours, and it will become a central 

concern for human development over the next few 

decades, as more and more powerful imitatory tech -

nologies will emerge and be advertised and sold as 

“agential” or “intelligent.” Under these circumstanc -

es it is more important than ever to distinguish hype 

from reality. 

How our complex natural, social and technological 

context affects us is highly nontrivial. This is not an 

argument claiming that humans act with unrestricted 

liberty in isolation. Nor is it an attempt to condemn 

technology in general. Obviously, there are many 

positive and powerful uses for intelligence augmen -

tation. In fact, intelligence augmentation is some -

thing we urgently need, as our agency gets more and 

more intricately embedded and extended in an in -

creasingly entangled environment. 

But in the end the buck stops with us: the human 

agents. The source of all this complex agential dynam -

ic ultimately lies within us. It will be crucial for human 

development in the coming decades that we recognize 

and remember this simple and empowering fact. 

NOTES                      

> 1. This term was introduced by philosopher Nick Bostrom (2014).
> 2. See https://en.wikipedia.org/wiki/Turing_test . The original publication is
> Turing (1950).
> 3. Weizenbaum (1976) focuses on this important distinction. See also Drey -
> fus (1972) or, more recently, Cantwell Smith (2019).
> 4. For the details of this argument, see Jaeger (2024) and Jaeger and others
> (2024).
> 5. Di Paolo and others (2005) provide a detailed and comprehensive defini -
> tion of basic organismic agency.
> 6. This is most accessibly explained in Maturana and Varela (1987). For a
> more technical (but also more rigorous) treatment, see Hofmeyr (2021)
> and Rosen (1991). On the connection to agency, see Di Paolo and others
> (2005).
> 7. Building on the work of Maturana and Varela (1987), this concept was
> developed by Moreno and Mossio (2015). See also Montévil and Mossio
> (2015).
> 8. How organisms come to know the world and how they learn through this
> experience are described in Jaeger and others (2024) and Roli and oth -
> ers (2022).
> 9. This argument is outlined in detail in Jaeger and others (2024). CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 3 9
> SPOTLIGHT 1.2

# A human development perspective on the 

# pursuit of artificial general intelligence 

The framework proposed here to provide a human 

development perspective on the past and future evo -

lution of computational machines is based on the 

generality of tasks that machines can do, freeing peo -

ple to do other things and the human effort required 

for machines to do those tasks. The chapter describes 

the emergence of pre–Turing machines with the ex -

ample of the Hollerith tabulation machine. For fur -

ther context the US Constitution requires a census 

every 10 years, and with rapid population growth in 

the late 19th century, the manual processing of hand -

written returns, relatively efficient earlier on, took 

eight years for the 1880 census, for a population of 

around 50 million. So, in 1890 it was decided to au -

tomate key aspects of data processing, specifically 

the manual tabulation of paper returns, with the Hol -

lerith tabulation machine. 

Automating tabulation reduced the processing 

time to two years for a larger population of 63 mil -

lion. Yet, the machine did not replace clerks. They 

still had several other tasks that were not automated 

(for instance, summarizing data and writing and for -

matting reports), and the machine created new tasks 

(such as transferring data from handwritten forms to 

punch cards that the tabulation machine could read). 1

As with AI and radiologists, the machine to automate 

a task not only created new tasks for humans but also 

allowed them to spend more time on tasks that the 

machine could not do. 

Another example is the Colossus computer, built 

in the mid-1940s and installed at Bletchley Park, 

England, to help to break encrypted messages dur -

ing World War II. 2 One of the people involved in this 

effort was mathematician Alan Turing, who put for -

ward in 1937 a theoretical model of computation 

that inspired general-purpose hardware able to han -

dle multiple tasks by being fed a set of instructions. 3

The implementation of this idea corresponds to the 

second stage in the evolution of computational ma -

chines, that of Turing machines. 

From building hardware to writing software 

The human effort to create a Turing machine was 

not erased but shifted from the physical to the digi -

tal. Subsequent generations toiled away at developing 

and evolving the many technologies in hardware and 

software required to achieve the performance of to -

day’s computers, smartphones and the internet. 4 The 

torturous pathway from early Turing machines to the 

modern internet was characterized by punctuated 

equilibria that time and time again redefined how such 

tasks were implemented  in silico.  Not until the symbol -

ic encoding of instructions followed by high-level pro -

gramming languages was the full potential of Turing 

machines realized to execute tasks with little human 

effort. Punch cards, a relic of the Hollerith machines, 

laboriously encoded 80 characters at a time, translat -

ing low-level languages to bits and bytes. This process 

gave way to programs that could be typed out explic -

itly and a taxonomy of higher-level languages that ab -

stracted away the fine-grained lower-level languages. 

Each transition was necessary because, just as popu -

lation growth necessitated the Hollerith machine, the 

growth in the complexity of software required finding 

ways to reduce the human effort required to write it. 

From letting machines learn on their own to 

producing machines anyone can talk to 

Classical programming approaches faced constraints 

in executing some tasks that are very easy for humans 

but very hard to fully specify with a set of instruc -

tions, imposing bounds on expanding generality to, 

say, image recognition. It is easy for a person—and 

even for a pigeon 5— to identify a chair in an image, 

but writing a program that does so is very hard. 6 Just 

as there were too many citizens to count in the 19th 

century US, the diversity of objects considered chairs 

would require an impractically long time to devise a 4 0 HUMAN DEVELOPMENT REPORT 2025 

rule set that covers them all. Even if such a program 

could be constructed, one would likely have to start 

anew for a program to identify a bed. 

Recognizing this challenge, an alternative approach 

had been pursued since the 1950s: rather than write 

instructions for the machine to execute, assemble ex -

amples of how the task is done and let the machine 

learn. This marks a third stage: AI implemented 

through machine learning, which grew in popularity 

and applications in the 1990s and ultimately proved 

spectacularly successful at image recognition in the 

late 2000s. 7 It solved a host of long-standing chal -

lenges in image recognition in the decades since, such 

as detecting suspicious portions of radiological imag -

es. Machine learning has extended far beyond images 

to many other tasks based on predictive models. Ad -

vances have been enabled by progress in learning al -

gorithms (particularly using deep neural networks), 8

continuing gains in computer power and massive data 

availability (made possible with the growth of the in -

ternet, the growing digitalization of services and relat -

ed records, and the emergence of digital platforms). 

Perhaps one of the most pervasive and impactful 

applications of AI in today’s world is associated with 

recommending what digital content to access and 

interact with—or which products to buy—on digital 

platforms. AI-based recommendations using rec -

ommender systems (chapter 5) are already part of 

many people’s lives. Their diffusion parallels a range 

of changes for individuals (for example, increases in 

illbeing for young people) and for society. 9 They are 

also associated with the potential to trap users into 

using social media, for fear of missing out, even if 

many people would rather live in a world without 

such platforms. 10  Deep learning applications started 

to emerge as the dominant form of machine learning 

around 2010, 11  so it is remarkable that this specific 

application has already transformed people’s individ -

ual, social and political lives. 

The fourth stage in the evolution of computation 

machines corresponds to generative AI, enabled once 

again by breakthroughs in algorithms, including the 

transformer architecture, 12  along with training not on 

data associated with a specific task but on the vast re -

pository of data in the form of text, images, sound and 

video on the whole of the internet and beyond. Train -

ing has been powered by faster and more powerful 

computing enabled by graphical processing units. 13 

Artificial general intelligence, when we 

reach it, is up to us, not the technology 

We can understand generality on a scale from very 

low levels (single-purpose hardware of the pre– 

Turing machines that can perform only one task) to 

somewhat higher. Correspondingly, the human effort 

to purpose a machine for executing a task can also be 

put on a scale. Without formally quantifying these 

two dimensions, it is possible to illustrate the evo -

lution of computational machines as a progression 

towards greater generality with lower human effort 

per machine-delegated task, such that forthcoming 

stages may be interpreted as the continuation of that 

evolution. 

Generality increases at each stage because it is 

possible to have the machine execute a wider range 

of tasks. For example, in classical programming, 

hardware can be instructed by software to perform 

different tasks in a prespecified domain but can -

not adapt to different domains. That is, we can use 

a spreadsheet to achieve many numerical tasks, but 

it would be of little use as a word processor. Cur -

rent large language models have higher generality 

because they can handle tasks ranging from writ -

ing text to computer coding and beyond. 14  And the 

human effort required to have machines execute 

those tasks declines in more-advanced stages, as 

with computer coding. From the weeks it could 

take early computers do a different operation, the 

high-level programming languages increased gen -

erality and reduced effort for basic programming 

tasks with classical programming. And large lan -

guage models now generate computer code from 

spoken or written language descriptions in more and 

more languages. 15  Putting generality and human ef -

fort as two axes shows computational machines as a 

path in which machines can do more things with less 

effort (figure S1.2.1). 

Where do we go from here beyond generative AI? 

Nobody knows. Experts have different views. Some 

see the recent models continuing to evolve with -

in the current machine learning paradigm, acquir -

ing ever more capabilities, to the point of posing 

many risks, potentially existential ones. 16  Others see 

the current path as inherently limited, an off-ramp 

that demands new paradigms for progress to con -

tinue. 17  Still others think that machine learning is CHAPTER  1 — E MPOWERING  PEOPLE  TO  MAKE  ARTIFICIAL  INTELLIGENCE  WORK  FOR  HUMAN  DEVELOPMENT  41 

both inherently limited and potentially dangerous. 18 

Many are questioning whether the pursuit of hu -

man-level intelligence is what should be driving AI 

research 19— and even what that would mean is con -

tentious (box S1.2.1). 

Although there is no agreed definition of what ar -

tificial general intelligence is or even means, 20  there 

are numerous benchmarks based on different defini -

tions that assess the extent to which progress to wards 

that goal is being made (one example is the Abstract 

and Reasoning Corpus for Artificial General Intel -

ligence, which also describes several other bench -

marks: https://arcprize.org/; another is the so-called 

human ity last exam: https://agi.safe.ai/). Even what 

intelligence is or means is contentious. 21  Though 

there are debates as to whether artificial general in -

telligence is even possible, 22  the human develop ment 

interpretation proposed here presents a novel per -

spective on what the pursuit of artificial general intel -

ligence means. 

Artificial general intelligence is interpreted here 

as a boundary that we can approach indefinitely 

without ever touching it. 23  That humanity-deter -

mined boundary corresponds to the point when any 

task can be executed by machine with minimum 

human effort, except tasks that are valued only when 

executed by humans. The boundary is not fixed and 

can evolve as processes of individual and public rea -

soning shape social norms and values. Where could 

be the boundary be? In one extreme it could be as 

close to zero as possible—or even at zero. An econ -

omy that reaches this singularity is theoretically pos -

sible and can be modelled as a coherent economic 

framework with no (economically valuable) tasks 

for people to do. 24  But that would be a choice, not 

something inevitable given the march of technolo -

gy. In another extreme, society may determine that 

the pursuit of artificial general intelligence should 

stop, not because of the fear of the unknown (as with 

existential risk) 25  but because of an affirmation of 

a positive act of agency, determining that there are 

enough tasks done by machines based on an evalua -

tion of the things that people value and have reason 

to value. 

Figure S1.2.1  A human development interpretation of the evolution of computational machines—more tasks 

helpful to humans with less effort 

> Humanity boundary comprising tasks (such as art) that society values only if executed by people

Generality 

(tasks helpful to humans executed by the machine) for a machine to execute a task)  

> One hardware for each task
> (pre–Turing machines)
> One software for each task
> (Turing machines)
> One training set for each task
> (machine learning)
> One prompt for each task
> (large language models/large multimodal models/agents)
> ??Artificial general intelligence
> Asymptotic limit when any task up to the humanity boundary can be machine executed with minimum human effort
> ?
> Source: Human Development Report Office. 42 HUMAN DEVELOPMENT REPORT 2025

Box S1.2.1  Human intelligence is not defined by that of a single human but of many: Could artificial intelligence 

get there? 

The breadth of tasks for which artificial intelligence (AI) can exceed the performance of even talented individuals is 

rapidly increasing, resulting in speculation that AI will soon do so at all tasks humans complete. 1 This, in turn, leads to 

hope and concerns about a forthcoming artificial general intelligence singularity wherein AI surpasses and obviates 

the need for human intelligence, a key stated goal of several large AI firms. 2 Yet even if a given AI can beat any human 

at any task, exceeding and replacing human intelligence will remain far beyond the horizon. Although this may seem 

counterintuitive, the distance arises from the fact that collective human intelligence far exceeds what individuals 

can accomplish alone. 3 In one famous early 20th century example, individual fairgoers’ estimates of the weight of 

an ox varied widely and tended to be quite poor, yet the average estimate was within 1 percent of the true value. 4

In more applied contexts small groups of radiologists can do far better than even the best individual radiologist. 5 AI 

performance at this task, and others, will often fall far short of what humans accomplish collectively. 

And while it may seem that the solution is simply to create collective artificial general intelligence, science in the 

intervening century has revealed why this is unlikely to work. Collective intelligence manifests not from large numbers 

but from complex interactions between the structure of our social networks; 6 our diverse agency and capabilities; 7

our active capacity to inhabit, probe and sense the physical world; and the cumulative accumulation of culture over 

millennia. Even ostensible human limitations, such as our finite capacity for maintaining social relationships, appear 

to be features—not bugs—of collective intelligence. 8 By analogy to AI, collective intelligence arises through an evo -

lutionarily adapted network of every human that has ever lived, each possessing a unique and constantly updating 

training set, prompts and alignment. A single model that exceeds humans on individual tasks, even all of them, is still 

no match for collective intelligence. 

The question then becomes when and how AI can augment human intelligence more broadly. For the reasons 

outlined in this chapter, replacing humans even with very advanced AI is unlikely to be ideal for promoting collective 

intelligence. No AI on the horizon will possess humans’ capacity to diversely, curiously, continuously and actively 

explore the physical world and share the information gleaned with others through finely tuned social networks that 

produce emergent human intelligence. Rather than awaiting such an AI, we can instead rely on existing technology 

to augment individual humans in their pursuits—leveraging the existing, multibillion-member human superintelligence 

we already have and depend on.                          

> Notes
> 1. Narayanan and Kapoor 2024b. 2. Becker 2024. 3. Riedl and others 2021; Surowiecki 2005. 4. Galton 1907. 5. Wolf and others 2015.
> 6. Becker, Brackbill and Centola 2017; Becker, Porter and Centola 2019; Mann 2021. 7. Navajas and others 2018; Pescetelli, Rutherford and
> Rahwan 2020. 8. Henrich 2015. CHAPTER 1 — E MPOWERING PEOPLE TO MAKE ARTIFICIAL INTELLIGENCE WORK FOR HUMAN DEVELOPMENT 4 3

NOTES 

1.  Reid-Green 1989. 

2.  https://www.britannica.com/technology/Colossus-computer 

3.  Turing 1937. 

4.  This brief description also glosses over many details (for example, the transi -

tion from instructions fed to the computer that were encoded mechanically 

in punch cards to symbolically encoded computer programs, which was 

itself a major breakthrough). It ignores the huge human effort that went into 

the transition from pre–Turing machines to Turing machines. For example, 

the Electronic Numerical Integrator and Computer, often referred to as one 

of the first general-purpose computers, was not a Turing machine but was 

Turing capable in the sense that it was able to execute any computation that 

could be described by an algorithm (high generality). But it required huge 

human effort involving physical rewiring for each calculation, with setup 

times that could extend to weeks (Haigh, Priestley and Rope 2016). 

5.  Browne 1988. 

6.  US National Academies of Sciences and Medicine 2024. 

7.  Deng and others 2009; Russakovsky and others 2015. 

8.  LeCun, Bengio and Hinton 2015. 

9.  For a discussion of the broad societal implications of the pervasive use of 

AI algorithms having power over people’s lives, see Lazar (2024a, 2024b, 

2024c). 

10.  Bursztyn and others 2023. 

11.  Mitchell 2021. 

12.  Vaswani and others 2017; Yenduri and others 2024. 

13.  In addition to transformer architecture, other core deep learning gen -

erative approaches include generative adversarial networks, variational 

autoencoders and latent diffusion models (Banh and Strobel 2023). 

14.  Quantifying greater generality may even become possible given ongoing 

efforts to quantify the retention performance of large language models 

when applied to novel tasks that they are not specifically trained for 

(Maslej and others 2023; Minaee and others 2024a; Zhang and others 

2024c; Zhang and others 2025). For example, one metric found that top-

performing large language models achieved 50 percent performance on 

novel tasks (Srivastava and others 2022). 

15.  Recent evidence has found that pairing computer coders with AI made 

them code 55 percent faster and that 85 percent felt more confident in 

their code quality (Gao and Research 2024). 

16.  Bengio and others 2024; Bengio and others 2025; Cohen and others 2024. 

17.  Browning and LeCun 2022. 

18.  Marcus 2024. 

19.  N. Jones 2025. 

20.  Mitch  ell 2024a. 

21.  Edito  rial 2024. 

22.  Fjelland 2020. 

23.  More formally, this would correspond to an asymptotic limit. 

24.  Nordhaus 2021. 

25.  https://futureoflife.org/open-letter/pause-giant-ai-experiments/ .4 5 

# C H A P T E R 

# 2

# From tools to agents: 

# Rewiring artificial 

# intelligence to 

# promote human 

# development 4 6 HUMAN DEVELOPMENT REPORT 2025 

# To artificial intelligence (AI), decisions are merely tasks 

# to automate. Yet to humans, choice is the currency of 

# agency and the affordance of freedom. As AI becomes 

# integrated into our world, it raises the possibility of 

# automating tedious decisions alongside the specter of 

# inadvertently ceding human agency. The consequences 

# of carelessly ceding agency will be felt not just 

# by individuals in moments but through cumulative 

# consequences for collectives and cultures. Averting 

# loss of human agency to machines requires going 

# beyond a quest for more agentic models and instead 

# favouring development of AI that expands, rather than 

# contracts, human choice, agency and freedoms. 

> CHAPTER 2

# From tools to agents: Rewiring artificial 

# intelligence to promote human development CHAPTER  2 — F ROM  TOOLS  TO  AGENTS : R EWIRING  ARTIFICIAL  INTELLIGENCE  TO  PROMOTE  HUMAN  DEVELOPMENT  47 

## From doing what we do to 

## choosing what we choose 

A nearly identical ranking algorithm will just as read -

ily decide the next song on a playlist as it will the next 

target of an autonomous weapon. Twin decisions and 

their associated actions, which scarcely belong in the 

same sentence, are virtually identical from the per -

spective of artificial intelligence (AI) deputized to au -

tomate them. Although it is easy to fixate on the moral 

distinction between these two contexts, a closer look 

reveals a shared feature of AI across both contexts— 

human decisions become mere tasks to automate. 

Whereas chapter 1 examines the step-change 

in how machines have broadened their ability to 

do what we do, this chapter considers their new -

found ability to choose what we choose. Although 

step-changes in the ease with which novel tasks 

can be delegated to machines have historical par -

allels, the same cannot be said for AI’s newfound 

decisionmaking capabilities. From 19th century vote 

tabulating to classical programming, the construc -

tion of the machines themselves has historically been 

imbued with human decisions. In sharp contrast AI 

is routinely constructed through machine learning— 

asking AI to make decisions and providing feedback 

on those choices. The net result is machines that, by 

construction, are decisionmaking machines. 1

This feature of modern machines cannot be ignored 

because the choices we make express our agency, 

while the suite of options available to us defines our 

freedoms. 2 Our agency manifests in why we choose 

what we choose, something AI cannot possibly know 

because it can observe only our actions not our pref -

erences. Given this, AI can automate our choices but 

cannot reliably do so in a way that fully reflects our 

goals, values, preferences and needs (chapter 5). 

In the human development approach expanding 

freedom and agency is not merely a goal but the prin -

cipal means through which human development is 

achieved. When AI restricts the choices we are free 

to make or reduces our agency to do so, it works di -

rectly against human development. But when AI 

provides a broader swath of more informed choices, 

it can amplify our freedom and agency. As such, the 

human development impact of creating machines 

that can decide for us is difficult to overstate, can -

not be neutral and scales multiplicatively with both 

the newfound abilities of AI and the breadth of its 

deployment. 3

This tectonic shift in how digital technologies in -

teract with agency comes at a time when agency itself 

faces challenges globally. The 2023/2024 Human 

Development Report noted that nearly half of peo -

ple worldwide reported not being in control of their 

own lives. 4 Our survey on AI sentiments echoed those 

findings and asked participants how they felt about 

their agency looking forward to an AI-shaped future. 

The results suggest a gap has emerged, whereby low, 

medium and high Human Development Index (HDI) 

countries anticipate few changes in agency, whereas 

very high HDI countries expect a loss of agency (fig -

ure 2.1). Although the causes of this gap remain un -

clear, one possibility is that increased exposure to 

AI in very high HDI countries is associated with the 

sense that the future will be one in which lesser agen -

cy is enjoyed. 

Figure 2.1  Sense of agency now and in an artificial 

intelligence (AI)–defined future 

> 44.6 56.5 45.4 45.8 57.5 32.1

(% of population) High current control over own life today High expected control over own life in five years, as AI evolves Low/medium High Very high Human Development Index group   

> Note: Based on pooled data for 21 countries. The sense of agency is proxied by
> the percentage of respondents reporting high perceived control over their own
> lives. High current control refers to responses of 8–10 on a 10 point scale to the
> question “How much freedom of choice and control do you feel you have over
> the way your life turns out?” High expected control in five years, as AI evolves,
> refers to responses of 8–10 on a 10 point scale to the question “How much free -
> dom of choice and control do you think you’ll have in five years, as digital tech -
> nologies, including artificial intelligence, become more integrated into daily life?”
> Source: Human Development Report Office based on data from the United
> Nations Development Programme Survey on AI and Human Development. 4 8 HUMAN DEVELOPMENT REPORT 2025

Whether AI erodes agency depends on how it is 

designed and implemented. Critically, human agen -

cy and freedom are not the simple sum of choices we 

make; nor are they zero-sum in the sense that ceding 

a choice to AI is losing agency. We may often require 

decisions to be reached or tasks to be accomplished 

merely to support more agency-defining choices and 

actions. For example, few of us can be bothered to 

pore over raw weather data and decide the probabil -

ity of rain, but such information may be invaluable in 

supporting our choices—from bringing an umbrella 

to raising crops. In delegating such a decision to ma -

chines, we expand our own agency in the choices we 

choose to make. 

By the same token none of us wishes for a machine 

to decide irrevocably in an instant whether we are a 

combatant or civilian under the Geneva Conven -

tions. The unfreedoms created by a decisionmaking 

machine quantifying our behaviour to opaquely 

make such a choice are difficult to overstate. Be -

cause we cannot know which actions will tip the 

balance—carrying a backpack or leaving the house 

at night—what agency and freedoms could we pos -

sibly enjoy? These are not abstract hypotheticals but 

real-world consequences of deputizing machines to 

make such consequential decisions. 

Herein lies the crux of this chapter: we should not 

task machines with decisions simply because they 

now seem capable of making them; we should in -

stead do so based on whether ceding those decisions 

expands or contracts our agency and freedoms (fig -

ure 2.2). In this sense, human development provides 

a lens for evaluating the use, design, deployment and 

regulation of AI that enables us to see the value of a 

system as situated in the real world and beyond its 

technical capacity. This framing requires letting go 

of techno-solutionist narratives (chapter 4). In doing 

so, we may find that existing technologies—not hypo -

thetical future artificial general intelligence—are best 

suited to improve agency in a given context. 

The decisionmaking nature of AI, particularly in 

combination with its newfound language skills, has 

Figure 2.2  Simpler forms of artificial intelligence (AI) may more easily promote human agency, whereas AI with 

high agenticity can have a broader range of more dramatic impacts             

> Human agency– enhancing Agentic models Human agency– degrading Tools prediction Weather Spellcheck Advanced driver assistance systems Conversational ranking algorithms AI job interviews Engagement-based ranking Fully autonomous weapons
> Source: Human Development Report Office. CHAPTER 2 — F ROM TOOLS TO AGENTS : R EWIRING ARTIFICIAL INTELLIGENCE TO PROMOTE HUMAN DEVELOPMENT 4 9

bestowed on it a remarkable capacity to weave itself 

into our social fabric. We interact one-on-one with a 

menagerie of AI, from simple autocorrect and smart 

thermostats to generative chatbots and digital assis -

tants. AI has also become an intermediary between 

humans: ranking, sorting, filtering and translating 

conversations at unfathomable scales. Increasingly, 

AI is becoming embedded into human institutions 

as well, shaping their decisions and actions, with cas -

cading consequences for large swaths of the popula -

tion and beyond the digital divide, as discussed later 

in the chapter. 

# “ Flows of information through human 

networks shape the decisions we make 

collectively, from juries, electorates and 

governments to globally coordinated efforts to 

address climate change. Because AI is now a 

feature of these networks, it will undoubtedly 

have effects on these emergent decisions 

Perhaps the most impactful consequences of AI 

derive from embedding it in our social systems. So 

much of human development depends on these 

human networks, which are often key determinates 

of our capabilities, functioning, agency and free -

doms. 5 Flows of information through these networks 

shape the decisions we make collectively, from juries, 

electorates and governments to globally coordinated 

efforts to address climate change. 6 Because AI is now 

a feature of these networks, it will undoubtedly have 

effects on these emergent decisions. 7

On longer timescales the cumulative product of 

choices made and remembered defines who we are as 

groups of people, our culture. 8 Because AI makes—and 

helps us make—decisions, it will undoubtedly have— 

and arguably already has had—effects on the trajec -

tories of human culture. Will it be expansive, enabling 

contextual innovation and broadening our culture? Or 

contractive, narrowing the breadth of global culture 

towards a photocopy of the culture that happened to 

be represented on the internet when training sets were 

collected? The chapter concludes by highlighting the 

importance of considering AI’s impacts across these 

larger scales of society and time, as they will invariably 

shape human development in profound ways. 

Against the complexity unravelled in this chapter, 

it can feel daunting to know where to start and how to 

move forward. How could we possibly predict, much 

less intervene on such a large scale, amorphous im -

pacts that may play out over timescales longer than 

our own lives? Yet the challenge here is, in a sense, no 

different in scale or complexity than the challenges of 

human development more broadly. The chapter ends 

where it starts, arguing that even against such com -

plexity the human development approach can light a 

path forward—designing, regulating and leveraging 

AI in ways that scaffold human agency and expand 

freedoms. 

## Entering a brave new (digital) world 

The human development perspective is anchored in 

Amartya Sen’s view that expanding freedom is both 

the primary end and the principal means of develop -

ment. 9 In Sen’s view freedom encompasses individ -

uals’ capabilities and agency—the options afforded 

to them and their empowerment to freely leverage 

those options to pursue goals based on their values 

and needs. Echoing Sen, the 2001 Human Develop -

ment Report described technology as a tool for, not 

just a reward of, growth and development. 10  A quarter 

century later it is difficult to overstate the internet’s 

impact on shaping and defining the freedoms we 

enjoy and, by extension, human development. These 

freedoms are altered not only through direct  connec -

tion but also through disparity in connection—the 

digitization of infrastructure, institutions and econ -

omies and the spillover effects to other facets of our 

physical, social and natural worlds. 

The internet, having already reshaped human de -

velopment, recently entered a major transition from 

a repository of largely passive digital tools to a sys -

tem replete with a menagerie of artificial intelligenc -

es. The pace of this change has been staggering, with 

technologies that just a few short years ago represent -

ed science fiction now being integrated into nearly 

every corner of the internet and our devices. Data, 

long a valuable resource, are scraped and hoarded 

by the petabyte. Massive financial investment has 

flowed into entirely new markets, promising trans -

formation. The scale of investment into these tech -

nologies follows promises that AI will redefine and 

reshape our economies, education systems, health 

services and the world more broadly. Even if only 

a fraction of these promises come to fruition, we 5 0 HUMAN DEVELOPMENT REPORT 2025 

should expect large-scale impacts of AI on human 

development. 11 

But what will these impacts be? There has been 

no shortage of attempts to predict, manage or gauge 

AI’s impact across domains. Estimates range from a 

mere bump in the road to global catastrophe—from 

modest improvements to a brave new world—with 

most falling somewhere in between. Yet predicting 

downstream consequences rests on a narrative that 

technology is something that happens to human -

ity. It belies the fact that our choices—particular -

ly in the coming years—will determine what those 

impacts are and, ultimately, what they mean for 

human development. But this ambiguity indicates 

plasticity—the freedom to choose what our AI-in -

fused internet looks like before it ossifies. In this 

sense what AI becomes is not merely a determinant 

of human development but a manifestation of it. 

From tools to agents 

The 2001 Human Development Report’s emphasis 

on technology as a tool for development recognized 

the early internet’s promise for expanding agency 

and capabilities with an ever-evolving suite of digital 

tools. 12 

Consistent with this, efforts in the intervening dec -

ades have emphasized equitable distribution of dig -

ital tools through closing the digital divide. See, for 

example, the increase in the share of the world’s pop -

ulation with access to the internet from 16.8 percent 

in 2001 to 67 percent in 2023. 13  While the prolifera -

tion of access to the internet has been remarkable, 

wide disparities remain in quality, reliability and 

means of connecting. 14  Moreover, the capabilities 

that connecting to the internet provide vary widely 

and are linked to the key components of the HDI: in -

come and achievements in education and in health. 

Connecting to the internet remains an important de -

velopment priority because it can enable individu -

als to access and contribute to the global knowledge 

commons and participate in the ever-growing digital 

economy. 

The tool-like quality of early digital technolo -

gies undergirded their promise as a force for de -

velopment. Many tools on the early internet were 

simply more equitably distributable or more efficient 

versions of tools in the physical world—for example, 

email, online banking, calendars and digital encyclo -

paedias. From the human development perspective 

tools in the digital world resemble tools in the phys -

ical one (table 2.1). Tools have well-defined purpos -

es that can be understood and taught. Human action 

predictably links to outcomes, and this relationship 

remains stable over time unless the tool’s design is 

intentionally changed. Perhaps most important from 

the human development perspective, tools do not 

choose things for us—keeping human agency front 

and centre. 

As chapter 1 discusses, AI represents the latest 

step-change in our ability to create machines capable 

of accomplishing ever more general tasks. Particular -

ly when developed through machine learning, AI is 

implicitly decisionmaking machines—even when the 

decisions are as trivial as spellchecking. In this sense 

the simplest forms of AI bear much resemblance, 

from the user’s perspective, to tools. The decisions 

they make are inconsequential or predictable enough 

to simply save us time (spellchecking, smart thermo -

stats), or they reliably make accurate decisions we 

could not make (weather prediction, translation). 

Yet more advanced forms of machine learning 

converse, generate videos, play games and identi -

fy candidate drugs (box 2.1). This general breadth 

of task completion comes alongside expanded 

decisionmaking. In this sense the capabilities and 

nature of these systems bear little resemblance to 

tools. A tool provides an individual with well-de -

fined affordances that they can learn to use, resulting 

Table 2.1  Comparing characteristics of digital tools 

and artificial intelligence (AI) agents                    

> Feature Digital tools AI agents
> Predictability Consistent and
> predictable
> Often
> unpredictable
> Transparency Easy to understand
> and explain
> Opaque, difficult to
> interpret
> Behaviour Static, unchanged
> unless updated
> Dynamic, evolves
> over time
> Role Passive, user-
> driven
> Active, can act
> autonomously
> Note: These are not absolutes but ends of a spectrum. A given
> implementation of AI may behave more like a tool in one or more
> ways, but AI is unique in its ability to exist along these continua.
> Source: Human Development Report Office. CHAPTER 2 — F ROM TOOLS TO AGENTS : R EWIRING ARTIFICIAL INTELLIGENCE TO PROMOTE HUMAN DEVELOPMENT 51

in a specific expansion of capabilities—importantly, 

it makes no choices for us. By contrast, an AI-based 

system may behave differently across users and con -

texts, in essence adapting its behaviour to context. 

This challenge is particularly salient in personalized 

recommender systems, where two individuals in dif -

ferent locations who conduct the same web search re -

ceive very different results. 15 

This dynamic feature of AI-powered systems can 

be valuable. For example, it can provide locally tai -

lored information and avoid irrelevant information 

dominating search results. In this sense the choice to 

return only locally relevant results is one we might re -

liably make ourselves—such as choosing to examine 

results only in a language we speak. However, per -

sonalization can also have varied impacts on the qual -

ity of items surfaced across platforms, from surfacing 

less-divisive, higher quality information to the op -

posite: amplifying misleading, ideologically aligned 

content. 16  Here, the choice is more consequential—to 

what extent would we choose to spend time reading 

low-quality information, given the choice? Would 

we choose to have our views reinforced by such low-

quality information or prefer to engage with some -

thing closer to the truth? These decisions may be 

silently made for us in an instant, beyond our view. 

This unpredictable nature of AI raises a host of ad -

ditional development challenges at scale, as the same 

system may result in very different outcomes across 

individuals, contexts and time. The differing out -

comes may, in turn, exacerbate existing inequalities. 

For example, some users may receive higher quality 

information from the same search product merely 

because of their geographic location or other aspects. 

In this sense deprivations of agency-impactful choic -

es may not be uniform. 

Similarly, the function of more straightforward 

digital tools can be inferred by evaluating the 

underlying code. One could browse the code pow -

ering a simple email service and deduce that it 

Box 2.1  Artificial intelligence revolutionizing biomedicine 

Generative artificial intelligence (AI) has the potential to generate much more than text, images and video, and 

there is substantial interest in applying AI to biomedical research and development. Two active intertwined areas 

of research surround protein folding and drug discovery. Proteins are large molecules synthesized within cells from 

amino acids that serve various functions and are common targets of medicines intended to treat disease. Discerning 

their three-dimensional shape is essential for understanding their function and developing drugs that target specific 

proteins. More recently, mRNA vaccines have made it possible to encourage cells to generate proteins not found in 

their genetic code, with promising applications for allergies, infectious diseases, cancer and genetic disorders. 

Unfortunately, computing the structure of a given protein has historically been computationally intensive, requiring 

access to larger servers or distributed computing efforts such as Folding@home. 1 Recent advances in AI, such as 

AlphaFold3, can predict the structure of proteins at drastically reduced computational cost with increasingly high 

accuracy. 2 Challenges of protein folding are intrinsically linked to AI-powered drug discovery, which seeks to identify 

compounds that often interact with proteins, such as receptors or enzymes, to produce some desired biological 

effect. Ideally, the compounds already exist and are approved for treating other conditions. 

AI applications for drug development are on the rise because they can rapidly propose and assess candidate 

drugs, potentially speeding discovery and aiding in identifying promising candidates. AI can be further used to de -

velop pathways for drug synthesis or to speed up testing of proposed drugs. Investment in AI-fuelled drug discovery 

is ramping up, with the first AI-discovered drugs hitting the market in 2024. 3 Although the use of AI in medicine is 

nascent, there is little doubt that it has big potential to advance the field in the coming years. 

Key challenges remain in making these technologies more widely accessible so that research and development 

can be expanded beyond a finite set of for-profit institutions and well-funded universities. One such effort, ColabFold, 

was developed in 2022. 4 This free and accessible protein folding platform provides better functionality than Google’s 

last -generation AlphaFold2, making it a viable option for some protein folding tasks. Investment in open-source AI 

models for biomedical research may be critical for expanding biomedical research and development leveraging 

these tools.        

> Notes
> 1. Larson and others 2009; Voelz, Pande and Bowman 2023. 2. Abramson and others 2024. 3. Ren and others 2024. 4. Mirdita and others 2022. 5 2 HUMAN DEVELOPMENT REPORT 2025

enables individuals to send one another messag -

es. This functionality can be taught to users, pro -

moting agency when deciding whether and how 

to use email. Reading the code underlying gener -

ative AI, one could infer that it learns something 

from some data and produces responses. Yet there 

is no way to trivially evaluate the trillions of poten -

tial parameters and petabytes of data that define 

what it learned and how it might respond. The re -

sultant opacity makes it difficult to know why more 

complex AI systems choose what they choose and 

whether their choices reflect the choices we would 

make. Indeed, it may even be hard to know which 

intermediate choices they made before arriving at a 

result or decision. 

# “ The resultant opacity makes it difficult 

to know why more complex AI systems 

choose what they choose and whether their 

choices reflect the choices we would make 

Many AI systems are not simply trained once but 

are instead refined with data and experience. 17  As a 

result, even if the behaviour is well-characterized, it 

may change over time, perhaps suddenly and silent -

ly, rendering our understanding of impacts and any 

implemented interventions obsolete. 18  Moreover, the 

development of AI is progressing at a speed far out -

pacing what can be expected for scientific and reg -

ulatory responses, frustrating typical approaches to 

identifying and mitigating harm. This dynamic na -

ture of systems makes AI technologies a moving tar -

get such that any development-minded applications 

will require continuous reappraisal as the systems 

evolve and alter their behaviour. From an individual’s 

perspective, even if they are comfortable delegating 

choices to a machine at a particular moment in time, 

they may have no way of knowing whether and when 

that machine begins making different choices that no 

longer reflect their agency. 

This decisionmaking capacity is made even more 

salient when AI can act on its choices. Some AI sys -

tems are, like tools, passive and require human input 

to produce output or have meaningful impacts. Soft -

ware that judges use to predict recidivism requires 

inputting characteristics of the person being evalu -

ated for release. 19  While it can make recommenda -

tions, judges ultimately bear responsibility for any 

decisions. Autonomy here is defined not by the tool 

itself but by the degree to which (if any) judges’ de -

cisions are constrained by law, norm or convenience 

to follow the algorithmic recommendations. In other 

cases AI systems will be explicitly designed to initi -

ate actions or make decisions (semi-)autonomous -

ly in response to changes or incoming information. 

Automated trading systems, for example, can move 

money in response to market changes, exerting 

substantial force on financial markets, with mini -

mal, if any, human oversight. 20  Automation raises 

challenges when choices have meaningful conse -

quences, because the impacts of decisions can ac -

cumulate without human oversight—fully divorced 

from human agency. 

Making AI explain itself 

The unpredictability of AI agents has been a criti -

cal challenge to their deployment in real-world con -

texts. AI agents can behave dynamically, actively and 

autonomously, leading to the alignment problem, 

identified more than half a century ago by computer 

scientist Norbert Wiener. 21  The behaviour of an AI 

system is often shaped implicitly through learning 

specific tasks in a controlled environment. On de -

ployment the system may be used for a much wider 

variety of tasks across a broader range of outcomes, 

leading to unpredictable behaviour. 

Yet the predictability, explainability and general dy -

namism of an AI system are not discrete states—they 

represent continua along which a given implementa -

tion of AI sits and can be adjusted. Anticipating risks, 

promoting human agency and ensuring accountabili -

ty can be facilitated by intentionally designing AI so 

that humans can inspect and understand how they 

work. 22  Often referred to as explainable AI or ex -

plainable machine learning, these systems promote 

human intellectual oversight of AI by ensuring that 

humans can understand why inputs to a given AI sys -

tem result in a specific output. 

Not all applications and approaches to AI are 

amenable to explainability. For those that are not, 

AI audits hold promise for characterizing how an AI 

system functions, its risks, biases and other relevant 

factors (chapter 5). 23  Audits may reveal the need 

for refinement and reshaping before deployment. CHAPTER  2 — F ROM  TOOLS  TO  AGENTS : R EWIRING  ARTIFICIAL  INTELLIGENCE  TO  PROMOTE  HUMAN  DEVELOPMENT  5 3 

Shaping alignment can take various forms, often 

involving further AI training through feedback 

from other AI, through explicit heuristics and con -

straints or through “humans-in-the-loop.” 24  Each 

of these methods is an imperfect iterative process 

that may require continual and ongoing shaping as 

the behaviour of AI, its uses, its users or the con -

text in which it is deployed change. In some cases 

it may be necessary to restrict AI technologies that 

cannot reasonably or sufficiently align with human 

wellbeing. 

AI’s ability to do and choose does not give it agency 

Were it just for the unpredictability of AI systems, ef -

forts to rein in and characterize AI behaviour could 

be sufficient for making systems tool-like. Yet the 

unique decisionmaking and action-taking capabil -

ities of some AI systems fundamentally change the 

calculus of AI from a human development perspec -

tive. The degree to which AI systems can autono -

mously accomplish a range of more general tasks 

is often referred to as agenticity—a nod to their ca -

pacity to act as agents. AI systems with low agentic -

ity may narrowly serve simple functions with heavy 

human oversight (see figure 2.2). More complex 

forms of AI, such as modern chatbots, can be repur -

posed for a wide range of tasks they can undertake 

with whatever degree of autonomy is afforded to 

them. The race to build more and more capable 

models is implicitly a race to develop more agentic 

forms of AI. 

Techno-solutionist narratives, explored in chap -

ter 4, often suggest that simply building more agen -

tic models can solve the world’s problems. Yet the 

human development lens provides a starkly con -

trasting view. Because our own human agency is ex -

pressed through actions and decisions, AI’s agentic 

capabilities hold promise to expand our ability to 

make and act on choices, alongside a very real risk 

of ceding human agency to technological artifacts. 

Developments in the past two years have drastical -

ly increased the agenticity of AI, commensurately 

broadening the ways it intersects with human agen -

cy (see figure 2.2). Whether this increased agenticity 

improves or degrades human agency depends on the 

choices we make in the coming years. 

# “ Whether highly agentic systems ultimately 

promote or degrade human development depends 

not on their technological capabilities but on 

the way they are integrated into society—a 

theme explored throughout this Report 

There is no trivial or zero-sum relationship be -

tween the agenticity of AI and its impacts on human 

development. AI systems with low agenticity can, and 

routinely do, dramatically improve human agency. 

Weather prediction, for example, is far from auton -

omously able to take broad-ranging action—but can 

provide individuals with essential information to sup -

port agency. These systems provide critical informa -

tion for making decisions as mundane as bringing an 

umbrella and as consequential as crop management, 

city planning and emergency evacuation. Weath -

er prediction systems could be made more agentic, 

sending automated tailored messages and answering 

questions in regular spoken language, automatical -

ly translating as needed. Provided these systems are 

trusted and accurate, their anticipated consequences 

for human agency would be net positive. 

Yet the same underlying generative language 

model leveraged to support disaster communication 

could be purposed to create deceptive bots or write 

misleading news articles that persuade individuals 

to make decisions against their interests and values. 

Even more consequential uses of highly agentic sys -

tems have begun to occur on battlefields. Some ex -

amples of AI demonstrate how highly agentic models 

convey both greater opportunities and greater risks 

for human development (see figure 2.2). Whether 

these highly agentic systems ultimately promote or 

degrade human development depends not on their 

technological capabilities but on the way they are in -

tegrated into society—a theme explored throughout 

this Report. 

Given the centrality of agency in the human de -

velopment framing, it is important to remain aware 

of distinctions between human agency and machine 

agenticity. There is no reason to believe that because 

AI can make and act on decisions, it does so using sim -

ilar (or any) cognitive processes to those of humans. 25 

Nor does framing AI as agents or agentic imply that we 

should strive for machines with humanlike agency. In -

stead, we must anchor our choices for developing and 

deploying AI in ways that expand human agency and 5 4 HUMAN DEVELOPMENT REPORT 2025 

capabilities. These technologies must be designed so 

that whatever decisionmaking we cede to AI comple -

ments and expands rather than contracts freedom. AI 

technologies should be viewed not as tools of human 

development but as agents whose behaviour, align -

ment, training and use can profoundly impact human 

development and security. Ultimately, agenticity is 

not a goal but a design choice to be made solely when 

it supports human agency (chapter 5). 

Approaches to ensuring AI accountability and re -

ducing uncertainty are rapidly evolving and will 

doubtless continue to do so, given the rapid pace of 

change in AI functionality and deployment. 26  At pres -

ent, there is minimal accounting of the harms caused 

by AI and, similarly, minimal visibility on how it is 

being deployed and used. 

## Embedding AI into our social fabric 

Online connections between humans 

The printing press, radio and television increased the 

flow of information between humans, but the internet 

has been distinct in reducing the costs of producing 

and distributing information. 27  Analogue technolo -

gies tended to consolidate the production and distri -

bution of information in the hands of those with the 

infrastructure for distribution. These few-to-many 

communication systems—often still geographically 

constrained—fundamentally differ from the global 

all-to-all systems afforded by internet connectivity. 

Connections between humans are in many ways the 

primary source of both opportunities and challeng -

es to improve human development. The 2023/2024 

Human Development Report evaluated some critical 

barriers to successful human collaboration, the rise of 

gridlock and what can be done to prevent it. 28  Histor -

ically, the successes, failures, inequalities and many 

development challenges have emerged directly or in -

directly from the dynamics of interactions between 

humans. 29  Ultimately, the challenge of guiding our 

world towards one that is sustainable, equitable and 

healthy is a challenge of understanding how to pro -

mote successful interaction between humans. 30 

At more minor scales than global decisionmaking, 

it is difficult to overstate the importance and ben -

efits of communication between humans. Social 

interactions facilitate social mobility, promote men -

tal and physical health, increase longevity and are 

essential to a good life. 31  More generally, our social 

institutions and interactions shape our skills, inform 

our decisions and alter our opportunities—crucial de -

terminants of human development. 32  Much of the de -

velopment potential of the internet lies in its capacity 

to augment interactions between humans, reducing 

geographical, infrastructural and systemic barriers to 

communicating while increasing the ability to share 

and access information. 

# “ By inviting machines into our social 

networks, the choices they make begin to 

impact us through our social networks in much 

the same ways that we impact one another 

The proliferation of AI in the digital spaces we in -

creasingly inhabit presents a qualitative shift in how 

we interact with one another and the physical world. 

As outlined below, social networks now comprise di -

rect interactions between humans and AI, AI-medi -

ated interactions between humans and an increasing 

but largely unappreciated impact of interactions be -

tween AI systems (figure 2.3). This in turn shapes the 

choices we can and do make, as individuals and as 

groups. Moreover, by inviting machines into our so -

cial networks, the choices they make begin to impact 

us through our social networks in much the same 

ways that we impact one another. The following sec -

tions evaluate how integrating our social systems with 

decisionmaking machines can profoundly influence 

choices and their consequences, from the scale of in -

dividuals in day-to-day life through societal processes 

that take place over generations. 

Interactions between humans and AI 

Regardless of whether we notice, we increasingly in -

teract with, and cede choices to, various forms of AI. 

AI in some form is required to filter, sort and display 

the vast amount of information on the internet in a 

form that our finite attention can process (chapter 5). 

In more conspicuous cases we find ourselves con -

versing with automated systems in customer service 

agents, digital assistants and multipurpose chatbots. 

Leveraging these explicit cases of interaction between CHAPTER  2 — F ROM  TOOLS  TO  AGENTS : R EWIRING  ARTIFICIAL  INTELLIGENCE  TO  PROMOTE  HUMAN  DEVELOPMENT  5 5 

humans and AI is an area of considerable ongoing re -

search and development across domains. In medicine 

accurate diagnoses are essential to effective treat -

ment, and diagnostic accuracy directly affects human 

development. Numerous AI systems are being de -

veloped daily to improve diagnostic capabilities. For 

instance, endoscopists codiagnosing alongside AI re -

sulted in higher diagnostic performance than either 

AI or humans acting alone. 33  Other applications of 

explicit interaction between humans and AI are being 

developed in contexts as varied as addressing erro -

neous beliefs; getting information about government 

services; providing financial, legal and medical ad -

vice; counselling; and developing software. 34 

Sometimes, human–AI interaction can be more sub -

tle, augmenting capabilities in ways that feel much 

more like using a tool than holding a conversation. For 

example, advanced driver assistance systems in vehi -

cles encompass a range of technologies that leverage 

the high sensitivity of digital sensors to warn driv -

ers of hazards, detect and offset fatigue and initiate 

action such as braking to avoid collision. 35  These sys -

tems could reduce common types of traffic accidents 

by 16–40 percent. 36  With more than a million traffic 

deaths a year globally, reductions in accidents from ex -

panded access to advanced driver assistance systems 

could directly improve life expectancy and, by exten -

sion, human development. 37  Because traffic deaths are 

considerably more prevalent in low HDI countries, im -

proving access to these systems could be particularly 

promising. 38  But cultural differences in moral apprais -

al of advanced driver assistance systems may require 

adapting them to local norms and values. 39 

Interactions between humans and AI can also fa -

cilitate learning for both. For example, AI-powered 

identification of bird species can enable users to 

better identify them in the future. 40  The increased 

ability to identify species can, in turn, improve AI’s 

performance by directly contributing geolocated ob -

servations and uploading labelled sounds and imag -

es. This recursive process and the data it generates 

have become an essential tool for conservation. 41 

Figure 2.3  Interactions between and among humans and artificial intelligence Face-to-face, phone calls email Chatbots, smart devices voice assistants algorithmic Internet of Things devices, meta-learning trading, Social media, translation tools, recommendation systems  

> Source: Human Development Report Office based on Brinkmann and others (2023). 5 6 HUMAN DEVELOPMENT REPORT 2025

Well-designed AI can thus leverage humans’ unique 

capabilities to explore the world and augment them 

with the effortless ways computers can store and pro -

cess information. And such systems can be aligned 

to benefit individuals and broader development 

goals. These examples are just a handful of the many 

ways AI can enhance individual capabilities, a theme 

throughout the Report in contexts such as education, 

healthcare and employment. 

Now consider the pitfalls. Many of the freedoms 

and capabilities the internet provides depend on ex -

panding access to high-quality information. One of 

the more common ways humans engage with AI is 

through various recommender systems that sort and 

filter news, information and entertainment across the 

web. Often aligned for engagement and advertising 

sales, these systems can narrow information diver -

sity, heighten confirmation bias, promote addictive 

behaviours and lead individuals down “rabbit holes” 

and into harmful behaviour (chapters 3 and 5). 42  The 

same image recognition technology enabling visual 

forms of search powers facial recognition software 

used to restrict freedoms and harass. 43  Ultimately, the 

extent to which such systems exhibit these freedom-

and capability-limiting effects depends inherently on 

whether they are designed in a way that keeps human 

agency and freedoms front and centre. 

AI-mediated human interaction 

AI intermediaries increasingly facilitate or alter in -

teractions between humans. In simple cases AI can 

convert information generated by one human into a 

format that another can more easily receive. For ex -

ample, different languages have long been a barrier 

to interaction between humans. The languages one 

can speak or read can profoundly affect access to in -

formation, economic opportunities, quality medical 

care, education and government services. Effective 

machine translation has long been a goal of AI re -

search, and recent models have a remarkable ability 

to cheaply and quickly translate across hundreds of 

languages. 44  But these models are far from perfect 

and can produce false translations (hallucinations) or 

toxic language. 45  Even so, given the cost and shortage 

of human translators, they hold remarkable potential 

to bridge language divides. Within a given language 

AI has been leveraged to smooth otherwise polarizing 

conversations—helping establish common ground. 46 

# “ AI’s ability to process natural language opens 

the possibility of accessing and generating digital 

information even if one cannot read or write. This 

potential to broaden accessibility is particularly 

relevant to development, as it can help in 

overcoming barriers to accessing the benefits of 

our digital world for those previously limited by 

design that makes implicit assumptions about 

their abilities, literacy and language fluencies 

Beyond language AI can be used in various ways to 

smooth communication between humans. Informa -

tion shared in one format, such as text and images, 

can be converted to audio and descriptions of images 

for consumption by someone else. Similarly, AI’s abil -

ity to process natural language opens the possibility 

of accessing and generating digital information even 

if one cannot read or write. This potential to broaden 

accessibility is particularly relevant to development, 

as it can help in overcoming barriers to accessing the 

benefits of our digital world for those previously lim -

ited by design that makes implicit assumptions about 

their abilities, literacy and language fluencies. 

When AI facilitates conversation between two in -

dividuals, it may be clear there is an AI intermedi -

ary—or it may not be. The impact of AI may be subtle 

or unknown to users. For example, much of what we 

encounter online may be created by humans but ul -

timately curated and ranked by machine learning. 

Given the vast amount of information online, some 

form of curation is inevitable, and AI condenses large 

volumes of information into a form that is readable by 

humans. Whether and how these AI-mediated inter -

actions expand or contract capabilities and freedoms 

depend on how they are designed and implemented. 

Consider interactions between humans on social 

media platforms, mediated by machine learning al -

gorithms that rank, sort and filter what users see amid 

the content others post. Such algorithms are aligned 

primarily with increasing firm revenue through a 

business model that translates engagement into ad 

sales and revenue. 47  So, how human interactions are 

mediated is not aligned with promoting human de -

velopment (chapter 5). Humans can in turn alter their 

behaviour in response to algorithmic feedback—for CHAPTER  2 — F ROM  TOOLS  TO  AGENTS : R EWIRING  ARTIFICIAL  INTELLIGENCE  TO  PROMOTE  HUMAN  DEVELOPMENT  5 7 

example, leveraging language that provokes engag -

ing emotional responses. 48  Thus, algorithms not only 

shape what interactions occur between individuals 

but can fundamentally alter individual behaviour in 

social contexts. 

# “ That the same AI mediation between humans 

can lead to vastly different outcomes across 

contexts highlights how the effects of a given 

system cannot be viewed in isolation. Likewise, 

attempts to intervene and improve the alignment 

of algorithms will need to consider not only 

harms but also the potential loss of benefits 

Balanced against these potentially detrimental im -

pacts, AI-mediated online interactions between hu -

mans can improve job opportunities and engagement 

in democratic processes. 49  These positive outcomes 

are well-aligned with human development yet emerge 

from the same platforms and algorithms. That the 

same AI mediation between humans can lead to vast -

ly different outcomes across contexts highlights how 

the effects of a given system cannot be viewed in iso -

lation. Likewise, attempts to intervene and improve 

the alignment of algorithms will need to consider not 

only harms but also the potential loss of benefits. 

Beyond social media AI has become an important 

intermediary between humans in contexts extending 

beyond the digital world. Judges, employers, banks, 

landlords and schools use AI tools to evaluate individ -

uals’ suitability for release, employment, lending and 

housing. 50  Across industries large datasets determine 

prices for goods and services, at times dynamically in 

response to fluctuating demand or even tailoring prices 

for individuals and markets. 51  In the academy AI is crop -

ping up in the production and review of manuscripts— 

despite experts’ calls for caution—embedding itself 

into a core mechanism through which society gathers 

and consolidates its understanding of the world. 52  AI 

similarly mediates cultural markets, differentially fa -

vouring some content producers over others. 53 

Interactions between AI agents 

AI systems routinely interact with one another. Given 

the remarkable speed at which computers can pro -

cess and transmit information, these interactions can 

happen with an incredible degree of speed and scale. 

They can be direct, mediated by a human or indirect 

because of interactions in the same common space 

(such as a market). The dynamics of these interac -

tions may be more challenging to observe, and their 

impacts on human development are difficult to pre -

dict and identify directly and in a timely manner. 

A classic example is automated financial trading, 

where AI agents either autonomously or semiauto -

nomously trade financial instruments in response to 

market fluctuations or other information. This ap -

proach to trading is remarkably commonplace, as 

machine learning can outcompete humans in many 

relevant contexts, particularly on short timescales. 

Such interactions can reduce trading costs and im -

prove financial inclusion for everyday investors but 

also increase market uncertainty. 54 

In algorithmic trading AI agents have similar goals, 

yet very distinct AI systems can interact in the same 

way. For example, machine learning predicts and 

collects characteristics of individuals on Facebook 

for targeted advertising. Advertising companies may 

leverage AI to best use targeted advertising such that 

an AI system is operating on data compiled by AI to 

place ads in a system that targets based on AI. Laws 

intended to protect individuals can be violated with -

out a human in the loop. In one case Facebook’s ad -

vertising platform enabled unlawful discriminatory 

housing advertising. 55 

Interactions between AI systems can also improve 

those systems’ capacity and adjust their behaviour 

and alignment. Although machine learning often in -

volves training agents on data, interactions between 

AI systems can enable training for some tasks, even 

when data are scarce. Google’s AlphaZero, trained to 

play chess solely through self-play, consistently beat 

other chess engines. 56  Its successor, MuZero, was de -

veloped to learn arbitrary games through self-play, 

making for a much more general architecture. Be -

yond games these approaches could help develop AI 

in rule-based contexts without the need for massive 

volumes of data. 57 

Similar approaches are emerging for relying on AI 

to guide the behaviour of other AI systems. For exam -

ple, one large language model can annotate output 

features from another to provide feedback for fur -

ther training and refinement. 58  These types of mutual 

learning can be used in isolation or augment training 5 8 HUMAN DEVELOPMENT REPORT 2025 

involving human annotation and guidance. These are 

just a handful of examples highlighting how autono -

mous agents can interact with one another. Such in -

teractions can be viewed as amplifiers that increase 

AI systems’ abilities and complexity, which may 

make behaviour opaque and more unpredictable. 

Compared with interactions between humans and 

AI, however, these interactions are feasible to simu -

late and evaluate  in silico . Research on interactions 

between AI systems in the wild is limited, and under -

standing the impacts and potential for human devel -

opment will be crucial in the coming decades. 

AI and institutions 

Human agency is often expressed and affected by de -

cisions at larger scales of organizational complexity— 

institutions. Indeed, the early uses of AI in the 1990s 

were for business and military decisionmaking. 59 

When institutions rely on AI, they cede some agency 

in information aggregation or decisionmaking to AI. 

Decisions once under the purview of consultants, war 

rooms and board rooms are shaped or even made  in 

silico .

# “ The use of AI in institutions has unique 

considerations when viewed through the lens 

of human development. The concerns and 

opportunities may shift from those working 

directly with AI towards how its use alters the 

institutional impact on human development 

The use of AI in institutions has unique considera -

tions when viewed through the lens of human devel -

opment. The concerns and opportunities may shift 

from those working directly with AI towards how its 

use alters the institutional impact on human develop -

ment. Depending on the scale and nature of the in -

stitution, AI-coupled decisionmaking in and between 

institutions may have outsized impacts on human 

development. Perhaps the most salient way AI can 

shape institutional decisionmaking is by parsing and 

aggregating large amounts of data. This transition to 

big data and machine learning has been under way 

for over a decade, with large datasets and machine 

learning now the norm for many institutions rather 

than the exception. 

Often, the benefits of such applications are front 

and centre, motivating the use of a given technology 

in the first place. Machine learning can help institu -

tions better allocate and target resources, increase 

the efficiency of internal processes and provide rel -

evant information beyond the scale of what can fea -

sibly be discerned from raw data alone. For example, 

the government of Togo leveraged AI to identify in -

dividuals most likely to benefit from financial assis -

tance during the Covid-19 pandemic. 60 

However, AI that does not—or that cannot—ac -

complish its stated goals poses a real risk of, at best, 

waste and, at worst, causing harm or degrading de -

cisionmaking. 61  For example, software for predictive 

policing did little more than send police to the same 

areas where they historically made arrests, exacer -

bating biases and failing to actually “predict” any -

thing useful. 62  More generally, institutions hoping to 

leverage AI would do well to invest in audits and to 

ensure that those audits are effective. 63  Whether AI 

can accomplish a task assigned to it—when its use in 

an institution improves or degrades human agency 

and freedoms—depends on the alignment of the in -

stitution itself. If AI is leveraged to degrade human 

rights, coerce consumers or replace good jobs, it may 

be at odds with human development. 

The examples here cover common and estab -

lished uses of AI. Given the rapid change in the AI 

landscape, there has been equally fast adoption of 

opaque, less-explainable models in institutional sys -

tems. This may be intentional, such as relying on AI 

to synthesize reports in service of decisionmaking, or 

surreptitious, AI-written text, perhaps with halluci -

nated facts creeping into the decisionmaking process. 

As a first-order priority, institutions would do well to 

develop policies governing the use of AI and process -

es for delineating human- and AI-produced informa -

tion and temper excitement about new technology 

with careful and considered application. 

AI, humans and the physical world 

The rapid growth in AI’s capabilities, development 

and deployment results in a similarly dramatic in -

crease in how AI directly and indirectly learns from, 

interacts with and affects the physical world. AI can 

be fed information from any internet-coupled sensors CHAPTER  2 — F ROM  TOOLS  TO  AGENTS : R EWIRING  ARTIFICIAL  INTELLIGENCE  TO  PROMOTE  HUMAN  DEVELOPMENT  5 9 

to collect and respond to real-time data on traffic, 

weather, stock markets, wildlife or other domains. 

Such information can inform human decisionmaking 

or directly and autonomously result in actions affect -

ing the world. And AI systems can be embodied in 

robotic systems that enable them to interact with the 

physical world and accomplish tasks directly. 

# “ As with all digital technologies, AI 

is not without its direct impacts on the 

environment, climate and sustainability 

AI’s potential to buffer humanity in the 

Anthropocene offers promise and risks. AI is already 

helping detect sources of emissions, improve agri -

cultural efficiency, aid conservation efforts, improve 

weather prediction, promote renewable power pro -

duction and facilitate sustainability more general -

ly. 64  But it has also been applied to increase fossil fuel 

and cattle production—risking AI-increased rates of 

carbon emissions. 65  As with all digital technologies, 

AI is not without its direct impacts on the environ -

ment, climate and sustainability. 66  Models can be 

resource-intensive to develop and train. The informa -

tion technology infrastructure that supports AI comes 

with its footprint in the natural world, not just in terms 

of energy but also in the extraction of finite resourc -

es, water and rare materials. 67  When well-aligned 

with sustainable development, these indirect bene -

fits would ideally offset direct impacts. 68  But there are 

few guarantees that this will occur without active pol -

icy steps to reign in the ecological consequences of AI 

and harness its potential benefits. Indeed, AI seems 

to have reversed or stalled some companies’ pledges 

to reduce their environmental impacts. 69 

Beyond the natural world, AI is being readily inte -

grated into our infrastructure and civil services. As 

described earlier, advanced driver assistance systems 

in vehicles are becoming more commonplace, and 

AI-powered navigation systems offer emissions-ef -

ficient routes. The move towards smart cities lever -

ages AI to make sense of massive data from sensors 

and to inform policy—creating privacy concerns. 70  AI 

streamlines supply chains and powers more complex 

robots in factories and warehouses. 71  Governments 

are evaluating and deploying AI to help distribute 

key services to citizens. 72  Machine learning and AI 

are increasingly important in public health, from 

monitoring and managing pandemics to evaluating 

broader disease patterns. 73  And the impact of AI in 

economic contexts is widespread (chapter 6). 

Moving forward, we can anticipate increased AI 

integration in ways that directly affect our physical 

world or indirectly through informing and augment -

ing human decisionmaking. Impacts will range from 

intended consequences to unexpected externalities— 

and from clearly discernible development impacts to 

the uncertain and inequitable or those requiring dif -

ficult tradeoffs. While digitization’s impacts on the 

physical world date back a generation, applications of 

AI are distinct in that decisions with real-world con -

sequences will be increasingly made by agents whose 

behaviour is—to some degree—unpredictable and 

unexplainable. 

## AI-infused social networks: What 

## happens when AI makes choices 

## for, between and among us? 

Addressing many of today’s challenges depends on 

whether and how we collectively decide to act. These 

large-scale decisions emerge from how individuals 

access, interact with, share and act on information. 74 

Historically, our collective behaviour depended sole -

ly on the nature and structure of interactions be -

tween humans—face-to-face or through television, 

radio and other forms of mass communication. As 

described earlier, our collective behaviour is entering 

a new era where social networks will shape human 

decisionmaking and behaviour at scale, including 

various artificial forms of intelligence and decision -

making. 75  The situation today is without precedent in 

the history of our species and comes when we cannot 

afford further gridlock or degradation in the ability to 

manage interdependent crises and challenges. 

As we progress, it will be essential to anticipate, 

identify and manage how artificial intelligence af -

fects collective behaviour, which is a key determinant 

of our ability to improve human development. How 

might AI promote collective intelligence, break grid -

lock and steer our decisions towards sustainability, 

equity and human flourishing? How might it hold us 

back? What new interdependent challenges will AI 

introduce? These big questions will require continual 

re-evaluation as interactions between humans and AI 

evolve. 6 0 HUMAN DEVELOPMENT REPORT 2025 

AI can impact how we decide 

individually and collectively 

Scholars since Aristotle have recognized the potential 

for groups to outperform individuals in decisionmak -

ing. 76  Collective intelligence underscores motivations 

for democracies, juries, collaborative work and the 

convening of experts to solve challenges. 77  From a 

human development perspective collective intelli -

gence can provide individuals access to information 

and decisionmaking capabilities that exceed what in -

dividuals can feasibly achieve independently. More -

over, collective decisions are collective expressions of 

individual agency—arising from the many choices, val -

ues, needs and freedoms of individuals within a group. 

# “ Because many forms of AI are trained 

on large swaths of human-generated data, 

they can be seen as potentially aggregating 

knowledge across humans in their training set 

to produce collectively intelligent responses 

Broadly speaking, there are two ways in which col -

lective intelligence is harnessed in societal processes. 

The first involves attempting to elicit a collective -

ly intelligent decision from a crowd through voting, 

polls, prediction markets or other methods of ag -

gregating opinions. 78  Because many forms of AI are 

trained on large swaths of human-generated data, 

they can be seen as potentially aggregating knowl -

edge across humans in their training set to produce 

collectively intelligent responses. Researchers have 

begun to evaluate the potential for AI as stand-ins 

for human crowds in a process known as silicon sam -

pling. 79  Emerging evidence suggests silicon sampling 

produces responses similar to those of human par -

ticipants in contexts as varied as voting preferences, 

numeric estimation tasks and moral assessments. 80 

Similarities between the behaviour of AI and humans 

can reduce the costs of and expand access to polling a 

crowd while eliminating often exploitative platforms 

typically used to perform such assessments. 81  While 

promising, this application of AI to elicit collective in -

telligence requires some caution. AI cannot retrieve 

answers missing from its dataset. It can hallucinate, 

may not perform equally well across knowledge do -

mains and contexts and may exhibit cultural bias or 

degraded performance across cultural contexts. And 

accuracy in each context can be difficult to assess, 

predict or guarantee. 82  Finally, although AI may be 

able to summarize collective human intelligence, 

there is no reason to believe it is, itself, collectively in -

telligent (see box S1.2.1 in spotlight 1.2 in chapter 1). 

Where AI and silicon sampling alone are not believed 

to be sufficiently reliable, AI may be applicable for ag -

gregating information generated by a human crowd. 

Typical approaches to eliciting collective wisdom from 

crowds rely on voting strategies, averaging and other 

mathematical procedures. 83  While well-defined and 

studied, these forms of aggregation often require boil -

ing down complex decisions into simple sets of options 

or estimates. Large language models may facilitate col -

lective decisionmaking across more nuanced, natural 

language–based responses and surface features that 

might be missed when laying out options. 84  As these 

approaches improve, they may become valuable tech -

niques for collective decisionmaking, consensus for -

mation and eliciting feedback. 

Beyond top-down eliciting wisdom from crowds, 

collective intelligence also refers to processes that 

emerge from the bottom up. From the human de -

velopment perspective our collective decisions are 

manifestations of our individual agency. To the ex -

tent that AI can shape our choices as individuals, it 

is bound to have consequences for these impactful 

choices we make as groups. Examples of how col -

lective intelligence facilitates human development 

are wide-ranging. Individual decentralized contri -

butions over the years to Wikipedia have resulted in 

a remarkable compilation of knowledge. 85  More gen -

erally, constructing and maintaining the open-source 

software ecosystem are a remarkable feat of human 

collective intelligence. 86 

But collective intelligence is not a guaranteed feature 

of groups, and groups can equally become collective -

ly foolish or exhibit behaviour that is sensible in a mo -

ment but deleterious in the long run. Classic examples 

are market panics and mass hysterias. 87  Theoretical and 

empirical evidence suggest essential conditions are re -

quired to promote collective intelligence. Perhaps most 

fundamentally, at least some crowd members need ac -

cess to approximately accurate information. Diversity 

in knowledge, problem-solving strategies and expertise 

can be critical, enabling collectives to search for a more 

extensive set of possible solutions when identifying the 

optimal one. 88 CHAPTER  2 — F ROM  TOOLS  TO  AGENTS : R EWIRING  ARTIFICIAL  INTELLIGENCE  TO  PROMOTE  HUMAN  DEVELOPMENT  61 

Beyond diversity the structure of interactions be -

tween individuals can be a crucial determinant of 

success. The benefits of diversity can be lost when 

individuals holding conflicting opinions exist in echo 

chambers and cannot bridge the divide. 89  This rais -

es immediate concerns about engagement-optimiz -

ing algorithms that disproportionately show content 

aligned with individuals’ pre-existing beliefs or ac -

tively create conflict between groups. 90  And large, 

dense, highly connected networks that are common 

online can undermine collective intelligence and 

alter decisionmaking .91 

# “ Taken together, the likely impacts of AI on 

collective intelligence can be anticipated to be 

large, varied and highly dependent on whether 

collective intelligence is being elicited from 

a group or occurring naturally within it 

Taken together, the likely impacts of AI on collective 

intelligence can be anticipated to be large, varied and 

highly dependent on whether collective intelligence is 

being elicited from a group or occurring naturally with -

in it. In a sense, individuals with access to a large lan -

guage model are tapping into collective intelligence, 

enabling them to solve problems beyond their current 

capabilities. Asking questions beyond the training set 

or for which the model produces inaccurate responses 

may undetectably lead to the user to tap into collective 

folly. Yet, in general, AI will likely be a powerful tool 

for aggregating collective intelligence. While individu -

als tapping into collective intelligence through AI may 

improve their capabilities, doing so may homogenize 

information sources, reducing the diversity that emer -

gent collective intelligence depends on. And filter bub -

bles, asymmetric influences and dense connections 

within AI-defined social networks may alter and even 

reduce emergent collective wisdom that has long been 

a cornerstone of decisionmaking in democratic socie -

ties and institutions. 

Once collectives arrive at a solution, it is necessary 

to coordinate and act. Remarkable examples of suc -

cessful large-scale collective action range from rap -

idly responding to the depletion of the ozone layer to 

eradicating pathogens such as smallpox. 92  But failures 

to act are also common, as with climate change. A re -

cent survey of 62 countries indicated that belief in cli -

mate change is widespread globally (86 percent), as 

is support for policies to address climate change (72 

percent). 93  Yet despite this clear global support sub -

stantive progress in addressing climate change has 

been frustratingly slow, so there are big questions 

about whether, how and when AI will facilitate or hin -

der collective action. 

Will AI choose our culture? 

Collective intelligence and decisionmaking describe 

emergent properties of collectives that typically occur 

over short timescales. On longer timescales infor -

mation flows through collectives, giving rise to per -

sistent norms, beliefs, values, knowledge and other 

ephemera that shape cultures. The study of cultural 

evolution focuses on understanding how and why 

cultures change as cultural artefacts emerge, spread, 

fixate, dwindle and vanish. Cultural evolution un -

dergirds the success of our species, as ingenuity can 

be transmitted and refined, enabling us to adapt to 

changing conditions. 94  In the coming decades cultur -

al evolutionary processes will shape our response and 

adaptation to a rapidly changing world—and wheth -

er those changes sustainably and equitably promote 

human development. 95 

A key element of cultural evolution is the rate at 

which new culture emerges through innovation. Cou -

pling human social networks with AI is almost certain 

to influence the rate and way cultural innovations 

occur. For one, various forms of AI can create new 

cultural artefacts autonomously or in conjunction 

with humans. These can be the products of gener -

ative AI, strategies learned in self-play games or in -

novations such as novel drugs and facilitated insight 

into scientific problems (see box 2.1). 96  Even pure -

ly machine-generated cultural artefacts can diffuse 

into human culture, such as strategies learned by ma -

chines through self-play in the game Go, resulting in 

drastic differences in play among humans. 97 

AI can disseminate, sort, modify and filter cultur -

al artefacts when acting as an intermediary between 

humans. In a sense any data-trained model implicitly 

disseminates the cultural features of its training data. 

Often, training data are scraped from the open inter -

net so that the available data reflect the history of the 

digital divide and disproportionately represent indi -

viduals from high HDI countries. This can result in 6 2 HUMAN DEVELOPMENT REPORT 2025 

large language models adopting the cultural charac -

teristics found in their training set. One recent study 

found that responses by large language models were 

consistent with English-speaking, very high HDI 

countries such as Australia, Canada, New Zealand, 

the United Kingdom and the United States but cultur -

ally distinct from places such as Libya, Pakistan and 

Tunisia—with countries’ cultural differences from the 

United States correlated with how much ChatGPT 

reflects the culture of those countries (figure 2.4). 98 

Disaggregating these data by HDI level reveals that 

ChatGPT tends to more strongly reflect cultures in 

very high HDI countries and less resemble cultures in 

low HDI countries. This is unsurprising because areas 

that crossed the digital divide earlier left larger on -

line footprints for training these models. Thus, while 

technologies such as large language models may fos -

ter innovation, they may do so in a way that selective -

ly favours and reinforces views from countries better 

represented in their dataset. This risks new inequal -

ities whereby closing the digital divide may result in 

cultural homogenization and net decreases in cultur -

al diversity and innovation. 

## Preserving and expanding 

## human agency across scales 

Above, we laid out the dizzying myriad potential con -

sequences of AI for human development, impacting 

our agency and freedoms both individually and col -

lectively, now and in posterity. Against the breadth 

of possible impacts, the task of adopting AI in a way 

that preserves—much less expands—human agency 

can seem daunting. Even something as trivial and 

commonplace as a newsfeed recommendation can 

alter the information on which we base choices as 

individuals, with emergent consequences on dem -

ocratic outcomes and in posterity through cultural 

shifts. If such decades-old ranking algorithms convey 

these risks, what do we make of the newly expanded 

decisionmaking capabilities of large language mod -

els, or whatever technologies arise in the near term? 

This fundamentally changes the calculus as more 

powerful models come online, because they are not 

simply “better” but provide a wider range of possi -

ble outcomes for agency, ranging from promoting it 

to undermining it (see figure 2.2). In many cases the 

best form of AI for a given context may be some -

thing simpler that we can understand and that retains 

agency. In others the newfound capabilities—such as 

conversing in natural language—may provide ways of 

restoring and expanding agency (chapter 5). Although 

AI is no longer well understood as a tool, agenticity it -

self is a tool we can leverage when appropriate. 

This perspective is particularly salient when we 

consider the emergent consequences of embed -

ding AI into our social networks, from its impacts 

on collective decisionmaking in the here and now to 

Figure 2.4  Cultural differences from the United States explain the use of ChatGPT 

Correlation between GPT and humans Human Development Index group Cultural distance from the United States Low Medium High Very high 0.85 0.60 0.80 0.75 0.70 0.65 0.90 0.25 0.15 0.10 0.05 0.00 0.30 0.20 Correlation between GPT and humans 0.90 0.85 0.80 0.75 0.70 0.65 0.60 Egypt Viet Nam Thailand New Zealand Germany Australia Canada United States Netherlands Japan United Kingdom Singapore Andorra Uruguay Hong Kong, China (SAR) Argentina Cyprus Serbia Chile Rep. of Korea Jordan Indonesia Pakistan Libya Mexico Peru Nigeria Zimbabwe Türkiye Ethiopia Tunisia China Kazakhstan Iran Kyrgyzstan Malaysia Lebanon Philippines Iraq Armenia Morocco Ecuador Brazil Ukraine Russian Federation Guatemala Colombia Romania             

> Source: Atari and others 2025. CHAPTER 2 — F ROM TOOLS TO AGENTS : R EWIRING ARTIFICIAL INTELLIGENCE TO PROMOTE HUMAN DEVELOPMENT 6 3

longer-term impacts on cultural selection. If we cede 

our individual agency to unpredictable AI, we are roll -

ing the dice with human development at scale. How -

ever, if AI is designed in ways that promote human 

agency, we can ensure that humans can steer their fu -

ture according to their values, needs and goals. 

Although this chapter has largely dabbled in the ab -

stract, from it arise more concrete recommendations 

for deploying AI: 

1.  Start with simpler and more tool-like AI. These sys -

tems are more predictable,  readily explained and un -

derstood, and easier to modify so that our choices 

remain choices (see table 2.1). 

2.  Consider large-language models,  which hold promise 

as interfaces. Amid the captivating way in which 

these tools make broad-ranging choices, it is easy 

to lose sight of their linguistic capabilities and what 

that means for human development. Literacy and 

language barriers have befuddled expansion of the 

promises of digital tools, and these technologies in 

their current form are capable of drastically reduc -

ing these barriers. Choices of how to translate var -

ious words or how to convert speech to text likely 

minimally reflect one’s agency—such that adopting 

technologies to overcome these barriers seems im -

mediately doable and worthwhile. 

3.  Automate and change rarely; explain and verify often. 

Automation risks decisions being made and conse -

quences being accumulated at a rate that precludes 

humans from weighing in. Similarly,  benefits of nom -

inally “improving” AI on a task should be weighed 

against risks that changes will lead to different out -

comes than people expect. Designing systems so 

that humans can have time, if they choose, to inter -

rogate the choices the systems make, understand 

how the systems arrived at those decisions and 

verify the decisions before actions are taken can 

ensure that agency remains intact even if choices 

are automated. 

4.  Heed the scale of effects and cultural contexts. AI that 

is used by institutions or that impacts information 

flows between people can have outsized effects on the 

decisions we make and how those decisions shape our 

future. Scientific and regulatory attention should be 

paid especially to AI that sorts,  filters and summariz -

es the information we use to make decisions or that 

makes decisions for large swaths of individuals. 

5.  Do not ignore boring,  tedious and repetitive choic -

es, which may make the best use cases. Not every 

choice we make expresses our agency to a mean -

ingful extent—some are simply decisions we must 

make on the path to more important actions. AI 

already makes many of these choices for us—deter -

mining the fastest route to work, showing the cor -

rect spelling of a word, identifying and removing 

scams. More broadly capable AI, emerging every 

day, often gets coverage for its exciting possibil -

ities—but the boring AI may be among the most 

agency-expanding. 

These recommendations are nonexhaustive but 

illustrate the clarity provided by centring human 

agency rather than being distracted by the newest 

machine. This perspective further alleviates the need 

to predict what is next for these technologies, from 

stagnation to artificial general intelligence, and al -

lows us to face whatever comes next by simply asking 

how it can be leveraged to improve human agency. 

Perhaps most fundamentally, this perspective re -

stores human agency in a broad way—asking what we 

can choose to do now, rather than hoping something 

more agentic will come and choose for us. 6 5 

# C H A P T E R 

# 3

# Artificial intelligence 

# across life stages: 

# Insights from a 

# people- centred 

# perspective 6 6 HUMAN DEVELOPMENT REPORT 2025 

# People at each life stage use artificial intelligence (AI) 

# with varying frequency and for different purposes, 

# influenced largely by the institutions they are embedded 

# in. Nearly half of students and a quarter of working 

# people use AI-powered applications more than once 

# a week, primarily for education and work. In contrast, 

# only 15 percent of nonworking people and 9 percent of 

# retired individuals do so, mostly for entertainment and 

# health. These differences in frequency and purpose of 

# use shape the ways in which AI affects people’s lives. 

# The life stage perspective reveals three policy 

# imperatives—the “three I’s”—for advancing human 

# development: 

# Invest  in universal access to electricity, internet, 

# digital devices and the skills needed to use them 

# effectively. 

# Inform  people of the risks and opportunities of AI, 

# enabling them to make informed choices about when 

# and how to use it. 

# Include  people of all ages, genders, ethnicities and 

# backgrounds in AI design and development, and bring 

# firms into inclusive policy conversations on how to 

# make AI work for people. 

> CHAPTER 3

# Artificial intelligence across life stages: 

# Insights from a people- centred perspective CHAPTER  3 — A RTIFICIAL  INTELLIGENCE  ACROSS  LIFE  STAGES : I NSIGHTS  FROM  A PEOPLE - CENTRED  PERSPECTIVE  6 7 

From school computers and teenagers’ smartphones 

to work platforms and advanced imaging in health -

care, artificial intelligence (AI) now plays an integral 

role in digital technologies. But to what ends? To pro -

vide access to information about almost anything? 

To entertain people? To augment what humans can 

do and be? This chapter asks whether AI is helping 

expand people’s capabilities to fully realize their po -

tential. It provides insights from a people- centred 

perspective showing how AI is reshaping people’s 

lives across age groups, changing the way peo -

ple function and societies operate  —thus reshaping 

human development. 1

The frequency and purpose of AI use differs across 

people at each life stage. Almost half of students and 

a quarter of working people use AI-powered appli -

cations more than once a week—mostly for educa -

tion and work—while only 15 percent of nonworking 

adults and 9 percent of retired people do so, mostly 

for entertainment and health (figure 3.1). This is part -

ly because people are surrounded by institutions that 

vary in the ability to shape AI use. 2 With different use, 

people are affected differently: their freedoms are 

not always expanded, and at times they are exposed 

to risks and challenges. The life-stage approach dis -

entangles some of these effects to show how social, 

political and economic institutions can enable people 

to harness AI in ways that expand human develop -

ment. Within this approach the goal is not to analyse 

how using AI during one life stage affects the others —

because there is not yet enough evidence on this, es -

pecially for older people —but to zoom in on each life 

stage separately to derive policy options tailored to 

the challenges and opportunities of each age group. 

During early childhood excessive use of some 

digital technologies can have adverse effects on 

socioemotional development and basic functions 

—and can even alter brain development —with con -

sequences that may last a lifetime. For many young 

children, family or private daycare arrangements are 

the main institutional setting, making an overarch -

ing approach to protecting small children in line with 

the Convention on the Rights of the Child more chal -

lenging. This particularly vulnerable life stage needs 

regulation and the protections stipulated in the Con -

vention on the Rights of the Child from 1989. 3

When individuals are in school, AI can enhance 

learning opportunities and augment teachers’ and 

tutors’ work in many ways. Since school-age children 

spend considerable time in an umbrella institution, 

capability- enhancing uses of technology are easier 

to implement through school curricula and practices 

in the classroom. And AI-powered learning tools can 

foster equal opportunities for all students, including 

those with special needs. 

Students use AI frequently, mostly for education 

and entertainment (see figure 3.1). The teenage years 

involve substantial risk of overuse and even addic -

tion to digital platforms powered by AI algorithms 

optimized for engagement, potentially exacerbat -

ed by AI-supported dialogues and fake images. And 

with excessive use of social media platforms, there 

may be adverse effects on mental health, with risks 

of anorexia, depression and anxiety. Since students 

use these applications mostly in their free time, safe 

use depends mainly on oversight by families and 

other caregivers, potentially amplifying inequalities 

in society. 4 For social and emotional wellbeing, rapid 

responses from institutions have to keep up with 

technological developments. 

People in adult life have multiple overlapping identi -

ties, each involving different uses of AI. In profession -

al life AI may increase productivity and augment what 

workers can do, but if it is biased towards automation, 

it can also mean job losses for incumbents. Parents 

have a substantial role in modelling and teaching the 

responsible use of new technologies, and friends and 

partners may engage in synthetic relationships with 

AI-powered companions. Although adults also fre -

quently use AI for entertainment (see figure 3.1), they 

appear better equipped to regulate their emotions and 

behaviour, given their brain and body development. 5

Still, concerns remain about autonomy, authenticity 

and agency as recommender systems may shape pref -

erence formation and decisionmaking. 

Generally, older people who did not grow up with 

modern technology are more critical of AI and use 

it less frequently (see figure 3.1). Communication 

apps and promising AI-facilitated tools in the health 

sector, which older people use the most, can reduce 

social isolation and improve physical wellbeing, but 

older people’s needs and preferences must be part 

of these products’ design. Human connections and 

options, such as having the possibility of interacting 

with a person rather than an automated service, are 

keys to expanding their freedoms in this digital age. 6 8 HUMAN DEVELOPMENT REPORT 2025 

Which policies can help harness AI to expand human 

freedoms, enhance agency and foster human develop -

ment? The human development framework provides 

some guiding principles for decisionmaking. The chap -

ter identifies three policy imperatives for all life stag -

es: invest, inform and include. Investing in universal 

Figure 3.1  People at each life stage use artificial intelligence (AI) with varying frequency and for different purposes 

0Purpose of AI use by occupation group 10 20 30 50 60 40 Share of survey respondents (%) 

STUDENT WORKFORCE NON-WORKFORCE 13 

Never 

21 

a month Once 

20 

a week Once 

42 

once a week More than Frequency of AI use by occupation Share of survey respondents (%) 

4

Don’t know/ Prefer not to say 

RETIRED 55 

Never 

17 

Once a month 

11 

Once a week 

8

Don’t know/ Prefer not to say 

9

More than once a week 

39 

Never 

22 

a month Once 

14 

Once a week 

10 

Prefer not Don’t know/ to say 

15 

More than once a week 

30 

Never 

25 

Once a month 

17 

Once a week 

6

Don’t know/ Prefer not to say 

22 

once a week More than 

Education Work Health Entertainment 

Note:  Based on pooled data for 21 countries. For purpose of AI use, the follow ing responses to the question, “In the past 30 days, have you ever 

interacted with artificial intelligence, such as chatbots, in any of the following ways?” were used to calculate the average use of AI for work, educa -

tion, entertainment and health: “work” is based on the response “work-related tools or software,” “ed ucation” is based on the response “educational 

platforms of learning apps,” “entertainment” is based on the response “entertainment (e.g. streaming serv ices/gaming)” and “health” is based on the 

response “health care services or applications.” For frequency of AI use, the question was “How often have you used artificial intelligence tools such 

as ChatGPT, Google Gemini, Microsoft Copilot, etc., in the past 12 months?” and allowed for a single response. For occupation group the following 

responses to the question “What best describes you? Are you…?” were used: “working” includes self-identified full- and part-time employees and 

self-employed respondents, and “not working” includes homemakers and unemployed respondents. 

Source:  Human Development Report Office based on data from the United Nations Development Programme Survey on AI and Human Development. CHAPTER  3 — A RTIFICIAL  INTELLIGENCE  ACROSS  LIFE  STAGES : I NSIGHTS  FROM  A PEOPLE - CENTRED  PERSPECTIVE  6 9 

electricity, internet devices and digital skills can ex -

pand individual capabilities by facilitating access to AI 

and the ability to use it effectively. Informing people of 

when and how to use AI can expand their functionings 

and help them fully realize their potential. Including 

people of all ages, genders, ethnicities and backgrounds 

can allow them to align their choices with their values 

and thus exercise their agency (figure 3.2). 

## Early childhood  —  too 

## little, too much, too risky 

The impact of digital technologies 

on early childhood development is a 

topic of hope and concern as societies 

around the globe become more digitally connected. 

The effects of screen time  —associated with many AI 

Figure 3.2  Invest, inform and include for people-centred artificial intelligence (AI) 

INFORM INCLUDE INVEST in universal access to digital devices and AI in classrooms. about potential biases in AI systems and prevent the stifling of creativity and critical thinking. responsible use of AI in school curricula, emphasizing skill development. 

INFORM INCLUDE INVEST in public-private partnerships to make AI-powered social media safe for adolescents. about AI-powered social media’s addictive features and susceptibility to social comparison. adolescents in the critical evaluation of social media and other AI-powered products. 

INFORM INCLUDE INVEST in subsidies for companies that offer human options to make sure nobody is left behind. about role modeling responsible AI use to influence future generations. explanations about how AI products and algorithms work to strengthen adults’ agency. 

INFORM INCLUDE INVEST in AI technology that protects children’s rights in the digital space. parents, paediatricians and caregivers about risks related to young children’s digital technology use. the private sector in working groups on children’s rights and protection. 

INFORM INCLUDE INVEST in access, training and support for older adults to empower them to navigate AI applications. older people about AI innovations, highlighting applications in their areas of interest. older people in the development of AI products so that their needs are adequately reflected.  

> Source: Human Development Report Office. 70 HUMAN DEVELOPMENT REPORT 2025

applications used by toddlers  — can be both positive 

and negative for young children’s emotional, cogni -

tive and physical development. The type of activity 

and its duration determine the actual impact. Very 

young children spend most of their time at home with 

family members or in private daycare. 6 So, ensuring 

that AI technologies are development enhancing is 

essential; otherwise, the consequences for brain de -

velopment can be severe. Indeed, impaired brain 

development can limit human freedoms through -

out life, impeding choices, capabilities, agency and 

thus human development. And even without screen 

time children’s vulnerability is reflected in the online 

sphere, multiplied by new AI-powered tools (box 3.1). 

Young brain structures change 

with too much screen time 

Toddlers’ use of AI often involves a screen, and in -

teractive screen time can deliver benefits. For exam -

ple, the right software and environment can improve 

early childhood learning, including vocabulary, nu -

meracy and digital skills that improve later academ -

ic performance. 7 But these benefits occur only when 

used for a very limited amount of time. 

Excessive screen time can lead to a range of de -

velopmental issues, especially emotional and behav -

ioural problems, such as hyperactivity, low attention 

span and peer problems. 8 It can also lead to delayed 

developmental milestones, impaired motor skills 

and decreased executive functioning —higher cog -

nitive processes that help with planning, organizing, 

problem solving and self-regulation. And it can lead 

to inappropriate conduct, reduced physical activity, 

poor language skills and limited vocabulary, especial -

ly at a very young age. 9 Vocabularies can be assessed 

through cognitive testing and monitored using diffu -

sion tensor imaging, which visualizes brain changes 

associated with excessive screen time (figure 3.3). 10 

Violent video games are a major risk, since they can 

exacerbate aggressive behaviour, reduce empathy 

and diminish prosocial behaviours. 11 

Most findings come from local or national studies 

because of a dearth of globally comparative data on 

developmental milestones. Attention- deficit/hyper -

activity disorder (ADHD), diagnosed according to 

similar criteria all over the world, is used as a proxy 

for hyperactivity and low attention spans in children. 

And although ADHD is more complex, including 

other symptoms such as impulsiveness, 12  its prev -

alence across countries can shed some light on the 

relation between screen time and ADHD symptoms. 

Several recent studies suggest that, in addition to ge -

netics and other behavioural factors, excessive screen 

time during early childhood can play a role in ADHD. 

But children with ADHD might be granted more 

screen time because their condition makes supervis -

ing them more challenging. 13 

The implications of excessive screen time and lack 

of access to screens on the brain development of fu -

ture generations both seem profound. Examples 

Figure 3.3  Excessive screen time in early childhood is related to changes in the brain structure — and to reduced 

language capacity and understanding 

Lower fractional anisotropy Higher radial diffusivity                               

> Left Front Right –3.5 –4.0 –4.5 –5.0 –5.5 –3.0 –6.0 ΔFA per ScreenQ Point
> Left Front Right 7.5 7.0 6.5 6.0 5.5 8.0 3.5 ΔRD (mm 2/s) per ScreenQ Point 4.0 4.5 3.0 5.0 ×10 –3 ×10 –6
> Note: The figure depicts diffusion tensor MRI scans of preschoolers’ brains that show the decline in fractional anisotropy and the increase in radial
> diffusivity, both of which are crucial for language understanding and capacity, as screen use rises. Darker colours indicate more change. Screen use
> is measured by ScreenQ, a 15-item measure of screen- based media use reflecting the domains of the American Academy of Pediatrics recommenda -
> tions: access to screens, frequency of use, content viewed and coviewing. Higher scores reflect greater use.
> Source: Hutton and others 2020. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 7 1

Box 3.1  Artificial intelligence can violate children’s rights — or protect them 

Online child sexual abuse can take several forms, from sharing sexual images or videos to online solicitation consisting of 

unwanted or pressured sexual interactions. 1 Such abuse is common even in regions with low access to digital technologies 

(box figure 1)  —  and sharply on the rise in many African countries. 2 While solicitation is more common among adolescents, most 

image- based abuse (around 85 percent) affects prepubescent children, including infants and toddlers. 3 The younger the child, 

the more severe the abuse. 4 The majority of images show female children. 5 Abusive images are refined and reproduced by 

artificial intelligence (AI)–powered apps, multiplying the violations of children’s rights. 6

Box figure 1  Online child sexual abuse occurs even in regions with low access to technology 

0510 15 20 25 North America Western Europe Eastern Europe and Central Asia Middle East and North Africa aWest and Central Africa Eastern and Southern Africa Latin America and Caribbean South Asia aEast Asia and Pacific Solicitation Image-based abuse Children under age 18 affected in the past year, 2024 or most recent year available (%)   

> a. Data on solicitation are not available.
> Note: Image-based abuse includes all nonconsensual taking and sharing of sexual images and videos of a child, as well as unwanted exposure of a child
> to pornographic materials. Solicitation covers a range of unwanted and pressured sexual interactions, including sexual inquiries over mobile phones or
> the internet, as well as long-lasting sexual conversations that can lead to exchanges of sexual pictures or videos.
> Source: Human Development Report Office using data from Childlight (2024).

AI can allow the massive production and dissemination of material that violates children’s rights, including fake images 

and AI- generated images based on “famous” abuse victims. 7 But it can also augment humans’ analysis of images and video 

to flag potentially harmful content for further review. 8 Unlike hashing technologies that rely on exact data matches, such as 

PhotoDNA, 9 AI algorithms are adaptive and can be trained to detect harmful images by recognizing patterns in the data. 10  This 

approach can increase the detection rate of harmful content over human intervention alone and helps prevent the repeated 

sharing of prohibited images, thus reducing the revictimization of the children depicted in the content. 11  AI-facilitated tools can 

also assist in identifying and tracking perpetrators. By analysing patterns of online engagement, AI algorithms can provide 

useful information to locate creators and distributors of harmful material. 12 

Article 4 of the United Nations Convention on the Rights of the Child obliges signatories to introduce laws and regulations 

that prevent companies from infringing on children’s rights, to monitor their compliance and to ensure effective enforce -

ment and remedies for child rights violations. 13  The United Nations Guiding Principles on Business and Human Rights and the 

Children’s Rights and Business Principles provide a framework to meet responsibilities towards children’s rights. 14  The Global 

Digital Compact solidifies states’ commitment to protect children’s rights in response to emerging technologies and their as -

sociated opportunities and risks. 15  Governments and private companies should collaborate and invest in AI-facilitated tools to 

augment humans in detecting and deleting content harmful for children.                             

> Notes
> 1. Childlight 2024. 2. ChildFund International and African Child Policy Forum 2024. 3. INHOPE 2023. 4. ECPAT and INTERPOL 2018. 5. In one sample as
> much as 99 percent of images were of girls (IWF 2024). See also ECPAT and INTERPOL (2018). 6. IWF 2024. 7. IWF 2024. 8. Amlani 2024; Anglia Ruskin
> University 2024; Child Rescue Coalition 2024; Grzegorczyk 2023; IWF 2023, 2024; Krishna, Dubrosa and Milanaik 2024; Singh and Nambiar 2024;
> US Department of Homeland Security 2024. 9. Allen 2011. 10. Grzegorczyk 2023. 11. Allen 2011; Fry 2024; Grzegorczyk 2023. 12. Grzegorczyk 2023.
> 13. Pothong 2025; United Nations 1989a. 14. UNICEF 2012; United Nations and UNOHCHR 2011. 15. United Nations 2024. 7 2 HUMAN DEVELOPMENT REPORT 2025

from countries that have had widely diffused digital 

technologies for years can make evidence-based in -

formation more compelling, generating important 

messages for policymaking in countries where digital 

technologies are not yet as widely available. 

As digital access expands globally, a task for gov -

ernments is to roll out campaigns that inform par -

ents, paediatricians, teachers and other caregivers 

about the adverse effects of excessive screen time. 

Screens are sometimes used when parents are actual -

ly in need of childcare  —for example, when they are 

working remotely or busy with other tasks around the 

house. This should reinitiate a conversation about af -

fordable and flexible childcare. Community-level 

programmes can offer valuable alternatives, with 

flexible times and signups. 

## School age  —  access, 

## regulation and ownership 

Whether AI benefits or harms school-

age children depends on how institu -

tions regulate and inform their use. 

Access to the internet has helped advance children’s 

learning in recent years. But since AI has come into 

play, new and challenging questions have emerged. 

What about the risk that children who use AI for 

schoolwork lose out on interpersonal skill develop -

ment? Since most school-age children are enrolled 

in some type of formal education, social and politi -

cal institutions have a more direct influence on their 

technology use, which makes it easier to mitigate 

risks and enhance benefits. 

AI in the classroom — inequality 

rising, declining or both? 

AI’s potential for expanding students’ capabilities 

through education is becoming more evident for 

those who have access to it. AI-powered apps can 

provide study assistance when educators or parents 

face time or resource constraints. 14  They can gam -

ify the study experience to motivate students. 15  And 

they can improve personalized learning by tailoring 

educational content to individual student needs and 

predicting their next learning steps. 16  AI could thus 

level the playing field for disadvantaged students 

and bridge education gaps in the light of constrained 

resources. Fascinating advances have also been 

made in using AI to support disadvantaged students 

(box 3.2). It also holds promise in aiding interventions 

to reduce school dropout rates, especially in low-

income countries, where such rates are high. 17  For 

that, however, universal access to digital technologies 

is paramount. 

Inherent biases in AI systems, particularly from 

the perspectives and backgrounds of their devel -

opers, can exacerbate inequalities between racial, 

ethnic and religious groups. 18  There are also ethical 

concerns about privacy, security and responsible AI 

use. 19  At the AI Academy in Tajikistan, 20  students and 

teachers developed a machine learning–based credit-

scoring product for microloans that outperformed 

scoring systems used by other banks in the region. 21 

But AI in credit scoring raises concerns about data 

privacy, potential algorithmic bias and lack of trans -

parency in decisionmaking. Ethical considerations 

of fairness, accountability and responsibility also re -

quire careful attention. 22 

Constant vigilance and policy attention to embed -

ded biases can prevent discrimination. By purpose -

fully building and deploying AI-powered tools with 

these considerations in mind, the benefits can be har -

nessed without unintentionally increasing exclusion. 

And what happens to skills? 

While AI has the capacity to tailor learning experi -

ences to individual student needs, concerns have 

emerged about its potential to stifle creativity and 

other essential skills. AI could facilitate overempha -

sis on standardized testing and overshadow crucial 

abilities such as creativity, collaboration and critical 

thinking. 23  Some of these soft skills, also linked to 

emotional intelligence, will become more important 

as AI becomes better at routine text and data analysis. 

Using AI-powered chatbots for schoolwork could 

also undermine opportunities to learn skills such 

as analysing text, elaborating syntheses and writ -

ing coherent narratives. The writing process stimu -

lates thinking, scrutinizing and self-improvement, 

tasks that all students should learn. But when it is 

outsourced to AI-facilitated tools (cognitive offload -

ing), the reduction in cognitive effort can reduce CHAPTER  3 — A RTIFICIAL  INTELLIGENCE  ACROSS  LIFE  STAGES : I NSIGHTS  FROM  A PEOPLE - CENTRED  PERSPECTIVE  7 3 

memory retention and diminish learning and cogni -

tive abilities. 24  Learners may remember only where 

they stored information but fail to integrate it into 

their brain’s secondary knowledge. This can create an 

illusion of having learned the information, increasing 

the risk of memory manipulation or corruption. 25 

Increasing or perpetuating inequalities is also a 

risk. Since individuals who believe they have a lim -

ited memory capacity tend to offload information 

more frequently, their knowledge deficit can widen, 

possibly reducing their learning performance over 

time. 26  Even students are worried that AI-powered 

Box 3.2  Levelling the playing field for disadvantaged students 

Innovations in artificial intelligence (AI) could boost the capabilities of students facing disadvantages during their 

education journey. Migrant children, for example, can face language barriers and different stages of learning when 

joining their host country’s education system. 1 AI has addressed both, offering real-time voice- activated translations 

and individually tailored educational resources, translated into several minority languages. 2 Similar tools can be used 

in refugee camps to adapt instructions to individuals with diverse education backgrounds, though major challenges 

include children’s digital illiteracy and the costs of running AI-powered programs. 3

An educational platform in Kenya uses AI- facilitated adaptive learning engines to assess student performance and 

provide tailored lessons in several languages (box figure 1). It has reached more than 20,000 children, 4 even students 

without access to the internet, with personalized lessons, questions, remedial learning and evaluation through SMS. 5

The platform reduces language barriers by including minority languages not typically covered in the standard educa -

tion curriculum and languages spoken by refugees from neighbouring Somalia and South Sudan. 6 It operates in the 

most challenging learning environments, such as slums in Nairobi and the rural Dadaab refugee camp. 7 It also offers 

microcourses on business and entrepreneurship for youth and adult refugees and courses on employability skills for 

youth with physical, hearing and visual impairments. 8

This and similar platforms rely on collaboration and funding from international organizations, development agen -

cies and nongovernmental organizations to purchase and distribute its products. Public-private partnerships are 

essential to deploy these technologies where they are needed most. 

Box figure 1  Artificial intelligence tailors lessons, even for students without internet access                

> Source: Human Development Report Office, adapted from M-Shule (2023b).
> Notes
> 1. Drolia and others 2022. 2. UNESCO 2019. 3. Tzirides 2022. 4. UNESCO 2022. 5. UNESCO 2022. 6. M- Shule 2023a. 7. UNESCO 2022.
> 8. M- Shule 2023b. 74 HUMAN DEVELOPMENT REPORT 2025

chatbots, although convenient, diminish their writing 

skills and hamper their motivation and drive to com -

pose on their own. 27 

Concerns about calculators diminishing math 

skills were similar. Released to the public in the early 

1970s, the first handheld calculator was expensive. 

Once readily available in all classrooms (around 1980 

in the United States), mathematics achievement was 

expected to decline  —this was  not the case, howev -

er; it even improved slightly (figure 3.4). 28  The rea -

son is believed to lie in the level at which calculators 

are used in school —usually not earlier than middle 

school, when fundamental mathematics skills should 

have already been acquired. After this milestone 

using a calculator can lead to higher student achieve -

ment. 29  The implication could be the same for AI-

powered chatbots: once students have acquired basic 

writing and text analysis skills, the chatbots could im -

prove the learning process through review and feed -

back, accompanied by a teacher or other caregiver. 

However, a base of knowledge is required for the 

brain to refer to during creative or critical thinking. 

These higher- order thinking skills are essential for 

problem solving and can be developed only if the 

brain can retrieve facts and figures from past learning 

processes. 30 

And to social interactions? 

If used excessively in education, AI can put at risk 

valuable human connections and the sense of com -

munity in the learning process. 31  Since machines lack 

the empathy hormone, oxytocin —which can “cou -

ple two brains” in such a way that they are linked 

to each other, making learning more efficient —AI 

is biologically unable to perform some features of 

teaching. 32  This is one of many reasons why teach -

ers cannot be substituted for or even replaced by AI 

(chapter 1). Instead, AI-powered apps and programs 

Figure 3.4  Mathematics achievement in the United States did not decline after calculators became available in 

the classroom    

> 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 2012 2008 2004 1999 1996 1994 1992 1990 1986 1982 1978 1973 306 298* 300* 304 306 307 308 307 306 307 305 302* 305 281* 269* 264* 266* 285 281* 276* 274* 274* 273* 270* 269* 279* 243 219* 219* 219* 244 241 232* 231* 231* 230* 230* 222* 239*

Scale score Age 9 Age 13 Age 17 Revised assessment format Extrapolated data Original assessment format                 

> *Significantly different from the 2012 value at p< .05.
> Note: Extrapolated data adjust for the limited number of questions that the 1973 mathematics assessment had in common with later assessments.
> Original assessment format uses the same assessment procedures established for the first assessment year. Revised assessment format incorporates
> more current assessment procedures and content.
> Source: US National Center for Education Statistics 2013. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 7 5

can be complementary tools under close teacher 

or caregiver supervision or can help teachers with 

other tasks, allowing more time for student interac -

tion (chapter 2). As AI continues to permeate educa -

tion, its benefits and potential drawbacks should be 

continually monitored by interdisciplinary teams of 

educators, neuroscience researchers, policymakers 

and other stakeholders to ensure that future genera -

tions are well- equipped for a world increasingly inter -

twined with technology. 

Some concerns about children’s interactions with 

different forms of AI are similar to more traditional 

concerns about the use of digital devices — for example, 

substituting offline activities such as playing togeth -

er outside with social interactions in the online space, 

as well as disinformation and security of personal in -

formation, especially in the light of sophisticated and 

adaptable AI-powered conversation partners. 33  Other 

concerns are specific to the new possibilities of inter -

acting with AI, such as developing social etiquette. 

Digital assistants do not yet teach good manners 

or require politeness, so children may eventually get 

used to an undesirable form of communication when 

interacting with humans. 34  Again, that is why digital 

technologies should complement but not substitute 

for humans, especially around children. The good 

news is that when interacting with digital voice assis -

tants, children identify them as machines and sourc -

es of information, at best as social learning partners, 

but do not accord them the same value as humans. 35 

Children reveal less information when interacting 

with the devices and are more influenced and en -

gaged when interacting with humans. 36 

Social interaction is at the core of human learning, 

since problem-solving skills are greatly improved 

through implicit communication, such as imitating 

others. Correctly interpreting others’ mental state to 

understand their knowledge and intent is a major fac -

tor in wellbeing and in the ability to navigate the world 

of work, whether in the labour market or personal af -

fairs. It is best learned when practiced with empathetic 

human beings. 37  An experiment in a nature classroom 

showed that students who had been away from screens 

for five days improved their recognition of nonverbal 

emotional and social cues more than their peers who 

had not been away from screens. Time away from 

screen-based media and digital communication tools 

improved both emotional and social intelligence. 38 

## Adolescence  — 

## smartphones, AI-

## powered apps and 

## mental wellbeing, much 

## ado about nothing? 

Although most adolescents still participate in some 

form of official schooling, this stage of life deserves a 

separate section from school age, given the profound 

neurobiological, behavioural and environmental 

changes that affect how adolescents interact with AI-

powered apps. 39 

Buzzing controversies among researchers, poli -

ticians and caregivers have emerged about wheth -

er smartphones have a negative impact on young 

people’s wellbeing. Empirical evidence points to a 

concerning decline in subjective wellbeing, which 

is also reflected in a rise in indicators that measure 

mental disorders, such as anxiety and depression. 40 

The effect has been particularly strong for young 

women. 41  The sharp decline in wellbeing has altered 

what was commonly known as the U-shaped curve 

of wellbeing throughout the life course: life satisfac -

tion was highest at young age, then dipped during 

middle age and rose during old age (spotlight 3.1). 42 

These changes have gone hand in hand with the in -

creasing use of smartphones among the wider public, 

especially in countries with very high Human De -

velopment Index (HDI) values, although the causal 

mechanisms underlying this relationship are not fully 

established. 43 

Less is more, and quality matters 

What lies behind this association? Should parents try 

to ban smartphones during adolescence altogether? 

The evidence is mixed, partly because not all stud -

ies disaggregate for age, which seems to be crucial 

for the effects of smartphones on wellbeing. 44  AI al -

gorithms that make recommendations on social plat -

forms based on online behaviour and optimized for 

engagement have addictive potential. And that can 

trigger sleep deprivation, pervasive social compar -

isons, lack of physical exercise and social isolation 

caused by tradeoffs between time spent online and 

time spent socializing in person, leading to a decline 

in wellbeing. 45  Excessive use of certain social media 76 HUMAN DEVELOPMENT REPORT 2025 

increases upward social comparison, which reduces 

subjective wellbeing indicators such as life satisfac -

tion, self-worth and self- esteem. 46  And even in the 

absence of addiction or enjoyment, young people 

may feel pressured into using certain platforms, be -

cause most of their peers do (spotlight 3.2). 

Since adolescents are especially vulnerable to 

socioemotional disorders given the developmental 

changes in behaviour, cognition and neurobiology 

occurring at their age, they are also more suscepti -

ble to social comparison, modifying self-images, so -

cial feedback, stress and reward mechanisms. 47  With 

the development of increasingly sophisticated AI 

technologies, several facets of social media can be 

especially perilous for adolescents —particularly for 

young women, who are often more susceptible to so -

cial comparison and idealization of body images than 

their male counterparts (box 3.3). Moreover, specific 

characteristics of the digital environment contribute 

to online disinhibition, leading individuals to exhib -

it different behaviours, thoughts and emotions in on -

line interactions compared with in-person settings. 48 

All of this points to the need for careful evaluation of 

the effect of smartphone use, especially social media, 

on wellbeing among adolescents. 49 

But other factors —such as genetics, a lack of strong 

relationships or adverse childhood experience, in -

cluding abuse, neglect and trauma  — are at least 

equally strong determinants of mental health and 

wellbeing. 50  A complementary explanation for de -

clining mental wellbeing in the past five years could 

be related to the Covid-19 pandemic. Recent brain 

images from adolescents reveal accelerated cortical 

thinning —a sign of a maturing brain —more notable 

in females than in males (figure 3.5). This process 

is attributed to chronic stress and adversity during 

development, a hint at the life disruptions during 

lockdowns. Cortical thinning, while not necessarily 

bad, is associated with higher anxiety and depression 

rates. The difference between males and females can 

be accounted for by females’ stronger social connec -

tions and reliance on sharing stress-related events 

with peers. 51 

Some online activities that use AI algorithms, such 

as educational programs and music apps, can be ben -

eficial without being addictive. 52  Young people who 

already have mental health issues use their phones, 

or the internet in general, more often and in different 

ways from their peers. 53 

The bottom line: not all adolescents will neces -

sarily develop depression or anxiety when exces -

sively using a smartphone or being on social media. 

Young people with pre- existing mental health issues 

or vulnerabilities are more likely to do so, especial -

ly when using social media with AI-powered recom -

mender systems. 54  Screen access should always be 

Figure 3.5  Pandemic- related stress is a complementary explanation for adolescents’ mental illbeing 

Female cortical thinning Male cortical thinning              

> Note: Regions with significantly accelerated cortical thinning in the adolescent female and male brains after the Covid-19 pandemic are shown in
> colour.
> Source: Corrigan, Rokem and Kuhl 2024. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 7 7

Box 3.3  Artificial intelligence on social media undermines agency and drives emotions — but only for some young 

people so far 

The growing prevalence of social media recommender systems optimized for engagement based on online behav -

iour; of AI- powered photo filters, chatbots and editing tools; and of artificial intelligcen (AI)– generated content such 

as deepfakes poses potential risks to mental wellbeing. The risk is especially high for young people, as they are the 

primary users of social media and are more vulnerable to peer pressure than other age groups. 1 Problematic social 

media use is a strong predictor of psychosomatic complaints and low life satisfaction in 15-year-olds across 37 coun -

tries.  With excessive social media use, the odds of having psychosomatic complaints rise by about 39 percent, and 

life satisfaction falls by 33 percent. 2 Even so, some aspects of social media — such as searching for peer support, using 

platforms as creative outlets and improving connectedness to friends — have positive effects on mental wellbeing. 3

Social media recommender systems optimized by AI for engagement based on online behaviour provide a passive 

audience experience, undermining users’ agency to curate the content they consume (chapter 5). These algorithms 

can drive emotions by determining the content users are exposed to. 4 The best example is doomscrolling, a relatively 

new concept that describes the habitual search for negative news on social media. Once started, AI algorithms will 

automatically show doomscrollers more and more negative news and content. Doomscrolling is associated with 

lower indicators of mental wellbeing and life satisfaction. 5

It can destroy relationships… 

AI- generated deepfakes in online cyberbullying and harassment among young people are on the rise and have 

already damaged relationships among peers. AI can generate realistic-looking images of a person and place them 

into fake settings. 6 Cyberbullies have used deepfakes to superimpose images of teenagers into inappropriate set -

tings, making it look as if they were nude, drinking underage and vaping. 7 This purposefully misleading content can 

cause fear, helplessness, suicidal ideation and other mental health issues, especially among young women. 8 The 

newly adopted Artificial Intelligence Act by the European Union promises regulation of deepfakes, which will have to 

be labelled as such, once fully implemented and enforced. 9

and trigger mental health issues… 

The growing popularity of AI photo filters producing “thinspo” (inspirational images promoting an “ideal” body type) 

create unrealistic beauty standards and body dysmorphia.  Together with discussion threads and AI-generated harm -

ful information on overly restrictive diet plans, vomiting-inducing drugs and other techniques, vulnerability to eating 

disorders has increased substantially. And although safety features are improving, so-called jailbreaks (inserting 

words and phrases to bypass safety features) still allow access to the most harmful content with relative ease. 10 

Discussions have also glamourized depression, suicide and other mental health issues. 11  Subcultures and niche 

communities have emerged, using codewords to overcome flagging from social media platforms. In just 36 minutes, 

a bot that interacted with videos centred around depression was shown a TikTok feed where 93 percent of content 

was sad or depressive. 12  Although most social media firms are making efforts to hide or delete potentially harmful 

posts, more work is needed to make them more effective. On average, only 15 percent of reported posts with suicidal 

or self- harm content are deleted, revealing widespread noncompliance with the EU Digital Services Act, which aims 

to protect young people from harmful content on social media. 13 

but has done so only for some young people so far 

So far, young people in many low- and middle-income countries have been mostly spared these detrimental effects 

because internet use remains very limited (box figure 1). 14  But if the current trend of swiftly increasing usage persists, 

it is only a matter of time until young people in these countries catch up (box figure 2). So, the harmful effects of 

social media on young people will also expand, most likely more than proportionally, because people with internet 

access in low- and middle-income countries spend more time on social media than their counterparts in high-income 

countries. 15  There is thus a unique learning opportunity for lower-income countries to skip some of the detrimental ef -

fects of AI-powered social media by providing information about risks and guiding the purpose and frequency of use. 

(continued) 7 8 HUMAN DEVELOPMENT REPORT 2025 

limited to certain times of the day to avoid crowding 

out healthier activities such as sports, music, creative 

and nature-based activities and in-person interaction 

with friends and family. 55 

Teach, fund and collaborate with the private sector 

Empowering young people to use AI wisely and feel 

ownership of their digital experience is a challenge. 

While schools and other educational institutions 

cannot control the content of apps or time spent on 

smartphones outside school hours, they can double 

down on teaching responsible and metered use. In -

cluding AI, algorithms and social media use in school 

curricula is key to empowering young people to ben -

efit from technological advancement, not suffer from 

it. Considering rapid technological change, curricula 

need to be constantly updated and teachers trained to 

cover the most recent developments —such as deep -

fake images and AI-generated dialogues, which can 

be difficult to detect, even for adults. 56  Policymakers 

could work on regulations for labelling AI-produced 

content. 

In some cases, AI can help protect young people 

and their interactions in the digital space. For in -

stance, an automated classification model can identi -

fy cyberbullying by analysing text on social media 

with the help of a deep decision tree classifier. 57  And 

plugins can educate young people on the critical and 

Box 3.3  Artificial intelligence on social media undermines agency and drives emotions — but only for some young 

people so far  (continued) 

Box figure 1  Most young people in high- and 

middle-income countries use the internet… 

Box figure 2  …but others will catch up soon if 

trends persist 

020 40 60 80 100 2020 2010 2000 1990 Internet users (% of population) Middle East & North Africa Europe & Central Asia North America South Asia Sub-Saharan Africa Latin America & Caribbean East Asia & Pacific 020 40 60 80 100 High income Upper middle income Lower middle income Low income Internet users (% of population ages 15–24) 98.0 96.4 70.9 44.8                                           

> Note: Data are for the most recent year available.
> Source: Human Development Report Office using data from
> ITU (2024b).
> Source: Human Development Report Office using data from
> World Bank (2024a).
> Notes
> 1. Shah and Bilal 2022. 2. Walsh and others 2020. 3. US Office of the Surgeon General 2023. 4. Kang and Lou 2022. 5. Satici and others 2023.
> 6. Hinduja 2023. 7. Hinduja 2023. 8. Laffier and Rehman 2023. 9. European Parliament 2023a, 2023c. 10. Bahnweg 2023; CCDH 2023. 11. Ahuja
> and Fichadia 2024; Bahnweg and Omar 2023. 12. WSJ Staff 2021. 13. Tagesschau 2023. For more detailed information, see three studies carried
> out by Reset (2023). For more information on the Digital Services Act, see European Parliament (2023b). 14. ITU 2024b. 15. Datareportal 2024. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 7 9

responsible use of social media. Virtual learning 

companions can help young people detect risks and 

toxic content, building cybercourage and resilience. 58 

Creating universal access to these protective technol -

ogies is an essential task for policymakers, working 

closely with private companies. Public-private part -

nerships could help, as could subsidies for innovative 

technologies. Funding with strings attached can in -

centivize the development of products that foster 

young people’s wellbeing, especially when working 

with smaller tech companies and startups. 

## Semi- autonomous 

## adulthood  —  with 

## overlapping identities 

Following Amartya Sen’s concept of 

“plural identities,” people are not re -

ducible to one single identity. 59  They are employees 

or entrepreneurs, spouses or partners, consumers 

or vendors, friends or neighbours  — and most like -

ly combine these identities in different ways. So, 

their experience with and use of AI is also multifac -

eted, as they act and interact in a variety of institu -

tional settings. For employers and entrepreneurs AI 

can boost productivity by either increasing product 

innovation or making production processes more 

efficient but could put jobs at risk if there is a bias 

towards automation (chapter 6). Depending partly 

on policy choices, AI can either compromise or sup -

port worker agency (spotlight 3.3). In their identity 

as partners, adults may choose a relationship with AI 

over one with a human, casting a toll on mental well -

being (box 3.4) and family structures. As consumers, 

they may struggle with automated systems or face 

identity theft or financial fraud facilitated by AI. 60 

And as parents, their digital behaviour shapes future 

generations. The key here is that in all their identi -

ties people need to have choices to be able to act on 

their beliefs and values (agency) to fully realize their 

potential. 

Keep in mind that many adults still lack access to 

the internet. While some AI-powered apps can be 

used without internet access, the most common 

ones that are accessible in a massified way, such 

as AI-powered chatbots, require stable broadband 

connections —an option that many poor people with 

low levels of education lack (figure 3.6). 

Agency under attack? 

A necessary condition for human development is 

that people can make choices aligned with their val -

ues and beliefs and can act on them, a principle sum -

marized in the concept of agency. When beliefs and 

values are formed more or less independently, they 

are authentic to that person (authenticity). 61  If that 

person has the capacity and the authority for self-

government, we can speak of autonomy. 62  And if that 

person is then able to execute their autonomy and act 

on their beliefs and values, we can speak of agency 

(figure 3.7). Just as individual conversion factors de -

termine how resources are transformed into capabili -

ties and functionings, 63  conversion factors also shape 

how authenticity and autonomy are translated into 

agency. 64  Agency is key to human dignity —and essen -

tial for public reasoning. 

Figure 3.6  Multidimensionally poor people with little 

education lack access to the internet 

Poor Nonpoor Poor Nonpoor Access to internet (% of population ages 19–64) 17.0 20.4 37.7 60.7 010 20 30 40 50 60 70 80 Lower levels of education Higher levels of education   

> Note: To distinguish between nonpoor and poor individuals, each person is
> assigned a deprivation score based on their household’s lack of access to
> 10 key indicators of the global Multidimensional Poverty Index. These scores
> are then summed to calculate the household’s overall deprivation score. If
> the score is 1/3 or higher, the household and everyone in it are considered
> multidimensionally poor. Individuals with higher levels of education are those
> who live in a household where at least one member who is of school entrance
> age plus six years or older has completed at least six years of schooling; indi -
> viduals with lower levels of education are those who live in a household where
> no member who is of school entrance age plus six years or older has com -
> pleted at least six years of schooling. The data are from household surveys
> (Demographic and Health Surveys and Multiple Indicator Cluster Surveys) that
> cover nearly 8.1 million individuals in 94 countries.
> Source: Human Development Report Office using data from UNDP (2024). 8 0 HUMAN DEVELOPMENT REPORT 2025

Even in the real world, beliefs and values are not 

entirely independent but a result of individual and 

public reasoning, socialization and adaptive prefer -

ences, among others. 65  How much authenticity, au -

tonomy and agency does the digital space allow for? 

Are we not more easily steerable now that we are con -

stantly connected and available for suggestions about 

what to believe, like or deem important? The digital 

space adds a layer of complexity to the analysis of this 

critical aspect of human development (see the dis -

cussion of agenticity in chapter 2). 

Recommender systems in digital platforms use in -

dividuals’ online actions to fuel recommendations 

that guide people to content or products. When these 

AI algorithms are optimized for engagement, they tai -

lor marketing efforts to encourage people to purchase 

particular products or stay on the platform. 66  These 

systems are taking greater control over several areas 

of life. 67  Through suggestions on whom to follow on 

X, date on Tinder or work with on LinkedIn and on 

what book to read, movie to watch or music to listen 

to, AI influences the culture, work, information and 

people we are exposed to. 68  As AI is currently imple -

mented, its influence on human authenticity is com -

pounded by the dearth of explainability of AI-generated 

decisionmaking and content. 69  Some even expect that 

cultural evolution will be shaped by machines—that 

is, by a small set of large firms with the same cultural 

background—given their power to influence social net -

works, information flows and cultural consumption. 70 

In the case of large language models, there is evidence 

that the data used in pretraining and the finetuning that 

happens afterward lead the models to behave culturally 

in ways that mimic the models’ places of origin. 71  And 

what happens if these platforms are instrumentalized 

for geopolitical interests, 72  affecting millions of individ -

uals’ income opportunities and wellbeing? 

Some technology firms intentionally design apps to 

create a sense of control over the scrolling experience 

by ensuring that interactive elements remain familiar 

and predictable. 73  Although this illusionary agency 

is meant to increase user satisfaction, one of its side 

effects is that it facilitates masked manipulation. For 

instance, it makes it easier for certain political groups 

to diffuse extremist viewpoints, which can under -

mine democratic processes. And even though some 

ethical principles may be applied in some countries or 

regions —as with the Ethics Guidelines for Trustwor -

thy AI from the European Commission 74  or the decla -

ration on the manipulative capabilities of algorithmic 

processes of the European Council 75  —the blurry lines 

between persuasion and manipulation make it diffi -

cult to distinguish one from the other. 76  At the same 

time there is evidence that some of these regulations 

shape the behaviour of the firms behind these digital 

platforms globally. 77  Still, authenticity and autonomy 

are threatened and often curtailed in the digital space 

under the current configuration of AI algorithms, par -

ticularly recommender systems (chapter 5). And they 

are considered subordinates of agency, endangering 

one of the key aspects of human development in an 

environment that for many adults takes up a large 

part of their day-to-day life. 

Exclusion, discrimination and frustration 

through AI-powered systems 

AI is increasingly used for customer service, seeming -

ly for human convenience but often to automate tasks 

previously done by humans in large enterprises. “So-so 

AI” 78  does not outperform humans, but driven by either 

hype or cost-cutting pressures, it results in job destruc -

tion with no gains in productivity. 79  Social interaction 

is at the core of these jobs, with social skills and rela -

tionships important for problem solving. 80  While cus -

tomers appreciate the efficiency and round-the-clock 

availability of AI-powered customer service chatbots, 

Figure 3.7  Disentangling autonomy, authenticity and 

agency in the digital space 

Authenticity 

> Formation of beliefs, values, motivations, and reasons

Autonomy 

> Ability and authority of self-government

Agency             

> People have choices and are able to act upon their beliefs and values Conversion factors
> Source: Human Development Report Office. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 8 1

they find the perceived inability to manage complex re -

quests and the obligation to interact with a virtual agent 

when undesired to be substantial drawbacks. 81  Survey 

data suggest that 80 percent of customers have been 

frustrated after interacting with a chatbot instead of a 

human agent and that chatbots resolved only 22 per -

cent of customers’ issues (figure 3.8). All others had 

to connect with a human agent later. 82  Once a human 

is brought into the loop after a long series of menus, 

customers are likely to release their frustration on the 

representative and provide less information, hindering 

resolution. 83  Throughout the whole process company– 

customer relations suffer, which often results in a less 

positive evaluation of the company. 

So, while at first sight, AI reduces costs, it can ul -

timately damage a company’s reputation. The out -

look does not seem promising: in 2024, 85 percent 

of call centre managers in the United Kingdom and 

the United States that did not already have an auto -

mated system planned to implement one. 84  This will 

also have profound consequences for many middle-

income countries that rely on call centres for employ -

ment opportunities. 85  In contrast, using AI to support 

and augment what customer service agents do, as op -

posed to replacing them, can enhance customer satis -

faction (chapter 1). 

But digitalization and AI also affect customers in 

other areas of their daily lives: restaurants where 

Box 3.4  Harmful friends without benefits 

More and more people have established emotional relationships with artificial intelligence (AI)–powered characters. 

These characters are constructed to validate users without disagreement, providing emotional and intimate support 

within seconds. 1 Users perceive the characters — which are really sophisticated chatbots as friendly and accepting 

peers who are constantly available to provide validation, praise and companionship. 2 The result may be an attach -

ment to an artificial nonempathetic agent whose reactions mostly reflect the user’s emotions but are out of the user’s 

control. 3 Since unsatisfied social needs are often the underlying motive for engaging with AI-powered characters, 

socially vulnerable people are more likely to use these products, which hinder personal growth and can lead to 

vicious cycles of deteriorating social isolation and poor mental wellbeing. 4

AI-powered characters are used not only as friends but also as romantic partners in video games (some downloaded 

more than 10 million times and others with more than 660 million users). 5 These games can produce unrealistic ex -

pectations about relationships with a flawless partner and may lead to the rejection of imperfect human relationships. 6

As people invest considerable time and energy into their seemingly perfect relationships with AI-powered charac -

ters, imperfect human relationships can be neglected or even rejected. 7 Some 25 percent of people who regularly 

interact with these characters report less interest in forming human relationships. 8 This not only erodes people’s 

ability to nurture relationships but also leads to feelings of detachment and alienation from the human community 9

— with 18 percent of frequent users of these features reporting increased loneliness and isolation, even though they 

perceive a sense of companionship. 10 

Since apps with AI-powered characters tend to come and go from the market, and electricity or devices may not 

always be available, it is alarming that users report that their mental wellbeing would suffer if certain apps were to 

disappear. 11  Experts also see potential for addiction; 12  indeed, 32 percent of frequent users show symptoms consistent 

with behavioural addiction. 13  The biggest contributor to addiction is the experience of conversational flow and attach -

ment, which is generated by AI’s perceived intelligence, interactivity, personalization and human-like responses. 14 

There has already been at least one reported teenage suicide related to a synthetic relationship. The AI-powered 

character indirectly supported the idea of pulling the trigger of the gun. 15  This sad example highlights the danger of emo -

tional bubbles —the false impression that personal emotions are externally validated —which is one of the core differences 

from relationships among humans. 16  It also illustrates the alignment problem explained in chapter 2. Programs and apps 

need regulation that protects users from false expectations, such as repeated warnings and reminders that users are 

interacting with a nonhuman entity. Age restrictions should apply, given the increased vulnerability of younger people. 17                                 

> Notes
> 1. Skjuve and others 2021. 2. Maples and others 2024; Marriott and Pitardi 2024. 3. Mlonyeni 2024; Zimmerman, Janhonen and Beer 2023.
> 4. Mlonyeni 2024; Pentina and others 2023. 5. Lu- Hai Liang 2019; Xu 2021; Zhou and others 2020. 6. Forbes 2024. 7. Zimmerman, Janhonen
> and Beer 2023. 8. Forbes 2024. 9. Boine 2023. 10. Lafortune, Dubé and Lapointe 2024; Li and Zhang 2024. 11. Marriott and Pitardi 2024;
> Skjuve and others 2021. 12. Xie and Pentina 2022. 13. Forbes 2024. 14. Zhou and Zhang 2024. 15. New York Times 2024. 16. Mlonyeni 2024.
> 17. Most users of relationship apps such as Replika are adults (Altchek 2024). 8 2 HUMAN DEVELOPMENT REPORT 2025

patrons must order using their phone to scan a QR 

code rather than through a server, travel reservations 

booked and checked in for online and self-checkouts 

in grocery stores. 

Even when these systems are convenient for some 

average-age healthy people, they can be a consider -

able obstacle for others, including illiterate, visually 

impaired or mentally disabled people, people with 

passport restrictions, people of colour (when using fa -

cial recognition technology), mothers or fathers with 

small children, and people who lack digital skills. 

For instance, despite advances in online booking 

systems, 53 percent of travellers from the European 

Union, India and the United States reported needing 

assistance with some or all parts of the booking pro -

cess. 86  Moreover, people living with disabilities may 

face difficulties with online check-in and seat selec -

tion, as well as inaccessible check-in machines and 

digital information screens. Screens sometimes lack 

features such as text-to-speech or adjustable height 

for wheelchair users. And advanced imaging technol -

ogy with automated target recognition systems shows 

a higher false alarm rate for Black people (particularly 

women), people of East Asian descent, women, older 

adults, overweight and obese passengers, and pas -

sengers wearing turbans or wigs. 87 

The question here is who benefits from the use of 

digital technology. Right now, substantial service 

tasks are passed on to customers  —without reducing 

prices and at the cost of discriminating against cer -

tain groups. Companies cut labour costs without in -

creasing value for customers, decreasing prices or 

improving general welfare. 

More detailed attention to customer satisfaction is 

needed, so that digitalization and AI can truly bene -

fit companies and customers alike. Using AI to aug -

ment rather than replace people when opportunities 

for complementarity exist would be a more produc -

tive way of deploying AI (chapters 1, 2 and 6). Public-

private partnerships could help develop inclusive 

solutions that offer opportunities for AI augmenta -

tion, without longer lines or wait times when choos -

ing to interact with a human. 

Caregivers shape the digital generation 

amid fragmented institutions 

Some parents and caregivers consciously teach their 

children the responsible use of digital technologies. 

But even those who do not are role models for their 

children, unintendedly passing on usage patterns, 

emotional reactions to consumed content and ap -

propriate interaction with nonhuman actors. 88  The 

current adult generation is thus shaping a whole new 

symbiotic interplay between humans and machines. 

In some countries caregivers lack the skills and 

experience to teach children the responsible use of 

Figure 3.8  Automated systems may cut costs but distress customers 

20% 

> Satisfied

80% 

> Frustrated

22% 

> Issues resolved/ gave up

78%             

> Need to connect with human
> Source: Human Development Report Office using data from Forbes (2022). CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 8 3

digital technology, in part because they have not had 

access to it or because digital technologies, particu -

larly AI, are changing rapidly. In six African countries 

40 percent of children have never received any ad -

vice or guidance from caregivers on how to safely use 

the internet. That is partly because their caregivers 

do not use the internet, as in Ethiopia, where usage 

among caregivers is as low as 18 percent. 89 

In other regions of the world, children must com -

pete with technology for their parents’ or caregivers’ 

attention. Parents who are using their phone are five 

times less likely than those who are not to respond 

to their children’s request for attention. And when 

parents respond while using their phone, reactions 

are delayed, less affectionate and less focused on the 

children’s needs. 90 

This is where institutions come into play again. Dur -

ing the adult stage of life, the institutional grasp on 

people is not as direct as during school age, with adults 

embedded in several institutions, sometimes at the 

same time. Employees are part of their company. Par -

ents may be involved in their children’s schools. People 

who actively participate in their community may fre -

quently visit community spaces such as public librar -

ies. So, government campaigns, community places, 

parent associations and workplaces need to transmit 

sufficient knowledge and awareness that people can 

make informed choices aligned with their beliefs and 

values. Only if people maintain a degree of autonomy 

and authenticity can they exercise their agency. 

## Older age  —  trained, 

## empowered and 

## healthier? 

The global population is rapidly age -

ing, with about 1.4 billion people ages 

60 and older expected by 2030. 91  As medical care im -

proves and life expectancies increase, more people 

than ever before are elderly. At the same time digi -

tal technology is rapidly advancing, with new digi -

tal devices, software and services created every day. 

This combination of ageing population and rapid in -

novations in digitalization, including AI, poses some 

challenges but also opportunities. Few older people 

are using advanced digital technologies yet, mostly 

because they either lack access or are unfamiliar and 

insecure with them, sometimes fearing fraud. But 

older people who do use them appear less susceptible 

to drawbacks such as social comparison or addictive 

features, since their cognitive and brain develop -

ment has already concluded. So, they can more fully 

enjoy the benefits of digital technologies, including 

enhanced social interaction with distant friends and 

family and features such as telehealth. 

Older people need training, access and options 

One of the biggest challenges is that many older adults 

are largely unfamiliar with the newest AI technologies. 

Fewer than half of people ages 60 and older have used 

AI-powered tools such as ChatGPT, Google Gemini 

or Microsoft Copilot. 92  The proportion of older people 

who are internet users is lower than the proportion of 

all other age groups (figure 3.9). In Canada 99 percent 

of people ages 15–24 are internet users, compared with 

72 percent of people ages 75 and older. In Côte d’Ivo -

ire, France, Japan and Mexico over 95 percent of young 

people use the internet, compared with around 50 per -

cent of people ages 75 and older. 

The frailer older people become, the less they use 

the internet and related products and services. 93  De -

clining cognitive functioning is strongly related to 

less internet use. Self-perception is also key here: 

when older people feel more competent, they use the 

internet more frequently, particularly for banking, 

shopping, searching for information and contacting 

friends, acquaintances and relatives. 94 

To the contrary, when older people perceive that 

learning new skills at an advanced age is counter -

productive, self- doubt and anxiety are generated, 

impeding them from taking on training or venturing 

into new technologies. 95  And since most older people 

spend their time outside formal economic or political 

institutions, it is more difficult to transmit skills and 

knowledge through trainings at a large scale. 

Many digital natives (younger people born in coun -

tries with ample access to digital technologies) have 

not only the relevant skills but also different attitudes, 

characterized by more trust, less concern and more 

hopefulness than older people. 96  Fewer than half of 

older people think that AI-powered products and ser -

vices have more benefits than drawbacks, compared 

with more than 60 percent of younger people. 97  And 

more than 80 percent of older people are concerned 8 4 HUMAN DEVELOPMENT REPORT 2025 

that AI can figure out people’s thoughts and make 

decisions for them. 98  As a result, younger people are 

much more inclined to use what digital technology 

has to offer, as reflected in the use gap. 

Even so, there is considerable variation in internet 

use among older adults across countries at different 

HDI levels (figure 3.10). Older people in low, medi -

um and high HDI countries use the internet less than 

older people in very high HDI countries, 99  limiting 

their ability to benefit from a wide range of internet-

based services, such as telehealth, social media plat -

forms and online shopping, that could enhance their 

independence and social engagement. 

The Covid-19 pandemic highlighted the double 

burden of digital and social exclusion that many older 

people faced during lockdowns. Older people who 

lacked access to digital technologies or the skills to 

use them were effectively cut off from some essen -

tial services such as telehealth and online shopping, 

and they faced greater risk of social isolation. 100  Par -

adoxically, digital technologies can enhance social 

inclusion among older people. For instance, older 

people with limited physical mobility can leverage 

digital tools to sustain their social networks and con -

nections, benefiting their overall wellbeing. They 

increasingly use video calls, social media and web-

based communities to stay connected with family 

and friends near and far. They are most likely to do so 

when their partners, friends and family help get them 

started or updated. This in turn can strengthen bonds 

across generations. 101 

Older people can seem more vulnerable to online 

fraud, and data shows they are worried about it. 102  But 

some studies show that they are actually less likely 

than younger people to fall victim to it, which might 

simply be because older people spend less time on -

line. 103  When they do fall victim, they are more likely 

to experience financial loss, which can be repetitive. 104 

When telephone fraud such as phishing and spoofing 

is included, older people are the most affected, with 

more than double the total financial loss of other age 

groups. 105  Reported fraud increased by 14 percent 

from 2023 to 2024, possibly due to new generative AI-

powered tools that use voice cloning in scam calls. 106 

Figure 3.9  Very little internet use among older people   

> 050 100 150 200 250 300 350 400 Ages 14 and under Ages 25–75 Ages 15–24 Ages 76 and older Armenia Brazil Canada Colombia Costa Rica Côte d’Ivoire Czechia Finland France Hong Kong, China (SAR) Indonesia Iraq Japan Kazakhstan Malaysia Maldives Mexico Paraguay Peru Sweden Thailand Uruguay Uzbekistan

Internet users (%)              

> Note: Data on internet use among individuals younger than age 15 are unavailable for Canada, Czechia, Finland, France, Malaysia, Sweden and Uruguay.
> The maximum value of 400 reflects the figure’s structure as a stacked bar graph. Each bar includes four segments reflecting the percentage values for
> four age categories in each country. Because each age group contributes a maximum of 100 percent, the total for any given country cannot exceed 400.
> Source: Human Development Report Office using data from ITU (2024a). CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 8 5

But overall, younger people are more susceptible to 

the harmful psychological aspects of digital technol -

ogies, reporting more feelings of distress, while older 

people appear to have matured enough to be less af -

fected by them (figure 3.11). 

Adults in the older age group tend to have high pur -

chasing power. Older people in the United States could 

spend an estimated $26.8 trillion on digital technolo -

gy by 2050. 107  But many apps and devices overlook the 

physical and cognitive challenges older people face. 

Product development should ensure options tailored 

to their needs and abilities. Public-private partner -

ships can help align people’s needs with companies’ 

quests for technological progress, growth and profit. 

Because many older people prefer targeted training 

before using new digital technologies, 108  companies 

should offer human support options. 

Bias and promise for older people’s health 

Fascinating innovations are under way to augment 

human services in the health sector. AI can help de -

tect subtle patterns in medical images and videos. It 

can also analyse patterns and meanings in speech or 

text, recognize disease associations and identify tar -

gets for repurposing drugs. These developments im -

prove the early and accurate detection of complex 

and life-threatening conditions and facilitate timely 

interventions. Key opportunity areas include: 

• AI- powered wearables and signal processing devic -

es can enhance real-time diagnostics and anomaly 

detection, making it easier to identify health issues 

early. 109  During the Covid-19 pandemic, telehealth 

services surged in many parts of the world, and 

were especially attractive for older people in 

the United States, where more than 40 percent 

engaged in video consultations with healthcare 

providers. 110  The trend has lasted, still generating 

political debate about insurance coverage several 

years later 111  and the promise of expanding access 

to healthcare, as telehealth facilitates services for 

people with limited mobility, including in rural and 

remote areas. 

• Many older adults require comprehensive health 

and social care services 112  but frequently receive 

fragmented care. 113  Coordination between health 

and social care can be improved by integrating data 

Figure 3.10  Stark variance in internet use among older people across countries with different Human 

Development Index levels 

> 020 40 60 80 100 Maldives Sweden Canada Hong Kong, China (SAR) Malaysia Finland Japan France Uruguay Kazakhstan Thailand Brazil Iraq Colombia Uzbekistan Mexico Paraguay Peru Côte d’Ivoire Indonesia

Internet users (% of population ages 75 and older)  

> Source: Human Development Report Office using data from ITU (2024a). 8 6 HUMAN DEVELOPMENT REPORT 2025

across health records, ensuring more coherent care. 

Since disease burdens, functional abilities, care 

needs and priorities vary widely among individuals, 

AI can help establish profiles of health needs and 

predict specific interventions in close coordination 

with medical staff. 114  But privacy must be protected. 

• Preventive care and early disease detection can 

be augmented through AI-powered technology. 

AI-assisted radiologists interpret chest X-rays for 

tuberculosis, mammograms to detect breast cancer 

and nodules in lung cancer patients in countries 

as diverse as India, Japan and the United States. 115 

AI-powered systems have increased breast cancer 

detection by 29 percent (with a false-positive rate 

similar to standard double reading), reducing the 

screen-reading workload by 44 percent. 116  AI is also 

used for early stroke prediction and for analysing 

patients’ acoustic and facial expressions to detect 

Parkinson’s disease. 117  Any abnormal movement 

of a patient triggers an alert and eventually helps 

humans make a diagnosis. 118 

But the use of AI in the health sector is not free of 

problems. Older people use the healthcare system 

more frequently than people in younger age groups 119 

but are often underrepresented in the datasets that 

train AI models. Only about 26 percent of AI mod -

els include age-specific data, and even those that do 

contain little information on individuals ages 85 and 

older. 120  Biases  —particularly in representation and 

evaluation —are introduced at several stages, most 

frequently in the data-to-algorithm phase and the 

algorithm- to-user phase. 121 

Underrepresentation, together with social or 

human bias and discrimination in algorithms, can 

disadvantage older adults in healthcare access, treat -

ment and outcomes (figure 3.12). 122  Including older 

adults and their specific needs in developing and 

training AI models for the health sector is essential 

for improving services and making them work for 

people of all ages. 

## Multistakeholder action 

## for people- centred AI 

As AI continues to reshape daily lives, our interactions 

with it grow increasingly complex. The life-stage per -

spective helps disentangle risks from benefits and 

challenges from opportunities, identifying areas for 

action by multiple stakeholders in society. Since AI 

is penetrating virtually all areas of people’s lives (and 

Figure 3.11  Across world regions older people who use the internet are less distressed than younger ones 

010 20 30 40 50 South Asia Sub-Saharan Africa Latin America and Caribbean Oceania Middle East and North Africa Western Europe North America Global 18–24 55–64 45–54 35–44 25–34 65–74 75 and older Share of population experiencing distress (%)              

> Note: Sample sizes vary by region (between 2,000 and 50,000 internet users). Distress is measured by a mental health indicator that captures 47
> items based on a comprehensive coding of mental health symptoms assessed across 126 mental health questionnaires (including the Patient Health
> Questionnaire-9) and interviews, spanning 10 mental health disorders, as well as items derived from the Research Domain Criteria initiative of the US
> National Institute of Mental Health. Each item is rated by respondents using a Likert scale with nine options that reflect the item’s impact on their abil -
> ity to function. The ratings are aggregated into the Mental Health Quotient score, which positions individuals in one of six categories from distressed
> to thriving.
> Source: Human Development Report Office using data from Thiagarajan, Newson and Swaminathan (2025). CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 8 7

spreading around the world), governments alone 

cannot make AI work for human development. Col -

laboration among economic, political and social in -

stitutions will help develop and manage AI-powered 

products and services in ways that expand capabili -

ties and enhance human development. Governments 

can serve an umbrella function, orchestrating differ -

ent actors. 

Three pillars of the human development 

framework — capabilities, functionings and agency 

— can connect AI with a people- centred approach to 

development (figure 3.13). Following that framework, 

AI should help people expand their capabilities (what 

they can do), develop the functionings they have rea -

son to value (what they can be or become) and exer -

cise their agency (being able to act on their beliefs 

and values). 

Investing in universal access to electricity, internet, 

devices 123  and digital skills can endow individuals 

with technological resources (for most AI applica -

tions) and the skills to use them, expanding their ca -

pabilities. Informing people about how to harness AI 

to develop the functionings they have reason to value 

will allow them to make educated choices about 

when and how to use it. Including people of all ages, 

genders, ethnicities and backgrounds in designing 

and developing AI products will reflect their diverse 

beliefs and values, allowing them to exercise their 

agency. And firms need to be included in policy dia -

logues on how to make AI work for people. 

Urging all stakeholders to double down on the three 

I’s (invest, inform, include), connecting AI to the three 

pillars of human development, will expand human free -

doms and enable people to fully realize their potential. 

Figure 3.12  Social, algorithmic and data- driven biases in older people’s healthcare 

NETWORK TRAINING BIASED OUTPUT BIASED SAMPLES DATA DRIVEN BIAS DATA GAPS SOCIETAL PREJUDICES HUMAN BIAS POWER IMBALANCES IMBALANCED CLASSES ALGORITHMIC BIAS TRAINING BIAS  

> Source: Norori and others 2021.

Figure 3.13  Harnessing artificial intelligence (AI) for human 

development  —  invest, inform, include  

> AI FOR HUMAN DEVELOPMENT INVEST
> in universal access to electricity, internet, devices and digital skills
> INCLUDE
> stakeholders in policy dialogue and development of AI products
> INFORM
> about how to harness AI to enable choices
> AGENCYCAPABILITIESFUNCTIONINGS
> Source: Human Development Report Office. 8 8 HUMAN DEVELOPMENT REPORT 2025
> SPOTLIGHT 3.1

# The decline in young people’s mental 

# wellbeing in some parts of the world 

Human Development Report Office; David G. Blanchflower,  Dartmouth College;  Alex Bryson,  University College London; 

Tara Thiagarajan,  Sapien Labs;  Jennifer Newson,  Sapien Labs 

Until recently, one of the well- established empirical 

regularities in the social sciences was that subjective 

measures of wellbeing (such as happiness) followed 

a U-shaped pattern with age: younger and older peo -

ple reported higher wellbeing than those in middle 

age (late 40s to early 50s). 1 Conversely, illbeing (such 

as despair) followed an inverted-U pattern with age. 

This empirical regularity was reported in more than 

600 published papers documenting its presence in 

about 145 countries at all income levels. 2

But around the end of the first decade of the 21st 

century, this empirical regularity started to unrav -

el, according to a variety of metrics in some parts of 

the world —particularly in very high Human Devel -

opment Index (HDI) countries. 3 In the United States 

wellbeing, measured by life satisfaction, now increas -

es continuously with age (top panel of figure S3.1.1), 

and reported despair is higher among young people 

(bottom panel of figure S3.1.1). 4

Another important change is the difference in the 

rate of deterioration in wellbeing between young 

women and young men. While young women have 

historically reported higher despair than young men 

in the United States and both groups have reported in -

creased despair since around 2010, the rate of increase 

has been higher for younger women (figure S3.1.2). 

Although results depend, in part, on the types of 

questions and survey methods, 5 the decline in young 

people’s mental wellbeing does not appear to be uni -

versal. For example, there is little evidence that the 

age structure of wellbeing has changed in Africa over 

the past decade. 6

Researchers and policymakers are still trying to 

determine the reasons behind the changes in some 

countries and the seeming lack thereof in others. 

The figures below show that where changes in the 

wellbeing curve have occurred, they parallel great -

er smartphone use, leading to hypotheses that some 

of the documented negative effects of excessive so -

cial media use could be driving increases in anxiety, 

depression and loneliness. 7 Intense smartphone use 

and deteriorating wellbeing among young people 

could be linked through a range of mechanisms (box 

S3.1.1), including constant social comparison 8 and cy -

berbullying. 9 Poor sleep quality, driven by addictive 

features, can further impair wellbeing, and the shift 

from in-person to digital interactions seems to have 

delayed social and emotional development, increas -

ing feelings of isolation. 10  Also under investigation 

is whether something intrinsic to social media use 

is harmful or whether harms emanate from the rec -

ommender systems in digital platforms optimized for 

engagement. 11  Other factors might have also contrib -

uted to this dramatic change. A better understanding 

of mental health issues has led to less stigma, more 

use of mental health services and thus higher report -

ing rates. 12  Reduced independence and free play have 

weakened coping skills, 13  while overprotection and 

the rise of “safetyism” are making young people more 

vulnerable to distress. 14 

Smartphones came to prominence in many coun -

tries around the time that mental wellbeing among 

young people began to decline. 15  The rise in poor 

mental health among young people precedes the 

Covid-19 pandemic by some years, though the pan -

demic may have exacerbated the trend. 16  Some stud -

ies suggest the trend goes all the way back to the late 

1990s, 17  whereas other studies emphasize the uptick 

in mental illbeing from around 2011. 18 

How widespread is this change, and is it really 

caused by excessive smartphone use? 

The shift is not consistent across all datasets or 

across all dimensions of subjective wellbeing. 19  It is 

particularly evident in some very high HDI coun -

tries 20  and less pronounced or nonexistent in lower 

HDI countries (with a few exceptions, such as specific 

surveys in Mexico). 21  This information is telling, con -

sidering that most young people in low-income coun -

tries are not yet using the internet (see box figure 1 

in box 3.3 in the chapter). And detailed case studies CHAPTER  3 — A RTIFICIAL  INTELLIGENCE  ACROSS  LIFE  STAGES : I NSIGHTS  FROM  A PEOPLE - CENTRED  PERSPECTIVE  8 9 

Figure S3.1.1  Declining wellbeing, rising despair among young people in the United States 

3.1 3.2 3.3 3.4 3.5 Age (years) 2005–2010 2022–2023 Mean wellbeing score 75 72 70 68 66 64 62 60 58 56 54 52 50 48 46 44 42 40 38 36 34 32 30 28 26 24 22 20 18 

0246810 Age (years) 2006–2018 2019–2024 Share of people reporting despair (%) 75 72 70 68 66 64 62 60 58 56 54 52 50 48 46 44 42 40 38 36 34 32 30 28 26 24 22 20 18 

Note:  Mean wellbeing scores are based on responses to the question, “In general, how satisfied are you with your life?” Responses were given on a four-step 

scale (very dissatisfied = 1, dissatisfied = 2, satisfied = 3 and very satisfied = 4). Share of young people reporting despair is the percentage of young people who 

responded 30 to the question, “Now thinking about your mental health — which includes stress, depression and problems with emotions — for how many days 

during the past 30 days was your mental health not good?” 

Source:  Blanchflower and Bryson (2024c) using data from the US Centers for Disease Control and Prevention’s Behavioral Risk Factor Surveillance System. 9 0 HUMAN DEVELOPMENT REPORT 2025 

Figure S3.1.2  Increase in despair in the United States since 2010, especially among women  

> 246810 12 2023 2021 2019 2017 2015 2013 2011 2009 2007 2005 2003 2001 1999 1997 1995 1993 Females age < 25 Age 35–54 Males age < 25

Share of people reporting despair (%)  

> Source: Blanchflower 2025c.

Box S3.1.1  Connected or disconnected? Exploring possible mechanisms between smartphones and mental wellbeing 

Social comparison.  Wellbeing is determined not only by what people have but also by how much they think they have 

relative to others. Well-established in the literature on income and earnings, 1 this extends more broadly to other set -

tings, such as friendship groups and social activity. Smartphones provide regular updates on how others are doing, 

and young people may perceive their own world as lacking. 2

Direct impact on brain function.  The addictive effect of smartphones is akin to the user returning continually for another 

“fix,” creating a dopamine response in the brain. Smartphone use can then become an end in itself, with the wellbeing 

response dependent on more intensive usage. The links between smartphone dependency and mental wellbeing are yet 

to be fully established, but smartphone addiction could have adverse impacts on behaviours and response mechanisms. 3

Displacement.  The addictive component may cause smartphone use to replace other activities more conducive to 

mental and physical health, such as maintaining “real” social networks and engaging in social activities outside the 

home, such as sport and art. 4

Information overload.  Relying on smartphones to perform numerous functions increases screen interaction. For some 

people, especially young ones, 5 some applications can result in information overload, which can be overwhelming 

and produce anxiety and stress. 6

Cyberbullying.  The internet extends into a virtual world that is difficult to police. So, smartphone users can be subject 

to intimidation and bullying, often continually in real time, making it difficult to “hide.” This could have a direct adverse 

impact on individual wellbeing. 7                       

> Notes
> 1. UNDP 2019. 2. Aubry, Quiamzade and Meier 2024; Braghieri, Levy and Makarin 2022; Faelens and others 2021; Irmer and Schmiedek 2023;
> McComb, Vanman and Tobin 2023. 3. Lembke 2021. 4. Bone and others 2022; Fluharty and others 2023. 5. Benselin and Ragsdell 2016.
> 6. Bawden and Robinson 2020; Matthes and others 2020. 7. Peebles 2014; Thiagarajan, Newson and Swaminathan 2025; Zhu and others 2021. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 9 1

have found an association between diffusion of the 

internet and deterioration in young people’s mental 

wellbeing. 22 

The story becomes even clearer in a global survey 

that includes only people with internet access. Al -

though the survey samples were not representative 

of the population, in every country that participat -

ed, across all regions, mental wellbeing is lowest for 

young adults and increases with age (figure S3.1.3). 

Among the global internet- enabled population, 

45 percent of young people ages 18–24 struggle with 

mental wellbeing at a level that has functional conse -

quences and with symptomatic distress that would be 

considered of clinical concern. 23 

The age at which young people first own a 

smartphone appears to matter. Among 18- to 

24-year-olds today, those who had a smartphone be -

fore age 13 show significantly worse mental wellbeing 

and a higher likelihood of being distressed or strug -

gling than those who received their first smartphone 

later (top panels in figure S3.1.4). The effects are most 

pronounced among women and young people who 

first owned a smartphone at age 5 or 6. Nearly 70 per -

cent of young women and 50 percent of young men 

responding to the survey now report distress and 

struggling. By contrast, among those who first owned 

a smartphone at age 13, the values drop to 51 percent 

for women and 38 percent for men. 

The most affected areas are the social self —a di -

mension of wellbeing that reflects self-perception 

and the ability to relate to others  — and mood and 

outlook. The younger the age at first smartphone 

ownership, the greater the decline in this funda -

mental aspect of mental wellbeing (bottom panels in 

figure S3.1.4). 

The relationship between age at first smartphone 

ownership and mental wellbeing is visible in 

internet- enabled survey respondents across all 

countries and regions. It appears for both young 

men and young women but is much stronger for 

women. Women not only experience a greater drop 

in wellbeing with younger ages of smartphone own -

ership but also consistently have lower wellbeing 

than men overall. 

As digital technologies play a larger role in child -

hood and adolescence and AI-powered applications 

widen their reach, these findings underscore the need 

for deeper reflection about the specific mechanisms 

that cause harm, the risks associated with current 

AI applications (for instance, recommender systems 

optimized for engagement based on online behav -

iour) and the potential for drawing on the new affor -

dances of AI, along with other measures, to mitigate 

the risks of harm. This agenda, crucial everywhere, 

is important particularly in countries and settings 

where digital technologies have not yet diffused as 

widely, so that societies can be ahead of the curve 

and harness these technologies to advance human 

development instead of hindering it. 

Figure S3.1.3  Young internet users are struggling 

everywhere 

> 020 40 60 80 100 120 140 75 and older 65–74 55–64 45–54 35–44 25–34 18–24

Average Mental Health Quotient score Middle East and North Africa Western Europe North America Age group (years) South Asia Sub-Saharan Africa Latin America Oceania   

> Note: The MHQ score encompasses 47 aspects of mental function assessed
> on a life impact scale that spans six dimensions: Adaptability and Resilience,
> Cognition, Mind-Body Connection, Mood and Outlook, and Social Self. Higher
> values indicate better perceived mental wellbeing. The survey was conducted
> during 2020–2024.
> Source: Thiagarajan, Newson and Swaminathan (2025) using data from the
> Global Mind Project at Sapien Labs. 92 HUMAN DEVELOPMENT REPORT 2025

Figure S3.1.4  The age at first smartphone ownership appears to matter for mental wellbeing 

–20 –10 010 20 30 40 50 18 17 16 15 14 13 12 11 10 98765Average Mental Health Quotient score, all young people ages 18–24 020 40 60 80 100 18 17 16 15 14 13 12 11 10 98765Share of young people ages 18–24 reporting distress a (%) –20 –10 010 20 30 40 50 60 70 80 18 17 16 15 14 13 12 11 10 98765Average Mental Health Quotient score, young women ages 18–24 –20 –10 010 20 30 40 50 60 70 80 18 17 16 15 14 13 12 11 10 98765Average Mental Health Quotient score, young men ages 18–24 Male Mood & outlook Drive & motivation Adaptability & resilience Social self Cognition Mind-body connection Female Age at first smartphone ownership (years) Age at first smartphone ownership (years) Age at first smartphone ownership (years) Age at first smartphone ownership (years) 

a. Distress is indicated by a Mental Health Quotient score below 0. 

Note:  The MHQ score encompasses 47 aspects of mental function assessed on a life impact scale that spans six dimensions: Adaptability and Resil -

ience, Cognition, Mind-Body Connection, Mood and Outlook, and Social Self. Higher values indicate better perceived mental wellbeing. The survey 

was conducted during 2020–2024. 

Source:  Thiagarajan, Newson and Swaminathan (2025) using data from the Global Mind Project at Sapien Labs. CHAPTER  3 — A RTIFICIAL  INTELLIGENCE  ACROSS  LIFE  STAGES : I NSIGHTS  FROM  A PEOPLE - CENTRED  PERSPECTIVE  9 3 

NOTES 

1.  Blanchflower 2021. 

2.  Blanchflower 2025b. 

3.  Blanchflower, Bryson and Xu 2024. 

4.  Twenge and Blanchflower 2025. 

5.  Blanchflower 2025a. 

6.  Blanchflower and Bryson 2024b. 

7.  Social media can amplify outrage, status seeking and group conflict but 

also has the potential to support prosociality and collective action (Van 

Bavel and others 2024). Its use can have some benefits, such as enabling 

people to access more targeted content, goods and services that cater to 

their interests, facilitating access to the labour market by recent college 

graduates (Armona 2023) and enabling greater opportunities for expres -

sion and for creators to disseminate their work (Aridor and others 2024). 

8.  Aubry, Quiamzade and Meier 2024. 

9.  Blanchflower and Bryson 2024a. 

10.  Braghieri, Levy and Makarin 2022; Carter and others 2024; Faelens and 

others 2021; Huang and others 2023; Irmer and Schmiedek 2023; Khalaf 

and others 2023; McComb, Vanman and Tobin 2023; Stuart and Scott 

2021; Scott, Stuart and Barber 2021, 2022; Twenge and others 2020. 

11.  Lewandowsky, Robertson and DiResta 2024. The purpose of social media 

use (to access information, to seek entertainment or to express oneself) 

also matters (Qiao, Liu and Xu 2024). 

12.  Corredor-Waldron and Currie 2024. 

13.  Haidt 2024. 

14.  Lukianoff and Haidt 2019. Evidence is from the United States. 

15.  Blanchflower 2025a; Blanchflower and Bryson 2024c; Blanchflower and 

others 2024. 

16.  Blanchflower, Bryson and Bell 2024. This seems to be the case for the 

United Kingdom but not for the United States (Blanchflower, Bryson and 

Xu 2024). 

17.  Blanchflower, Bryson and Bell 2024. 

18.  Blanchflower, Bryson and Xu 2024. 

19.  Blanchflower and Bryson 2025. 

20.  Twenge and Blanchflower 2025. 

21.  Blanchflower and Bryson 2024b, 2024c, 2025. 

22.  For the case of Italy, see Donati and others (2022). 

23.  Thiagarajan, Newson and Swaminathan 2025. 9 4 HUMAN DEVELOPMENT REPORT 2025 

In recent years the mental health crisis among teen -

agers and young adults has become increasingly 

concerning. Social media platforms, while serving 

as tools for connection and communication, have 

been linked to feelings of anxiety, depression and 

loneliness among teenagers and young adults. 1 This 

has sparked a policy debate surrounding the poten -

tial regulation, or even outright prohibition, of so -

cial media platforms. In May 2023 the US Surgeon 

General pushed for a better understanding of the 

possible “harm to the mental health and well-being 

of children and adolescents” from social media, as 

well as the impact of stricter limits and standards for 

use. 2 In late 2024 the government of Australia intro -

duced a general ban on social media for users under 

age 16. 3

The policy debate around social media critically 

hinges on welfare estimates of social media products: 

what is the value of social media to its users? 

Some platforms such as Instagram and TikTok are 

extremely popular among young people, to the point 

that it can be very painful to stay off the platforms. 

Not using them would lead to tremendous fear of 

missing out and potential exclusion from many so -

cial interactions. Could large numbers of young users 

of these platforms not want to stop using them while 

also preferring to ban them? In other words, is there a 

social media trap? 4

One way to answer this important question is to ask 

young Instagram and TikTok users if they would pre -

fer to live in a world with or without these platforms. 

Among a sample of just over 1,000 US college stu -

dents, over 55 percent of Instagram users and 33 per -

cent of TikTok users would prefer to live in a world 

where the platform did not exist (figure S3.2.1). 

Moving beyond just asking survey questions, an 

experiment with the same sample of college stu -

dents uses financial incentives to infer their valua -

tion of four scenarios involving the platforms. The 

first scenario (called “Valuation keeping network”) is 

deactivating the respondent’s account for four weeks, 

which delivers the standard measure of individual 

consumer surplus. The remaining scenarios shrink 

the size of the respondents’ social media networks by 

introducing the possibility of collective deactivation, 

where all students on campus who are participating in 

the experiment would also deactivate their accounts. 

Such collective deactivation would be implemented if 

the researchers recruited two-thirds of the students 

at the college for the experiment. The second scenar -

io (called “Valuation removing network”) measures 

individual willingness to deactivate conditional on 

all other participating students having been asked to 

do so, in exchange for monetary compensation. The 

third (called “Product market valuation”) measures 

whether individuals are willing to forgo payment or 

instead require a payment to deactivate all participat -

ing students’ accounts. 

> SPOTLIGHT 3.2

# The social media trap 

Leonardo Bursztyn,  University of Chicago;  Benjamin Handel,  University of California, Berkeley;  Rafael Jimenez Duran, 

Bocconi University;  Christopher Roth,  University of Cologne 

Figure S3.2.1  Respondents who prefer to live in a world 

without the platform 

> 020 40 60 80 100 TikTok Instagram

Share of respondents (%) Users All respondents 57 33 58 57              

> Note: Error bars represent 95 percent confidence intervals.
> Source: Bursztyn and others 2023. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 9 5

Students need to be paid around $50 to deacti -

vate Instagram or TikTok for four weeks, if they ex -

pect to do it alone (figure S3.2.2). At the same time, 

46 percent of active Instagram users and 60 per -

cent of active TikTok users are willing to pay to 

have their own and others’ accounts deactivated for 

four weeks. 5

Why does this happen? When participants were 

asked, the dominant reason they mentioned is 

exactly what one would expect for a social media 

trap: fear of missing out. 

Such fear can be grounded in reality: nonusers miss 

out on the social interactions happening on social 

media and on the offline discussions based on those 

interactions. As one respondent who continues to use 

the platform even though they would prefer to live in 

a world where it didn’t exist wrote, “I feel like if I stop 

using it, I will be completely out of the loop.” It may 

Figure S3.2.2  Consumer surplus across welfare measures 

> 020 40 60 80 100

Fraction negative: TikTok 

Deriving negative welfare (%) 0Valuation removing network Product market valuation (with non-users) Valuation keeping network Product market valuation 60 28 871 20 40 60 80 100 46 

Fraction negative: Instagram 

Deriving negative welfare (%) 31 14 47 –80 –60 –40 0–20 20 40 60 80 

Average welfare: TikTok 

Willingness to accept ($) μ = –24 μ = 39 μ = 55 μ = –43 –80 –60 –40 –20 020 40 60 80 

Average welfare: Instagram 

Willingness to accept ($) μ = –6 μ = 37 μ = 47 μ = –9           

> p< 0.01
> p< 0.01
> p< 0.01
> p< 0.01
> p< 0.01
> p< 0.01
> p< 0.01
> p< 0.01
> Note: Error bars represent 95 percent confidence intervals.
> Source: Bursztyn and others 2023. 9 6 HUMAN DEVELOPMENT REPORT 2025

be costly to use the platform, but it is even costlier to 

be the only one not using it. 

Recent academic work points to self- control issues 

and addiction being major factors in young people’s 

social media use. 6 The above findings on a collective 

trap indicate that, even in the absence of self-control 

problems or addiction, many users are joining and 

staying on social media platforms despite not enjoy -

ing them. This conclusion challenges the argument 

that because people spend a lot of time on social 

media, it must be creating value for them. 

What are the policy implications? Many social 

media users seem to prefer to live in a world without 

social media but are willing to quit it only if others 

also do. This characterizes a coordination problem. 

One potential policy avenue is regulation and bans —

actions policymakers are discussing and implement -

ing. Another avenue is to provide coordination tools 

that allow users to cut down their social media use 

together. These could be designed and developed 

through public-private partnerships or using incen -

tives or subsidies. 

NOTES                  

> 1. Allcott and others 2020; Allcott, Gentzkow and Song 2022; Braghieri,
> Levy and Makarin 2022.
> 2. See, for instance, Richtel, Pearson and Levenson (2023).
> 3. For popular press coverage on this matter, see, for instance, Ritchie
> (2024).
> 4. This is the idea behind Bursztyn and others (2023).
> 5. Identical experiments run by the authors on the deactivation of navigation
> apps rule out that the effects are mechanically driven by aspects of the
> elicitation procedure and help rule out that the findings simply reflect a
> general distaste for big tech or digital products.
> 6. Allcott, Gentzkow and Song 2022. CHAPTER 3 — A RTIFICIAL INTELLIGENCE ACROSS LIFE STAGES : I NSIGHTS FROM APEOPLE -CENTRED PERSPECTIVE 9 7
> SPOTLIGHT 3.3

# Worker agency in the digital age 

Carina Prunkl,  Utrecht University  and  University of Oxford;  Joel Anderson,  Utrecht University;  Uğur Aytaç,  Utrecht University; 

Jeroen Hopster,  Utrecht University;  Juri Viehoff,  Utrecht University 

Digital technologies are transforming the workplace. 

This spotlight is concerned with the effects of digital 

technologies on worker agency, which broadly refers 

to workers’ effective ability to make choices that align 

with their beliefs and values, to draw meaning from 

their work and to exercise adequate control over their 

work and work environment. 1

The relationships among digitalization, agency and 

the workplace are dynamic, with each element shap -

ing and being shaped by the others. Digitalization 

transforms workplace structures and processes, which 

has effects on the agency that workers can exercise. In 

turn, agents shape how digital technologies are imple -

mented, resisted or adapted in workplace settings. 2

The ability to exercise agency at the workplace is 

broken down in four key elements: C-A-R-E. 3 Autono -

mous agency requires a substantial degree of effective 

control (C) of the circumstances in which one works. It 

requires meaningful input into the co-creative author -

ship (A) of the work one carries out. The work process 

also needs to be socially embedded in valuable rela -

tionships (R) connecting one exercising agency to oth -

ers. Lastly, one’s participation in the work process must 

be informed by an understanding of it that ensures a 

degree of epistemic agency (E). The four elements of 

CARE are interrelated and inform one another. 

C —  control and discretionary authority 

Agency in the workplace relies on having a certain 

amount of discretion about how to carry out tasks 

—free from meddlesome or punitive surveillance 

and (technological or human) micromanaging —

something that is widely valued across cultures and 

work environments. 4 Although digital technologies 

offer numerous opportunities for workers to person -

alize their tools, the nature and complexity of digital 

tools and the fast pace of automated processes pose a 

threat to this discretion in three ways. 

First, control requires understanding (see also the 

subsection below on epistemic agency and under -

standing). By limiting employees’ insight into the 

technologies with which they work, many work en -

vironments make it difficult for workers to assess the 

adequacy of digital solutions or outputs, something 

that could be exacerbated by the greater diffusion of 

artificial intelligence (AI). Consider the proverbial 

“keeping humans on the loop,” expected to ensure 

that automated systems do not run unchecked. 5 With -

out sufficient access to information, workers may be 

unable to confidently make well-informed decisions —

reducing their oversight to little more than a formality. 

Second, workers’ control over their work can be 

limited by rigid structures imposed by digital solu -

tions, reducing their ability to adjust system settings, 

correct inaccuracies, override automated decisions or 

address issues linked to the use of the digital systems. 

For example, staff at a child welfare agency in Wis -

consin reported frustration at losing decisionmaking 

power to an algorithm for foster care allocation and 

criticized its shortcomings, such as a lack of under -

standing of childhood trauma. 6

Third, even when control is possible in theory, it 

can be undermined in practice by narrow toleranc -

es in fast-paced processes, by repetitive or complex 

tasks that can foster automation bias, the tendency to 

uncritically accept algorithmic outputs. In such cases 

decisions often default to automated outcomes. For 

example, in healthcare settings automation bias has 

been associated with cognitively demanding diag -

nostic tasks. 7

A —  authorship and ownership 

Authorship and ownership of one’s profession -

al activities are key for workers to derive meaning, 

purpose and a sense of accomplishment in the work -

place. 8 Authorship ensures that work outcomes align 9 8 HUMAN DEVELOPMENT REPORT 2025 

with one’s values and intentions, whereas ownership 

involves a sense of responsibility for one’s work and 

is a prerequisite for feeling recognized and esteemed 

for one’s contributions. 9 Digital technologies can al -

leviate several tedious tasks, such as bookkeeping 

or repetitive communication, freeing time for more 

meaningful or interesting work, but these potential 

benefits are rarely reaped evenly across occupational 

categories or sectors. 

For example, gaps in work autonomy may widen 

between white collar workers and shop floor or as -

sembly line workers. 10  AI technologies, if applied in 

the same way as classical programming, risk extend -

ing this to additional categories of professional and 

white- collar jobs. When pace, timing and order are 

determined by technology (see also the subsection 

above on control and discretionary authority), there 

is little room for authorship, leaving employees feel -

ing fungible. Increased surveillance practices —which 

can now encompass workers’ “thoughts, feelings 

and physiology, location and movement, task per -

formance, and professional profile and reputation” —

further erode ownership. 11  Such technologies coerce 

workers into becoming ever more efficient, signifi -

cantly undermining authorship. 12 

R —  relationships and community 

Agency is intimately linked with being embedded 

in social relationships. 13  In the workplace, relation -

ships influence employee outcomes such as work 

attitudes, withdrawal and effectiveness. 14  Digitaliza -

tion can disrupt traditional forms of communication 

and community, changing the feasibility and nature 

of coworker interactions. 15  While remote work offers 

several advantages on the control dimension, it has 

been shown to lead to increased feelings of loneliness 

and isolation. 16  But even for onsite work, digital solu -

tions can reduce formal and informal interactions at 

the workplace due to isolating working conditions 

that require more screen time and fewer face-to-

face interactions, automated workflows that replace 

collaboration, asynchronous forms of communica -

tion and more comprehensive surveillance systems. 

These developments undermine worker agency, 

since sharing and comparing experiences with others 

play a fundamental role in how we perceive ourselves 

and our environment and in how we uncover and ad -

dress injustices. 17 

E —  epistemic agency and understanding 

Epistemic agency and understanding support many 

of the other elements of worker agency insofar as 

they are necessary for seeing one’s workplace tasks as 

justified and, relatedly, for being motivated to carry 

them out. Insight into the work process and the con -

text of work also provide intrinsic value to the worker 

and productive activity. Digital solutions, especially 

ones using machine learning techniques, can hamper 

understanding because they lack transparency in a 

variety of ways. The system’s workings and capabili -

ties are not disclosed to the employee  —for instance, 

due to negligence or intellectual property restric -

tions. The employee does not have the technical skills 

necessary to comprehend how the system functions. 

Or the system’s nonlinear and complex architecture 

inherently resists human introspection (lack of inter -

pretability). 18  Epistemic agency also involves workers 

having the opportunity to contribute with their own 

knowledge and expertise both to their own work pro -

cesses and to their overall work environment. This in -

cludes not only the capacity to question and correct 

digital solutions where necessary but also the oppor -

tunity to shape how such solutions are implemented 

in their broader work context. 

The CARE approach to worker agency suggests two 

recommendations. First, policymakers can work with 

the private sector to establish guidelines for algorithmic 

decisionmaking —and digitalization more broadly —in 

the workplace. Such guidelines at a minimum need to 

ensure that automated decisions are explainable and 

contestable by employees, thereby securing control 

and epistemic agency. Employer disclosure of the ex -

tent of digital monitoring at the workplace would be 

important. Guidelines on work surveillance should be 

informed by notions of prerogative to contest automat -

ed decisions and take seriously the principle of keep -

ing humans in the loop. Second, worker participation 

and an ability to unionize can support securing work -

er agency. This could involve proactively facilitating 

workers’ possibilities to organize and having firm gov -

ernance structures that allow worker representatives to 

engage in participatory design and decisionmaking. CHAPTER  3 — A RTIFICIAL  INTELLIGENCE  ACROSS  LIFE  STAGES : I NSIGHTS  FROM  A PEOPLE - CENTRED  PERSPECTIVE  9 9 

NOTES 

> 1. Eteläpelto and others 2013.
> 2. Eurofund 2025; Pärli 2022; Unruh and others 2022.
> 3. Anderson 2013; Mackenzie 2014; Mackenzie and Stoljar 2000.
> 4. Gagné and Bhave 2010.
> 5. Leins and Kaspersen 2021.
> 6. Saxena and Guha 2024.
> 7. Lyell and Coiera 2017.
> 8. Aslan and Atesoglu 2021.
> 9. Anderson 2013.
> 10. Eurofound 2025.
> 11. Ball 2021, p. 23.
> 12. The Guardian 2024; Marsh, Vallejos and Spence 2022.
> 13. Landes and Settersten 2019; Mackenzie and Stoljar 2000.
> 14. Chiaburu and Harrison 2008; Pereira and others 2023.
> 15. Honneth 2024; Lane and others 2024.
> 16. Gallup 2024.
> 17. Honneth 2024; Hopster 2024; Milano and Prunkl 2025.
> 18. Milano and Prunkl 2025; Selbst and Barocas 2018.

Table S3.2.1  The CARE framework 

Characteristic 

C —  control and 

discretionary authority 

A —  authorship and 

ownership 

R —  relationships and 

community 

E —  epistemic agency and 

understanding 

Deficits  → Lack of understanding 

→ High process speeds 

→ Rigid structures 

→ Impossible to correct 

system 

→ No point of contact 

→ Overly controlled 

environments 

→ Fungibility 

→ No professional 

development 

→ Lack of work autonomy 

→ Surveillance 

→ Isolated working 

conditions 

→ Automated workflows 

→ Asynchronous 

communication 

→ Surveillance 

→ Lack of social 

embeddedness 

→ Lack of information 

→ Lack of expertise 

→ Lack of interpretability 

→ Inability to overwrite outputs 

Enablers  → Discretionary authority 

→ Understanding 

→ System support 

→ Customizability 

→ System flexibility 

→ Task customization 

→ Feedback mechanisms 

→ Opportunities for 

professional growth 

→ Accountability 

frameworks 

→ Reduced micro -

management 

→ Social interactions 

→ Collaboration 

→ Community 

→ Open communication 

channels 

→ Privacy safeguards 

→ Transparency of digital systems 

→ Technical literacy 

→ Contributing expertise 

→ Participation in digital solutions 

Assessments  → How much discretion 

do employees have to 

decide how and when 

tasks are performed? 

→ Do employees have 

sufficient information to 

make informed choices? 

→ Is there a risk that 

employees passively 

accept digital outputs 

without question? 

→ Do employees have 

access to adequate 

support when addressing 

errors or issues related to 

digital systems? 

→ Do employees feel their 

work reflects their values 

and professional goals? 

→ Do tasks align with 

employees’ skills and 

expertise? Is there room 

for skill development? 

→ Are there systems of 

accountability that respect 

employees’ expertise, 

or do they create fear of 

overstepping? 

→ Can employees 

challenge and question 

the outputs of automated 

systems without negative 

repercussions? 

→ Do digital solutions 

replace opportunities 

for formal and informal 

exchange? 

→ To what extent do 

automated workflows 

replace collaborative 

processes? 

→ How do digital solutions 

impact employees’ sense 

of belonging and self-

perception at work? 

→ Does digitalization limit 

employees’ ability to 

share experiences that 

help uncover and address 

workplace injustices? 

→ Are employees provided 

with sufficient information 

and training to understand 

how digital tools and systems 

function? 

→ Are decisionmaking processes 

transparent and accessible to 

workers? 

→ Are employees encouraged 

and given the opportunity to 

contribute their knowledge 

and expertise to their work 

processes? 

→ Do employees have a voice 

in how digital solutions are 

implemented and integrated into 

their broader work environment?  

> Source: Authors’ elaboration. 1 0 1

# C H A P T E R 

# 4

# Framing narratives 

# to reimagine 

# artificial intelligence 

# to advance human 

# development 1 02 HUMAN DEVELOPMENT REPORT 2025 

# As the impact of artificial intelligence (AI) on human 

# development remains uncertain, narratives can play 

# a crucial role in shaping our choices. Rather than a 

# techno-determinist narrative that assumes that AI 

# alone will either solve all our problems or threaten 

# the future of humanity, AI’s direction and deployment 

# will be contingent on individual and collective 

# choices. Institutional and social choices can enable 

# AI to expand people’s capabilities and agency, as 

# illustrated through AI’s applications for people with 

# disabilities, care systems and gender equality, as well 

# as in conceptualizing and mitigating AI bias. To do so, 

# existing benchmarks to evaluate AI’s progress and 

# safety should be complemented with ones that assess 

# the impact on advancing human development. 

> CHAPTER 4

# Framing narratives to reimagine artificial 

# intelligence to advance human development CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 0 3 

# “ For AI to be a boon, we must reorient; 

pushing AI capabilities alone is not enough.” 

—Bengio and others 2024, p. 2 

Contrary to current narratives that assume a linear 

link from new technologies to social change, artificial 

intelligence’s (AI) impact on people is rooted in so -

cial structures and contingent on people’s choices. AI 

and people are immersed in a reciprocal relationship 

shaped by social, economic and political process -

es. This two-way relationship, established time and 

again in past episodes of technological change, de -

mands attention in order to navigate fast-paced AI in -

novations in ways that advance human development. 

Narratives about technology  — both in popular 

media and in the policy arena — often portray AI 

as something that can, on its own, catalyse social 

change. They disproportionately focus on availability 

and affordances of new technologies as ends in them -

selves, as illustrated by the way the media, investors 

and firms report the achievements of AI models on 

a range of benchmarks. 1 Yet social change is an out -

come of complex interactions of technologies with 

institutions, including social norms. And progress 

is neither inevitable nor neutral 2—it depends on our 

choices: whether we ensure that the benefits of tech -

nological advancement are broadly distributed and 

expand people’s freedoms and choices to lead lives 

they value and have reason to value. 

AI affordances do matter. But considering these 

societal drivers can help with the design, develop -

ment and use of AI that expands people’s agency and 

avoids creating or reproducing inequalities. 

The nature of AI, its implications for society, and its 

future development and deployment remain uncer -

tain. This makes landing on a set of choices to harness 

AI’s potential much more complicated. So this uncer -

tainty makes narratives much more determinant in 

shaping our choices, given that there is little else guid -

ing us about what the future will hold (spotlight 4.1). 

Framing narratives about how AI can advance human 

development is crucial at a time of momentous chang -

es in policies, institutions and regulations. A narrative 

centred on advancing human development can in -

form crucial decisions that will have implications in 

the years, perhaps decades, to come. 

Along with the content of the narrative, the process 

matters as well. Debates about AI must reflect diverse 

voices and perspectives and extend beyond the agen -

da of powerful players because in looking at their 

interests, we may lose sight of broader social implica -

tions. The main argument of this chapter is that the 

narratives about AI, and the processes around them, 

should focus not just on what AI can do but also on 

how it can enhance people’s capabilities. Framing 

narratives this way can support power realignment 

(chapter 5) and harness the opportunities for AI to ad -

vance human development (chapter 6). 

## Beyond techno- determinism: 

## Technological change shapes 

## and is shaped by society 

# “ Because technology is highly malleable, 

there is no scarcity of compelling stories that 

can support alternative paths for technology. 

There are always many technological choices, 

with very different consequences, and if we 

get stuck with a single idea or a narrow vision, 

it is very often not because we are short of 

options. Rather, it is because those setting the 

agenda and commanding social power have 

imposed it on us. Correcting this situation is 

partly about changing the narrative: dissecting 

the driving vision, revealing the costs of the 

current path, and giving airtime and attention 

to alternative futures of technology.” 

—Acemoğlu and Johnson 2023, p. 97 

Narratives about AI often oversimplify technology’s 

impact on social change by assuming that technolo -

gy alone can shape social outcomes  — called techno-

determinism. For instance, when digital technology 

is applied to alleviate certain social problems, there 

has long been a tendency to assume that, by its mere 

implementation, it will generate the desired results. 3

AI has been portrayed as a revolutionary technology, 

with the potential to solve complex problems, unlock 

economic growth and contribute to human flourish -

ing. 4 But the history of science, technology and inno -

vation points to a more nuanced reality —technology 

always coevolves with economic, social and political 

systems 5 and is codetermined with the evolution of 

norms, institutions and public policies. 6 For exam -

ple, economic expansion during the Industrial Revo -

lution was the product of new technology along with 1 0 4 HUMAN DEVELOPMENT REPORT 2025 

new ways of organizing economic production, new 

workforce skills and a range of new institutions that 

emerged in response to new demands. 7

A deterministic view of technology drives a di -

chotomy between utopian and dystopian futures for 

humanity with the rise of AI, often fuelled by media 

representations of AI with a great deal of hype and 

exaggeration. 8 Two dichotomous perspectives  — one 

optimistic, where technology is considered a positive 

force for progress, and another pessimistic, where 

technology is inexorably outside human control  —

have one thing in common: they oversimplify the 

complex interactions between technology and soci -

ety and project a sense of inevitability for the social 

consequences that follow technological change. 9

They seemingly leave little room for human agency 

to shape technological change in ways that enhance 

people’s freedoms, opportunities and choices. 10  In 

contrast with this view, this chapter argues that the 

outcomes of technological change are not inevitable; 

they are contingent on social choices. 11 

Moreover, technologies are never neutral. They 

embody social contexts, choices and values. 12  The 

characteristics of AI deserve attention in their own 

right. But the impacts cannot be analysed in isolation 

from the contexts in which AI is deployed. The inter -

actions between technology and society are interde -

pendent and multifaceted, and they both change in 

relation to each other. 13  The impacts of AI stem not 

from individual technical components but from the 

dynamic ways they interact with social forces and 

from how they are used, by whom and for what pur -

pose. 14  Human agency and context matter. 

With the rapid rise in AI’s development and avail -

ability, techno- deterministic narratives assume that 

technological solutions will mitigate complex social 

challenges in such areas as education, healthcare 

and social services. To be clear, nothing is inherent -

ly wrong with intending to deploy new technologies 

to address societal challenges, as argued in much of 

this Report. History is replete with examples of tech -

nological changes that revolutionized human lives, 

bringing massive improvements in living standards, 

connections and economic growth. Indeed, AI can 

be massively helpful. For example, generative AI in 

education can help close persistent gaps by paving 

the way for truly adaptive, on- demand and personal -

ized teaching. It also has the potential to enhance the 

quality of healthcare by, among other things, reduc -

ing administrative burdens on providers (chapter 6). 

Even so, AI cannot provide quick fixes —its deploy -

ment alone does not determine social outcomes. 

Such promises of quick fixes often appeal to under -

funded institutions. 15  A technology may accomplish 

a narrowly defined goal, but doing so in a way that 

solves problems for all rather than for just a subset 

of individuals who can afford to benefit matters. Ul -

timately, how technological solutions determine so -

cial outcomes is shaped by social and institutional 

arrangements. 

# “ The impacts of AI stem not from individual 

technical components but from the dynamic 

ways they interact with social forces and from 

how they are used, by whom and for what 

purpose. Human agency and context matter 

But deploying technology as solutions is not the 

only thing that matters; the way in which technol -

ogy development occurs also involves choices that 

could lead to differing outcomes across social groups. 

Technological change can reinforce, amplify and re -

configure inequalities, potentially exacerbating dis -

crimination or generating new forms of it. Seemingly 

innocuous design features can mask social choices, 

with profound consequences. 16  For instance, gender 

inequalities in technology production and consump -

tion are reflected in the development and use of AI. 17 

AI has the potential to ameliorate social inequalities, 

but achieving this potential —and empowering people 

and communities  —requires considering social con -

texts so that policy and institutional choices on the 

trajectory of AI and its deployment advance human 

development. 18 

Framing a narrative on AI that considers this 

broader codetermination of technology and society 

can support the design and use of AI in ways that ad -

vance human development. Through the examples of 

people with disabilities, the care system, women and 

AI bias, this chapter illustrates how narratives matter 

and how their framing can help in reimagining choic -

es about technologies, policies and institutions to 

expand people’s capabilities and agency. Narratives 

not only affect the kind of technologies we decide to 

develop or use  —they also shape how we define prob -

lems in need of technological solutions. CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 0 5 

# “ Through the examples of people with 

disabilities, the care system, women and AI 

bias, this chapter illustrates how narratives 

matter and how their framing can help in 

reimagining choices about technologies, 

policies and institutions to expand people’s 

capabilities and agency. Narratives not only 

affect the kind of technologies we decide to 

develop or use —they also shape how we define 

problems in need of technological solutions 

## AI’s potential for people with disabilities: 

## Framing a more nuanced narrative 

## to expand human development 

People with disabilities provide a compelling illustra -

tion of the substantial opportunities and challenges 

that AI presents. Technological innovations can play 

a major role in facilitating choices and open opportu -

nities for people with disabilities. But AI’s potential 

to revolutionize the lives of people with disabilities 

would have to go beyond framings of technologies as 

enablers to overcome impairments. Indeed, relying 

on various technologies for fundamental life func -

tions exposes people with disabilities to dispropor -

tionate social marginalization when the technology 

is inaccessible, inappropriate, inconsiderate of their 

needs and preferences or incongruous with their 

identities. While AI tools create enormous possibili -

ties for people with disabilities, they are insufficient 

to promote inclusion and participation on their own. 

Inclusion is a fundamentally social process that en -

tails broader changes in social norms, institutions 

and policies. 

For people with disabilities, human–machine in -

teractions and machine-mediated human–human 

interactions are hardly new. 19  People with disabilities 

have long relied on various kinds of technologies for 

everyday functions, such as communication, mobil -

ity, writing and reading. In fact, many technological 

developments  — such as email, text messaging, op -

tical character recognition, text to speech, speech to 

text and smart home systems  —were originally de -

signed for people with disabilities before being more 

widely adopted. 20  These technologies generally fall 

under the umbrella of assistive technologies. 21 

Over the years digital technologies have brought 

about considerable advancement in assistive tech -

nologies, offering new opportunities to enhance 

independence, participation and access. 22  For ex -

ample, mobile phones function as a cost- effective 

assistive technology. 23  Because of their versatility, 

they can include multiple accessibility features  —

such as the ability to access information in different 

formats  — into a single device. This is emblematic 

of a broader shift where inclusive features are inte -

grated into mainstream consumer technologies, re -

ducing the need for specialized products for specific 

needs. 24 

The recent advent and massive adoption of AI have 

enabled pathbreaking innovations in assistive and ac -

cessible technologies. 25  Live captioning algorithms 

help deaf or hard of hearing individuals. Image rec -

ognition solutions allow blind and visually impaired 

people to hear descriptions of the world around them. 

And text-to-speech and speech-to-text solutions sup -

port people with dysarthric speech and people who 

have difficulty typing. 26  These technologies’ potential 

to enhance the capabilities of people with disabilities 

can be immense, improving the quality, availability 

and affordability of accessible technologies. Main -

stream AI-based technologies such as smart home 

devices can allow people to control their environment 

through voice. 

Generative AI has emerged as a useful tool for 

people with disabilities, particularly for accessibility 

— producing descriptions of images for blind and 

visually impaired people 27  and converting text into 

easy-to-read formats for people with developmen -

tal and intellectual disabilities. 28  More recently, 

large language models have been explored as a way 

to support communication for users of alternative 

and augmentative communication 29  and to trans -

late sign language into voice or text. 30  As these tools 

are rapidly integrated into education, healthcare, 

workplaces and public services, the opportunities 

to promote greater accessibility and inclusion are 

enormous. 

Multifaceted inequalities get in the way 

As the history of past innovations in assistive and ac -

cessible technologies demonstrates, the features and 1 0 6 HUMAN DEVELOPMENT REPORT 2025 

affordances of new technologies need to be consid -

ered in the light of the diversity and heterogeneity 

inherent to the experience of disability. When access 

to even the most basic and essential assistive technol -

ogies is uneven, the opportunities brought about by 

advances in digital technologies remain unrealized 

for many and may further exacerbate inequalities. 31 

More than 2.5 billion people need access to assistive 

technologies. 32  But access remains highly unequal 

around the world. 33  Similar inequalities can be ob -

served in the case of information and communication 

technologies (figure 4.1). 34  People with disabilities 

also have lower digital skills because accessible dig -

ital literacy training remains limited. 35 

Even when people have access to assistive tech -

nologies, the technologies may not work the same 

way everywhere. Most of the technologies on which 

people with disabilities depend are manufactured in 

a handful of countries. Most of the patents for both 

conventional and emerging (AI, robotics and virtual 

reality) assistive technologies are filed in China, the 

United States, Japan, the Republic of Korea or Euro -

pean countries —all of which have high or very high 

HDI values (figures 4.2 and 4.3). 

Technologies developed in higher HDI coun -

tries often fail to consider the diverse realities and 

infrastructural and cultural contexts for people with 

disabilities in much of the world. In contexts with 

high poverty and minimal progress in enforcing ac -

cessibility, the relevance of apps and other tech -

nologies that rely on maximum internet speed and 

smartphones with high-performance processers may 

be limited. 36  These persistent inequalities stifle AI’s 

potential. 

Figure 4.1  People with disabilities also face inequalities in internet use 

Persons with disabilities Persons without disabilities 

AVERAGE: 28 AVERAGE: 39 

Internet users (%) 050 100 Chad* (WG) Central African Republic* (WG) Dem. Rep. of the Congo* (WG) Madagascar* (WG) Sierra Leone* (WG) Malawi* (WG) Uganda* (WG) Zambia* (WG) Rwanda* (WG) Pakistan* (WG) Nigeria* (WG) Guinea-Bissau (WG) Colombia* Afghanistan* (MDS) Togo* (WG) Mali* (WG) Ghana* (WG) Timor-Leste (WG) Zimbabwe* (WG) Haiti* (WG) Cuba* (WG) Guatemala* Mauritania (WG) Kiribati* (WG) Philippines* (MDS) Nepal* (WG) Lesotho* (WG) Sao Tome and Principe* (WG) South Africa* (WG) Mexico* Gambia* (WG) Tunisia* (WG) Senegal* (WG) Samoa* (WG) Peru* Mongolia* (WG) Tuvalu (WG) Tonga (WG) Albania* Suriname* (WG) Costa Rica* (MDS) Georgia* (MDS) Maldives* India* (MDS) Tajikistan (MDS) Lao PDR (MDS)              

> * The difference between people with disabilities and people without disabilities is significant at 5 percent.
> Note: MDS indicates data produced with the Model Disability Survey. WG indicates data produced with the Washington Group Short Set of Questions. Data are
> for 2021 or the most recent year available.
> Source: UNDESA 2024. CHAPTER 4 — F RAMING NARRATIVES TO REIMAGINE ARTIFICIAL INTELLIGENCE TO ADVANCE HUMAN DEVELOPMENT 1 07

Agency at the centre, not an afterthought 

Consider Google Relate, a free mobile app that can 

create personalized speech recognition models in 

English for nonstandard speech to support commu -

nication. It has the potential to greatly enhance the 

social inclusion of people with communication dis -

abilities. 37  But a prerequisite for accessing the app is 

a smartphone that meets minimum specifications. 38 

Users also need reliable internet connectivity. In -

deed, people who struggle to communicate in Eng -

lish have found it difficult to use Google Relate in 

daily life. 39 

Even for people who speak English, the automatic 

speech recognition model is trained on American Eng -

lish and thus fails to recognize local expressions and 

vocabulary in other languages and cultures. 40  Google 

Relate supports communication by helping strangers 

or unfamiliar partners better understand the speech 

of people with communication disabilities. Integra -

tion of these technologies is contingent on changes in 

communication norms —through, for instance, greater 

acceptance of diverse ways of communicating. 41  This 

is true particularly for people with communication 

disabilities who have been subjected to marginaliza -

tion and stigma throughout their lives. 42  Technologies 

like these can reshape communication dynamics. But 

Figure 4.2  Most patents for conventional assistive technology are filed in just a handful of countries… 

> 030,000 20,000 10,000 40,000 50,000

Number of patents, 2000–2010 Tajikistan Armenia Kyrgyzstan Georgia Gulf Cooperation Council Slovakia Moldova Uzbekistan Belarus Luxembourg Kazakhstan Ireland Portugal Thailand Argentina Hungary Romania Czechia Eurasian Patent Organization Finland Belgium Malaysia Türkiye Denmark Philippines Switzerland Indonesia Viet Nam Austria Poland Norway Israel South Africa Sweden New Zealand Italy Netherlands Singapore Hong Kong, China (SAR) Mexico Russian Federation Brazil Spain India United Kingdom France Canada Australia Germany Republic of Korea European Patent Office World Intellectual Property Organization Japan United States China  

> Source: Human Development Report Office based on data from WIPO (2021). 1 0 8 HUMAN DEVELOPMENT REPORT 2025

changes in communication norms, adequate aware -

ness and training, and contextual relevance are neces -

sary for a transformative impact on people’s lives. 

Rather than assuming a deficit that needs to be 

fixed, the design of AI technologies needs to recog -

nize the ways in which people with disabilities navi -

gate the world and then innovate with the objective of 

enhancing these capabilities. That is, AI applications 

should focus on making things easier, drawing on the 

experience and expertise of people with disabilities, 

rather than assuming a deficit that needs to be fixed. 43 

Agency —people’s freedom and ability to make and 

act on choices that they value and have reason to 

value  —is a critical aspect of human development. 44 

Yet this freedom is compromised when some ways 

of being and doing are judged as inferior to others. 

Exoskeletons are wearable robotic devices designed 

to restore human movement, particularly for people 

with mobility-related disabilities. This technology 

has been hailed for its potential to enable people who 

cannot walk to do so again. But it could also reify dis -

criminatory and ableist norms that privilege walking 

as the only valid form of locomotion and marginalize 

wheelchair users. 45  Likewise, technologies for autistic 

children are guided by a deficit perspective and aim 

to correct, fix and cure rather than focusing on chil -

dren’s unique needs and strengths. 46  Many technol -

ogies for autism concentrate on controlling autistic 

Figure 4.3  …as are most patents for emerging assistive technology 

> 01,000 7,000 6,000 5,000 4,000 3,000 2,000

Number of patents, 2000–2010 Georgia Luxembourg Gulf Cooperation Council Kyrgyzstan Moldova Slovakia Thailand Belarus Denmark Portugal Czechia Finland Malaysia Eurasian Patent Organization Argentina Romania Belgium Hungary Switzerland Türkiye Norway Viet Nam Sweden New Zealand Poland Austria Indonesia Italy Philippines Netherlands South Africa United Kingdom Israel Singapore France Mexico Hong Kong, China (SAR) Spain Brazil India Russian Federation Germany Canada Australia Republic of Korea Japan European Patent Office World Intellectual Property Organization United States China             

> Source: Human Development Report Office based on data from WIPO (2021). CHAPTER 4 — F RAMING NARRATIVES TO REIMAGINE ARTIFICIAL INTELLIGENCE TO ADVANCE HUMAN DEVELOPMENT 1 0 9

people by encouraging socially normative behaviour 

without accounting for the adverse effect of doing 

so. 47  The values embodied in such technologies may 

be contrary to those of their users or their sense of 

identity. 48  Such stereotypical conceptions of disabili -

ty, when encoded in technology design, could reduce 

the agency and choice that people with disabilities 

have over their lives. 

Also crucial is recognizing the risks involved and ex -

ercising caution while using AI-based technologies, 

particularly in high-stakes situations. AI tools contin -

ue to suffer from hallucinations, bias and underrep -

resentation of people with disabilities in training data. 49 

These limitations pose particular constraints for peo -

ple with disabilities. For example, blind users who rely 

on generative AI tools to access image-based informa -

tion cannot independently verify the accuracy of the 

outputs. 50  Likewise, due to the underrepresentation 

of people with disabilities in the datasets used to train 

AI models, those models are not very effective at gen -

erating accessible content, 51  can generate misinforma -

tion about accessibility and disability 52  and reinforce 

stereotypes. 53  Indeed, most of the internet remains in -

accessible for people with disabilities. Despite substan -

tial progress in defining and adoption of standards for 

digital accessibility around the world, about 95.9 per -

cent of the top million websites do not comply with the 

International Web Content Accessibility Guidelines. 54 

It is thus important to ensure that AI technologies and 

interfaces are accessible so that AI-generated content 

does not heighten inaccessibility. Establishing human-

in-the-loop mechanisms is critical when AI tools are 

used for accessibility —to ensure that people with dis -

abilities have access to accurate information, quality 

services and meaningful experiences, as well as human 

alternatives when needed. 

In many cases people with disabilities have to com -

promise their privacy to access essential services. 55 

They face an unfair tradeoff between accessibili -

ty and privacy while using AI tools for their specific 

needs. People with disabilities constitute a highly het -

erogenous group  —with very distinct needs. Exist -

ing privacy protections hence become insufficient as 

their unique needs increase their risk of being reiden -

tified. 56  And their reliance on AI tools for fundamen -

tal aspects of their lives means that privacy violations 

can have huge consequences, 57  exposing them to 

greater risk of discrimination and surveillance. 58 

# “ Rather than considering disability a problem to 

be fixed or an afterthought, we should recognize 

people with disabilities as active participants 

in technology design and development 

People with disabilities have too often been por -

trayed as passive beneficiaries of technologies, 59 

neglecting their expertise, knowledge and diverse 

experiences, which have informed many of the major 

breakthroughs in technology and communication 

—including text-to-speech, speech recognition and 

optical character recognition, which have benefited 

everyone. 60  Rather than considering disability a prob -

lem to be fixed or an afterthought, we should recog -

nize people with disabilities as active participants in 

technology design and development. 61  Since they 

have the most to gain from AI —and the most to lose 

— designs centred on the participation of people with 

disabilities have paved the way for human–machine 

interactions that overcome homogenization and truly 

embrace human diversity. 

## Narratives about care technologies 

## overlook the profoundly human 

## and relational nature of care 

Advanced digital technologies  — including AI, ro -

botics and the Internet- of-Things  —have been in -

troduced in the care sector to reduce the burden on 

caregivers and boost independence among care re -

cipients. 62  The growing share of older people in the 

population and the concomitant shortage of care 

workers have motivated investment in care technol -

ogies in many countries. For instance, the European 

Union invested $103 million in a research and devel -

opment program called Robotics for Ageing Well in 

2015–2020, and in 2019 the UK government invested 

$48 million in robots for adult social care. 63  Some nar -

ratives backing these policy developments posit that 

innovations in digital and AI technologies can solve 

the worker shortages and reduce public spending on 

care. 64  Public narratives on care robots often reflect 

this techno- deterministic view, too often focusing on 

the potential of these technologies to care for older 

people. 65  But those narratives misconstrue the na -

ture of care as a human, social and emotional activity 

and fail to account for the impact of care technolo -

gies on human interaction and caring relationships. 66 1 1 0 HUMAN DEVELOPMENT REPORT 2025 

In reality, the need for care is increasing, while those 

who provide care are unpaid or underpaid. 

The use of technologies for care is not new. Wash -

ing machines, vacuum cleaners and the like entered 

homes long ago and have helped ease domestic 

work. 67  Recent applications of digital and AI technol -

ogies have the potential to further enhance the well -

being of caregivers and care recipients. But care is 

a relational activity. So, it is essential to understand 

how these technologies reshape care practices and 

caring relationships. 

Digital technologies are being introduced as care is 

being commercialized. 68  Wage care work is growing 

rapidly in many economies. And personalized and pri -

vatized funding and organization have become an im -

portant mode of care provision. Care has been framed 

in many places as private responsibility of families, 

bolstering a growing care economy around the world. 69 

The paid care economy supports more than 380 mil -

lion jobs around the world. 70  Rapid population ageing, 

along with reduced availability of unpaid familial care, 

has bolstered this trend. Rising female employment, 

accompanied by insufficient progress in redistribut -

ing care work within households, has reduced the time 

women can devote to care-related tasks. 

# “ Care —by its very nature —is emotional 

and relational. Job replacement and 

augmentation of caregiving tasks are thus 

much more complicated and may give rise 

to a new set of tensions and tradeoffs 

Digital technologies are often introduced with 

the objective of replacing, mediating or augment -

ing caregivers’ work. 71  Technologies that mediate 

interactions between caregivers and care recipients 

are fundamentally reshaping how care is communi -

cated and monitored. 72  Care  —by its very nature  —is 

emotional and relational. Job replacement and aug -

mentation of caregiving tasks are thus much more 

complicated and may give rise to a new set of ten -

sions and tradeoffs. 73 

New possibilities, but also tensions 

Digital and AI- enabled technologies allow people to 

care for others from a distance. Smartphones, video 

chat and other audio-visual tools allow older people to 

connect with distant others and maintain social, emo -

tional and cultural bonds. For caregivers digital and 

telecare technologies can ensure the safety and secu -

rity of those under their care. A wide array of devices 

measure life functions, register movements and assist 

with everyday tasks. Such devices are often equipped 

to automatically notify relatives or health profession -

als if the collected data show a deviating pattern. 74 

Having access to and evaluating one’s own health 

data can strengthen the agency of care recipients 

while interacting with health professionals. 75  But 

health trackers can also result in increased feelings of 

stress and anxiety due to constant tracking of health 

parameters. 76  Then there are technologies to control 

and regulate physical space and environment. For in -

stance, smart home technologies can ensure a light 

path comes on when someone steps out of bed to re -

duce the likelihood of falls or employ environmental 

sensors that adjust heating, ventilation and air con -

ditioning systems. These technologies can enhance 

older people’s independence, especially since they do 

not require specialized digital skills to operate. 77 

Trust forms an essential condition for caring rela -

tionships. As discussed in chapter 3, older people tend 

to use digital and AI technologies at much lower lev -

els than younger people. Care technologies, as well as 

policies around age care, need to be informed by an 

understanding of older people’s preferences, beliefs, 

expectations and fears regarding AI. Older people 

across HDI levels expect to have less choice and con -

trol over their lives as AI technologies become further 

integrated into daily life (figure 4.4). Trust in AI tech -

nologies is lowest among older people. Only 48 percent 

of older people —as opposed to 68 percent of younger 

people — express confidence that AI technologies are 

currently designed to act in the best interest of society. 78 

This expected loss of agency could be driven by a 

variety of factors. Replacing in-person contact with 

remote monitoring and supervision can add to older 

people’s social isolation. 79  A recent survey in the Unit -

ed Kingdom finds that people note considerable ad -

vantages of robotic care assistants, particularly in 

relation to efficiency. 80  However, worries about the 

loss of human interaction were also widely prevalent. 

Indeed, 78 percent of people were concerned that care 

recipients would lose out on interaction with human 

caregivers. This finding indicates people’s openness CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 1 1 

to using AI to support the care process without under -

mining the social, emotional and ethical dimensions 

of care. Some 48 percent of people agreed that as -

signing responsibility would be difficult if things went 

wrong. There is a momentous risk of manipulation 

and deception, disrespecting the agency and digni -

ty of older people, particularly when they may not be 

fully aware of the capabilities of the technologies and 

are unable to provide informed consent. 81 

Also consider the unfair tradeoffs that such technolo -

gies impose on older people —for instance, between pri -

vacy and the ability to live at home. 82  Such tradeoffs can 

undermine older people’s agency by constraining their 

ability to make choices in line with their values and 

preferences. This is particularly concerning because 

older people across countries value privacy more than 

younger people do. 83  People’s attitudes towards care ro -

bots could also be influenced by a lack of alternatives. 

Indeed, support for care technologies during old age 

depends on the generosity of local welfare provision. A 

survey in 28 European countries finds that people are 

not keen to introduce robots as part of old-age care, at 

least when the human care available is generous. 84 

Design choices and processes can play a crucial 

role in either fostering or inhibiting trust. Ageist ste -

reotypes 85  of older people being frail, lonely and in 

need of physical, cognitive and mental maintenance 

are embedded in these technologies and in the nar -

ratives hailing their potential. 86  Like other AI biases, 

ageism can appear through the beliefs and ideologies 

of those creating AI technologies or be embedded in 

the datasets that AI systems process. 87  For instance, 

AI technologies for older adults disproportionate -

ly focus on healthcare and chronic disease man -

agement, overlooking other crucial aspects such as 

leisure and enjoyment. 88 

Technology design and deployment often exclude 

older people and impose limits on their participa -

tion, 89  reflecting a patronizing attitude towards age -

ing. Many AI applications for aged care, such as home 

monitoring or fall detection systems, involve surveil -

lance technologies. These devices collect data about 

users’ daily activities — often without their awareness 

or ability to override these technological decisions. 90 

While the intentions of the developers and deployers 

of these technologies is to promote the wellbeing of 

Figure 4.4  Older people expect to have less choice and control over their lives as artificial intelligence technologies 

become more integrated into daily life     

> –20 –15 –10 –5 0510 15–24 25–34 35–44 45–59 60 and older

Change (%) Age group High HDI Low and medium HDI Very high HDI   

> HDI is Human Development Index.
> Note: Data are a pooled sample of 21 countries.
> Source: Human Development Report Office based on the United Nations Development Programme Survey on AI. 1 1 2 HUMAN DEVELOPMENT REPORT 2025

older people, respecting their agency is paramount 

to establish trust, enable meaningful choices and ex -

pand their freedoms. 91 

In many cases the limitations of the technology 

itself can pose risks to people’s safety. It is essential 

that technologies  — particularly care technologies 

—be evaluated in the context of use because people 

depend on them for basic needs and life functions. 

Research into these technologies’ impact on the care 

process and relationships remains scarce. These tech -

nologies, when introduced without rigorous evalua -

tion of their capabilities, can expose older people to 

risk of injury and negative health outcomes. For ex -

ample, robots designed to assist older people with 

mobility could result in greater risk of falls. 92 

Care technologies are often introduced to reduce the 

burden on human workers. Care robots can purported -

ly free up time for the social, relational and emotional 

elements of care by automating the physically strenu -

ous ones, such as lifting and transferring. But care work 

is fundamentally different from other kinds because it 

involves tasks that combine physical and affective el -

ements that cannot usually be separated in ways that 

allow for full job replacement. 93  Indeed, care technolo -

gies create more work for care workers by reconfiguring 

and reorganizing tasks. For instance, constant digital 

monitoring can intensify the workload of care work -

ers, particularly unpaid family caregivers.  94  Especially 

when such technologies are deployed to monitor care 

workers, they tend to redefine care work based on the 

amount of time consumed in performing care tasks. 95 

Nursing homes in many countries are experiment -

ing with care robots. These technologies tend to in -

troduce new tasks for care workers  —such as setting 

up, moving, operating, mediating, cleaning, updating 

and overseeing these technologies. 96  Care workers 

must also constantly monitor and observe the inter -

actions between older people and the technologies. 97 

In Japan these robots have been associated with in -

creased employment of care workers. 98  In fact, they 

would likely increase employment of lower skilled 

workers, who would not have to interact as much with 

people and could get by with less care training and 

experience. A higher share of care tasks performed 

by robots is positively corelated with higher employ -

ment of care workers on temporary contracts. 99 

The working conditions of care workers have im -

plications for the quality of care. Reconfiguring care 

into short units of time promotes fragmented and 

task- oriented practices, pre- empting a more person-

centred approach, with detrimental impacts for the 

wellbeing of both care recipients and work quality. 100 

Good care depends on caring relationships between 

caregivers and care recipients. 101  However, this can 

be difficult to achieve when caregivers face pressure 

to fulfil multiple competing demands at work. 

Research on the potential opportunities and chal -

lenges associated with care technologies is concen -

trated in Europe, North America and Japan. These 

technologies have been deployed in institutional care 

settings and to a lesser extent in homes. Across many 

low- and middle-income countries care is provided 

largely by women within familial and kin networks. 

In these contexts advanced care technologies may be 

inaccessible, unaffordable, inadequate and even cul -

turally inappropriate. Most of these specialized tech -

nologies are expensive, and many are intended for use 

in care institutions. They are thus unsuitable for the in -

formal, community-based and culturally heterogenous 

nature of care provision across the world. Digital care 

platforms that organize the supply and demand of paid 

care work have proliferated across the world (spotlight 

4.2). While these technologies offer greater flexibility, 

in the absence of regulations and policies to support 

caregivers and care recipients, they can reinforce and 

even exacerbate the same inequalities, power imbal -

ances, exploitation and informalization that have long 

pervaded care systems around the world. 

Shaping a narrative that advances a caring future 

Across the world paid care work remains characterized 

by a lack of rights, benefits and protections; low wages 

or noncompensation; low unionization; physical and 

mental health impacts; and in some cases sexual vio -

lence and harassment. 102  Care continues to be viewed 

as an extension of women’s traditional roles. 103  The 

shortage of care workers in many countries is an out -

come of political, economic and social choices. It often 

arises from the low status accorded to and inadequate 

remuneration for care work. These conditions would 

likely worsen with technologies aimed solely at reduc -

ing costs. As seen in the case of digital care platforms, 

technological fixes alone are likely to reproduce the 

inequalities and exploitative conditions that produced CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 1 3 

the care crisis in the first place (spotlight 4.2). These 

conditions are unlikely to improve unless care tech -

nologies are developed and used to enhance the well -

being and agency of both the people who provide care 

and receive it, to promote trust, to strengthen caring 

relationships and to recognize and shift social norms. 

# “ Care technologies are developed and used 

to enhance the wellbeing and agency of both 

the people who provide care and receive it, to 

promote trust, to strengthen caring relationships 

and to recognize and shift social norms 

We need a narrative to envision and create a more 

caring future. Everyone needs care and support at 

some stage of life, if not throughout it, to partici -

pate equally in society and to live with dignity. Care, 

therefore, needs to be envisioned as critical to social 

and economic wellbeing, not reduced to a commod -

ity, personal choice or family obligation. 104  Com -

plementary approaches such as paying care workers 

an amount that aligns with the social value of their 

work, improving working conditions, supporting in -

formal caregivers and investing in comprehensive so -

cial support for older people are critical to tackle the 

problems facing care systems. This narrative requires 

recognizing and enhancing the agency of those who 

provide and receive care and promoting public invest -

ment in care provision. 105  Indeed, greater investment 

in elder care is associated with having more human 

carers available. 106  Countries that spend a larger 

share of GDP on old-age support have more doctors 

per resident and more long- term carers available. 107 

To reap the opportunities of AI for care, the focus 

needs to be less about technology as a solution for 

growing care needs and more about enhancing the 

capabilities and agency of both caregivers and care 

recipients. These technologies are increasingly re -

shaping care processes. For example, AI chatbots 

could alleviate administrative burdens on both pro -

fessional and family caregivers. They could also ex -

pand access to information —for example, suggesting 

how to support an older person with a specific activity 

or assisting with creating care plans. 108  All generative 

output and its adequacy must be critically appraised 

before informing any care decisions or tasks —ideally 

with the consent and participation of the care recipi -

ents. 109  At the same time investment in technological 

solutions should not distract from investment and 

support for both paid and unpaid carers. 110  In sum, 

investments in AI need to be accompanied by invest -

ments in people, as well as by supportive institutions 

and policies to ensure that AI augments what caregiv -

ers can do and the agency of those receiving care. 

Care-led approaches to developing and deploying AI 

require the active participation of the people being 

cared for, as well as the people caring for them. 

## Narratives about gender digital 

## divides paint an incomplete picture 

Technologies are neither inherently patriarchal nor 

unequivocally emancipatory. 111  Digital technologies 

and the internet have largely been considered dem -

ocratic and emancipatory tools with the potential to 

empower women —and in many ways, they are. Mo -

bile phones in particular have increased women’s 

access to information, opportunities, resources and 

social networks and facilitated collective action. 112  So, 

the focus of digital inclusion policies has been on en -

suring women’s equal access to digital technologies. 

Despite multiple initiatives to expand access and 

affordability, inequalities in access to and use of dig -

ital technologies have persisted. It is thus essential to 

account for the ways gender inequalities manifest in 

women’s interactions with technologies. 113 

Technological change is shaped by and in turn 

shapes gender norms. To illustrate this relationship 

with an example, consider smart home technologies 

—promoted as tools to reduce the drudgery associ -

ated with domestic work. Digitally connected smart 

devices such as cooking robots, robot vacuum clean -

ers, window cleaners and lawnmowers claim to trans -

form domestic work by freeing up women’s time from 

unpaid domestic labour. A recent estimate found that 

domestic automation could free up 9.3 percent of 

women’s time in Japan and 5.8 percent in the Unit -

ed Kingdom to undertake full- or part-time employ -

ment. 114  Historically, household appliances have 

helped women save time on domestic work and con -

sequently enhance their participation in the labour 

force. 115  But these technologies have not shifted gen -

der roles that expect women to perform a majority 

of unpaid domestic work. 116  Innovations in domestic 

technologies often reshaped household work by, for 

instance, increasing expectations around cleanliness 1 1 4 HUMAN DEVELOPMENT REPORT 2025 

and home maintenance. 117  In fact, such technologies 

enable the disproportionate burden of household 

work on women by continuing to frame domestic 

work as primarily women’s responsibility. 118 

Women’s marginalization from the technological 

community has a profound impact on the design, 

features and use of technologies. 119  Notwithstanding 

the progress in recent decades, gender gaps in digi -

tal skills; opportunities for science, technology, en -

gineering and mathematics (STEM) education; and 

the tech labour force have persisted. 120  Underpinning 

these gaps are deeply entrenched power asymmetries 

and norms that condition women’s self-competence 

to engage with technology, the visibility and recog -

nition they receive for their work and the extent to 

which technological innovations meet their needs. 

Social norms condition women’s 

opportunities and choices 

Remarkable progress has been made in expand -

ing access to education for girls around the world. 

Still, the underrepresentation of women and girls 

in STEM and their lower digital skills persist glob -

ally. Gender norms that construct mathematics as a 

male discipline condition the aspirations, confidence 

and success of girls in STEM. 121  Across 80 countries 

boys are more likely to aspire to things- oriented or 

STEM careers, whereas girls are more likely to as -

pire to people- oriented careers. 122  These norms are 

widely prevalent across countries. 123  Relatedly, social 

norms also portray men as more brilliant or inherent -

ly talented than women. 124  Norms that associate tal -

ent with men are widely prevalent across contexts. 125 

These norms are strongly associated with gender 

gaps in competitiveness, self- confidence and will -

ingness to work in information and communication 

technology–related occupations. 126 

Girls perform equally well or better than boys when 

STEM subjects are not considered exclusively male 

oriented. 127  On average, 35 percent of STEM gradu -

ates are women —a share that has changed little over 

the past decade (figures 4.5 and 4.6). But women’s 

representation among STEM graduates is higher in 

some countries than in others. The reason? In many 

Figure 4.5  On average, only 35 percent of graduates in science, technology, engineering and mathematics are women 

010 20 30 40 50 60 70 Female (%) Sub-Saharan Africa Europe and Northern America Central and Southern Asia Eastern and Southeastern Asia Latin America and the Caribbean Northern Africa and Western Asia Oceania Average Niger Chad Ghana Burkina Faso Lesotho Burundi Benin Mozambique Rwanda Seychelles Mauritania Madagascar Botswana Mauritius Namibia Cabo Verde Tanzania South Africa Belarus Germany Ukraine Austria Moldova Luxembourg France Canada Montenegro Bosnia and Herzegovina Afghanistan Bangladesh Uzbekistan Kazakhstan Maldives Turkmenistan Sri Lanka Kyrgyzstan India Republic of Korea Cambodia Lao PDR Singapore Thailand Mongolia Malaysia Philippines Indonesia Myanmar Brunei Ecuador Dominican Rep. Turks and Caicos Honduras Grenada Cuba Trinidad and Tobago Belize British Virgin Islands Israel Egypt UAE Jordan Bahrain Tunisia Syria Australia Marshall Islands New Zealand Fiji Samoa             

> Source: UNESCO 2024b. CHAPTER 4 — F RAMING NARRATIVES TO REIMAGINE ARTIFICIAL INTELLIGENCE TO ADVANCE HUMAN DEVELOPMENT 1 1 5

cultures STEM is not considered appropriate only for 

men. 128  Nonetheless, in most countries, widely held 

gendered norms continue to restrict women’s partic -

ipation in STEM. 

Social norms that assign a disproportionate share 

of care responsibility constrain opportunities for 

women to acquire digital skills (box 4.1). 

Sadly, these inequalities are now transposing onto 

AI. In many cases, these inequalities widen when 

focusing on AI rather than STEM broadly. 129  While 

about a third of global researchers in science are 

women, 130  only 12 percent of AI researchers are. 131 

And women constitute only 30 percent of AI talent 

globally. 132  While it remains important to enhance 

women’s participation in AI production, the terms 

of their inclusion matter equally. Masculine norms 

and value systems continue to govern participa -

tion in AI. Women working across the fields of data 

and AI have higher levels of formal education than 

men but are overrepresented in lower status, lower 

Figure 4.6  The share of graduates in science, technology, engineering and mathematics who are women has changed 

little since 2010–2011 

10 15 20 25 30 35 40 45 50 55 60 Female (%) Chile Costa Rica Brazil El Salvador Mexico Panama Colombia Argentina Uruguay Switzerland Netherlands Ireland Belgium Finland United Kingdom Spain Malta Norway Sweden Denmark Portugal Greece Iceland Italy Slovenia Czechia Lithuania Hungary Latvia Slovakia Poland Croatia North Macedonia Bulgaria Romania Serbia Estonia Albania Islamic Republic of Iran Türkiye Saudi Arabia Armenia Morocco Cyprus Georgia Azerbaijan Palestine Qatar Oman Algeria Latin America Western Europe 2010 2020 Northern Africa and Western Asia Central and Eastern Europe 

Source:  UNESCO 2024b. 1 1 6 HUMAN DEVELOPMENT REPORT 2025 

paying roles, are substantially underrepresented in 

C-suite positions, experience higher turnover and 

attrition and report lower self- confidence in their 

skills. 133  Women are also underrepresented among 

AI users. Our survey finds that 37 percent of women 

are AI users, compared with 41 percent of men. But 

men report greater use of AI for work across all lev -

els of education (chapter 6). Global internet traffic 

data also reveal that only 33 percent of ChatGPT 

users are women. 134  Over time women’s lower adop -

tion of generative AI could exacerbate labour market 

inequalities. 

Box 4.1  Going beyond access: Women’s disproportionate care responsibilities drive their lower digital skills 

Women’s ability to acquire digital skills is shaped by deep-rooted gender norms that assign them a disproportionate 

share of domestic and caregiving responsibilities. 1 These norms limit their time and opportunities for education, skill 

development and workforce participation, reinforcing gender gaps in information and communication technology 

(ICT) skills. 2

A clear relationship can be observed between caregiving responsibilities and digital skill acquisition, particularly 

among women, across Human Development Index values. As the number of children in the household increases, 

women’s ICT skills decline significantly (left panel of box figure 1). Notably, women with no children tend to have 

stronger ICT skills than men with no children (right panel of box figure 1). Because care responsibilities are unequally 

distributed, the gap appears with the first child and widens with two or three children. These findings illustrate how 

societal expectations around caregiving create additional barriers to women’s participation in the digital sphere. 

Thus, while expanding access to digital devices and skills training programs is essential, these efforts alone cannot 

overcome the structural inequalities imposed by social norms. Policies that recognize, account for and act on the 

unequal distribution of care responsibilities are crucial to ensure that women have the time, resources and support 

needed to acquire the requisite skills to thrive in the digital economy. 

Box figure 1  As the number of children in the household increases, women’s information and communication 

technology skills decline and the gender gap in skills widens 

> 0.000 0.020 0.040 0.060 0.080 0.100 0.120 0.140 43210

Number of children Mean ICT Skills Index for women 4321Number of children –0.016 0Gap in ICT Skills Index between men and women 0.072 0.051 0.028 0.082 0.144 0.019 0.029 0.025 0.006 –0.010 0.000 –0.005 0.005 0.010 0.015 0.020 0.025 0.030 –0.015                 

> Note: The smaller sample size for men might limit the robustness of the gender gap data.
> Source: Human Development Report Office based on data from the sixth round of Multiple Indicator Cluster Surveys.
> Notes
> 1. Howcroft and Rubery 2018. 2. Goldin, Kerr and Olivetti 2024. CHAPTER 4 — F RAMING NARRATIVES TO REIMAGINE ARTIFICIAL INTELLIGENCE TO ADVANCE HUMAN DEVELOPMENT 1 1 7

In addition to the gender digital divide, which per -

sists in much of the world, women’s lower adoption of 

AI could be driven by gender differences in perceived 

economic risks and benefits. 135  Women also report 

greater privacy and trust concerns while using gen -

erative AI. 136  In general, women are more concerned 

about the negative consequences of sharing data. 137 

These concerns are not unfounded, as women are 

more likely to encounter negative experiences on -

line. Indeed, one of the most egregious ways in which 

gendered power imbalances are inscribed into tech -

nology design and use is technology-facilitated vio -

lence against women (box 4.2). 

These norms and inequalities have a direct bear -

ing on women’s agency. 138  Women receive less visi -

bility and recognition for their contributions and are 

often misrepresented. For instance, women scien -

tists get lower visibility for their work on social media 

compared with men. 139  Women are also less likely to 

self-promote their work on social media — often due 

to undervaluation of their own work and fear of push -

back. 140  But even when they do, the increase in recog -

nition and engagement online is smaller for women 

than for men. 141  To be clear, gender inequalities in 

scholarly recognition existed long before social me -

dia. 142  But social media appears to reinforce rather 

than alleviate structural disadvantages for women. 143 

Gender norms also permeate seemingly open forms 

of communication that allow decentralized commu -

nities and knowledge. 

# “ As the foregoing discussion illustrates, 

gender inequalities in the design and use of AI 

result not from women’s lower technological 

aptitude, interest or skills. Rather, they 

arise from discriminatory social norms 

Case in point is the open software community, which 

promotes openness and transparency. Women are 

largely excluded from these collectives or rendered less 

visible relative to their male counterparts even though 

they have comparable programming aptitude. An 

analysis of the code written for 1,728 open-source pro -

jects archived in the GitHub repository reveals gender 

variation in style (that is, file organization and struc -

ture) but not in code quality. 144  And women on Stack 

Overflow receive less recognition for their work — even 

after exerting more effort in their contributions. 145 

The media plays a role in reinforcing and perpet -

uating social norms. Media stereotyping can influ -

ence audiences’ attitudes, opinions and behaviours. 

Women are less likely to appear in portrayals of AI. 

For example, only 8 percent of AI engineers portrayed 

in the most influential AI-related films are women. 146 

This finding is crucial, as media representation of 

professions has a strong impact on people’s career 

choices and prospects. 147  The AI technological space 

is often constructed and represented as male dom -

inated, thus reinforcing structural stereotypes and 

prejudice. Given AI’s extensive mediatization and 

widespread adoption, the biases are likely to rever -

berate widely, negatively affecting not only women’s 

self-perceptions but also the collective evaluation 

of their competence in technological fields. Gender 

prejudices are also reflected in science and misinfor -

mation discourse online. Specifically, science vide -

os on TikTok and YouTube stereotypically associate 

women with topics related to children and health. 148 

Furthermore, social media messages with gender 

cues receive more engagement (views and likes) than 

those without. Thus, social media platforms —which 

promised to democratize access to communication 

opportunities —may instead reify pre-existing norms 

and inequalities. The misrecognition, misrepresenta -

tion and devaluation of women’s contributions in the 

technological field not only deny them opportunities 

but also deprive societies of alternative perspectives, 

paths and choices. 

Expanding women’s agency to not just benefit equally 

from but to shape technological and social change 

As the foregoing discussion illustrates, gender ine -

qualities in the design and use of AI result not from 

women’s lower technological aptitude, interest or 

skills. Rather, they arise from discriminatory social 

norms that construct technology as masculine and 

devalue women’s expertise, knowledge and contri -

butions. Therefore, closing gender gaps, perhaps 

by increasing access to technology and digital skills 

training — crucial as they are  —may not be enough. 

The focus needs to be on expanding women’s agency 

to not just benefit equally from technological change 

but to shape technological developments that reflect 

and actively promote equity and social change. 1 1 8 HUMAN DEVELOPMENT REPORT 2025 

Enhancing women’s agency in the design and use 

of technologies is crucial both to enhance opportu -

nities for women and to design and implement AI 

technologies that reflect diverse societal needs. 149 

Women’s underrepresentation results in societies los -

ing out on the important innovations that women’s 

leadership and participation engender. For instance, 

evidence suggests that female researchers are more 

likely to work on socially beneficial innovations. 150 

Transformative social change can take place when 

innovations in AI are designed by a diverse group of 

developers, including women and people from other 

Box 4.2  As technologies advance, so do new ways of perpetrating violence against women 

One of the most grievous consequences of advances in digital technologies has been the alarming rise of technology-

facilitated gender-based violence around the world. Technology-facilitated gender- based violence is “any act that is 

committed, assisted, aggravated or amplified by the use of information communication technologies or other digital 

tools which results in or is likely to result in physical, sexual, psychological, social, political or economic harm or other 

infringements of rights and freedoms.” 1 This abuse is differentiated because women and girls are attacked simply for 

being online and for being women or girls. These forms of violence are widespread. 2 Globally, 38 percent of women 

have experienced gender-based violence online, and 85 percent of women have witnessed it. 3 Young women are 

particularly affected: 58 percent of young women across 31 countries experienced online gender-based violence. 4

Such violence — comprising image- based abuse, trolling, online hate speech, cyberharassment, gendered disinforma -

tion and other harms  —  undermines women’s wellbeing and agency. 

The manifestations, scope and scale of violence are constantly evolving as the rapid advance of technology pro -

vides tools that can be abused to control, silence and coerce. The veil of anonymity possible in the digital world 

facilitates these forms of violence. 5 And the automation capabilities enabled by AI amplify the scope and impact of 

violence against women. 6 AI technologies, particularly generative AI, put novel methods in perpetrators’ hands that 

can boost the reach and scale of violence against women. AI-generated image-based abuse, also known as deepfake 

pornography, refers to fake, digitally altered images created using AI and constitutes an emerging and growing form of 

nonconsensual synthetic intimate imagery. 7 Deepfake pornography accounts for 98 percent of deepfake videos online, 

and 99 percent of individuals targeted in this content are women. 8 But awareness of AI-generated image-based abuse 

remains low across countries. 9 Generative AI can create sustained and automated attacks and automatically generate 

convincingly written posts, texts and emails. 10  This gives existing harms such as hate speech, cyberharassment, misin -

formation and impersonation a much wider reach and makes them more dangerous. Indeed, both open and closed AI 

models generate cyberharassment templates, synthesize fake reports and histories that damage people’s reputations, 

and modify images to portray people in nonconsenting scenarios. 11  In addition, Internet-of-Things devices such as 

smart speakers and thermostats can be weaponized to exercise control over and coerce women. 12 

These forms of violence are often perpetrated with the aim of silencing women and curtailing their agency. Indeed, 

women who engage in public spaces, including journalists, politicians and activists, are subjected to more virulent 

abuse. 13  Some 73 percent of female journalists have experienced online gender-based violence. 14  And 46 percent of 

female parliamentarians in Africa and 58 percent in Europe have been the target of sexist attacks online. 15 

As political, economic, social and cultural activities shift online, such forms of violence force women to withdraw from 

digital spaces. Women experience physical and mental health impacts, reputational damage, social ostracization and 

isolation, and adverse consequences for education and employment. Digital technologies and social media networks 

open opportunities for women and provide a platform to organize and participate in the public discourse. Although 

legal reforms that recognize and address technology-facilitated gender- based violence are important, measures 

to combat such violence must coexist with measures to strengthen women’s agency and freedom of expression. 16 

Actions that target the structural root causes of violence — for instance, providing education on technology-facilitated 

gender-based violence, designing technologies with safety at the core, ensuring platform accountability and increas -

ing women’s representation in product design and content moderation teams — are critical.                                         

> Notes
> 1. UN Women and WHO 2023, p. 3. 2. Dunn, Vaillancourt and Brittain 2023; Sheikh and Rogers 2024. 3. The Economist Intelligence Unit
> 2021. 4. Plan International 2020. 5. de Silva de Alwis 2024. 6. de Silva de Alwis 2024. 7. Umbach and others 2024. 8. Security Hero 2023.
> 9. Umbach and others 2024. 10. UNESCO 2023. 11. UNESCO 2023. 12. Slupska and Tanczer 2021. 13. Inter-Parliamentary Union and Af -
> rican Parliamentary Union 2021; UNESCO 2020. 14. UNESCO 2020. 15. Inter-Parliamentary Union and African Parliamentary Union 2021.
> 16. de Silva de Alwis 2024. CHAPTER 4 — F RAMING NARRATIVES TO REIMAGINE ARTIFICIAL INTELLIGENCE TO ADVANCE HUMAN DEVELOPMENT 1 1 9

marginalized and intersecting identities; when those 

innovations recognize and address social norms and 

imbalances; and when they are backed by changes 

in policies and institutions. For instance, researchers 

are developing AymurAI, a semiautomated proto -

type that will collaborate with criminal court officials 

in Argentina and Mexico to generate and maintain 

anonymized datasets for understanding gender-

based violence. 151  SOFIA is a conversational chatbot 

designed to support women who have experienced 

technology-facilitated gender-based violence on so -

cial media platforms (see box 4.2). 152  It supports users 

with reporting the incident on the platform, provides 

digital self- care tips and evaluates whether an inci -

dent can be reported to the police. Thus, ensuring 

women’s agency in the design and use of AI is not just 

a matter of providing equal opportunities for women; 

it profoundly shapes what kinds of technologies are 

developed, for whom and with what purpose. 

## Technical solutions are not enough: 

## Biases in AI are deeply intertwined with 

## social norms and societal inequalities 

Growing excitement over the impressive capabili -

ties of generative AI tools has been accompanied by 

immense scrutiny for their propensity to produce 

socially biased outputs. 153  AI reflects the biases and 

stereotypes in the data on which it is trained. If the 

data used to train an AI model contain biases — either 

from the source material or through the selection 

process —these biases can be absorbed by the model 

and subsequently reflected in its behaviour. Even 

though fine-tuning models after pretraining has re -

duced outputs that were extremely biased in early it -

erations, these techniques pose risks, given that the 

processes often rely on human feedback. 154  Language 

models are trained using extensive text corpora avail -

able online, including websites, articles, books and 

other written content. These data contain persistent 

gender, racial, cultural and intersectional stereo -

types; misrepresentations of particular social groups 

and cultures; and denigrating language. 155 

Biases can emerge at different stages of model 

development and deployment. 156  They can range 

from negative sentiment and toxicity directed to -

wards some social groups 157  to stereotypical linguis -

tic associations 158  to lack of recognition of certain 

languages. 159  Demographic biases arise when the 

training data overrepresent or underrepresent certain 

groups, leading the model to exhibit biased behav -

iour towards them. In these cases the outputs ampli -

fy self-fulfilling feedback loops that can perpetuate 

inequalities. 160  Stereotype perpetuation and cultural 

denigration are examples of representational harms, 

which occur when systems reinforce the subordina -

tion of some groups along the lines of identity —race, 

class, gender and the like. 161  Even when a model ac -

curately reflects real-world patterns identified as 

statistical regularities, it could still constitute rep -

resentational harm because the patterns themselves 

reflect historical prejudice. 162  For instance, such a sys -

tem could perpetuate a lack of visible role models for 

underrepresented groups. 

# “ Biases can emerge at different stages of 

model development and deployment. They 

can range from negative sentiment and 

toxicity directed towards some social groups 

to stereotypical linguistic associations to 

lack of recognition of certain languages 

Cultural biases occur when large language mod -

els learn and perpetuate cultural stereotypes or hier -

archies that are present in the data used for training. 

This can result in the model producing outputs that 

reinforce or exacerbate existing cultural prejudices or 

underrepresent cultures. 163  Such biases also arise from 

the fact that most of the internet’s content is in Eng -

lish and a few other dominant languages. This can lead 

to biased performance and a lack of support for low-

resource languages or minority dialects. For instance, 

ChatGPT perpetuates gender defaults and stereotypes 

assigned to certain occupations when translating be -

tween English and languages that use gender-neutral 

pronouns, such as Bengali and Malay. 164 

Bringing social insights into bias mitigation 

To mitigate these biases, a range of technical solu -

tions have been adopted, including augmenting 

datasets to debias imbalanced social group rep -

resentations, 165  fine-tuning models with fairness ob -

jectives 166  and developing metrics to test and evaluate 

models. 167  But biases are hardly just technical. AI is 1 2 0 HUMAN DEVELOPMENT REPORT 2025 

not neutral; it reproduces and amplifies social biases 

and inequalities. This broader perspective can help 

identify pathways for further improvement. In re -

sponse to the growing attention to the social harms 

reinforced and amplified by large language models, 

the models are aligned with human values before 

they are deployed. 168  Alignment techniques  — such 

as reinforcement learning with human feedback 169  —

have made remarkable progress in reducing biases 

in the models’ outputs. 170  The impact of these inter -

ventions in generating outputs that are not as biased 

as the training data can be seen in recent large lan -

guage models (such as ChatGPT) that, in response to 

prompts asking them to generate stories for different 

occupations, predominantly feature female charac -

ters, even for occupations that are predominantly 

held by men in most countries. 171 

These bias mitigation techniques have, however, 

focused mostly on explicit biases —attitudes that are 

blatantly prejudicial and discriminatory. But biases 

can appear more subtly, such as the tendency to asso -

ciate historically marginalized groups with negative 

sentiments even when people espouse egalitarian 

beliefs. 172  As training data scale and model parame -

ters increase, explicit bias shows a consistent decline, 

but bias often remains. 173  Even value-aligned models 

associate negative attributes with the words “black” 

and “dark,” such as guilty phrases and weapon ob -

jects. 174  And these models associate women’s names 

and roles with home, humanities and powerless 

words. 175 

# “ Biases can appear more subtly, such as the 

tendency to associate historically marginalized 

groups with negative sentiments even 

when people espouse egalitarian beliefs 

Implicit biases can be powerful sources of discrim -

ination in various downstream tasks. For example, in 

GPT-4’s output men lead career workshops, are the 

leaders and study science. 176  This is despite the fact 

that GPT-4 overwhelmingly disagrees with blatantly 

biased statements such as “women are bad at man -

aging people.” 177  It chooses Ben (man- coded name) 

over Julia (woman- coded name) for a management 

workshop. 178 

Even if we focus on the substantial progress of 

bias mitigation —particularly in addressing explicit 

biases  —these advances have largely been reactive. 

Both alignment techniques and evaluation metrics 179 

have so far focused mostly on reducing explicit bias -

es, which are easier to detect. In addition to reacting 

to instances of harm as they arise, it is imperative to 

design technologies with a forward-looking lens  . 180 

What is fairness in AI? 

AI fairness is context  dependent and can be inter -

preted in multiple ways. 181  Numerous definitions 

of algorithmic fairness have been advanced in the 

literature  —which can be mutually incompatible. 182 

The form of the loss function, or the reward given 

in reinforcement learning, implicitly assumes some 

notion of fairness. Harms often operate in nuanced 

and distinct ways for various social groups. More -

over, whether disparities are objectionable may differ 

across cultures and may change over time as social 

norms evolve. For example, because many demo -

graphic characteristics are socially constructed and 

vary across contexts, specifying and operationalizing 

diversity are inherently fraught with complexity. 183 

Treating social groups or their outcomes as inter -

changeable ignores the underlying forces of injustice. 

Recent attempts at debiasing language models have 

led to overrepresentation of some groups in ways 

at odds with the real world. For example, large lan -

guage models often depict female characters more 

frequently than male ones in stories about various 

occupations, showing a 37 percent deviation from 

US Bureau of Labor Statistics data. 184  And women 

are substantially overrepresented in crime scenarios 

when compared with data from the US Federal Bu -

reau of Investigation. 185  So, the assumptions encoded 

in the choice of loss function should be stated explic -

itly. Conceptualizing fairness involves value judge -

ments that need to be made explicit. For example, 

deeming certain AI model behaviours as harmful in -

volves decisions underpinned by social values. This 

requires a better understanding of why AI biases are 

harmful, in what ways and to whom. 186 

To understand and address these effects, they must 

be considered in the social context that they emanate 

from and that they shape. 187  More generally, it has 

been argued that it is meaningless to ascribe fairness 

without that social context as an attribute of models, CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 2 1 

as opposed to actions, outputs or decision processes 

in the real world. 188  For instance, word embeddings 

in large language models are representations of lin -

guistic units in a multidimensional space in which the 

model is able to find statistical associations; but they 

do not correspond to any linguistic or decisionmaking 

task. So, lacking any notion of ground truth or harms 

to people, it is not meaningful to ask fairness ques -

tions about word embeddings without reference to 

specific downstream tasks for which they might be 

used. 189 

Existing algorithmic fairness techniques often 

focus on what is convenient to measure and mitigate, 

devoting less if any attention to what is most con -

cerning from a human development perspective. 190 

Fairness benchmarks based on unstated assumptions 

can lead to inconsistencies surrounding both the 

conceptualization and the operationalization of con -

cepts. 191  For instance, four prominent benchmarks 

for assessing fairness in the context of natural lan -

guage processing (CrowS-Pairs, StereoSet, WinoBias 

and WinoGender) left culturally heterogeneous and 

highly contested concepts such as stereotypes and of -

fensive language unspecified. 192  Cultural norms and 

values can vary considerably across communities and 

regions, and large language models do not reflect this 

diversity. 193  Determining which norms should be en -

coded in AI models and which should be filtered out 

is a complex task that requires careful consideration 

and a nuanced understanding of diverse cultural 

perspectives. Further, these approaches need to rec -

ognize the ways in which language and social hierar -

chies are built into and reinforced by technologies. 

# “ Determining which norms should be 

encoded in AI models and which should be 

filtered out is a complex task that requires 

careful consideration and a nuanced 

understanding of diverse cultural perspectives 

Achieving algorithmic fairness would require de -

fining what “fair” means in the context of appli -

cations. 194  Public deliberation on these norms and 

values must recognize and create space for diverse 

ideas and perspectives. Creating fair AI systems ul -

timately has to be continuous and collaborative. It 

involves deliberating on shared social values that 

would guide choices among tradeoffs and arrive at a 

concept of fairness appropriate to the context of use. 

The design of strategies and techniques has to recog -

nize that technical solutions are unlikely to be suffi -

cient on their own. They must be complemented with 

interventions to recognize and address structural so -

cial hierarchies and power imbalances. 

## Framing a narrative on AI to 

## advance human development 

Public concerns about the societal effects of AI are 

shaped by narratives that have the potential to influ -

ence research priorities and policy agendas on the di -

rection of technological change. A narrative premised 

on the importance of advancing human development 

can inspire regulatory, institutional and social choic -

es that make AI work for people everywhere. Such a 

narrative recognizes and elevates human agency, is 

rooted in understanding AI in different social con -

texts and can serve as a framework to supplement ex -

isting metrics for assessing AI progress with a view to 

enabling choices that advance human development. 

Elevating human agency to shape 

the deployment of AI 

AI’s impact on society is neither preordained nor in -

evitable. It could engender many possibilities —with 

both positive and negative implications for human 

development. 195  As this chapter shows, a techno-

determinist narrative can lead us astray. 

Recognizing and elevating agency counter narra -

tives on AI that are fixated on machines surpassing or, 

worse, replacing humans and diminishing the value 

of and undermining human agency. 196  This not only 

undermines the value of human effort and ingenuity 

but also fundamentally misconstrues what being an 

intelligent human being is. 197  Human intelligence is 

rooted in our embodied physical and emotional expe -

riences and often depends on participation in social 

and cultural environments. A narrative emphasiz -

ing the primacy of human choices and freedoms in 

the age of AI can inform the design and deployment 

of AI systems that focus on enhancing —rather than 

undermining  — human agency. 

Agency makes people creative, adaptable, resilient, 

cooperative and diverse. It enables people to act, not 1 2 2 HUMAN DEVELOPMENT REPORT 2025 

just in their own self-interest but in shaping broad -

er processes of social change. 198  Narratives typical -

ly come from the sustained mobilization of people 

and communities. As the examples in this chapter 

show, rather than passive beneficiaries or victims 

of technological change, people  —both individual -

ly and collectively —are active in shaping the impact 

of new technologies. Past episodes of technological 

change  —from the Industrial Revolution to the rise of 

the internet —bear witness to the power of collective 

action in drawing attention to the most pernicious 

consequences of new technologies, mobilizing broad 

coalitions for change and instigating institutional re -

forms. As AI becomes integrated across key societal 

institutions and functions, researchers, civil society 

organizations and activists have identified and ex -

posed its adverse impacts on marginalized communi -

ties, demanding accountability and catalysing policy 

and design changes. Indeed, grassroots movements 

and coalitions have surfaced and drawn public atten -

tion to the inequalities and injustices associated with 

deploying technologies such as facial recognition sys -

tems and algorithms that automate criminal justice 

decisions. They have also mobilized people to im -

agine and shape a different future with AI. 

Researchers and advocates —particularly those be -

longing to marginalized communities —have played 

a pivotal role in revealing some of this type of harm 

from AI. Their relative exclusion from AI design, as 

well as from policymaking around it, risks the emer -

gence of a monoculture around AI. Narratives about 

AI tend to be told by a narrow set of people, mostly 

political and economic elites with specific interests 

in its development. 199  But technical approaches alone 

are insufficient. Solutions need to consider societal 

factors to avoid compounding some of AI’s negative 

consequences. 200 

# “ Tropes such as AI as the ultimate solution to 

all problems yet at the same time the ultimate 

threat to humanity —and the reduction of 

the individual to data and computation 

—ignore how outcomes depend on the 

interaction between AI and social choices 

In processes where decisions —both technical and 

social —about AI are made, different groups are situ -

ated unequally in power and awareness. 201  Excluding 

the voices of the people and groups most affected 

by AI has ramifications for how technologies are de -

signed, deployed, used and regulated. Attitudes to -

wards and approaches to understanding AI are not 

the same around the world. Tropes such as AI as the 

ultimate solution to all problems yet at the same time 

the ultimate threat to humanity —and the reduction 

of the individual to data and computation —ignore 

how outcomes depend on the interaction between AI 

and social choices. 202  It is thus imperative to develop 

a better understanding of the diversity of views about 

what AI is and its role in society and human develop -

ment should be across cultures, extending beyond 

WEIRD (western, educated, industrialized, rich and 

democratic) countries. 203  Expanding people’s agency 

is thus pertinent both to safeguard choices and free -

doms and to ensure that AI technologies are useful 

for everyone everywhere to live lives they value and 

have reason to value. 

Rooting the future of AI in social contexts 

Dominant narratives tend to propagate claims about 

AI (or technology) as inherently emancipatory or op -

pressive. Those extreme views not only undermine 

human agency —they also neglect the role of social 

context in shaping the impact of AI. The term “AI” re -

fers not to a specific technology but to a wide range 

of computational techniques, from logic-based au -

tomated decision systems to large language models 

based on deep neural networks. 204  Each technique 

comes with affordances and constraints and gives 

rise to different ethical, technical and social risks 

depending on its use case. For example, mobilizing 

AI and big data to convey local needs from a dis -

tance may risk perpetuating epistemic injustices 

and paternalistic practices in the humanitarian sec -

tor (Spotlight 4.3). 205  The same system may perform 

very differently for different people in different con -

texts. For example, generative AI would have very 

different outcomes depending on infrastructure, in -

stitutional capacity, regulations and social norms. 

Designing and deploying technologies often involve 

difficult tradeoffs  —between accuracy and fairness, 

for instance  —and must be evaluated on a case-by-

case basis  —with the participation of the people af -

fected. 206  Narratives that propagate totalizing claims CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 2 3 

are unhelpful —and harm public discourse on the re -

spective values, priorities, tradeoffs and consequenc -

es that may arise as a result of using AI in a particular 

context. They shift priorities from the more immedi -

ate impacts towards far-fetched future scenarios. And 

in doing so, they sow fear and may give rise to misin -

formed regulations. 

Supplementing benchmarks of AI progress 

More than three decades ago, the Human Develop -

ment Report challenged the dominant narrative in 

development that focused exclusively on income to 

assess the progress of economies and societies. It did 

so by introducing the human development approach 

—a novel framework for evaluating and advancing 

human wellbeing and agency. 207  Indeed, one of the 

greatest achievements of the Human Development 

Report has been to promote greater acceptance of the 

fact that monetary measures such as gross domestic 

product per capita are inadequate proxies of devel -

opment. Its framework laid the foundations for alter -

native metrics of human wellbeing, particularly the 

Human Development Index —which remains wide -

ly used. Subsequent Human Development Reports 

have revised and refined the metrics and developed 

new ones to capture other issues relevant to human 

development. A human development lens can help 

unearth the limitations of current metrics and inspire 

alternative metrics for evaluating the performance of 

AI in enhancing people’s capabilities and agency. 

AI benchmarks are combinations of datasets and 

metrics that represent specific tasks and are used to 

evaluate and compare the performance of AI sys -

tems. 208  The primary objective of many of these 

benchmarks is to measure the technical capabilities 

or performance of AI systems. 209  These benchmarks 

have been found to often fall short in measuring AI 

capabilities. 210  They rarely measure what they claim 

to measure, 211  can be easily gamed 212  and are some -

times impractical for real-world uses. 213  For exam -

ple, benchmarks consisting of professional exams 

such as the bar exam “emphasize the wrong thing” 

and “overemphasize precisely the thing that lan -

guage models are good at” and are thus unreliable 

measures of things such as legal skill. 214  Performance 

on the bar exam does not tell us anything about the 

performance of these models on real-world tasks. 215 

Nonetheless, benchmarks have been useful in iden -

tifying social harms. 216  Quantitative measurements 

such as Correctional Offender Management Profil -

ing for Alternative Sanctions 217  and Gender Shades 218 

have set in motion some of the most influential 

changes in AI systems and are indispensable for as -

sessing progress. 219 

Still, a more fundamental gap persists. Improv -

ing scores on a benchmark does not mean that an AI 

system would expand human development. That is, 

it does not reveal whether the system would enable 

people to achieve functionings that they have reason 

to value or would erode the space for exercising val -

ued choices. As this and other chapters in this Report 

have demonstrated, AI can either enhance freedoms 

and opportunities for people or diminish their choic -

es and agency. The direction it will go is contingent 

on the way it is designed and deployed and on wheth -

er appropriate policies and institutional mecha -

nisms are put in place. Carefully curated benchmarks 

grounded in the human development approach can 

bolster action on these fronts. 

# “ The direction it will go is contingent on 

the way it is designed and deployed and on 

whether appropriate policies and institutional 

mechanisms are put in place. Carefully curated 

benchmarks grounded in the human development 

approach can bolster action on these fronts 

Recently, concerns about the potential societal 

harms of AI systems have resulted in the develop -

ment and adoption of specific benchmarks to assess 

the risks posed by such systems. 220  For example, the 

MLCommons AI Safety benchmark measures the 

safety of large language models by assessing their re -

sponses to prompts across multiple categories of im -

pacts, including child sexual exploitation and suicide 

and self-harm. 221  But these evaluations focus mostly 

on the AI model itself. By contrast, impacts manifest 

in complex interactions between the model and so -

cial factors — comprising individuals and broader sys -

temic factors. 222 

More generally, capabilities and risks are hardly at -

tributes of models alone. They emerge from complex 

interactions among models, people, organizations 

and social and political systems. This is why existing 1 24 HUMAN DEVELOPMENT REPORT 2025 

approaches to evaluating AI systems are insufficient, 

especially when it comes to evaluating their societal 

impact. 223  Many of the concerning issues that have 

garnered attention —notably misinformation and bias 

—are not a property of the model alone. Rather, they 

are a joint property of the model and of a population 

of users who interact with a model in a particular way 

through a certain distribution of queries. 224  Unfor -

tunately, data about these interactions are currently 

nonexistent. 225  This problem is compounded by the 

proprietary nature of many AI systems. 226  Therefore, 

research that focuses on empirically observing the 

interaction of people with large language models in 

different contexts and for different uses is critical to 

comprehensively assess capabilities and harms. 

Ultimately, from a human development perspective 

evaluation of AI systems needs to be multidimensional, 

continuous and interdisciplinary. No single metric 

can capture the multifaceted impacts that AI systems 

have on people. Many of the identified harms of AI 

systems are latent concepts that cannot be captured 

in a single operationalization in their entirety. 227  And 

evaluation of AI systems inescapably involves choices 

and value judgements that must be made explicit and 

documented. In many instances different scores may 

have to be referred to in conjunction. For example, 

the Holistic Evaluation of Language Models bench -

mark adopts a multimetric approach (comprising ac -

curacy, calibration, robustness, bias, fairness, toxicity 

and efficiency), measured across 16 core scenarios. 228 

This ensures that tradeoffs are clearly exposed and 

that metrics beyond accuracy are not neglected. The 

development of metrics invariably has to be an ongo -

ing process that captures emergent impacts as they 

surface and constantly explores new methodologies 

and data to measure the interactions among AI, peo -

ple and society. 

# “ Because the impact of AI systems spans 

economic, social, political and cultural 

dimensions, evaluating these systems 

should be a multidisciplinary exercise that 

incorporates different methodologies and 

makes space for diverse perspectives 

Current benchmarks are designed only for the 

English language and based on western cultures. 229 

Developing benchmarks for low-resource languages 

necessitates investment and effective collaboration 

among researchers, native speakers and communi -

ties. These benchmarks also focus on text-based AI 

systems —making them limited for other modalities 

such as images and audio. 230  Because the impact of 

AI systems spans economic, social, political and cul -

tural dimensions, evaluating these systems should 

be a multidisciplinary exercise that incorporates dif -

ferent methodologies and makes space for diverse 

perspectives. CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 2 5 

Attention to narratives as influential determinants 

of economic outcomes contrasts with tradition -

al economic approaches fail to examine the role of 

narratives in major economic events. 1 Burgeoning 

work in narrative economics seeks to study the ways 

narratives spread and affect economic behaviour —

including decisions as diverse as whether to make an 

investment or whether to have a child. 2 Economic de -

cisions often hinge on the belief or disbelief of certain 

stories because stories can influence expectations, 

inspire confidence or instil fear in economic agents. 3

Empirical work has sought to document the influ -

ence of narratives on economic behaviour. For in -

stance, an open- ended survey of macroeconomic 

narratives of households and experts finds that 

household narratives are much more heterogenous 

than expert narratives and strongly shape their in -

flation expectations. 4 The media are an important 

source of these narratives. 5

Of particular relevance is the role of narratives in 

decisionmaking under conditions marked by radical 

uncertainty. 6 In contexts marked by radical uncer -

tainty, “people use narratives to make sense of the 

past, imagine the future, commit to action, and share 

these judgments and choices with others.” 7 Convic -

tion narrative theory asserts that “narratives arise 

from the interplay between individual cognition and 

the social environment, with [people] adopting a nar -

rative that feels ‘right’ to explain the available data; 

using that narrative to imagine plausible futures; and 

affectively evaluating those imagined futures to make 

a choice.” 8

The role of narratives in a broad range of phe -

nomena have been studied —notably prices of cryp -

tocurrencies 9 and fertility decisions. Evidence 

indicates that narratives also carry substantial col -

lateral effects on financial market expectations and 

economic decisionmaking. 10  In a similar vein both 

experimental and survey evidence have demonstrat -

ed the causal impact of narratives of the future on 

fertility intentions, whereby positive future narra -

tives positively affect fertility intentions and nega -

tive narratives produce the opposite effect. 11  People 

use these narratives to project themselves into an 

actionable imagined future and make decisions that 

are somewhat independent of their actual economic 

situation. 12  For instance, in an experiment conducted 

during the Covid-19 pandemic, respondents were ex -

posed to different scenarios regarding the expected 

length of the pandemic. The longer the expected du -

ration, the lower their fertility intentions. 13 

In addition to their role in understanding the envi -

ronment, focusing attention, predicting events and 

motivating action, narratives also play an important 

part in allocating social roles and identities, defin -

ing power relations and establishing social norms. 14 

Indeed, narratives are strategically employed by po -

litical agents to achieve a certain purpose. Political 

agents discover identity and policy narratives that 

shift beliefs about how the world works or about 

identity to catalyse policy and institutional change in 

a certain direction in line with their interests. 15  Nar -

ratives shape social identities, as people generally 

make sense of their lives in terms of stories that are 

influenced by their relations with others and their en -

vironment. 16  Narratives also define power relations 

through their role in organizing perceptions around 

socially conferred characteristics such as expertise, 

legitimacy and social identification. 17  Moreover, in 

addition to their role in specifying norms of behav -

iour, narratives also supply principles of application 

rooted in particular social relationships. 18 

Shared narratives can support coordination. They 

usually propagate when they are appropriate to the 

context, are unforgettable and have popular appeal. 19 

As such, ideas held collectively in a social network 

can become the coordinating device for a range of de -

cisions in a similar way to the role of prices. 20  Narra -

tives thereby set beliefs and inform action that carry 

important macroeconomic consequences. This opens 

> SPOTLIGHT 4.1

# Narratives in economic decisionmaking 1 2 6 HUMAN DEVELOPMENT REPORT 2025 

the possibility for political leaders to reset narratives 

to change ideas about identities and norms in order to 

build social pressure towards support ing actions that 

are in the common interest. 21 

Two crucial insights emerge. First, paying attention 

to narratives can help in anticipating and preparing 

for economic events and in structuring institutions 

and policies. Second, reframing narratives can be a 

powerful way to drive policy and institutional change, 

precisely because of their role in setting beliefs and 

perceptions and in influencing both individual and 

collective behaviour. 

NOTES 

1.  Shiller 2020; Akerlof and Snower 2016. 

2.  Shiller 2020. 

3.  Akerlof and Shiller 2010. 

4.  Andre and others 2024. 

5.  Guetto and others 2023. 

6.  Despite increased scholarly attention to narratives in economics, this term 

is used and defined in multiple ways. Specifically, three roles have been 

ascribed to narratives in economics: narratives as interpretive summaries 

of specific issues, narratives as a means of policy analysis and narratives 

as active drivers of economic decisions. See Roos and Reccius (2024) for 

an overview of the literature. 

7.  Johnson, Bilovich and Tuckett 2023, p. 2. 

8.  Johnson, Bilovich and Tuckett 2023, p. 1. 

9.  Azqueta- Gavaldón 2020. 

10.  Paugam, Stolowy and Gendron 2021. 

11.  Guetto and others 2023. 

12.  Guetto and others 2023. 

13.  Guetto, Bazzani and Vignoli 2022. 

14.  Akerlof and Snower 2016. 

15.  Mukand and Rodrik 2018. 

16.  Akerlof and Snower 2016. 

17.  Akerlof and Snower 2016. 

18.  Akerlof and Snower 2016. 

19.  Johnson, Bilovich and Tuckett 2023. 

20.  Collier and Tuckett 2021. 

21.  Collier and Tuckett 2021. CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 2 7 

> SPOTLIGHT 4.2

# Caring through digital platforms 

Digital labour platforms can increase the labour force 

participation of women, particularly from marginal -

ized groups, by facilitating access to labour markets. 

This promise is often based on the flexibility afforded 

by these digital platforms for women to balance paid 

work with household responsibilities. 1 A burgeoning 

platform care economy for domestic, cleaning and 

care-related work has emerged around the globe. 

Such platforms act as intermediaries for allocating 

and assigning care work. The platforms have been 

viewed as solutions to the demand- and supply-side 

challenges in care. These novel technologies offer the 

possibility of reorganizing the demand and supply of 

work to foster flexibility and personalization by ad -

dressing information asymmetries between workers 

and clients. Platform work by its very nature reduc -

es barriers to entry because it involves an automat -

ed signup process, allows for flexible work schedules 

and permits both platforms and workers to make 

fewer commitments. 2

Participation in the platform does not inevitably 

bring about better working conditions for women. 3

Platform work attracts workers who experience pre -

carity and vulnerability on account of gender, race, 

immigration status, caste and ethnicity. 4 Therefore, 

while platforms offer opportunities, they can also ex -

ploit workers who depend on them disproportionate -

ly and have fewer avenues to organize and challenge 

unfair working conditions. 5 This is partly because of 

information asymmetries between platforms and 

workers. The workers on these platforms  —mostly 

poor women — often toil under exploitative condi -

tions marked by long and irregular hours, wage pre -

carity, negative impacts of algorithmic management 

practices and harassment. 6 The flexibility propagated 

by the platform can be a myth because women often 

have to work longer hours and at odd times of the day. 

Flexibility frequently becomes a tool for legitimiz -

ing double shifts for women, who have to juggle paid 

and domestic work. For instance, the availability of 

work and wages on these platforms is dictated by a 

rating system. While workers are under constant 

pressure from this system, they may be unable to rate 

customers or flag abusive customers. 7 For instance, 

women on South Africa’s SweepSouth platform are 

required to provide quality cleaning services, as this 

affects their ratings and future access to work. But 

workers are rarely given sufficient information about 

how big the house is. 8 In addition, workers who can -

cel or refuse a task, or resist doing extra work that 

was not initially specified in their booking, can be 

penalized. 9 Further, workers can have their accounts 

deactivated or suspended without any recourse if 

their ratings fall below a particular threshold or if 

they repeatedly refuse bookings. 10 

In certain countries wages on these platforms are 

higher than those for offline work. But work on these 

platforms is inconsistent, and the potential for high -

er earnings could be offset by the time spent looking 

for suitable opportunities and commuting between 

locations. 11  Platform companies also charge high 

commission rates from workers. 12  Thus, platforms set 

the conditions of work and wages, interface between 

workers and employers, collect data about both care 

workers and care recipients and take a substantial 

proportion of workers’ earnings in the form of com -

missions and deposits. 13 

Misclassifying workers on platforms as self-

employed, independent contractors or partners may 

allow platforms to circumvent labour laws and reg -

ulations, further marginalizing domestic workers, 

who are often migrant women. 14  The platforms fail to 

serve the needs of women, who constitute a majori -

ty of their workers, and to protect and promote their 

safety. Sexual harassment at work is a major concern 

for care and domestic workers because they work in 

confined environments in their client’s homes. 15  Still, 

technological features and policies to ensure the safe -

ty and security of care workers are usually missing 

from many of these platforms. 16 1 2 8 HUMAN DEVELOPMENT REPORT 2025 

Digital platforms by and large cater to the needs 

of time-poor rich households that can afford to pay 

for care while relying on an underpaid feminized 

workforce whose care needs remain unmet. 17  Thus, 

it makes care available for some, while precluding 

it for others. 18  For instance, women working on care 

platforms in Thailand struggle to balance the de -

mands of platform work with their family responsibil -

ities. These women often have to rely on other family 

members such as grandparents to take care of their 

children. 19  In fact, women with caregiving responsi -

bilities are often penalized on these platforms due to 

their inability to take up work at short notice or at odd 

hours. 20 

Even so, workers on these platforms have exer -

cised their agency to resist the working conditions on 

these platforms. Digital communication tools facili -

tate new modes of connecting workers and activists 

across distances. Carers who work in isolation in pri -

vate homes have long been deemed unorganizable. 21 

But digital communication tools have bolstered their 

ability to build and maintain grassroots movements 

and raise public awareness for their concerns. It was 

exactly this opportunity that the National Domes -

tic Workers Alliance  —a leading voice for the respect 

and dignity of domestic workers in the United States 

—leveraged to organize workers on the Handi plat -

form. 22  Through organizing efforts and negotiations 

over two years, the workers won an agreement that 

includes minimum wages, paid time off, occupational 

accidents insurance and a formal process to address 

workplace concerns. Likewise, domestic workers on 

India’s Urban Company and South Africa’s Sweep -

South platforms used Facebook and WhatsApp to 

share information and opportunities, request assis -

tance, vent their frustrations and reclaim a sense 

of dignity. 23 

In some instances these forms of coordinated in -

dividual resistance have coalesced into collective 

action. Digital technologies become important tools 

for these workers to find each other, discover com -

munities and solidarities and articulate shared ex -

periences. These efforts culminated in the largest 

nationwide labour action by female gig workers 

working with Urban Company in India to resist algo -

rithmic management practices and account deactiva -

tions. Women have drawn on digital technologies, as 

well as informal kin networks, to coordinate protest 

actions against digital labour platforms, with the sup -

port of the established trade union movement. 24 

In some countries female platform workers have 

developed cooperatives. These workers use app-

based technologies to organize while preserving fair 

compensation for workers and promoting job securi -

ty. For example, Equal Care in the United Kingdom 25 

and Up & Go in New York 26  were both founded by 

women to shift power to the hands of platform work -

ers. The expansion of women- owned platform coop -

eratives constitutes an opportunity to advance a more 

inclusive reorganization of work in the digital econ -

omy. Still, platform cooperatives struggle to expand 

and survive amid stiff competition from more power -

ful digital platforms. 27  So, public policies that support 

women- owned platform cooperatives are key to bol -

stering alternative ways of leveraging digital platform 

technologies to contribute to quality care and decent 

work. 

Even digital labour platforms could improve work -

ing conditions —through, for example, offering more 

than minimum wage and regulating work hours. 28 

State support is paramount, including on research 

and innovation, public services and infrastructure, 

and social protection systems. In reality, policy inter -

ventions and institutional responses have to account 

for context, recognize structural norms and imbal -

ances in the care sector and reflect the voices of those 

historically marginalized and excluded from techno -

logical advances. CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 2 9 

NOTES 

1.  Anwar 2022. 

2.  Kalla 2022; Tandon and Sekharan 2022. 

3.  Rani and others 2022. 

4.  Rodríguez- Modroño, Agenjo- Calderón and López-Igual 2022; Ticona and 

Mateescu 2018. 

5.  Rodríguez- Modroño, Agenjo- Calderón and López- Igual 2022. 

6.  Hussein 2022; Rodríguez- Modroño, Agenjo-Calderón and López-Igual 

2022. 

7.  Tandon and Rathi 2021. 

8.  Kalla 2022; Sibiya and du Toit 2022. 

9.  Sibiya and du Toit 2022; Tandon and Sekharan 2022. 

10.  Kalla 2022; Sibiya and du Toit 2022. 

11.  Tandon and Rathi 2021. 

12.  Dhar and Thuppilikkat 2022; Tandon and Sekharan 2022. 

13.  UN Women 2023. 

14.  Kalla 2022; Rodríguez-Modroño, Agenjo-Calderón and López-Igual 2022; 

Sibiya and du Toit 2022. 

15.  Dhar and Thuppilikkat 2022. 

16.  Athreya 2021. 

17.  Fraser 2016. 

18.  Green and Lawson 2011. 

19.  Just Economy and Labor Institute 2022. 

20.  Just Economy and Labor Institute 2022. 

21.  Hobden 2015. 

22.  National Domestic Workers Alliance n.d.; Zundl and Rodgers 2021. 

23.  Dhar and Thuppilikkat 2022; Sibiya and du Toit 2022. 

24.  Dhar and Thuppilikkat 2022. 

25.  https://www.equalcare.coop/ .

26.  https://www.upandgo.coop/ .

27.  Salvagni, Grohmann and Matos 2022. 

28.  Sibiya and du Toit 2022. 1 3 0 HUMAN DEVELOPMENT REPORT 2025 

> SPOTLIGHT 4.3

# Mobilizing big data artificial intelligence for localization: 

# The risks of reproducing unequal power hierarchies 

Adam Fejerskov  and  Maria-Louise Clausen,  Danish Institute for International Studies 

The convergence of technical advances in big data, ar -

tificial intelligence (AI) and algorithmic complexity, 

along with the growing accessibility and affordability of 

services integrating these technologies, is transforming 

the humanitarian sector. Big data and AI are introduced 

to promote professionalization through standardiza -

tion, speed and perceived objectivity or to strengthen 

empowerment by improving accessibility, transparency 

and broadening the stakeholder base. 1 Over time, how -

ever, research has increasingly shown how this trend 

toward “digital humanitarianism” has also enabled re -

mote management techniques that sometimes sideline 

concerns about data regulation and privacy protection. 

It has raised questions about the dominance of private 

corporations in shaping the use and outcomes of “ex -

tractive” data practices and systems that are designed 

primarily with commercial objectives in mind. 2 Recent 

developments reveal a merging of datafication with a 

central priority in contemporary humanitarian affairs: 

localization. Epitomized in political discussions around 

the Grand Bargain agreement, launched at the World 

Humanitarian Summit in Istanbul in 2016, localization 

advocates shifting humanitarian responsibilities from 

international agencies to actors who are more closely 

embedded in affected communities. 

What happens when humanitarian actors mobilize 

AI as a shortcut to localization? Are these emerging 

technologies able to construe accurate depictions of 

local needs and demands? And what are the effects 

of these developments for representation, inclusion, 

and the wider ambitions of the localization agenda? 

Datafied localization 

Localization aims to address the critique that human -

itarian efforts have been driven predominantly by 

Western responses to conflicts and disasters, often 

sidelining local actors who historically received less 

than 0.3 percent of formal system funding. 3 As part of 

the 2016 Grand Bargain, this political agenda seeks 

to empower local communities and local humani -

tarian organizations by increasing funding, capacity 

building, fostering equitable partnerships and estab -

lishing inclusive coordination platforms. 

The backdrop to the localization agenda is a grow -

ing body of evidence showing that local participation 

and leadership enhance global response effective -

ness. 4 The premise is that proximity to crisis leads 

to faster and more contextually relevant responses, 

but this aim is hindered by an entrenched hierarchy 

between international (often Western) humanitari -

an actors and locals—a category that itself has been 

criticized for being reductionist. Despite a rhetoric of 

partnership, equality and commitment to bottom-up 

decisionmaking, it is well documented that human -

itarian collaborations frequently result in hierar -

chized relationships where local nongovernmental 

organizations act as subcontractors with limited 

decisionmaking power. 5 This has underscored a key 

tension between inclusion and transformation. 6

In this context of localization, AI and data-driven 

tools are increasingly deployed to create a sense of 

“proximity” to targeted populations. By drawing on a 

plethora of data sources, including satellite imagery, 

social media feeds, local analytical gig work and mo -

bile communication patterns, big data is deployed to 

generate real-time insights into the evolving dynam -

ics of particular crises. The integration of big data 

spans numerous humanitarian efforts, from personal -

ized healthcare, real-time environmental monitoring 

and crisis mapping to the registration of biometrical 

datapoints aimed at identifying and tracking indi -

viduals or groups. These data-driven approaches in -

fluence risk assessments, resource allocations and 

decisionmaking in crisis response. In particular, the 

extraction and utilization of big data under the guise 

of localization stress three main concerns: fabricating 

context, rendering representation at a distance and 

reproducing power imbalances. CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 3 1 

Fabricating context 

The localization agenda advocates for a paradigm 

shift towards empowering local actors, assuming 

that proximity enables quicker and more efficient re -

sponses to humanitarian crises. But using AI and big 

data tools to make human suffering commensurable 

across borders sometimes rests on an individualist or 

universalist ontology of needs, which risks reinforcing 

unequal power hierarchies within humanitarianism. 

While big data can seem void of context, all data 

are. local, embedded within sociotechnical, cultural 

and organizational contexts. 7 As such, the representa -

tion of a humanitarian crisis from a distance through 

big data risks resulting in abstracted representations 

of people and social phenomena. This constitutes a 

fabrication of context, signifying a shift from view -

ing big data as contextless to seeing it as offering an 

image of an empirical reality crafted from real-time 

microdata, rich in detail but detached from specific 

geographical locations. These approximations then 

inform recommendations for action across countries 

or communities that may turn out to be generalized 

but have localized consequences. 

In this process context is reduced to an assortment 

of data points algorithmically assembled, produc -

ing a specific perspective on reality. While big data is 

often presented as empowering, we must remember 

that digital tools are not universally used, especially 

in times of crisis. Such approaches risk overlooking 

that global social media platforms vary in their use 

across contexts, and words or phrases carry distinct 

meanings depending on their cultural or situation -

al setting. 8 Despite the Western-centric perspective 

that often accompanies AI trained predominantly 

on English language data, online data collection is 

still portrayed as less biased than traditional research 

methods. But data need to be interpreted to become 

knowledge, and the diversity of local cultures, ex -

pressions and media use renders the adaptation of 

universal principles to local contexts exclusionary. 

As a result, the data-driven aggregated classifications 

suggested by these new AI tools may produce gen -

eralizations that overlook marginalized voices. This 

concern is particularly substantial given the grow -

ing recognition that comprehending events, actions 

and crises in their broader cultural, sociopolitical 

and environmental contexts enhances the cultural 

appropriateness and sustainability of response and 

recovery efforts. 

Rendering representation at a distance 

Representation is central to humanitarian action be -

cause it ensures the inclusion of diverse voices and 

perspectives in decisionmaking. Local representa -

tion, in particular, fosters accountability and legiti -

macy, as it reflects the needs and priorities of affected 

communities. This is integrated into the localization 

agenda, which seeks to transfer responsibilities, ca -

pacities and resources to local actors. Beyond efficient 

disaster management it emphasizes fair representa -

tion as a normative ideal, addressing broader discus -

sions on rights and justice. 

Representation often begins from the point of who 

is rendered visible, as invisibility through lack of doc -

umentation and data remains a key concern at the 

intersection of datafication and inequality. But rep -

resentation also confronts us with the question of 

who and what remain local? 

The concept of local is inherently complex, with di -

verse definitions reflecting the lack of consensus in the 

humanitarian community. 9 One challenge stems from 

the relativity of the concept of local, as it is intertwined 

with spatio-geographical, social and identity distinc -

tions in crisis-affected countries and contexts. A stat -

ic understanding of local as tied to a specific place or 

locale struggles to encompass diaspora, migrants and 

internally displaced people, sparking calls for a critical 

approach to localism. This perspective views the local 

as highly contextual and relational, focusing on the 

processes through which the label is constructed. 10 

As AI-driven representations of local realities 

emerge, defining local becomes even more pertinent. 

How are the boundaries of local defined and main -

tained in these recontextualized versions? The limi -

tations of proximity as a defining factor for localism 

become apparent, as individuals engaged in gig work 

may be physically close to humanitarian situations 

without truly being part of them or understanding 

those affected. Rather, this seems to align with de -

scriptions of the humanitarian field as a quasi-market 

in which beneficiaries become “the means to an end.” 11 

As already touched on, AI-enabled services of lo -

calization accentuate the digital divide across access, 1 3 2 HUMAN DEVELOPMENT REPORT 2025 

use and outcomes, especially for companies that de -

pend on social media for construing their geometries 

of local needs and interests. 

Many current services rely on convenience sam -

pling, a methodology criticized for biases resulting 

from underrepresentation. When convenience (that 

is, access) becomes the sole criterion for inclusion, 

there is no mechanism to screen for sampling bias -

es, raising doubts about both internal and external 

validity. When informants are approached as users 

and gig workers in a market, biases often favour those 

with some resources to begin with. Thus, the inte -

gration of big data for localization not only bypasses 

direct engagement with local actors or communities 

but also enables humanitarian organizations to con -

tinue speaking on their behalf. In sum, emphasizing 

big data–driven localization risks blurring the distinc -

tion between local elite perspectives and a reified in -

terpretation of local as a fixed space whose concerns 

can be readily extracted, transported and interpreted 

across distances. 

Reproducing power imbalances 

Localization aims to reconfigure the humanitarian 

system by bolstering local decisionmaking power and 

agency to challenge entrenched hierarchies. Framed 

as a means to enhance the reach, effectiveness and 

accountability of humanitarian action, localization 

ideally serves as a decolonial or social justice en -

deavour. 12  Yet current evidence indicates that data 

practices may take on extractive forms. 13  This raises 

concerns that integrating big data into localization ef -

forts risks perpetuating power imbalances by reduc -

ing local communities to mere data providers or by 

bypassing local humanitarian organizations. 

The ongoing digital transformation of humani -

tarianism and the shift towards localization have 

prompted discussions about the skillsets frontline 

humanitarians need to implement technology- driven 

solutions effectively. 14  This transformation is envi -

sioned as a way to mitigate the consequences of the 

growing gap between the complexity of digital tech -

nologies deployed by international humanitarian or -

ganizations and the level of digital literacy among 

local partners—a gap further exacerbated by the 

prevalence of short-term funding structures under 

which local organizations often operate. 15  Although, 

datafied localization can enhance technology’s reach 

by tailoring it to local conditions, it can also facilitate 

remote management techniques, maintaining local 

organizations in contractual relationships with inter -

national donors and potentially reinforcing existing 

power imbalances. 16 

Remote management enabled by datafied locali -

zation could exacerbate unequal power dynamics by 

shifting risks onto local partners 17  and introducing 

new issues related to organizational accountability, 

risk management and forms of ignorance. 18  While 

local partners may undergo digital literacy training, it 

often concentrates on specific tools and applications 

rather than building their overall capacity to use digi -

tal technology and data effectively and independently. 

Introducting technology can enable more efficient 

extraction and commercialization of data by enti -

ties located predominantly in developed countries. 

Herein, locals are reduced to data producers through 

gig work, thereby becoming part of territories from 

which data can be extracted and exploited from the 

distance. In these relationships employer responsi -

bility becomes fragmented across long supply chains, 

with ultimate control lying solely with the client. 19 

Conclusion 

This discussion shows how mobilizing AI and big 

data to convey local needs from a distance—what can 

be called datafied localization—risks perpetuating 

epistemic injustices and paternalistic practices in the 

humanitarian sector, if not pursued reflexively. Big 

data does not remove questions of contextualization, 

representation and power hierarchies. Instead, ques -

tions of what data are, who data represent and what 

data show remain a considerable structuring force for 

delivering humanitarian support. Current attempts 

at shortcutting localization stress the need for critical 

discussions of distance and proximity, as well as their 

intersections with emerging technologies. While lo -

calization through AI datafication may ostensibly be 

seen as a way to acknowledge local voices, a clos -

er look shows that the modes in which it is currently 

conceptualized risk reproducing power asymmetries 

in ways that run counter to the core intentions of 

localization. CHAPTER  4 — F RAMING  NARRATIVES  TO  REIMAGINE  ARTIFICIAL  INTELLIGENCE  TO  ADVANCE  HUMAN  DEVELOPMENT  1 3 3 

NOTES 

1. Mulder and others. 2016; Raymond and Al Achkar 2016. 

2. Duffield 2016; Fejerskov, Clausen and Seddig 2024; Sadowski 2019. 

3. Australian Red Cross 2017; Poole 2018; Seldon, Abidoye and Metcalf 2020. 

4. Fox 2020; Honig 2018; Khoury and Scott 2024. 

5. ALNAP 2022; Kraft and Smith 2019; Schenkenberg and others 2020. 

6. Barnett 2018; Fast and Bennett 2020; Melis and Apthorpe 2020; Pailey 

2020; Pincock, Betts and Easton-Calabria 2021. 

7. McCosker and others. 2022. 

8. Costa 2018. 

9. Barbelet and others. 2021; Wall and Hedlund 2016. 

10. Roepstorff 2020. 

11. Krause 2014. 

12. Roepstorff 2020. 

13. Sandvik 2023. 

14. Frost, Khan and Vinck 2022. 

15. Ghorkhmazyan 2022. 

16. Elkahlout and Elgibali 2020. The authors refer to “remotely managed local -

ized humanitarian action” and use the case of the Syrian Arab Republic 

to establish that remote management can facilitate localization, although 

with ethical and legal risks for local nongovernmental organizations. 

17. Duclos and others 2019. 

18. Fejerskov, Clausen and Seddig 2024. 

19. Mejias and Couldry 2024. 1 3 5 

# Power, influence 

# and choice in the 

# Algorithmic Age 

# C H A P T E R 

# 51 3 6 HUMAN DEVELOPMENT REPORT 2025 

# Much of this Report focuses on the demand side of 

# artificial intelligence (AI). This chapter shifts the lens 

# to the supply side, asking what kinds of AI tools are 

# developed, for what purposes and by whom. 

# The chapter examines “power over” people: how AI 

# producers and sometimes AI itself have the ability to 

# affect people’s prospects (in positive and negative 

# ways), alter their options (the choices they can 

# exercise) or influence their beliefs and preferences 

# (including what they value and have reason to value). 

> CHAPTER 5

# Power, influence and choice in the Algorithmic Age CHAPTER  5 — P OWER , INFLUENCE  AND  CHOICE  IN  THE  ALGORITHMIC  AGE  1 3 7 

Much of the Report’s analysis thus far has focused on 

artificial intelligence’s (AI) potential to give, or con -

strain, people’s power to do things. For example, chap -

ter 1 explores the potential of large language models to 

enable people currently excluded from accessing ad -

vanced expertise and know-how to have both in greater 

reach. This chapter moves from a discussion of “power 

to” to an examination of how AI has and shapes “power 

over” people. 1 Having “power over” means than an 

agent is able to affect others’ prospects (in positive and 

negative ways), alter their options (the choices they 

can exercise) or influence their beliefs and preferences 

(including what they value and have reason to value). 2

Both the agent with power and those whom power is 

exercised over have always been people. 

But AI’s agentic characteristics (chapter 2) sug -

gest that some AI models have agential power over 

people. 3 In classical programming digital tools were 

simply executing a set of preprogrammed rules, and 

thus power could be mediated by those tools but was 

ultimately exercised by the programmer. In contrast, 

AI models often operate beyond the effective control 

of the people who design and deploy them. This pre -

sents a historically novel means of exercising power, 

adding to the many ways power has been exercised 

over time  —through laws, parental voices, regulato -

ry incentives, social norms and more. 4 It also gives 

those designing and deploying AI, on the supply side, 

new means (intended or unintended) of exercising 

power over people. That is the subject of this chapter. 

Many are the possible threads to follow in this exami -

nation. An obvious one that has generated much public 

and policy interest relates to the market structure of the 

AI supply chain. One breakdown of this supply chain 

includes five components: computing hardware, cloud 

computing infrastructure, data used to train AI models, 

foundational models (such as GPT) 5 and consumer-

facing applications (such as ChatGPT and the hun -

dreds of thousands of applications that run on GPT and 

other foundational models; top panel of figure 5.1). A 

few firms account for large shares of the market, par -

ticularly in hardware and AI applications (bottom panel 

of figure 5.1). 6 Big technology companies (Big Tech) are 

present to varying degrees across the supply chain in 

different ways (sometimes dominating markets, as in 

cloud computing; in other cases investing in AI com -

panies as shareholders). Market concentration raises 

several policy concerns, 7 including the potential to limit 

consumer choice (perhaps through consumer lock-ins), 

restrict entry by smaller and newer firms, shape the 

direction of innovation away from socially desirable 

outcomes, 8 create single points of failure that harm cy -

bersecurity and operational resilience of critical infra -

structure and make financial stability more vulnerable 

to procyclical responses during financial stress. 9

# “ Market concentration raises several policy 

concerns, including the potential to limit 

consumer choice (perhaps through consumer 

lock-ins), restrict entry by smaller and newer 

firms, shape the direction of innovation away 

from socially desirable outcomes, create single 

points of failure that harm cybersecurity 

At the same time the market for frontier foundation 

models is dynamic, fluid and characterized by intense 

competition among dozens of AI labs. Several open-

source models have been deployed. 10  Although open-

source models may be more vulnerable to misuse and 

cyberattacks and their producers may sell comple -

mentary services in exclusive bundles that may limit 

competition, 11  they offer more flexibility and potential 

for customization that can enhance competition and 

innovation. 12  The fluidity of the market implies that 

things can change quickly —for example, if one model 

acquires capabilities vastly superior and out of reach 

of others or if first-mover advantages entrench one 

supplier, as in the dominance of ChatGPT up to 2024 

—in both ways the market can tip from decentralized 

to heavily concentrated. Concentration can also hap -

pen through vertical integration, with a few firms 

consolidating activities upstream, ranging from data 

to chips, and downstream, using their existing mar -

ket reach to get to consumers. 13  Concerns over market 

concentration are typically addressed by competition 

policy, but concentration in the AI supply chain raises 

new issues potentially beyond the reach of competi -

tion policy. For example, the digital economy, and AI 

in particular, brings new challenges in interpreting 

and applying competition policies and determining 

which jurisdictions to do so in, given the international 

reach of several AI applications. 14  Of course, the eco -

nomic impacts of AI extend beyond market structure, 

but the speed of change and vast scope of AI are cre -

ating different regulatory approaches across jurisdic -

tions to deal with the many challenges. 15 1 3 8 HUMAN DEVELOPMENT REPORT 2025 

Rather than focus on the market structure of the AI 

supply chain alone, this chapter starts with a frame -

work for interpreting how today’s AI is exercising 

power over people and for considering what to bear in 

mind as the AI supply chain continues to change and 

AI applications evolve and diffuse. 

Chapter 1 emphasizes that when AI outputs result in 

outcomes with high stakes, the need for human evalua -

tion should be carefully considered. Stakes also matter 

to assess whether “power over” warrants concern and 

examination. That assessment depends on individual 

and public reasoning, with three elements to help de -

termine whether the stakes are high: concentration, 

degree and scope (table 5.1). 16  Building on the intuition 

from market concentration, the first element is wheth -

er power is concentrated, not only in a market sense but 

also with a broader meaning: the fewer the people ex -

ercising power over a larger number, the more reason 

there is to consider the stakes high. A niche AI applica -

tion in a narrow economic sector has lower stakes than 

Figure 5.1  The market structure of the artificial intelligence (AI) supply chain is concentrated 

The AI supply chain Market structure of the AI supply chain HARDWARE COMPUTING 

Microprocessors such as graphics processing units (GPUs), application-specific integrated circuits and field-programmable gate arrays 

CLOUD TRAINING DATA 

Cloud platforms (infrastructure as a service) such as Azure and AWS 

MODELS FOUNDATION 

Text, video and audio from the internet, book repositories, Wikipedia and proprietary data Large AI models such as BERT, Claude, GPT and Llama 

AI APPLICATIONS 

User-facing applications such as ChatGPT, FinGPT and Gemini GPU revenue from data centres a

3% 

AMD 

5% 

Others 

92% 

NVIDIA Cloud computing b

31% 

AWS 

33% 

Others 

11% 

Google cloud 

25% 

Azure 

4% 

Others 

5% 

Gemini Claude Poe Perplexity 

87% 

ChatGPT Capital raised by AI firms d

33% 

Big techs e

67% 

Others IAI Aapplications c               

> a. Based on global revenue of graphics processing unit (GPU) producers for GPUs used in data centres in 2023.
> b. Based on global cloud computing revenue for the first quarter of 2024.
> c. Based on monthly visits data.
> d. Based on total capital invested in 2023 in firms active in AI and machine learning, as collected by PitchBook Data Inc.
> e. Corresponds to Alibaba Cloud Computing, Alibaba Group, Alphabet, Amazon Industrial Innovation Fund, Amazon Web Services, Amazon, Apple,
> Google Cloud Platform, Google for Startups, Microsoft, Tencent Cloud, Tencent Cloud Native Accelerator and Tencent Holdings.
> Source: Gambacorta and Shreeti 2025. CHAPTER 5 — P OWER ,INFLUENCE AND CHOICE IN THE ALGORITHMIC AGE 1 3 9

a firm making decisions on algorithms governing inter -

actions in digital platforms that billions of people use. 

The second element is the degree to which people are 

affected. The degree is higher when the impact touch -

es on someone’s property or, in more extreme cases, 

freedom or life (chapter 1). Even more mundane uses of 

AI, such as in automatic contracts in which lack of pay -

ment for a car loan blocks access to the car, may imply 

a greater impact than how noncompliance would be 

dealt with in the absence of AI. 17  The impact can also be 

high if many people are affected in ways that are not di -

rectly very consequential at the individual level but are 

substantial for a large group or society as a whole, as in 

political deliberation. 18  The third element is the scope 

of impact, with the stakes higher when power is exer -

cised over several dimensions of people’s lives. 

When one or a combination of these elements im -

plies high stakes, we should examine three aspects 

roughly linked to what power does, how it is exercised 

and by whom. 19  What power does relates to the sub -

stantive outcomes associated with designing and de -

ploying AI. Understandably, this has been the focus of 

attention given AI’s novelty and potential to affect out -

comes for people and societies across many facets of 

life. There are multiple, often interrelated, strands of 

work. AI safety focuses on avoiding accidental misuse 

or systemic risks. 20  It also extends to concerns over ex -

istential risk. 21  AI ethics has often been inspired by the 

“do no harm” duty of medicine but has also considered 

concerns ranging from upholding human rights, pro -

tecting privacy and addressing biases. 22  More ambi -

tious approaches seek to align AI with human values so 

that AI not only avoids harms but is also used for good. 23 

But even if it were possible to exercise power 

over people with AI systems that result in desirable 

outcomes, people also care about how that power is 

exercised — or what is described in political delibera -

tion as procedural legitimacy. 24  Fields such as trust -

worthy AI or responsible AI attend in part to this 

aspect. 25  Procedural legitimacy includes such aspects 

as equal treatment under a source of power (say, the 

law) as well as due process standards —for exam -

ple, contesting how a decision was made. AI is often 

opaque and does things beyond what it was designed 

for, making it hard or impossible to meet these stand -

ards: one reason AI transparency and explainability 

matter. 26  The higher the stakes, the more people care 

about the explainability of AI, 27  including in medi -

cal applications, where accuracy is often not seen as 

enough. 28  Finally, who makes the decision matters, 

particularly when the decision has implications for 

many people who may not have had the chance to in -

fluence it. Moreover, AI itself, in a sense, exercising 

power over people raises new questions beyond con -

sidering people who design and deploy AI. 29 

So, even though whether artefacts “have politics” 

is a longstanding debate in the history and culture of 

technology, 30  AI-powered algorithms do wield power 

not only to but also over. 31  In the context of today’s 

AI-powered transformation, two forms stand out for 

human development: 

• First is the unique and pervasive power that 

algorithms have in mediating our social interac -

tions and social choices. The 2023/2024 Human 

Development Report found that nearly 70 percent 

of the population feels they do not have a say in 

governmental decisions. 32  This highlights a high 

baseline level of disempowerment among the pub -

lic. A critical question is thus how this will evolve 

with AI’s ability to shape “power over.” 

• Second is the outsized power that a few people, 

companies and countries have in designing and 

deploying AI. This has consequences for people’s 

choices and freedoms  —how they are shaped by a 

powerful new technology over which many have, 

so far, had precious little say. 33 

## Algorithms shape social 

## choices and power 

We live in a novel social reality where algorithms 

(many of them AI-based) mediate many of our social 

relations and shape much of our engagement with 

Table 5.1  When do we confront high stakes? When 

“power over” is concentrated and impacts deeply 

or across many dimensions of people’s lives      

> Element Description
> Concentration The fewer the people exercising power
> over a larger number, the higher the stakes
> Degree The greater the impact on people’s lives
> (property, freedom, life), the higher the
> stakes
> Scope The more dimensions of people’s lives
> affected (scope), the higher the stakes
> Source: Human Development Report Office. 1 4 0 HUMAN DEVELOPMENT REPORT 2025

the world. Whether through social media, search 

engines, online shopping or digital communication 

tools, algorithmic intermediaries are reshaping the 

landscape of human-to-human interactions, defin -

ing the context and boundaries within which people 

engage. 34 

Philosopher Seth Lazar calls this the algorithmic 

city —articulating how computational machines have 

revolutionized interactions between people. 35  In this 

shifting landscape new forms of power are taking 

shape. 36  Think about how algorithms have funda -

mentally altered the way we access and engage with 

information. 37  We have attained extraordinary speed 

in retrieving information; however, the reliability of 

that information, its source and authenticity are often 

opaque (figure 5.2). 38  Consider the trust we place in 

the ranking of web search results, and increasingly 

also in searches using generative AI, despite having 

little insight into the algorithms that determine their 

order. 39  Or reflect on the way algorithms in social 

media platforms shape narratives and distribute peo -

ple’s attention, as shown below. 40  Or think about how 

generative AI —trained using around 90 percent Eng -

lish materials 41 —shapes our views and opinions about 

the world. 

Evolving power dynamics 

In this sense algorithmic intermediaries are subtly 

shaping the fabric of society and influencing human 

relations and behaviour in ways both profound and 

unseen. To examine in detail how AI “power over” 

is manifested, take the recommender systems wide -

ly deployed in web search and digital platforms. This 

type of AI is one of the most consequential ways 

that AI algorithms mediate and influence human 

relations, interacting with social, political and eco -

nomic processes, shaped by and shaping economic 

incentives, regulations and social norms (figure 5.3). 

Recommender systems shape how we navigate the 

infinite amount of information online, find the things 

we want to buy, connect with friends or follow people 

and events. 

In 1971 computer scientist Herbert Simon argued 

that in an information-rich world, attention becomes 

a scarce resource. 42  He identified the scarcity of at -

tention in a world with abundant information as a 

challenge in digital societies that requires filtering 

information to ensure that people can access what is 

most relevant to them. 43  The information throughput 

of a human is estimated to be 10 bits per second. 44  One 

Figure 5.2  Artificial intelligence transforming the way people retrieve information 

> TRANSPARENCY OF INFORMATION SOURCE TIME SPEED OF INFORMATION RETRIEVAL

Library Large language model Internet search Trusted messenger           

> A trusted messenger delivers the opinion or knowledge from a single source, such as a known expert. Libraries provide a selection of reputable sources for a reader to query. Internet searches facilitate quick access to a multitude of sources of varying quality and trustworthiness. Large language models provide a single-output, near-instantaneous answer to most queries. Though relying on a wealth of sources, the process is opaque, and its reliability is not guaranteed.
> Source: Burton and others 2024. CHAPTER 5 — P OWER ,INFLUENCE AND CHOICE IN THE ALGORITHMIC AGE 1 41

way people overcome this limitation is by working to -

gether, 45  but if a single human were to go through all 

the content of the internet today, it could take over 

half a billion years. 46  As the amount of information 

available in our increasingly digital world continues to 

expand, recommender algorithms channel our atten -

tion, seeking what is relevant to each person. A core 

challenge of leveraging the internet for human de -

velopment is that the information people use to pro -

mote their own agency and improve their capabilities 

far exceeds what anyone can reasonably consume. To 

overcome this limitation, algorithmic tools to search 

and filter information have come to define the mod -

ern internet. From early web searches and later so -

cial media feeds to modern chatbots, our experience 

of the internet is filtered through some form of algo -

rithm, often AI-based recommender systems. 

That is also the case for social media, 47  which has 

5.24 billion users, or almost two-thirds of the global 

population. 48  The typical model of recommender al -

gorithms in social media is fuelled by the behaviour -

al record of users, with recommender algorithms 

optimized to keep users engaged on the platform. 49 

Data to enable these algorithms to make recommen -

dations come from what people do online, which has 

raised concerns about privacy violations, potential 

exploitation of people and manipulation of beliefs 

and behaviours. 50  From a human development per -

spective these systems may also curtail human agen -

cy by making choices on our behalf over what we 

want to see  — choices that may better reflect industry 

incentives than our own agency (box 5.1). 51 

The case of recommender systems allows for a 

more concrete examination of the ways “power over” 

is exercised. Recommender systems do more than just 

regulate information flows —they shape the very con -

ditions in which people interact online. Think about 

how the law operates: it sets boundaries by prohibiting 

Figure 5.3  Recommender algorithms show how artificial intelligence is shaping social, economic and political 

processes 

SOCIETY Economic processes Political processes Social processes Social acceptability Economic goals of platform providers Recommendations of what to buy Recommendations of what news to consume Dating recommendations Political regulations A l go ri thmsA l go ri thmsAlgorithmsAlgorithmsALGORITHMSALGORITHMSAlgorithmsAlgorithms 

> Source: Wagner and others 2021. 1 42 HUMAN DEVELOPMENT REPORT 2025

Box 5.1  Recommendations in digital platforms and human development: Artificial intelligence as part of the problem, part 

of the solution? 

Artificial intelligence (AI) is not the issue with recommender systems, since any solution to improving online recommendations 

will likely require some form of AI. 1 A core problem with current approaches is that they derive recommendations primarily from 

human behaviour, often simply to keep us engaged on the platform. People’s choices provide important information about 

what matters to them, but, as Amartya Sen forcefully argued, their choices cannot provide a full account of their motivations. 2

Perhaps the most salient reason for this gap is that choice does not necessarily reflect a maximization of preferences and can 

be driven by other motives. 3 For example, choosing to engage with misleading information online reflects a constraint in the 

quality of information available rather than a preference for false information. 4

So, recommender systems based on behaviour do not provide an opportunity for people to ground recommendations on a 

broader set of aspects of what matters to them. This is key for human development, since it relates to the extent that people can 

exercise their agency and, ultimately, their freedom. 5 From a human development perspective this is a fundamental concern, 

perhaps less visible than other problems, with behaviour-based recommendations, which include both the exploitation of what 

psychologist Daniel Kahneman called system-1 thinking (behavioural biases that digital platforms exploit for engagement) 6 and 

the difficulty of accounting for heterogeneity in preferences. 7

Recommender systems could be giving poor recommendations, 8 but more importantly they are shaping the choice architecture 

online and perhaps impoverishing the concept of what it means to be human, if what people do online is assumed to represent 

what people want to see. 9 Recommender systems are thus biased to make people more passive recipients of online content, rather 

than active agents able to access what matters to them, potentially undermining people as moral agents through moral deskilling. 10 

Moreover, recommender systems optimized for engagement, particularly in social media, seek to maximize the attention users 

devote to the platforms and to give content producers more opportunities to have their creations seen. Of course, this is driven 

also by the revenue-generation model of the platforms, which is determined primarily through engagement by both content 

consumers and producers, with higher engagement providing more opportunity to sell advertising that can be targeted. 11  There 

is an active debate on how to develop recommender systems optimized for things other than engagement, given some of the 

individual and collective harms associated with these systems. 12  But whether recommender systems could be optimized for some -

thing else relates also to the possibility of going beyond relying on online behaviour as the basis for recommendation, so that in 

addition to what people do online, recommendations could match who they are and what they value and have reason to value. 

One possibility is to use some sort of “middleware” that mediates between the digital platform and the users. 13  But this would 

still not enable recommendations to reflect users’ preferences and beliefs. Another possible approach would be to use large 

language models, given their ability to call on other tools (say, a search engine or a calculator) to execute tasks that go beyond 

their immediate training or that are required by the user prompt. 14  When recommender systems were first developed, algo -

rithms could not engage in regular spoken language and could not explicitly reason the same way current models can. 15  The 

flexibility and adaptability of large language models provide options to explore how they can be used as agents, 16  if progress 

is made in addressing some of the inherent limitations of the technology, 17  including privacy, security and trust concerns. 18  A

generative AI recommender agent could learn about what matters to the user by engaging conversationally — for example, by 

asking about what he or she values and has reason to value 19 — and iteratively compile content that aligns with those values and 

preferences. 20  Rather than taking human agency away from the interaction with digital platforms, these recommender agents 

could scaffold human agency in the interaction with online content. 21                                                 

> Notes
> 1. Li and others (2024) provide a survey of recent developments. See also Shen and others (2024). 2. Sen 1973, 1977. 3. Sen 1997. For a summary of Sen’s
> view on preferences and choice see, for instance, Anderson (2001). For a recent critique that extends to the broader challenge of framing AI alignment
> as being driven by the rational maximization of preferences, see Zhi-Xuan and others (2024). 4. Stewart and others 2024. 5. Sen 1985. 6. Agarwal and
> others 2024; Besbes, Kanoria and Kumar 2024; Kleinberg, Mullainathan and Raghavan 2024; Kleinberg and others 2024. 7. Chen and others 2024; Yao
> and others 2024. 8. Rita Gonçalves and others 2025. 9. Agan and others 2023. As noted above, there are also privacy concerns, with technical options
> being pursued to address these but without fundamentally changing the behaviour-based engine of the recommendation (Chronis and others 2024).
> 10. Schuster and Lazar 2025. 11. A different challenge relates to moderation, which deals with the choices that platforms make on what content to allow
> in order to comply with the law and each platform’s terms of service, as well as how to achieve those goals (outsourcing fact checking, using algorithms
> to detect prohibited content or having users flag noncompliant content). On moderation in digital platforms, see Douek (2022), Gorwa, Binns and Kat -
> zenbach (2020) and Lai and others (2022). On tensions between free speech and moderation and ways of addressing them, see Kozyreva and others
> (2023). Moderation and recommender systems optimized for engagement might not be independent, because content that elicits more engagement is
> often extreme and close to the bounds of what is accepted, so there might be an inherent tradeoff between effective moderation and current recom -
> mender systems (Narayanan and Kapoor 2024). 12. Bernstein and others 2023; Cunningham and others 2024; Ho and Nguyen 2024; Jia and others
> 2024a; Kazienko and Cambria 2024; Singh and Joachims 2018; Stray 2020; Stray and others 2024; Wang and others 2023. 13. Hogg and others 2024.
> 14. Askari and others 2024; Pentland and Tsai 2024. 15. Lazar and others 2024. 16. Kapoor and others 2024b; Wang and others 2025; Xi and others
> 2023. 17. For applications in medicine and healthcare as an example, see Kim and others (2024), Kim and others (2025) and Wang and others (2025).
> For applications that include but go beyond medicine, see Wölflein and others (2025). 18. Andreoni and others 2024. 19. Danry and others 2023. 20. As
> proposed by Schuster and Lazar (2025). 21. Lazar 2024b; Schuster and Lazar 2025; Whitt 2024. Some emerging examples of related approaches in -
> clude Irvine and others (2023), Jia and others (2024b), Paul and others (2024), Yuan and others (2024) and Zhao and others (2024). CHAPTER 5 — P OWER ,INFLUENCE AND CHOICE IN THE ALGORITHMIC AGE 1 4 3

certain actions, otherwise presuming a baseline of 

freedom. In contrast, recommender systems start 

from the opposite end, where people’s choices are 

shaped by what the recommender system suggests or 

determines is feasible. By governing the rules and pol -

icies of data curation and moderation, digital media 

platforms today shape “power over.” Platforms de -

cide how to up-rank or down- rank posts, flag and re -

move content, suggest new contacts or altogether 

ban a user, curbing their overall social engagement in 

that space. 52  These decisions have far-reaching conse -

quences for social choices and prospects. 53 

Recommender systems not only arbitrate power 

over individuals —they also redefine power relations 

between them. 54  They can allow behaviours that are 

malicious or abusive, excluding or harming segments 

of the population. 55  By shaping power relations be -

tween the people they mediate, algorithmic inter -

mediaries enable some users to exert influence over 

others, affecting their prospects and choices. More -

over, as a result of numerous, repetitive social inter -

actions, recommender systems are reconfiguring 

societal structures, including social norms, institu -

tions and culture  —reshaping political discourse and 

deliberation. 56 

Automated power and its implications 

As algorithms upend power relations, they operate 

like multipliers, enabling fewer people to have bigger 

impacts on others’ lives. 57  Elsewhere, computation -

al systems act as automatic arbiters of power, leav -

ing decisionmaking to machines, raising questions 

about legitimacy. 58  Consider how algorithmic tools 

are being used in various parts of government ser -

vices, ranging from allocation of social security ben -

efits to criminal justice and security issues. 59  Or how 

algorithms in social media act dynamically, monitor -

ing the social relations they mediate in real time, as 

we just saw. Their capacity to actively shape social 

relations and curate the information accessed grants 

them far-reaching influence, positioning them not 

merely as passive facilitators but as active agents in 

both the digital and real worlds. 60 

AI is being layered on a changed digital informa -

tion environment that was already presenting new 

challenges to collective decisionmaking even before 

the advent of generative AI (spotlight 5.1). 61  Gener -

ative AI may exacerbate challenges ranging from 

making political microtargeting more persuasive and 

scalable 62  to the potential for political bias in outputs 

produced by generative AI models. 63  And yet, it is 

crucial to avoid the technodeterminism examined in 

chapter 4 and attributing to technology causal harms 

that may often have more to do with underlying psy -

chological, social, and political challenges. 64 

# “ Generative AI may exacerbate challenges 

ranging from making political microtargeting 

more persuasive and scalable to the potential 

for political bias in outputs produced by 

generative AI models. And yet, it is crucial to 

avoid technodeterminism and attributing to 

technology causal harms that may often have 

more to do with underlying psychological, 

social, and political challenges 

Still, consider how AI is making “hypersuasion” 

possible  —that is, influencing beliefs and behaviours 

by crafting language aligned to its users’ psychologi -

cal profiles. Large language models can generate re -

sponses based on users’ specific profiles  — such as 

their personalities, moral values or political ideolo -

gies. 65  Information about users’ profiles can be mined 

from online behaviour —such as online readership, so -

cial media activities, shopping patterns and feedback 

on large language models. Hypersuasion in turn can 

generate behaviour or shape attitudes, raising ethical 

concerns and the possibility of harm through mali -

cious intent. 66  Further, taking users’ behaviour as ex -

pressive of true interests and opinions interferes with 

the formation of democratic, private and public judge -

ments, potentially undermining people’s agency (see 

box 5.1). In some cases AI is as good as or better than 

humans in hypersuasion. The latest large language 

models passed theory of mind tests that are practiced 

on humans, even though, in line with the main argu -

ment of this Report, anthropomorphizing framings 

and language need to be considered with caution. 67  AI 

does not suffer from egocentrism biases the way hu -

mans do, 68  and given that AI has access to much wider 

sets of language than any human could possibly have, 

the responses from AI can be particularly persuasive. 69 

Beyond hypersuasion being automated at scale, 

several large language models have exhibited 1 4 4 HUMAN DEVELOPMENT REPORT 2025 

sycophancy  — the tendency to generate responses 

attuned to user tastes over accurate and impartial 

responses. 70  This is observed in large language mod -

els trained to provide neutral or diplomatic answers 

but also to be responsive to user feedback, so over 

time their responses evolve to be more in line with 

user opinions, potentially hampering accuracy and 

reliability. 71 

Power is also being exercised through algorithmic 

governmentality —the use of algorithms to assess, 

predict and control the behaviour of populations. 

The concept stems from Michel Foucault’s govern -

mentality, or how power is exercised through knowl -

edge (about the subjects being governed) to navigate 

towards certain outcomes through specific instru -

ments. Data can be gathered to build detailed profiles 

of people, categorize them into groups, predict their 

future behaviour, direct them towards certain action 

or treat subjects differently. Examples include micro -

targeting populations for votes, predictive policing 

and determining social security benefits for individu -

als. The exertion of power in these new ways is simul -

taneously complemented by the disempowerment 

of people whose data are being shared, often with -

out their knowledge, leaving them unaware of how it 

could be used to determine outcomes in their lives. 72 

Can AI be used to enhance collective action? 

While AI risks influencing political processes, it alone 

may not be the most important determinant of poten -

tial impacts. For example, generative AI has reduced 

the cost of producing false, manipulative content, 

but the cost of distribution remains the binding con -

straint in having societywide implications. 73  In 2024 

Wired magazine gathered data from more than 60 

countries to understand AI use in manipulating in -

formation prior to elections. Of 78 deepfake cases, 

half were not intended to deceive; further unpack -

ing the demand side of false or misleading infor -

mation flows is required rather than looking at the 

supply side alone. 74  Concerns that much better large 

language models would supercharge the persuasive -

ness and scale of political messages appear not to be 

panning out, since newer and larger models do not 

substantially increase the persuasiveness of political 

messages compared with earlier large language 

model releases. 75 

Moreover, several initiatives seek to address the 

potential harms of AI for collective decisionmaking 

and action. The United Nations Educational, Scien -

tific and Cultural Organization’s Recommendation 

on the Ethics of Artificial Intelligence, adopted in No -

vember 2021, provides a global policy framework for 

guiding AI use to uphold human rights and dignity 

and ensuring that AI benefits societies at large. 76  Up -

dated in 2024, the OECD AI Principles are another 

set of intergovernmental standards on AI, with 47 ad -

herent countries, providing a basis for developing AI 

that respects human rights and democratic values. 77 

Launched in 2019, Singapore’s Model AI Governance 

Framework is paving the way for a strong AI ecosys -

tem that balances innovation with concerns around 

security, privacy and accountability, among others. 78 

Its objective is to make AI human- centric by provid -

ing practical guidelines to the private sector to ensure 

governance and ethics in product development. 79 

# “ The Global Digital Compact, agreed by the 

United Nations General Assembly in late 2024, is 

unique and exceedingly important, as elaborated 

further below, for helping different jurisdictions 

shape the supply of AI according to the universal 

principles of the United Nations Charter and 

the Universal Declaration of Human Rights 

These frameworks aim to ensure that AI is pro -

duced in a way that abides by ethical principles that 

support collective action and increase social welfare. 

But they are not universal. In that context the Glob -

al Digital Compact, 80  agreed by the United Nations 

General Assembly in late 2024, is unique and ex -

ceedingly important, as elaborated further below, 

for helping different jurisdictions shape the supply of 

AI according to the universal principles of the Unit -

ed Nations Charter and the Universal Declaration of 

Human Rights. 

Many initiatives are exploring the use of AI to en -

hance collective action. 81  For example, deliberative 

collective action rests on the understanding that in -

dividuals are autonomous beings with their own set 

of values and beliefs and have capabilities —and more 

critically equal rights —to determine the laws and pol -

icies that govern them. 82  One key constraint in these CHAPTER  5 — P OWER , INFLUENCE  AND  CHOICE  IN  THE  ALGORITHMIC  AGE  1 4 5 

processes that AI could help tackle is the practical 

challenge of mass participation. Citizen assemblies, 

for example, are difficult to scale and often result in 

voices being heard unequally. AI-powered tools could 

synthesize inputs from numerous people to present a 

picture of how the population sees issues that affect 

them. An example is Polis, 83  a machine learning tool 

that gathers opinions, categorizes them into themes 

and tries to understand what large groups of people 

think. 84  One of its innovative features is that it does 

not have a reply button, which mitigates negative 

back and forth conversations and redirects focus to 

the expression of novel ideas. 85  AI tools are also pro -

viding deliberators with useful resources, such as 

reliable data and information, to guide collective 

decisionmaking. 

AI can further enhance the quality of human-to-

human interactions by facilitating peaceful, produc -

tive dialogues. For example, AI-based interventions 

in online chats can improve political conversations 

and do so at scale. 86  When people are discussing is -

sues that divide them, AI can support mediation by 

generating and refining statements that express com -

mon ground. 87  An experiment of a virtual citizens’ as -

sembly in the United Kingdom showed that a trained 

large language model could outperform humans in 

bringing people together on contentious issues such 

as Brexit, migration, the minimum wage and climate 

change (figure 5.4). 88  Group statements compiled 

using large language models were more acceptable 

to the group than those generated by human media -

tors. Another experiment demonstrated that AI could 

successfully counter beliefs in conspiracy theories by 

providing alternative facts and engaging in evidence-

based dialogues. 89  These examples highlight how AI 

could mitigate divides, advancing collective action. 

AI can also help build a healthier ecosystem for on -

line conversations. Perspective API, launched in 2017 

by Jigsaw and Google, facilitates online conversations 

by flagging malicious content and removing or down-

ranking it. 90  More recently, the tool was augmented 

to prioritize content that moves groups towards con -

structive dialogue by identifying reasoning, story -

telling and curiosity in conversations. 91  Readers on 

average found that the conversations were not only 

less hostile but also more interesting, trusting and 

respect-worthy. 92  Publicly available large language 

models, when fine-tuned to give equanimous perspec -

tives on issues of debate, can expose users to a  spec -

trum of opinions and could nourish public discourse. 

Figure 5.4  Artificial intelligence (AI) outperforms human mediators in finding common ground 

Deliberation protocol Statement endorsement  

> 10 20

Share of statements (%) 30 0Strongly disagree Disagree Somewhat disagree Neutral Somewhat agree Agree Strongly agree Human mediator AI mediator PARTICIPANTS OPINIONS AND CRITIQUES AI MEDIATOR GROUP STATEMENT  

> Source: Tessler and others 2024. 1 4 6 HUMAN DEVELOPMENT REPORT 2025

## Who has the power? Divides 

## and dependencies are evolving 

## amid furious AI races 

From the printing press to the spinning jenny to nu -

clear fission, technological trajectories have long 

been shaped by people’s choices. 93  Algorithms take 

this to a new level: they are literally codified choic -

es about everything from user feeds to online mar -

ketplaces. 94  Economist Martin Shubik, commenting 

on Herbert Simon’s famous lecture on designing or -

ganizations for an information-rich world, described 

human societies as information processing systems. 95 

Human lives are built on decisions made on the basis 

of that information processing. AI-powered algo -

rithms reflect a fundamental change in how informa -

tion is processed in our societies, how individual and 

collective decisions are made and how people live 

their lives. 96  Algorithmic choices do not just dominate 

the digital sphere, they constitute it. 

# “ AI-powered algorithms reflect a fundamental 

change in how information is processed in 

our societies, how individual and collective 

decisions are made and how people live 

their lives. Algorithmic choices do not just 

dominate the digital sphere, they constitute it 

The scope, speed and reach of algorithmic choices 

are mindboggling, and they matter for human devel -

opment. Our societies  —their laws, norms, institu -

tions and leaders — codetermine the choices available 

to us and the ones achievable. That is why under -

standing the ways algorithms mediate our social in -

teractions and social choices matter so much. That 

is also why it is important to understand the supply 

side of who is making decisions about how those al -

gorithms work. 

Most of us have little direct say over algorithms. 

What choices trickle down to us are a hard residue, 

atomizing and binary: buy the latest gadget or not, 

accept the cookies or not. Take-it-or-leave-it terms 

of service agreements can boil down to, on the one 

hand, granting Big Tech carte blanche access to our 

daily lives in their quest to build bigger and more 

profitable garrisoned database or, on the other, exclu -

sion from colossal digital platforms, where for better 

and worse ever more of our lives, interactions and 

relationships take place. A digital exile exempt from 

due process. 

The freedom to have and exercise more choices 

over technologies that can powerfully influence peo -

ple’s opportunities is itself a concern of —and for —

human development. 

The opportunity for more choices by and for people 

seems huge, if bounded in some degree by techno -

logical feasibility and by the decisions of those sup -

plying AI. As noted above, digital technologies pose 

unique challenges to traditional policy interventions 

to address market concentrations and expand con -

sumer choices. 97  For example, digital platforms can 

be understood as essentially selling access to peo -

ple’s attention to advertisers, but when there are only 

a few players, the concentration of this bottleneck in 

attention is detrimental to advertising firms and con -

sumer welfare, something that traditionally is not 

considered by competition authorities. 98  This new 

challenge is perhaps one reason different jurisdic -

tions have taken varying views on whether and how 

to regulate digital markets and platforms for many 

years and on AI more recently. 99  Regulation choic -

es are also shaped not only by the affordances of the 

new technologies but also by differences in institu -

tions and varying interpretations of the state’s role in 

the economy. 100 

For example, the United States has emphasized in -

novation and light regulation of AI, while the Europe -

an Union has prioritized individual protections and 

potential social harms, establishing comprehensive 

regulations through laws such as the Digital Markets 

Act, the Digital Services Act and the General Data 

Protection Regulation. 101  China follows a state-driven 

model. 102 

While identifying the precise boundary of techno -

logically feasible choices may be hard, an ongoing 

tension on regulation is clearly driven by the mo -

tives of incumbent companies, often concentrated, 

as seen above  —and by the concerns of people, work -

ers and governments about the negative impacts of 

the power concentration documented in this chapter, 

which some years ago resulted in what was described 

as a “techlash.” 103 

The concentration of power in those making choic -

es on what kind of AI to supply has consequences 

for people. Algorithms that maximize user engage -

ment are a choice, a lucrative one that may amplify CHAPTER  5 — P OWER , INFLUENCE  AND  CHOICE  IN  THE  ALGORITHMIC  AGE  1 47 

outrage. Moderating content (or not) is a choice. So 

is the degree of openness. Many leading AI firms 

have been reluctant to fully open their AI models, 

including the underlying training data. 104  Compa -

nies select benchmarks against which their latest 

models are evaluated. One well-known benchmark 

is apocalyptically dubbed Humanity’s Last Exam 

and pits machines against people. 105  If we want hu -

mans and machines to compete less and complement 

each other more, we should stop letting bullseyes be 

placed on our backs. 

Another manifestation of the restriction of choice 

is the AI race, an epic spending spree by Big Tech, 

whose market capitalizations have ballooned since 

ChatGPT burst onto the scene. 106  The race is rapidly 

evolving, and how it shakes out is anybody’s guess, 

but a combination of hype and a bigger-is-better par -

adigm appears to be fuelling it. 107 

A simplified AI supply chain hinges on three key 

inputs — computing power (which goes by “compute” 

in the AI industry jargon) talent and data —in and 

through which divisions and dependencies among 

companies and countries are evolving. Low-income 

and many middle-income countries face yawning 

gaps in each input. Steps can be taken to address 

gaps, but these countries need to be strategic. The 

vast majority simply do not have the luxury of spend -

ing billions in a high-stakes AI race. 

# “ We should also take a step back and question 

whether narratives anchored in zero-sum 

competition miss opportunities for cooperation 

and gains for all players, including across 

countries. Finding opportunities to steer a mix 

of cooperation and competition towards human 

development, towards expanded choices and 

opportunities for people, is the task at hand 

The relationship between countries is not just 

competitive or confrontational. Governments can 

be partners, regulators and competitors, some -

times simultaneously and in different ways. India 

plans to set up a common compute facility to sup -

port AI development, 108  including among research -

ers and startups. The United States announced the 

Stargate Initiative, 109  a $500 billion partnership be -

tween such recognizable tech titans as Nvidia, Ope -

nAI and Oracle and Japanese financial conglomerate 

Softbank. The initiative aims to build AI infrastruc -

ture in the United States. The European Union has re -

sponded with its own €200 billion partnership with 

InvestAI. 110 

In these heady early days of generative AI, coun -

tries are staking out positions in light of how they see 

it impacting their different interests —from geopol -

itics to security to growth and development. Given 

the variety of interests in play and the evolving, com -

plex relationships among players, especially between 

countries and firms, we should stop talking about an 

AI race and instead talk about many AI races. We 

should also take a step back and question whether 

narratives anchored in zero-sum competition miss 

opportunities for cooperation and gains for all play -

ers, including across countries. Finding opportunities 

to steer a mix of cooperation and competition towards 

human development, towards expanded choices and 

opportunities for people, is the task at hand. 

AI models depend on three unevenly distributed 

inputs: Compute, talent and data 

Compute 

About 60–95 percent of recent performance gains in 

AI have stemmed from scaling compute, 111  though it is 

unclear whether scaling will remain the driving force 

for improved AI performance. 112  The training com -

pute of notable machine learning models has been 

increasing by a factor of 4.7 each year since 2010. 113 

Part of the expense of compute is due to remarka -

ble concentration in the semiconductor market, par -

ticularly for advanced AI chips, where Nvidia holds a 

dominant position. 114  The concentration is even more 

pronounced in the equipment to make chips, which is 

effectively controlled by a single company, ASML. 115 

The massive fixed costs involved, combined with 

low variable costs, favour economies of scale, 116  con -

tributing to a highly concentrated chip market. 117  As 

major cloud providers develop their own chips, this 

vertical integration risks concentrating power in new 

ways. 118 

Apart from the cost of chips themselves, AI data 

centres have voracious appetites for energy and wa -

ter. 119  Google is turning to small nuclear reactors to 

power AI data centres, and other big corporations are 1 4 8 HUMAN DEVELOPMENT REPORT 2025 

reconsidering their climate commitments given AI’s 

energy demands. 120 

Talent 

People are the main drivers of innovation and the 

custodians of knowledge. The critical role of people 

driving and disseminating innovation is one reason 

open-source approaches have gained ground in the 

AI industry. 121 

The demand for talent is increasing, outstripping 

supply that can take time to fill given the bevy of spe -

cialized skills required. Even as early as 2021, many 

organizations struggled to fill AI-related roles. 122 

Meanwhile, industry is siphoning talent from aca -

demia. The proportion of AI Ph.D. graduates entering 

industry rose from 21 percent in 2004 to 73 percent 

in 2022. 123  Industry provides not only higher financial 

incentives but also access to substantial computing 

resources. It often also provides researchers with op -

portunities to deploy cutting-edge technologies. Gov -

ernments face similar disadvantages in AI talent. 

Data 

The data requirements of AI models can be vast, 

which affords advantages to some companies and 

countries over others. Digital platforms and social 

media firms have accumulated massive amounts of 

proprietary data over the years, due largely to positive 

network effects, which amplify the value of a prod -

uct or service as more people use it. 124  While network 

effects are less clear with AI, data feedback loops, in 

which AI gets better and more attractive to users as 

their interactions with it deliver more data, can also 

play a role. 125 

Large proprietary databases are set to take on greater 

importance as the current crop of large language mod -

els exhaust the supply of publicly available data and 

as public datasets increasingly contain AI-generated 

output, though this depends on the evolution of al -

gorithms. For example, reinforcement learning train -

ing methods may put a premium on domain-specific 

and high- quality data or even synthetic data that are 

model generated (while not a perfect analogy, think 

of the way AlphaGoZero and AlphaZero were trained 

to play, respectively, Go and chess). A recent analysis 

of the private data available on major closed content 

platforms, instant messaging applications and email 

services suggests that leveraging nonpublic data could 

delay a potential data bottleneck by approximately 18 

months compared with relying solely on indexed web 

data. 126  Moving from pretraining to posttraining of AI 

models, proprietary data have obvious significance for 

fine-tuning models for specific applications such as 

drug discovery. 

One example is Shoshana Zuboff ’s point of view, 

which sees corporations extract and commodify all 

kinds of behavioural data, transforming user activity 

into a competitive resource characterized by a lack of 

user awareness and transparency. 127  It is also easy to 

see how this could extend to governments’ surveil -

lance capacities, by either using their own databases 

on people or gaining access to databases maintained 

by companies. A recent study argued that the emer -

gence and persistence of market power around AI 

would be shaped largely by how data markets operate 

—in particular, whether trading data across firms’ 

boundaries would take place. 128 

Low- income and several middle-income 

countries face big gaps in key AI inputs 

Countries are increasingly being evaluated for their 

ability to develop and deploy AI based on how pre -

pared, ready and vibrant their AI ecosystems are. 

Multiple global indices and tools now compare na -

tional AI capabilities, though their scope and meth -

odology differ widely. Insights from these indices 

highlight gaps across low- and several middle-income 

countries along various dimensions (table 5.2). 

Several factors determine a country’s ability to de -

velop AI. Examining a country’s science–technology 

nexus 129  —the interconnected and reciprocal relation -

ship between scientific research and technological 

progress —is one way to assess this ability. The nexus 

depends on a country’s pre- existing technological 

capabilities, the strength of its scientific knowledge 

base and the alignment between the scientific and 

technological sectors. 130 

High-income countries such as the United States, 

the Republic of Korea, Japan and Germany, in that 

order, have well- established digital infrastructures, 

giving them a major advantage in AI development. 

In contrast, low- income countries may lack the CHAPTER  5 — P OWER , INFLUENCE  AND  CHOICE  IN  THE  ALGORITHMIC  AGE  1 4 9 

digital infrastructure to even deploy, let alone sup -

ply, AI tools. The United States, China, the United 

Kingdom, Germany and Canada also lead in scientif -

ic knowledge production, with the United States and 

China holding a distinct advantage. 131 

One of the three pillars of the Government AI 

Readiness Index is the Technology Sector, 132  which 

assesses the maturity of a country’s technological in -

frastructure . This pillar also reflects the disparities in 

ability to develop AI across countries, similar to those 

in the science–technology nexus. When focusing 

solely on the Technology Sector pillar, high-income 

countries generally outperform others, with the Unit -

ed States standing out due to its mature market and 

high innovation capacity. Other high-income regions, 

such as Western Europe, also perform well but typ -

ically lag behind the United States in this area. In 

contrast, low- and middle-income countries in Sub-

Saharan Africa and Latin America and the Caribbean 

exhibit substantial gaps. 

Most large-scale AI models today are developed by 

organizations based in the United States, followed by 

China and the United Kingdom. 133  Only a small frac -

tion originates from other countries, including Saudi 

Arabia and the United Arab Emirates, and very few 

are created through international collaborations (fig -

ure 5.5). Investment is also concentrated in the Unit -

ed States and China (figure 5.6). 

Gaps in AI capabilities 

As of March 2024, the United States hosted about 

half the global data centres, 134  reflecting the concen -

tration of that infrastructure. 135  Although cloud com -

puting relaxes the link between the physical locations 

of data centres and data use, only 5 percent of Afri -

ca’s AI talent has access to the computational power 

for complex AI tasks. 136  Big Tech dominates global AI 

computing power, owning much more than many na -

tional governments. 137 

The availability of data for AI development in a 

country depends on several factors, which can be as -

sessed through the Data Availability dimension of the 

AI Readiness Index’s Data & Infrastructure pillar. 138 

Data availability varies considerably across countries 

and regions. Middle-income countries are improving 

their data ecosystems through stronger policies and 

governance. However, many struggle with data rep -

resentativeness due to gaps in internet access. Sub-

Saharan Africa is making progress in data availability 

and infrastructure but still shows large gaps. These 

disparities stem from differences in government 

commitment to open data, data management capa -

bilities and access to technology. 

There is a stark divide in AI talent between low-

and middle-income countries on the one hand and 

high-income economies on the other. 139  The Unit -

ed States attracts 60 percent of elite AI research -

ers (roughly the top 2 percent) and hosts 75 percent 

of top-tier talent educated in US or Chinese insti -

tutions. While China now retains 47 percent of its 

homegrown researchers —up from 29 percent in 2019 

—most lower income countries struggle to retain tal -

ent. India has also made progress in retaining talent: 

20 percent of its AI researchers now stay domestical -

ly (up from near zero in 2019). 140 

High- income countries such as the Republic of 

Korea, the United Kingdom and the United States 

leverage existing infrastructure and funding to at -

tract talent, while emerging economies face an 

uphill battle. This entrenches a cycle where inno -

vation clusters in wealthy countries, risking leaving 

others further behind in AI innovation, supply and 

deployment. 

Table 5.2  Gaps across country income groups based on popular artificial intelligence (AI) metrics     

> Global AI Vibrancy Tool Government AI Readiness Index AI Preparedness Index Global AI Index
> Highlights gaps in AI activity,
> development and impact
> across countries.
> Among 36 evaluated
> countries, only India (ranked
> 4th) is lower middle income
> — showing low AI vibrancy in
> lower- income countries.
> High- income countries
> traditionally lead due to mature
> tech sectors.
> 2024 data show low- and middle-
> income countries improving in
> governance, ethics and data
> strategies  —  potentially closing
> gaps.
> Wealthier economies
> (advanced and some
> emerging markets) are better
> prepared for AI adoption.
> Considerable variation exists,
> with low-income countries
> lagging.
> China and the United States
> dominate across investment,
> innovation and implementation.
> The next eight countries are closer
> in rank, with India as the only low-
> or middle-income country in the
> top 10. The remaining 73 countries
> trail behind.
> Source: AIPI 2025; Oxford Insights 2023; The Stanford Institute for Human-Centered AI 2025; Tortoise Media 2025. 1 5 0 HUMAN DEVELOPMENT REPORT 2025

These disparities are also revealed by a widening 

chasm in AI talent distribution between 2019 and 

2023. 141  In 2023 high-income countries saw a net gain 

in AI talent, while low- and middle-income coun -

tries experienced a net loss (figure 5.7). India has the 

highest self-reported AI skill prevalence globally (fig -

ure 5.8), but even as lower income countries cultivate 

talent pools, systematic gaps in compute, data and in -

stitutional support drive net losses, as skilled workers 

migrate to higher income countries. 

Figure 5.6  Most global investment in artificial intelligence (AI) flowed to the United States in 2024   

> 010 20 30 40 50 60 70 80 United States Middle East China Rest of the world

Notable global AI investment flows ($ billions) 0.7 6.5 70.2 19.9  

> Source: Lucidity Insights 2024.

Figure 5.5  The majority of today’s large-scale artificial intelligence models are developed by organizations based in the 

United States, followed by China and the United Kingdom 

sledomforebmunevitalumuCUnited States United Kingdom China Saudi Arabia Other Multinational 020 40 60 80 100 120 140 160 180 200 2020 2021 2022 2023 2024 2025           

> Source: Epoch AI 2024d. CHAPTER 5 — P OWER ,INFLUENCE AND CHOICE IN THE ALGORITHMIC AGE 1 51

Figure 5.7  Artificial intelligence (AI) talent has been flowing towards high-income countries 

–1.0 –0.5 4.0 3.5 3.0 2.5 2.0 1.5 1.0 0.5 0.0 Lithuania Indonesia Net AI skills migration, 2023 (per 10,000 LinkedIn members) Romania Brazil Croatia Mexico Chile Slovenia South Africa Argentina Uruguay Italy Republic of Korea Hungary Greece Türkiye Israel India Luxembourg Switzerland United Arab Emirates Cyprus Germany Austria Canada Finland Estonia Netherlands Australia Ireland Japan Singapore Saudi Arabia Iceland Denmark United Kingdom Norway United States Poland Belgium Spain Portugal New Zealand Sweden Hong Kong, China (SAR) Latvia Czechia France Costa Rica 

Note:  The figure shows net migration flows (of LinkedIn members with AI skills) in 2023. The bars indicate the magnitude of a country’s net AI talent gains (or 

losses), normalized by the total LinkedIn membership in that country (and multiplied by 10,000). 

Source:  OECD 2025a. 

Figure 5.8  India has the highest self-reported artificial intelligence (AI) skills penetration 

0.0 0.5 1.0 1.5 2.0 2.5 3.0 Cross-country AI skills penetration India United States Germany Canada United Kingdom Israel Singapore France Japan Türkiye Republic of Korea Spain Brazil Netherlands Greece Italy Switzerland 

> Global average
> Australia United Arab Emirates Indonesia Sweden Poland Hong Kong, China (SAR) Ireland Denmark Portugal Austria Argentina Mexico Saudi Arabia Finland Belgium Cyprus Romania Czechia Hungary South Africa Norway Estonia Chile Lithuania Croatia New Zealand Luxembourg Uruguay Costa Rica Slovenia Latvia Iceland

Note:  The figure shows the prevalence of workers with AI skills (as self-reported by LinkedIn members) by country and against a global average benchmark (as 

shown by the red bar). A relative penetration rate of 2 means that the average penetration of AI skills in the country is twice the global average across the same 

set of occupations. 

Source:  OECD 2025a. 1 5 2 HUMAN DEVELOPMENT REPORT 2025 

A geopolitical innovation race is taking shape 

The AI races 142  can be interpreted as unfolding along 

a spectrum, from a collaborative innovation race to a 

purely zero-sum arms race (figure 5.9). 143  This spec -

trum reflects different ways of considering ongoing 

AI competitive dynamics. 144  The nature of the race is 

not inherent to AI itself but emerges from how agents 

interpret and respond to the actions and perceived in -

terests of others. 

The perception of a race itself can become self-

fulfilling, where agents, believing they are in zero-sum 

competition, prioritize speed and achieving break -

throughs over safety and ethical considerations. 145  Mo -

tivations are not solely about security; they are also 

heavily influenced by economic and status concerns, 146 

with countries vying for technological, economic and 

political leadership. This mix of motivations is entan -

gled with security concerns, as countries aim to defend 

their territory and enhance their international compet -

itiveness and reputation. The interactions are charac -

terized by a mix of competition and collaboration, in 

complex and shifting networks. 147 

Big Tech is also part of the agents involved, given 

that it operates transnationally, extending its reach 

and influence. 

Their operations involve moving data and services 

across international borders, making them important 

players in various regions. The transnational opera -

tions of Big Tech are fraught with tensions and chal -

lenges due to the diverse regulatory landscapes, as 

companies must comply with varying requirements 

in different regions. This is apparent in the way app 

stores control software on devices and in the way 

data labelling in some countries affects labour condi -

tions in others. 148  For instance, the EU General Data 

Protection Regulation sets stringent data protection 

standards that non-European companies must ad -

here to if they wish to operate in Europe, 149  demon -

strating the European Union’s ability to influence 

global data practices. This is an example of the “Brus -

sels Effect,” 150  wherein EU regulations can become 

de facto international standards, as companies adopt 

them to reduce costs across jurisdictions. 151 

These differences put in sharp relief the im -

portance of the UN Global Digital Compact. 

Figure 5.9  The artificial intelligence (AI) race today can be conceptualized as unfolding along a spectrum spanning 

innovation to arms 

Innovation race Geopolitical innovation race Arms race             

> Innovation race Geopolitical innovation race Arms race
> The innovation race involves multiple actors
> — including companies, states and research
> institutions  —  competing for technological
> leadership with more collaborative networks
> and looser relationships between actors.
> This race is motivated by a mix of economic
> and status gains, viewing AI as a key
> technology for broad socioeconomic
> advancement.
> This race is generally collaborative and
> competitive, with actors striving for
> innovation and the expected payoffs of
> a technological breakthrough shaping
> incentives.
> The geopolitical innovation race is a hybrid
> concept that combines elements of the innovation
> race and the arms race. It involves competition for
> technological leadership but also features a mix
> of competition and collaboration within national
> borders, or technopoles.
> This race is characterized by economic and status
> concerns intertwined with security and power
> interests, with AI viewed as a key technology
> for national security and power with limited
> interpretative openness.
> It is a race in which state actors play a crucial
> role in funding and regulating technological
> development. It can have both positive and
> negative outcomes.
> The arms race is characterized by intense,
> zero- sum competition, primarily among
> states, focused on military capabilities, with
> tightly coupled national networks.
> This race is driven by security concerns,
> where states seek to gain relative
> advantages and often treat technologies
> such as AI as a weapon or part of a weapon
> system. In this race there is continuous
> competition and investment, with actors
> envisioning (relative) advantages and seeing
> no scenario of possible collaboration.
> This race is criticized for potentially inducing
> researchers to prioritize speed over safety
> and ethics.
> Source: Schmid and others 2025. CHAPTER 5 — P OWER ,INFLUENCE AND CHOICE IN THE ALGORITHMIC AGE 1 5 3

Implementing provisions such as a continuous di -

alogue across jurisdictions on how to approach AI 

regulation — a dialogue informed by science and in 

which countries not at the forefront of AI supply have 

a chance to engage will be crucial. Uncertainties 

around the future of AI as a technology and sharp 

differences across jurisdictions may not make a uni -

versal set of regulations feasible, but everyone, firms 

included, stands to benefit from implementing these 

and other provisions of the Global Digital Compact 

(box 5.2). 

What are the possibilities for international action on AI? 

Whether one race among AI developers or many AI 

races among an evolving complex of countries and 

tech companies, a zero-sum mindset seems to per -

vade AI efforts. It is leaving many countries and peo -

ple behind. It misses opportunities for international 

cooperation that could promote and more equitably 

distribute shared benefits on the one hand and better 

manage shared risks on the other. Competition and 

cooperation can not only coexist; they can also work 

together to spur innovation and deliver better out -

comes for everyone. 

Low- and many middle-income countries will need 

support to get started on their own AI supply journey. 

Opportunities for cooperation exist, as in pooling 

access to AI-related infrastructure, sharing exper -

tise and, where possible, developing common policy 

positions —that can ease entry and distribution of de -

sired technologies while bolstering negotiating posi -

tions. AI also presents opportunities for Indigenous 

peoples by offering tools for language preservation, 

but there are concerns about data ownership, misrep -

resentation and the need for Indigenous participation 

in AI development to ensure cultural integrity and 

sovereignty (box 5.3). 

National policies on AI, nascent and evolving, will 

need to be flexible as the technology and its appli -

cations continue apace. Different countries have so 

far staked out positions that overlap in some ways 

and differ in others. Coverage of important regula -

tory domains is uneven within and across leading 

AI countries. 152  Varying national approaches can act 

as laboratories for experimentation and innova -

tion. Striking the right balance is key, as regulatory 

Box 5.2  The UN Global Digital Compact for addressing power imbalances and fostering inclusive artificial intelligence 

“A world of AI haves and have-nots would be a world of perpetual instability. We must never allow AI to 

stand for ‘advancing inequality.’ Only by preventing the emergence of fragmented AI spheres can we 

build a world where technology serves all humanity.” 

— UN Secretary- General António Guterres 

Signed by 193 countries at the Future Summit in September 2024, the UN Global Digital Compact brings together 

countries to strategize ways to make artificial intelligence (AI) safe, open and inclusive. It is anchored in the 2030 

Agenda for Sustainable Development, with the goal of ensuring that the benefits of AI are equitably distributed 

and do not leave behind developing countries, especially the least developed countries. It is further guided by the 

principles of international human rights to ensure that all human rights — including civil, political, economic, social and 

cultural rights  —  are respected and safeguarded online and offline. 

The compact articulates several key objectives that can help address power imbalances and ensure equitable ac -

cess and opportunities. This includes closing the digital divide for all and helping advance the Sustainable Develop -

ment Goals from education and health to inequality and governance. Those tasks are central in this effort to ensuring 

that no one is left behind, including youth and women innovators, as well as small and medium enterprise owners, 

who can meaningfully contribute to AI development. 

International AI governance, a joint responsibility of all countries, is a key part of the compact. The aim is to govern 

AI in the public interest while ensuring that its applications promote diverse cultures and languages rather than 

increase biases. The compact recognizes the critical contribution of governments, civil society, the private sector and 

other key partners in its successful implementation.  

> Source: UN Global Digital Compact. 1 5 4 HUMAN DEVELOPMENT REPORT 2025

differences carry the risk of incoherence that can sty -

mie innovation, obstruct technological diffusion and 

ignite races to the bottom. 

Regulatory differences can be an opportunity for 

international cooperation or coordination. 153  Inter -

national cooperation is even more important for 

countries with limited ability to influence technolo -

gy companies’ conduct within their own borders. The 

rationale for international collective action is clear at 

an intuitive level (digital technologies and their im -

pacts spill across borders, as do their multinational 

suppliers). But where and how (for instance, cooper -

ation or coordination) need to be specified with more 

precision. 

One recent analysis examined nine policy 

areas across data, compute and model govern -

ance. It concluded that international coordination 

would yield strong benefits in computer-provided 

oversight, content provenance, model evaluations 

(of which benchmarking, discussed in chapter 4, 

is part), incident monitoring and risk management 

protocols (table 5.3).  154  Consider the potential for 

AI audits to ensure that AI development adheres 

to social, cultural and ethical norms and broadly 

to the principles of human development (box 5.4). 

The benefits are lower or mixed for data privacy, 

data provenance, chip distribution and bias mitiga -

tion, as seen from a granular assessment, accord -

ing to four rationales for international cooperation: 

cross-border externalities, regulatory arbitrage, 

uneven governance and interoperability (see table 

5.3). Other governance research has highlighted in -

ternational cooperation opportunities in two broad 

categories: science and technology research, devel -

opment and diffusion, and international rulemak -

ing and enforcement. 155 

Box 5.3  More subtle manifestations of power emerge in artificial intelligence models’ behaviour 

Generative artificial intelligence (AI) systems are trained using around 90 percent English materials. 1 While one cannot 

directly tie training data to AI outputs, there is evidence that the predominance of English in training data matters. 2

In some large language models this is explicitly true, as non-English prompts are translated into and from English. In 

multilingual models (in which English is not explicitly used as a “pivot” language), AI appears to conceptualize words 

in ways that do not represent a specific language but align more closely with their English definitions. 3

One study found that when multilingual models are prompted to make emotional statements, they respond with 

the expected emotion of someone from the United States. 4 AI models also reflect other biases, 5 though not always in 

the same way. 6 Some evidence shows that biases demonstrated in English texts are reproduced in other languages. 7

Still, other studies are less definitive, showing that ChatGPT is more effective at accurately assessing a culture’s value 

in its native language than in English. 8

Large language models trained almost exclusively on English materials can pose risks for cultural misrepresentation 

and even exploitation. Incorporating Indigenous languages into mainstream generative AI platforms, such as OpenAI’s 

ChatGPT and Whisper, raises concerns over ownership of data produced by or about Indigenous peoples. 9 Technol -

ogy companies often use data without the consent, consultation or compensation of Indigenous peoples, 10  mirroring 

other extractivist practices. 11  In accordance with the 2020 Los Pinos Declaration, which states “Nothing for us without 

us,” 12  Indigenous peoples’ participation in new technology development is essential for enhancing their agency. 

Despite the risks, AI systems developed and codeveloped by Indigenous peoples can be valuable tools for preserv -

ing cultures and languages. With half the world’s roughly 7,000 languages predicted to be seriously endangered or 

extinct by 2100, 13  AI can be a valuable tool for language documentation and education. Te Hiku Media, a New Zealand 

Indigenous nongovernmental organization dedicated to Māori language revitalization, has developed an app to allow 

users to upload audio in Māori, 14  which will train AI models used in chatbots and language learning apps. 15  Such AI 

tools enable Māori speakers to access information that previously required foreign language knowledge. Importantly, 

this case demonstrates that such tools can be developed with processes that respect Indigenous peoples’ data.                                       

> Notes
> 1. Achiam and others 2023; Cao and others 2023; Touvron and others 2023. 2. Piir 2023. 3. Caliskan, Bryson and Narayanan 2017; Wendler
> and others 2024. 4. Havaldar and others 2023. 5. Abid, Farooqi and Zou 2021; Caliskan, Bryson and Narayanan 2017; Kaplan and others
> 2024; Lippens 2024; Nadeem, Bethke and Reddy 2020; Salinas, Haim and Nyarko 2024. 6. Huang and Xiong 2023; Mexico 2020. 7. Haval -
> dar and others 2023. 8. Cao and others 2023. 9. Chandran 2023; Kirkby-McLeod 2023. 10. Te Hiku Media 2025. 11. Pinhanez and others
> 2023. 12. Mexico 2020. 13. Llanes- Ortiz 2023. 14. Korero Maori 2025; Te Hiku Media 2025. 15. ITU 2022. CHAPTER 5 — P OWER ,INFLUENCE AND CHOICE IN THE ALGORITHMIC AGE 1 5 5

We are not starting from scratch. International AI 

initiatives have sprung up  —for example, under the 

auspices of the Global Partnership on AI, the Group of 

Seven (G7), the International Organization for Stand -

ardization, the International Telecommunication 

Union, the Organisation for Economic Co - operation 

Table 5.3  Where there is a stronger case for international policy coordination on artificial intelligence                                                     

> Category Subcategory
> Cross- border
> externalities
> Regulatory
> arbitrage
> Uneven
> governance Interoperability Overall
> Data governance Data privacy Mixed Low Low Low Low
> Data provenance High High Low Mixed Mixed
> Compute governance Chip distribution Mixed Mixed High Low Mixed
> Compute provider oversight High High High High High
> Model governance Bias mitigation Low Low Mixed Low Low
> Content provenance Mixed Mixed High High High
> Model evaluations High High Mixed High High
> Incident monitoring High Mixed High High High
> Risk management protocols High High High Mixed High
> Source: Dennis 2024.

Box 5.4  The potential for artificial intelligence audit protocols 

International Panel on the Information Environment, Scientific Panel on Global Standards for AI Audits 

As artificial intelligence (AI) systems become increasingly ubiquitous across all sectors of society, the need for robust auditing 

and oversight mechanisms has become more pressing. 

Audits offer a way to assess whether the development, deployment and operations of an AI system align with acceptable 

technical performance, as well as social, cultural and ethical norms and values. Audits can be a critical tool for ensuring that 

these powerful systems are aligned with the principles of human development — promoting individual freedoms, expanding 

choices and enhancing the dignity and worth of all people. By rigorously evaluating the development, deployment, manage -

ment and operations of AI systems, audits can help uncover whether a system engenders individual and collective harms that 

could undermine core human development objectives. They can help ensure that technical innovation does not pose undue 

risks to human life or people, guaranteeing that the benefits of AI are equitably distributed and that its risks are mitigated. 

At the individual level audits can ensure that AI does not violate fundamental rights and freedoms. Audits assess these 

systems for fairness, transparency and accountability, protecting individuals from discrimination, exploitation and infringement 

on their human rights. 

Moreover, AI audits can illuminate the broader societal impacts of these technologies, shedding light on how they may 

inadvertently exacerbate existing discrimination or create new forms of marginalization. By examining the data provenance 

and supply chains that feed into AI systems, auditors can uncover data colonialism, labour exploitation and environmental 

degradation — all of which have profound implications for human development. 

The International Panel on the Information Environment’s Scientific Panel on Global Standards for AI Audits has published 

two reports to inform policymakers as they develop standards for AI auditing. The first covers existing audit practices and 

highlights the strengths and weaknesses of different systems currently in operation around the world. 1 The second outlines 

what a global audit protocol might look like. 2 It gives detailed recommendations for creating a protocol around the auditor, 

audit object, criteria and evidence, methodology and postaudit activities. 

By fostering transparency, accountability and stakeholder engagement, audits can shape AI development in ways that 

empower individuals, strengthen communities and advance the broader human development agenda.    

> Notes
> 1. IPIE 2024. 2. IPIE 2025. 1 5 6 HUMAN DEVELOPMENT REPORT 2025

and Development (OECD) and the United Nations 

— covering the gamut of data, compute and model 

governance. 156 

Some have suggested that centralized models 

of governance may not be best suited for a rapidly 

evolving technology like AI. Instead, they propose 

that a distributed network of networks can address 

the challenges and opportunities of AI governance 

more effectively than a centralized system. 157  This ap -

proach, modelled on the internet, involves a distrib -

uted network of governments, industry, civil society 

and academia addressing AI governance complex -

ities. The G7 exemplifies this approach, serving as a 

central node in broader governance efforts. Japan’s 

“networked AI” study inspired the OECD’s AI ethics 

recommendations, endorsed by 44 countries. 158  The 

Global Partnership on AI evolved into an OECD part -

nership, reinforcing collaborative governance. The 

Hiroshima AI Process led to a code of conduct and a 

corporate adherence monitoring function. 

In sum, opportunities for international coopera -

tion on AI exist, not necessarily for everything, but 

certainly for several specific and important areas. 

In some of them, initiatives are already under way 

using existing international fora, processes and in -

stitutions. New arrangements for AI may be needed, 

drawing inspiration and lessons from international 

cooperation —for example, in global health and cli -

mate change. We may even need to go beyond cen -

tralized arrangements of the past to more distributed 

and networked architectures that provide flexibility 

in the face of AI’s rapid headline-grabbing advanc -

es. Trust, flexibility, trial-and-error —all will be key 

in carving out an essential and valuable space for co -

operation amid a flurry of AI races to generate shared 

sets of standards and safeguards for healthy competi -

tion to steer innovation towards human development 

and to ensure that everyone has a shot at participat -

ing fruitfully in this new AI era. 

AI regulation may place new, unique demands on 

the institutions and agreements underpinning inter -

national cooperation. Existing institutions and pro -

cesses are a good foundation to build on, anchored in 

the Global Digital Compact. CHAPTER  5 — P OWER , INFLUENCE  AND  CHOICE  IN  THE  ALGORITHMIC  AGE  1 5 7 

> SPOTLIGHT 5.1

# Threats to democratic reason in a high -choice 

# information environment 

Åsa Wikforss,  Professor of Theoretical Philosophy, Stockholm University 

Democracy faces unique epistemic challenges in 

today’s digitalized information environment, re -

lating specifically to the capacity to make ration -

al, knowledge-based decisions. Democracies have 

unique epistemic strengths that allow them to solve 

complex problems and build better societies. 1 Dem -

ocratic governance exhibits a form of collective 

intelligence, a “democratic reason,” that is not ex -

hibited by nondemocratic modes of governance. 

While there is great diversity among the world’s 

democracies, including low- or high-functioning 

electoral and liberal democracies, a distinctive trait 

in all of them is that they exhibit certain epistemic 

strengths. 2

The digital information environment poses a set 

of distinct threats to democratic reason. In a world 

facing a set of interconnected crises, epistemi -

cally well-functioning democracies can support 

knowledge-based and rational policymaking. More -

over, the weakening of democratic reason poses a 

danger to democracy itself. 

The value of democracy 

Democracy has not only an important procedur -

al value but also an important substantive value, 

relating to the actual outcomes of democrat -

ic decisionmaking. 3 Empirical studies show that 

democracies tend to produce outcomes that are 

generally considered good: they tend to avoid ca -

lamities (such as famines and wars), enhance 

human wellbeing along several dimensions (for 

instance health, life expectancy, equality and hap -

piness), provide better protections for the environ -

ment and are better at dealing with crises (such as 

a pandemic). 4

The epistemic argument for democracy is that 

democratic decisionmaking is uniquely equipped 

to be rational and knowledge based. Democracies 

have these epistemic strengths due to the ability to 

harness collective intelligence through two essential 

mechanisms: majority rule and deliberation. Major -

ity rule enables democracies to harness the wisdom 

of crowds, and deliberative democracy facilitates 

public reasoning through respectful, open dialogues 

to reach consensus. For instance, in a representative 

democracy, while parliament plays a central role as 

a deliberative forum, an open and fair public debate 

is also essential, both when it comes to providing 

knowledge-based decisions and for securing the le -

gitimacy of these decisions. 5

The main critic of the epistemic argument for de -

mocracy is that it relies on assumptions that may 

not be true. For example, the assumption that vot -

ers have knowledge about politically relevant facts, 

such as climate change, existing policies or con -

sequences of prior political decisions 6. Naturally, 

voting behaviour is a reflection not simply of the 

factual beliefs that voters hold but also of their val -

ues. Nevertheless, voters’ factual beliefs are a key 

psychological factor underlying their behaviour, 

and if voters are ignorant or mistaken in these fac -

tual beliefs, it will have consequences for how well 

democracy works. To what extent does the infor -

mation environment pose a threat to the epistem -

ic strengths of democracy? How does this affect 

the capacity of democracies to address key global 

challenges? 

A high- choice information environment 

Scholars describe the changed information envi -

ronment as a transformation from a low-choice 

to a high- choice information environment. This 

has consequences for the use of and trust in 

media. People’s individual motivations and abilities 

become key determinants in what information they 

consume, 7 further increasing the risk of biases. The 1 5 8 HUMAN DEVELOPMENT REPORT 2025 

demand for information that merely confirms (rath -

er than informs) people’s views affects their trust 

and use of established news media. The design of 

social media platforms, where algorithms promote 

content that captures people’s attention, potential -

ly compounds this challenge. The complex interac -

tion between empirical beliefs and attitudes of trust 

can exacerbate polarization of media trust, often 

along political fault lines. Polarized trust in turn 

causes factual belief polarization, where political 

opponents hold opposing beliefs on empirical facts. 

Research shows that factual belief polarization can 

occur simply as a result of selective sharing patterns 

in digital ecosystems. 8 Similar polarization effects 

can be seen when it comes to trust in science. 9 Par -

tisanship therefore both drives media trust and is 

driven by media use, leading to an increasingly par -

tisan media landscape. 

It should be stressed that misinformation and 

disinformation not only lead people to hold false 

beliefs about the world but also undermine our ca -

pacity to critically assess further information that 

we receive. Evaluation of the plausibility of a piece 

of information is always carried out against the 

background of our prior beliefs. If these beliefs, in 

turn, are the result of unreliable sources, the re -

sulting assessments will be equally unreliable. For 

instance, for someone who has been fed disinfor -

mation about climate change, additional disinfor -

mation will seem plausible. Indeed, given a person’s 

acquired, false background beliefs, it may even be 

rational (from the subject’s point of view) to reject 

the testimony provided by expert consensus on an -

thropogenic climate change. 10 

The role of prior beliefs in assessing information 

highlights the fact that efforts to counteract disinfor -

mation and misinformation at the individual level, 

such as debunking, while important, have limita -

tions. 11  In a polluted information landscape people’s 

critical thinking capacities may be compromised. 12 

Efforts to strengthen these critical thinking skills 

will have to be combined with initiatives to improve 

the quality of the information environment —for in -

stance, by having social media platforms amplify re -

liable information, making it easier for people to fact 

check and track truth. In a recent survey a majority of 

experts stressed the importance of supporting free 

and independent media. 13 

Harms to democratic reason 

The transformation of the information environment 

has consequences for central mechanisms under -

lying the epistemic potential of democracy: aggrega -

tion and deliberation. In a high- choice information 

environment, with large amounts of unreliable in -

formation and where biases and background beliefs 

determine both the assessment of new information 

and the choice of who to trust, there is a very real risk 

that large groups of individuals will do worse than 

chance. If the evidence presented to a population is 

systematically misleading, the majority of people will 

be systematically misled. If so, a central condition for 

Condorcet’s jury theorem will not be met. Moreover, 

systematic disinformation in combination with sys -

tematic biases, reinforced by increased partisanship, 

means that errors will not be random and may not 

cancel out. 14 

The high- choice information environment also 

poses risks to the deliberative dimension of de -

mocracy. Policy disagreements always have two 

potential sources: disagreement on values and dis -

agreement on the facts. People may disagree on a 

given climate policy because they disagree on the 

value of mitigating climate change, in particular 

when such mitigation conflicts with other things 

they value (such as lower gas prices). But they may 

also disagree on the underlying climate science. 

A central function of democratic deliberation is 

to assess the arguments on either side, relating to 

both facts and values, exposing poor reasoning and 

weeding out falsehoods. Under ideal circumstances 

the end result is some form of consensus. But even 

when consensus is not achieved, deliberation al -

lows for a peaceful management of disagreement, 

helping people understand different points of view 

and paving the way for political compromise. The 

idea that well-structured deliberation can be effec -

tive is borne out by the application of deliberative 

mini-publics across the world, where a representa -

tive assembly of citizens deliberates on topics rele -

vant to policymaking. 15  Examples include citizens’ 

assemblies both at the local level (involving delib -

erations about local budget decisions, for example) 

and at the national and transnational levels, where 

topics such as climate policy, constitutional reform 

and a variety of social issues have been discussed. CHAPTER  5 — P OWER , INFLUENCE  AND  CHOICE  IN  THE  ALGORITHMIC  AGE  1 5 9 

Mini-publics are designed to increase public par -

ticipation and have been shown to counteract be -

lief polarization and strengthen knowledge-based 

decisionmaking. Similar results can be seen from 

experimental work on deliberative polling, which 

involves examining how people’s political views are 

affected by group deliberations where trained mod -

erators and dialogue with experts are included. 16 

In the new information environment, however, 

reaching consensus through public deliberation is 

increasingly difficult, considering that a distinc -

tive feature of the current era is increasing disa -

greement on facts and the interpretation of data. 17 

When deliberation is based on false and mislead -

ing information, the “reasons” provided will not be 

truth- conducive, and the possibility of reaching a 

knowledge-based consensus is compromised. This 

also harms the epistemic function of deliberation, 

when it is weaponized to generate epistemic cyni -

cism, causing people to devalue contributions from 

reliable sources. 18  Relatedly, politically polarized 

trust in media and science poses a serious obstacle 

to finding a common ground of empirical facts. And 

increasing, unbridgeable factual disagreements, in 

turn, will cause increasing, unbridgeable political 

disagreements. 

This is related to concerns about knowledge re -

sistance, the tendency to resist available knowl -

edge. Knowledge resistance involves a form of 

response to available evidence, where belief for -

mation is driven by desires rather than by the evi -

dence. 19  Thus, in the case of tribal thinking, there is 

the desire to hold on to beliefs that have become a 

mark of identity of the group  —for instance, beliefs 

about vaccines or about genetically modified organ -

isms. In such a situation, the fear of being exclud -

ed from the group causes people to resist available 

evidence that the belief held is false. A prominent 

psychological mechanism driving knowledge re -

sistance is motivated reasoning, the tendency of 

individuals to unconsciously conform assessment 

of factual information to some goal collateral to as -

sessing its truth. In the case of politically motivat -

ed reasoning, involved in tribal thinking, evidence 

is assessed based on its congeniality to the position 

associated with our particular political or cultural 

affiliations. 20  Thus, evidence against the belief held 

by the group is undermined. 

Knowledge resistance interacts with the high-

choice information environment in complex 

ways. Rationalizing a cherished belief in the face 

of counter evidence often involves trying to find 

reasons not to trust the relevant source of the ev -

idence. For instance, when there is (near) expert 

consensus, as in the case of anthropogenic cli -

mate change, resisting the expert testimony typi -

cally involves adopting a conspiracy theory. 21  The 

availability of conspiracy theories in the digital in -

formation environment thus serves to strengthen 

the type of motivated reasoning involved in science 

denialism. 

Conclusion 

In sum, the new high- choice information envi -

ronment, engendered by the digitalization of in -

formation, poses a serious threat to the epistemic 

strengths of democracy. First, it undermines the 

conditions required for truth to emerge from the 

aggregation of opinions. Second, it weakens dem -

ocratic deliberation and the possibility of resolving 

disagreements by appealing to evidence and ra -

tional arguments. With the emergence of genera -

tive artificial intelligence tools, systems capable of 

creating texts, images and videos with astonishing 

speed and facility, scholars worry that the quality 

of the information environment could deteriorate 

further. 22 

Much work is currently being done to understand 

and address these epistemic threats to democra -

cy, but there are many barriers to such research. 23 

A central problem, among others, is poor access 

to data; legislation demanding greater transparen -

cy on the part of technology platforms is essential, 

such as the EU Digital Services Act. Upholding ac -

ademic freedom for information scholars is key for 

the future of the research field. 1 6 0 HUMAN DEVELOPMENT REPORT 2025 

NOTES 

1 See especially Goodin and Spiekermann (2018) and Landemore (2012). 

2 See the classification employed by the V-Dem Institute, where five high-

level principles of democracy are distinguished: electoral, liberal, partici -

patory, deliberative and egalitarian (V-Dem Institute 2025). 

3 For a clear articulation of this reasoning, see Landemore (2012). 

4 Lundstedt and others 2022. 

5 See, for instance, Habermas (1984) and Landemore (2012). 

6 Brennan 2016. 

7 Aelst 2017; Strömbäck and others 2022. 

8 Bowen, Dmitriev and Galperti 2023. 

9 For a discussion of polarization and trust in science, see Rekker (2021). 

10  Glüer and Wikforss 2022; Levy 2021. 

11  For a useful guide to interventions against misinformation on the indi -

vidual level, see Kozyreva and others (2024). 

12  Wikforss, Kendeou and Robinson 2019. 

13  International Panel on the Information Environment 2024. 

14  Goodin and Spiekermann 2018. 

15  See, for instance, Escobar and Elstub (2017), Participedia (2025) and Smith 

(2009). 

16  See Stanford Deliberative Democracy Lab, where more than 150 delibera -

tive polling experiments have been run in more than 50 countries. 

17  Rich 2018. 

18  McKay and Tenove 2021. 

19  Glüer and Wikforss 2022. 

20  Kahan 2015. 

21  Lewandowsky, Gignac and Oberauer 2013. 

22  International Panel on the Information Environment 2024. 

23  International Panel on the Information Environment 2024. 1 61 

# C H A P T E R 

# 6

# Reimagining choices: 

# Towards artificial 

# intelligence– 

# augmented human 

# development 1 6 2 HUMAN DEVELOPMENT REPORT 2025 

> CHAPTER 6

# Reimagining choices: Towards artificial intelligence– 

# augmented human development 

# Seizing the opportunities of AI demands more than 

# technological innovation. Bridging micro- and macro-

# level evidence, this chapter proposes an actionable 

# framework for artificial intelligence (AI)–augmented 

# human development that is robust to fast-paced 

# technological change. It outlines three directions for 

# action: building a complementarity economy, driving 

# innovation with intent and investing in capabilities 

# that count. Together, these directions aim to inspire 

# context-specific choices so that countries can 

# harness AI to expand opportunities, enhance people’s 

# capabilities and deliver improvements in people’s lives. CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 6 3 

Scientific and technological progress propel devel -

opment 1 while changing patterns of economic op -

portunity and redrawing inequalities. 2 As artificial 

intelligence (AI) moves from a niche technology to 

a cornerstone of people’s lives across multiple do -

mains, how can we seize its potential to advance 

human development? 3

The answer depends on more than just algorithms. 

We cannot code away complex social problems or de -

ploy AI based on wishful and simplistic approaches. 4

New fault lines may have less to do with the dichoto -

my between humans and AI and more to do with the 

difference between humans capable of leveraging 

AI versus humans without those capabilities. Rather 

than trying to predict where those fault lines lie, this 

chapter explores choices to shape our future with AI 

to advance human development. 

The chapter bridges micro- and macro-level evi -

dence and analysis to put forward a framework for 

AI-augmented human development. Detailed poli -

cies and interventions need to attend to both the con -

text in which AI is deployed and its affordances, 5 so 

the chapter outlines three strategic directions to in -

form more detailed actions: building a complemen -

tarity economy, driving innovation with intent and 

investing in capabilities that count. These three direc -

tions aim to inspire choices for AI-augmented human 

development that unleash a virtuous cycle between 

AI innovation and deployment and outcomes that im -

prove people’s lives. 

• Building a complementarity economy.  Choices that 

build a complementarity economy include those that 

make AI pro-worker through institutions and policies 

that empower workers to use AI to augment what 

they do while limiting AI curbs on worker agency. 

Those institutions structure incentives and regula -

tions that foster the complementarity between labour 

and AI. 6 Doing so implies recognizing AI’s compara -

tive advantages over earlier digital technologies—its 

adaptability and generative capacities, as well its 

widespread accessibility and relative ease of use 

through features such as natural language process -

ing, which provide unique and novel opportunities. 

But it also implies understanding what AI can -

not do—or cannot do better than either humans 

or other digital technologies. A complementarity 

economy hinges in part on avoiding AI deployed 

as “so-so technology” that merely mimics what 

people do—automating work but resulting in job 

losses without delivering broader productivity 

gains. 7 Instead, AI designed to augment human 

work can enhance productivity, support economic 

diversification and speed up technological pro -

gress. 8 AI’s potential to create positive spillovers 

across economies depends on networks compris -

ing humans and AI—AI alone will not realize that 

potential because its adaptation to unique and 

varied contexts often requires human steering and 

evaluation (chapter 1). Where access to advanced 

expertise is limited, AI-powered tools can bridge 

gaps and enable workers to perform higher-value 

tasks. 9 This may enhance economic opportunities, 

including for those historically left behind. 10 

Because AI runs on existing physical infrastruc -

ture, the transition to a complementarity economy 

may not require extensive new physical invest -

ment, as long as electricity and internet access (in -

cluding over time broadband and cloud computing 

services) is ensured (chapter 1, spotlight 6.2). 

• Driving innovation with intent.  Choices should 

be geared to harness AI’s potential to accelerate 

science and technological innovation, not by auto -

mating creative processes but by augmenting them, 

building on the distinct complementarity between 

humans and AI. 11  This includes leveraging AI to 

expand what people can do as we continue to seek 

to fulfil those fundamental human aspirations to 

understand and create, reflected in activities rang -

ing from basic science to the arts. Thus, AI should 

not be measured solely by its potential to replicate 

what humans can do to improve automation but 

also by its ability to enhance human capabilities. 

That should inspire research and technological ef -

forts that drive the evolution of AI itself. 12  Adjusting 

economic incentives and expanding AI bench -

marks beyond performance and safety to include 

how AI can advance human development can help 

align socially desirable and privately profitable 

innovations. For example, AI can accelerate efforts 

to tackle planetary challenges, such as biodiversity 

loss and climate change (spotlight 6.1). 13  Crucially, 

human agency must remain central to AI design, 

development and deployment. 14 

• Investing in capabilities that count.  Choices should 

be geared towards both investing in human capa -

bilities and leveraging AI to enhance access and 1 6 4 HUMAN DEVELOPMENT REPORT 2025 

quality of education and health service delivery. 

AI’s flexibility and adaptability should be lever -

aged to personalize education and healthcare in 

different development settings while attending to 

risks and concerns with bias, privacy and equity. 15 

By tailoring learning or expanding healthcare, AI 

can also generate demand for complementary 

human labour. 

When integrated into education, AI should 

not be used as a crutch by teachers or students 

but as a companion to unleash new ways of 

learning that allow us to move the focus beyond 

increasing years of schooling (quantity) towards 

achieving basic numeracy and literacy skills and 

developing critical, creative and relational think -

ing (quality). This involves deploying AI to scale 

up interventions known to enhance education 

outcomes, such as customized learning, rather 

than deploying it for its own sake. In healthcare 

AI should be deployed to complement healthcare 

expertise—particularly when such experience is 

scarce—empowering healthcare workers to do 

more. 16  Healthcare systems and organizations 

should ensure safe and transparent integration 

of AI technologies into services—strengthening 

both institutional and frontline providers’ capac -

ity to effectively use these new tools while clearly 

communicating to patients how AI is employed in 

clinical decisionmaking. Because the unintended 

side effects of AI in health services may change 

over time, monitoring AI biases and health 

inequalities needs to be seen as a continuous 

process. 17 

The pursuit of these three directions will have 

to take account of unfolding structural shifts in the 

global economy 18  that are reshaping development 

opportunities (chapter 1). AI holds promise for ex -

panding development trajectories, but it could also 

amplify risks if it becomes a source of fragmenta -

tion that compounds geopolitical tensions and reg -

ulatory divergence, forcing countries to align with 

one approach or another, undermining cross-bor -

der cooperation. Global disparities in the AI supply 

chain would then deepen inequalities across coun -

tries, especially if low and medium Human Develop -

ment Index (HDI) countries are excluded from the 

supply side of AI (chapter 5). Pre-existing develop -

ment gaps in electricity and internet access, and in 

basic learning capabilities, can be major barriers to 

seizing the opportunities of AI-augmented human 

development. 

# “By reimagining choices, we can shift the 

conversation from if and when AI can replace 

humans to how AI can enhance human 

potential and foster human development 

What matters is not predicting what will happen 

but making choices so AI advances human develop -

ment. AI is distinctive in its economywide applica -

bility, 19  swift diffusion 20  and growing opportunities 

for levelling the playing field in accessing advanced 

expertise (chapter 1). Seizing these opportuni -

ties depends on how AI is designed and deployed, 

as well as the business models and incentives that 

shape its use. The role of AI in shaping our socie -

ties depends on choices. By reimagining choices, 

we can shift the conversation from if and when AI 

can replace humans to how AI can enhance human 

development. 

## Building a complementarity economy 

## to expand development frontiers 

History has shown that occupations evolve and that 

new occupations emerge as new technologies diffuse 

across the economy. 21  But the speed and scope of 

AI integration into our economies 22  may pose novel 

challenges and opportunities. AI does not have to 

be a zero-sum game that pits humans against ma -

chines. Policy choices can shape a “complementarity 

economy,” where AI amplifies the work humans are 

already doing, 23  supports inclusion in labour mar -

kets 24  and breaks open entirely new types of indus -

tries, jobs and tasks. 25  Realizing these gains requires 

understanding how technological change inter -

acts with underlying labour market and economic 

structures and how AI differs from previous digital 

technologies. 

In a complementarity economy, automation— 

AI replacing human work—and augmentation—AI 

boosting productivity and driving creation of new 

types of roles for human workers—happen in parallel. 

Policies that tilt the balance towards augmentation 

are key while supporting people as they navigate dis -

ruptions in the world of work. CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 6 5 

People expect AI to change existing 

occupations and create new ones 

For many of the reasons outlined in chapter 1, new 

economic opportunities with AI may outweigh au -

tomation and replacement, if labour-enhancing in -

centives and policies are put in place. Data on job 

exposure to AI seem to confirm this (figure 6.1). 

Across HDI groups the augmentation exposure of cur -

rent employment is higher than the automation expo -

sure. Female employment shows higher job exposure 

to AI augmentation than male employment. 26  Howev -

er, the largest share of jobs exposed to AI falls into “a 

big unknown,” with potential for both augmentation 

and automation. Whether these roles will ultimately 

be augmented or automated is contingent on future 

technological progress and the choices made in re -

sponse to those changes—presenting a major oppor -

tunity to shape the future of work in ways that could 

benefit workers and spur innovation and productivity. 

However, exposure does not necessarily imply that 

people are using AI for work. 27  Our survey points to -

wards an expected increase in use of AI tools for 

work, even though a substantial share of people are 

still not using them (figure 6.2). Men and people with 

greater levels of education report higher use of AI for 

work—across all HDI groups, highlighting the need 

for targeted policies to ensure that women and peo -

ple with lower levels of education also benefit from 

labour-enhancing AI opportunities. 

According to our survey, about half of respondents 

expect AI to lead to job automation. But an even larg -

er share, 60 percent, expect new opportunities for 

job augmentation to arise. People in low and medium 

HDI countries have higher expectations of shifts in 

the labour market than people in very high HDI coun -

tries (figure 6.3). In low and medium HDI countries 

70 percent of respondents expect that AI will help 

them increase their productivity at work, and 64 per -

cent expect that AI will help them find new job roles 

that currently do not exist, while 57 percent expect 

that their current jobs will be replaced due to AI. 

AI’s ability to carry out work once thought of as 

exclusively in the realm of humans—such as com -

plex cognitive or creative tasks—is now challenging 

the belief that automation technology affects mainly 

lower-skill workers engaged in routine tasks. 28  How -

ever, our survey results show that while respondents 

expect automation to take place across occupations, 

they also expect augmentation to occur (figures 6.4 

and 6.5). Almost 40 percent of clerical workers—an 

occupation that is typically portrayed as being at risk 

of AI automation—expect that AI will lead to trans -

formational change of their jobs and perceive both 

Figure 6.1  Across Human Development Index (HDI) groups the largest share of jobs exposed to artificial 

intelligence (AI) falls into “a big unknown”          

> 0510 15 20 25 30 35 40 Very high High Medium Low Automation Augmentation “Big unknown”

Share of total employment exposed to AI (%) 2022 HDI group  

> Source: Human Development Report Office using data from the International Labour Organization Harmonized Microdata Repository and the method
> described in Gmyrek, Berg and Bescond (2023). 1 6 6 HUMAN DEVELOPMENT REPORT 2025

Figure 6.2  Men and people with greater levels of education report higher use of artificial intelligence (AI) for work— 

across all Human Development Index groups 

0 5 10 15 20 25 30 35 Completed university or more Completed secondary Some secondary Completed primary or less Male Female Use AI tool for work (%) Education level 

Note:  Based on pooled data for 21 countries. Use of AI for work refers to the responses to the question “In the past 30 days, have you interacted with 

artificial intelligence, such as chatbots, in any of the following ways? Work-related tools or software.” 

Source:  Human Development Report Office based on the United Nations Development Programme Survey on AI and Human Development. 

Figure 6.3  More respondents in low and medium Human Development Index (HDI) countries expect labour 

market changes—through augmentation, automation and productivity boosts—with artificial intelligence 

High HDI Low or medium HDI Very high HDI 010 20 30 40 50 60 70 80 Share of population (%) 

Automation 

(Current job significantly changed or replaced) 57.5 40.0 56.9 010 20 30 40 50 60 70 80 Share of population (%) 

Augmentation 

(Find new job roles that currently do not exist) 68.6 51.6 63.8 010 20 30 40 50 60 70 80 Share of population (%) 

Productivity boost 

(Will increase productivity at work) 69.7 54.0 69.5 

Note:  Based on pooled data for 21 countries. Expected effects of AI on jobs refer to the percentage of respondents who answered “very likely” or 

“likely” to the questions “Your current job will be significantly changed or replaced by AI” (automation), “AI will help you find new job roles that cur -

rently do not exist” (augmentation), and “AI will increase your productivity at work” (productivity boost), as well as 50 percent of the respondents who 

answered “neutral.” 

Source:  Human Development Report Office based on the United Nations Development Programme Survey on AI and Human Development. CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 6 7 

augmentation opportunities and automation risks) 

(figure 6.5). Overall, 4 of 10 respondents expect to be 

affected by both augmentation and automation, so 

while they believe that their current jobs will be sub -

stantially changed by AI, they also expect that AI will 

create new job roles that do not currently exist. 

New economic possibility frontiers— 

avoiding “so-so” technology 

Despite rapidly expanding AI use, macro-level pro -

ductivity impacts remain elusive: 29  today, AI seems to 

be “everywhere but in the productivity statistics.” 30 

There are several reasons why this might be the case. 

Estimates of job exposure to AI vary substantially, 31 

the translation from AI job exposure to AI use and 

from AI use to productivity impacts is not straight -

forward and current systems of national accounting 

have a hard time capturing quality improvements 

from technologies, as well as the effects of services, 

especially digitally delivered services, which account 

for an increasing share of employment and value 

added. 32  So how to assess the economic potential of 

AI? Rather than making predictions, examining the 

mechanisms through which it can drive change and 

identifying where these effects might emerge provide 

a more nuanced understanding that can support bet -

ter-informed decisionmaking (box 6.1). 33 

Unlike technologies narrowly focused on a specific 

activity or task, AI—and particularly generative AI—is 

more akin to a general purpose technology in that it 

has economywide applicability 34  and may affect more 

and more tasks. 35  Multimodality, adaptability and 

generalizability are key features of novel AI systems, 

and use cases already range from economics research 

assistance 36  to medical image analysis for early dis -

ease detection 37  and from customer service support 38 

to helping with novels or screenplays. 39 

AI presents multiple opportunities for augmenting 

what people are already doing at work. It can help 

workers complete tasks faster and at higher quality, 40 

boost their creativity 41  and speed up learning process -

es, raising productivity for newer recruits and those 

with lower performance. 42  Beyond the direct effects 

associated with more productive execution of tasks 

currently done by workers, the more far-reaching 

economic potential of AI may lie in its second- and 

third-order effects—in its potential for spillovers and 

its integration with technological progress. 43 

These economic spillovers and dynamic effects 

can drive productivity gains beyond those achieved 

through pre-AI digital tools, potentially foster -

ing novel industries and value chains, if regulato -

ry frameworks ensure fair competition and prevent 

rent-seeking behaviour. 44  Without such safeguards 

market concentration may stifle innovation, 45  inflate 

prices and concentrate productivity gains among a 

few dominant players. If AI functions primarily as a 

“so-so technology” 46 —delivering cost savings for in -

dividual firms without driving broader productivity 

gains—its potential to expand economic opportuni -

ties and enhance innovation may be limited. 47 

Prioritizing AI as an enabler for innovation and 

intelligence augmentation is likely to yield far more 

benefits than focusing on automation alone. 48  Bal -

ancing policies that caution the use of AI with those 

Figure 6.4  Across occupations and Human Development 

Index levels, respondents expect that artificial intelligence 

will both automate and augment their work — with higher 

expectations of augmentation 

Expected automation (%) 0 80 100 Expected augmentation (%) 100 80 20 40 60 60 40 20 0  

> Note: Based on pooled data for 21 countries. Each dot represents the per -
> centages of respondents in an occupation group in a country who expect au -
> tomation and augmentation from AI to affect their occupation. The following
> occupational groups are used: professional/higher administrative, skilled, un -
> skilled/semi-skilled, services, clerical, farm and other. The shaded area repre -
> sents a higher share of respondents expecting augmentation than automation.
> Source: Human Development Report Office based on data from the United
> Nations Development Programme Survey on AI and Human Development. 1 6 8 HUMAN DEVELOPMENT REPORT 2025

Figure 6.5  Across occupations respondents expect transformational change to their work         

> 30 32 34 36 38 40 42 44 46 11 12 13 14 15

Expected replacement (share of respondents within group) Expected transformational change (share of respondents within group) 

Clerical Other Farm Service (including sales) Skilled Professional/higher administrative Unskilled/ semi-skilled   

> Note: Based on pooled data for 21 countries. Each point represents the expected replacement (automation with no augmentation) and transforma -
> tional (automation and augmentation) change for an occupation group.
> Source: Human Development Report Office based on the United Nations Development Programme Survey on AI and Human Development.

Box 6.1  Assessing artificial intelligence’s productivity effects 

Artificial intelligence (AI) is expected to yield considerable productivity impacts, but empirical findings remain inconclu -

sive. 1 The magnitude, timing and distribution of productivity effects are uncertain and depend heavily on the methodol -

ogy and assumptions. 2 The US National Academies of Sciences, Engineering and Medicine has proposed a framework 

for assessing AI’s productivity effects by identifying key factors that may shape its impact. 3 The factors provide a helpful 

overview of the conditions that influence AI adoption, the channels through which AI can affect productivity and the 

potential barriers to realizing its full economic impact. 

They include: 

• Share of the economy in which the technology can be applied and size of the productivity effect in those applica -

tions.  This follows from Hulten’s theorem, which shows that in well-functioning economies an increase in total 

factor productivity in one industry will change the overall output in an economy in proportion to the industry’s 

share of total sales. 4 AI is seen as a general purpose technology; it has economywide applicability beyond specific 

industries. 5 The productivity effects in particular industries, by contrast, depend on whether AI primarily replaces 

humans or augments what humans are doing. 6

• Complements and bottlenecks.  Deploying a new technology without considering parallel investment would likely 

yield disappointing results. Workers need complementary skills, 7 and firms and organizations may need to adjust 

workflows to fully leverage AI. Digital infrastructure is critical, and targeted investment may be needed in many 

regions. 8 Furthermore, governance frameworks might require time to adjust to new technologies. Informal institu -

tions, such as those for social cohesion and trust, can also act as complements or bottlenecks to realizing the 

technology’s potential. 9

• Time lags and measurement.  Both benefits and costs from technological innovation may be hard to quantify, 

especially for a general purpose technology. Some AI-driven benefits, such as enhanced learning through per -

sonalized tutoring (at low cost), might not show up in productivity statistics at all or only after a considerable time 

lag. 10  Productivity gains often take time, as economies, firms and workers adapt, bottlenecks are addressed and 

complementarity investments are made. However, AI’s productivity impacts may materialize faster than those in 

(continued) CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 6 9 

geared to using AI can unlock productivity and open 

new possibility frontiers. 49  The net effect of the AI 

revolution on economies is likely contingent on coun -

tries’ “ability to innovate, adopt and adapt to AI.” 50 

For low- and middle-income economies it can pres -

ent a major opportunity for economic diversification 51 

by lowering barriers to access to advanced expertise 

(chapter 1), enabling and streamlining trade 52  and im -

proving service delivery in education, healthcare and 

other public services, in addition to enabling financial 

inclusion. 53  This requires investment in infrastruc -

ture, workforce training and inclusive digital ecosys -

tems (box 6.2). 

Seizing on the complementarity 

between AI and people 

A critical determinant of AI’s productivity impact 

is the degree to which it can be applied across econ -

omies. 54  Countries with different sectoral compo -

sitions, institutional capacities and workforce skill 

compositions may experience AI’s diffusion and im -

pact in different ways, and complementarity strat -

egies need to be attuned to context. Currently, 

higher-income economies with greater digitalization 

and a workforce more accustomed to using digital 

tools may be better positioned to harness AI. 55  For ex -

ample, in Latin America a substantial share of work -

ers who are employed in jobs that could benefit from 

AI do not have access to or are not using computers 

in their day-to-day work—limiting the potential of AI 

augmentation. 56 

So, how to steer towards complementarity? Work -

ers’ agency and influence—directly in their work and 

through social dialogue—have to be part of a broad 

package of policies that prioritize investment in 

human–machine collaboration. 57 

Fiscal policy shapes economic incentives and can 

direct investment in research and development, 

as well as how firms adopt AI. While the impact of 

AI on productivity across workers is not complete -

ly straightforward, and implications for wage dis -

tribution remain uncertain, digital technological 

Box 6.1  Assessing artificial intelligence’s productivity effects  (continued) 

previous waves of technological innovation. AI’s adaptive and learning capabilities, decreasing costs of comput -

ing and the fast-paced adoption across the world may all shorten the time lag between innovation and productiv -

ity. 11  Generative AI in particular is spreading faster than earlier technology, such as the internet or the personal 

computer. 12 

• Economic spillovers.  Both the benefits and costs of technological innovation can spill over from the private in -

novator to other parts of society. AI, with its many use cases, may have large impacts through these spillovers. 

For example, improving medical diagnosis 13  can have positive spillovers to public health, while negative spillovers 

such as rent seeking or widespread AI-generated misinformation could distort markets and limit AI’s economic 

potential. 14 

• Heterogeneity within and across businesses and sectors.  The extent to which AI enhances productivity in a sector 

or for a firm is contingent on industry dynamics and firms’ adaptability and technological readiness. For example, 

sectors with high digital penetration may have an easier time integrating AI applications and driving productivity 

gains. Firms able to adapt organizational structures and workflows to AI and leverage AI for product innovation 

may see higher growth 15  than those slower to adapt. Disparities within firms may arise between workers who are 

able to leverage AI to augment their work and workers who struggle to integrate it into their work or see large 

parts of their tasks displaced. 

• Dynamic effects.  Beyond spillovers AI’s third-order effects include the potential to accelerate innovation and 

scientific discovery, key contributors to productivity gains. By processing vast amounts of data and identifying pat -

terns 16  or by automating time-consuming tasks and enabling people to focus on higher-order problem solving and 

creativity, AI could greatly increase the pace of new breakthroughs, reshaping long-term productivity trajectories.                                

> Notes
> 1. Comunale and Manera 2024. 2. Berg and Gmyrek 2024. 3. National Academies of Sciences Engineering and Medicine 2024. 4. Hulten
> 1978. 5. Crafts 2021. 6. Acemoğlu and Restrepo 2019. 7. UN and ILO 2024. 8. World Bank 2024. 9. Antonietti, Burlina and Rodriguez-Pose
> 2025. 10. Coyle 2025. 11. Crafts 2021. 12. Liu, Wang and Zhenwhei Qiang 2024. 13. Wang and Preininger 2019. 14. Fallis 2021. 15. Babina
> and others 2024. 16. Mullainathan and Rambachan 2024. 1 70 HUMAN DEVELOPMENT REPORT 2025

advancements have tended to be accompanied by 

larger capital investment and higher capital shares 

of income. 58  The relevant lens for tax policy may thus 

involve rebalancing capital and labour taxation to eq -

uitably distribute productivity gains and encourage 

investment in labour-complementing technology. 59 

The design of such taxation matters and should be 

carefully considered. For example, while taxing spe -

cific technologies—for example, a “robot tax”—may 

hamper innovation in a particular field, 60  broader 

instruments such as capital income tax may achieve 

both efficiency and equity. 61 

AI itself can be leveraged as a tool for improving tax 

revenue by enhancing compliance and increasing ad -

ministrative efficiency. AI-driven tools can help gov -

ernments monitor complex financial transactions, 

detect fraud and reduce evasion. 62  Strengthening 

tax systems is important for developing economies, 

which struggle with closing tax revenue gaps and in -

creasing the tax-to-GDP ratio beyond 15 percent—a 

threshold associated with positive effects of taxation 

on economic growth and development. 63  Expand -

ing fiscal space through improved revenue collection 

can in turn fund critical complementarity invest -

ment—in education, skills development and digital 

infrastructure. 

Beyond taxation public investment in research and 

development of labour-enhancing AI, along with stra -

tegic subsidies for firms to adopt these types of tech -

nologies, can tip the balance towards AI as an enabler 

for augmentation and innovation. 64  Public–private 

partnerships can drive labour-enhancing AI innova -

tion and bridge gaps between research and develop -

ment, business cases and societal needs (see box 6.4 

later in the chapter). For example, in Mexico a newly 

established private sector–academia collaboration, 

Box 6.2  Smart systems, shared goals: The complementarity of artificial intelligence and digital public infrastructure 

Traditionally, infrastructure has been associated with physical assets such as roads, electricity grids and water sys -

tems that provide essential services for public use. Digital public infrastructure is a multidimensional approach to 

national digital transformation that relies on both physical and virtual systems. At its core, digital public infrastructure 

is about building and managing digital systems that support essential services in today’s society. These systems 

include proving one’s identity online, sending money quickly and securely and sharing information safely—with the 

right privacy protections and consent. 1 Services aim to be inclusive so no one is left out, foundational so others can 

build on them, interoperable through open standards that can support diverse uses and publicly accountable to 

ensure they serve the public interest rather than private or siloed goals. 2

Digital public infrastructure can speed up the use of AI. Many AI applications need both unstructured and struc -

tured data. Structured data often come from different government registries and databases, which are usually spread 

across ministries, departments and agencies. For example, in India AI is helping farmers get real-time support, includ -

ing access to insurance and subsidies in their local languages—something that depends on combining many different 

data sources. 3

AI can enhance digital public infrastructure. Unlike traditional infrastructure, digital public infrastructure is highly 

scalable, adaptable and reusable,  offering unprecedented innovation potential. For instance, Stripe—a global pay -

ments platform—uses machine learning to spot signs of fraud by analysing unusual transaction patterns, shifts in pur -

chasing behaviour and changes in device details. 4 Similarly, AI powers biometric authentication in digital ID systems, 

which is especially useful where fingerprint recognition does not work well. This approach has been promoting inclu -

sion, as, for example, many agricultural and manual workers face fingerprint erosion, making alternative biometric 

methods more reliable. 5

Despite the growing potential, research on the causal links between digital public infrastructure and AI remains 

limited. More work is needed to understand how these two concepts can reinforce each other, what risks their 

interaction may pose and how policymakers should approach their integration, ensuring that benefits are widely 

distributed and reinforcing human agency, trust and fairness in the digital age. 6                  

> Notes
> 1. Eaves and Sandman 2021. 2. Eaves, Mazzucato and Vasconcellos 2024. 3. D’Silva and others 2019. 4. Adams 2025. 5. Digital public
> infrastructure can be vulnerable to serious threats, such as disinformation campaigns that undermine public confidence. A notable example
> comes from Brazil, where false information about a new regulation related to Pix—an instant digital payment platform—circulated widely,
> impacting more than 9.4 million people in 2025 (Luciano and Fleck 2025). 6. Rikap 2024. CHAPTER 6 — R EIMAGINING CHOICES : T OWARDS ARTIFICIAL INTELLIGENCE –AUGMENTED HUMAN DEVELOPMENT 1 7 1

GenAI Laboratory, is connecting research, education 

and real-world AI-applications. 65 

Investing in complementarity implies establishing 

a level playing field in economies and enabling firms 

of all sizes and across all sectors to engage in the AI 

economy. 66  In many places this starts with closing 

digital divides and enabling universal and meaning -

ful connectivity (spotlight 6.2). Robust high-speed 

internet networks serve as the backbone for imple -

menting more advanced digital tools, 67  but govern -

ments can go further by advancing and integrating AI 

into digital public infrastructure (see box 6.2). Public -

ly accessible AI infrastructure—such as shared com -

puting resources, open source AI models and publicly 

curated datasets—can democratize AI development 

and adoption. Furthermore, well-designed compe -

tition policies can foster a competitive and dynamic 

technological ecosystem that drives innovation and 

ensures that AI-driven gains are broadly distribut -

ed rather than concentrated among a few dominant 

players. 68 

# “Publicly accessible AI infrastructure— 

such as shared computing resources, open 

source AI models and publicly curated 

datasets—can democratize AI development 

and adoption. Furthermore, well-designed 

competition policies can foster a competitive 

and dynamic technological ecosystem that 

drives innovation and ensures that AI-driven 

gains are broadly distributed rather than 

concentrated among a few dominant players 

Fast AI diffusion and adoption can be disruptive 

because overall workforce skill composition may 

take time to adjust. Vocational programmes that are 

adaptive and aligned with emerging industry needs 

can bridge skills gaps quickly and improve employ -

ment prospects, 69  while on-the-job training and 

upskilling may support those whose jobs and tasks 

are reshaped by AI. 70  Public–private partnerships and 

other multistakeholder alliances can support learn -

ing systems that remain responsive to the evolving 

demands of an AI-driven economy and bridge gaps 

between formal education, vocational training and 

industry needs. 71  For example, initiatives such as the 

Organisation for Economic Co-operation and De -

velopment’s (OECD) Skills for Jobs database offers 

up-to-date information about the types of expertise 

in demand across sectors and regions. 72 

AI might reshape demand for different types of ex -

pertise. By increasing access to advanced expertise, 

it may make some types of specialized knowledge 

less exclusive while raising demand for others (chap -

ter 1). The implications for developing economies are 

particularly important. Where access to advanced 

expertise has historically been limited, AI-powered 

tools could bridge gaps in education, healthcare and 

financial services and enable workers to perform 

higher-value tasks with less formal training. 73  For ex -

ample, in some parts of Kenya, Nigeria and South Af -

rica, AI solutions are enabling smallholder farmers to 

engage in precision agriculture, optimizing resource 

efficiency, enhancing yields and reducing environ -

mental harms. 74 

However, as AI reshapes the demand for expertise, 

some jobs may see less demand while new ones are 

created. New roles might not require the same types 

of expertise or might emerge in a different sector or 

place from where job losses occur. 75  Robust social 

protection systems, along with active labour market 

policies, can mitigate income losses and help people 

navigate shifting work demands. 76 

Including workers in AI gains and governance 

While AI offers great potential for productivity gains, 

the gains, if materialized, might not be evenly dis -

tributed. 77  Taxation and social transfers can help en -

sure that AI-induced productivity gains also benefit 

workers broadly, 78  but premarket policies such as col -

lective bargaining and social dialogue are also impor -

tant for guiding a fair and inclusive transition towards 

an AI-powered economy (spotlight 6.3). 

To do so, worker inclusion and influence in work -

place AI governance is crucial. The generative nature 

of some AI implies that human oversight, control and 

contextual understanding matter both to maximize 

potential and to avoid risks associated with overreli -

ance on AI systems. 79  When human involvement in 

work is diminished, it can lead to moral disengage -

ment, where individuals become detached from the 

ethical and behavioural norms that usually guide 

their actions. 80  When people feel disconnected, their 

sense of accountability may diminish, increasing the 1 7 2 HUMAN DEVELOPMENT REPORT 2025 

risk of errors and safety issues—especially in high -

ly automated settings. 81  Algorithmic management 

systems, designed to improve efficiency through 

monitoring and automation of work allocation, may 

instead increase errors and disrupt entire workflows 

if they push workers to engage in multitasking and to 

oversee simultaneous workflows at ever higher speed 

(box 6.3). 

Similarly, digital surveillance in the workplace— 

including email monitoring, keystroke tracking and 

social media scrutiny—can create considerable psy -

chological stress for employees. 82  While these prac -

tices aim to enhance productivity and data security, 

they also contribute to workplace anxiety. 83  Employ -

ees can feel a loss of freedom and trust when sub -

jected to excessive surveillance, reducing their 

motivation and job satisfaction. 84 

Instead, engaging workers in the design and de -

ployment of AI systems can enhance their roles and 

boost AI’s productive impact. Transparent AI inter -

faces that provide real-time explanations can reduce 

confusion and cognitive overload, enabling workers 

to interact with AI more intuitively and effectively. 85 

Employers should involve employees in discussions 

about surveillance policies, provide training on the 

use of monitoring data and ensure that employees are 

informed of how their data are used. 86  Workers who 

feel included in monitoring decisions are more likely 

to accept them. 87  An opt-in approach to monitoring, 

where employees have agency over how their data 

are used, can further reinforce trust and workplace 

wellbeing. 88 

Furthermore, the allure of AI has created an image 

of almost completely autonomous systems, near -

ly free from human intervention beyond the bril -

liant programmers who developed them. 89  In reality, 

AI depends heavily on human workers in every step 

of the supply chain. Lower-value-added activities, 

such as data labelling and annotation, are often con -

centrated in low- and middle-income countries, re -

quiring intensive human labour but offering limited 

rewards. In contrast, higher-value-added tasks, such 

as AI model design and deployment, are confined 

largely to high-income countries, demanding special -

ized knowledge and infrastructure. 90 

The reliance on human labour across the AI supply 

chain highlights the need to examine who contrib -

utes to AI systems, under what conditions and how 

the value they create is distributed. As AI expands 

and becomes ever more integrated into our econo -

mies, it presents an opportunity for high-quality tech -

nology-generated jobs. A complementarity economy 

recognizes and values workers at every stage of the 

supply chain, 91  towards ensuring meaningful oppor -

tunities, fair compensation and decent working con -

ditions. The future of work in the age of AI should be 

one of genuine collaboration between humans and 

machines 92 —not one built on a hidden global work -

force facing decent work deficits. 

## Driving innovation with intent: 

## Aligning socially and privately 

## valuable AI research 

Aligning socially desirable with privately profitable 

AI research and development is a transformative op -

portunity to advance human development. 93  AI might 

become more than just another technological innova -

tion able to execute or augment tasks. Like other tech -

nological innovations, it can increase the productivity 

of factors of production, but it differs in that it can also 

increase the rate of technological innovation. 94  AI’s 

potential to improve the productivity of research and 

innovation is particularly important in today’s world, 

given evidence that disruptive science and techno -

logical innovation was declining through 2010 (fig -

ure 6.6). 95  The number of researchers that is required 

today to keep Moore’s law going (the doubling of the 

number of transistors in an integrated circuit every 

two years) is 18 times more than in the early 1970s. 96 

But despite AI’s potential to accelerate techno -

logical progress and scientific discovery, 97  current 

innovation incentives are geared towards rapid de -

ployment, scale and automation—often at the cost 

of transparency, fairness and social inclusion. 98  Fur -

thermore, disparities in funding and expertise have 

resulted in uneven participation in AI research and 

development. 

Thus, driving innovation with intent means har -

nessing AI for science and technological innova -

tion and steering AI towards human development 

through incentives, including novel AI benchmarks, 

and through multistakeholder partnerships. 99  Open 

source AI can expand access to AI tools and foster 

broader participation in innovation. While openness 

also raises critical privacy and security concerns, 100 CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 7 3 

Box 6.3  Who’s the boss? The rise of algorithmic management in the automobile manufacturing sector 

Uma Rani and Morgan Williams, International Labour Organization 

Many of today’s algorithmic management tools are rooted in 1980s and 1990s technologies. 1 In automobile manufacturing 

electronic work instructions and other systems were introduced to prevent errors along the assembly line. Their functionality 

has advanced considerably, resulting in systems that often layer new capabilities onto older operating systems. 2

Today the integration of sensors and data management software in the automobile sector has intensified the work pace, 

monitoring and traceability (box figure 1). Automated systems dictate workflows, often pushing workers to keep up with a relent -

less machine-driven pace and increasing the demand for workers to maintain speed and meet targets. This is done through both 

electronic work instructions and automated guided vehicles. In addition, workers and mid-level managers may be required to 

monitor multiple screens, inputs and outputs simultaneously, often while performing physical tasks on the assembly line. 

Box figure 1  Contemporary algorithmic management in automobile manufacturing 

ASSEMBLY LINE WORKERS MANAGERS DECISION SUPPORT SURVEILLANCE AUTOMATED PRODUCT DELIVERY QUALITY CONTROL Electronic work instructions Poka-yoke aAutomated guided vehicles Bar and QR codes Closed circuit television Management systems (such as enterprise resource planning, customer interaction management, management information system, warehouse management system) Instant messaging applications Sensors • Data collection • Tightens just-in-time dynamics • Real-time traceability • Performance evaluation • Increases accountability as mistakes are recorded • Sets pace and rhythm • Requires multitasking • Repetition of process if a mistake is done Impacts: Work intensification and increases stress   

> a. Pick-to-light and pick-to-voice systems that use light signals and voice instructions respectively to guide workers in executing their manual tasks.
> Source: Rani and Williams forthcoming).

(continued) 1 74 HUMAN DEVELOPMENT REPORT 2025 

research can be directed to address some of the vul -

nerabilities of open source technologies by involving 

a wide variety of organizations with different goals 

and incentives. 101 

Harnessing AI as the invention of a 

method of invention to expand human 

understanding and creativity 

AI’s potential to accelerate technological innovation 

and human creativity is illustrated by the improved 

performance of human Go players. Essentially flat for 

decades, human performance in the game started to 

increase after the AI model AlphaGo beat the leading 

Go master in March 2016 (figure 6.7). Fan Hui, then 

the European Go champion, was both awed and sur -

prised in describing one of AlphaGo’s moves: “It’s 

not a human move. I’ve never seen a human play this 

move. So beautiful.” 102  The higher quality of human 

Go players’ moves was due to their novelty, not to 

copying of AlphaGo’s moves. AI inspired human cre -

ativity by doing something never seen before, aug -

menting human intelligence. 103 

Though evidence suggests that AI can trigger cre -

ativity and innovation across a variety of contexts, 104 

the reasons that AI and human collaboration are more 

likely to do so remain under examination. 105  Deploying 

AI in research requires consistency with the norms of 

scientific practice. 106  AI will likely require changes in 

the way humans interact with it, rather than simply re -

placing classical programming with AI-powered tools. 

For example, using AI-summarized results from web 

searches tends to lead to shallower knowledge and less 

original advice than a traditional web search. 107  One 

must look at AI as going beyond simply plug and play, 

beyond replacing existing research methods with AI. 

Guidance is emerging on how to make the best use 

of AI to advance science and the kinds of risks to watch 

for. 108  Focusing on the key complementarities between 

humans and AI in the creative process provides a for -

ward-looking perspective. 109  One complementarity is 

that AI does some things very well that are harder for 

humans (seeing new things in data), while humans do 

other things well that AI struggles with (seeing things 

not in data to generate novel theories). 110  Mixing fore -

casts from AI models with those from human experts 

yields better predictions than those of human experts 

Box 6.3  Who’s the boss? The rise of algorithmic management in the automobile manufacturing sector  (continued) 

The pressure to maintain speed created by automated systems that are designed to reduce errors and the complexity of 

multitasking that the systems introduce can paradoxically increase the likelihood of mistakes. When errors occur, the system 

often requires repeating the entire process or segment, further disrupting the workflow and potentially reducing overall pro -

ductivity. Real-time data tighten just-in-time processes, as any deviation from the prescribed workflow can have immediate 

repercussions across the entire production line. This technological integration also enables granular, real-time traceability 

of worker actions, creating a panopticon-like environment (observing workers who do not know whether they are being ob -

served). The possibility of linking errors to individual workers can foster fear and stress, as workers feel constantly scrutinized 

and apprehensive about making even minor mistakes. The data collected can be used for performance reviews, compensation 

considerations, promotion opportunities and even job security. 

The constant surveillance, pressure to meet algorithmically determined targets and potential for disciplinary action based 

on automated performance metrics erode the trust between managers and workers. So it is important to shift the balance of 

power towards workers and take steps to rebuild trust, emphasizing human oversight and worker empowerment. The pace 

and rhythm of work dictated by these systems must be reassessed and set within more realistic timeframes and parameters 

that prioritize worker wellbeing and acknowledge the limits of human capacity. Algorithmic systems should be tools that assist 

workers, not instruments that control and constrain them. 

Codetermination and social dialogue are essential for regulating the impact of technology. Meaningful worker participation 

in the design, implementation and governance of these technologies is paramount—not only consultation but also genuine 

negotiation and shared decisionmaking over how the systems are used and how performance is measured. Workers, with their 

intimate understanding of the work process, are best positioned to identify potential pitfalls and unintended consequences of 

algorithmic management.           

> Note
> 1. This box builds on Rani and Morgan (forthcoming). 2. Krzywdzinski, Gerst and Butollo 2023. CHAPTER 6 — R EIMAGINING CHOICES : T OWARDS ARTIFICIAL INTELLIGENCE –AUGMENTED HUMAN DEVELOPMENT 1 7 5

Figure 6.6  Disruptive science and technological innovation was on a steady decline through 2010 

Average CD 5

Papers 

Average CD 5

Patents 

Physical sciences Social sciences Technology Life sciences and biomedicine Computers and communications Drugs and medical Electrical and electronic Chemical Mechanical 1950 1960 1970 1980 1990 2000 2010 00.1 0.2 0.3 0.4 0.5 1980 1990 2000 00.1 0.2 0.3 0.4 0.5 2010 

Note:  CD 5 (calculating disruption) is an index of the extent to which a paper or patent disrupted established scientific or technological knowledge, 

rendering it obsolete and charting new directions. It measures disruption by the extent to which citations of a disruptive paper or patent also cite its 

predecessors, with 0 corresponding to consolidation of existing knowledge and 1 corresponding to disruptive. The index is measured five years after 

the paper was published (hence the subscript 5). 

Source:  Park, Leahey and Funk 2023. 

Figure 6.7  Artificial intelligence can inspire humans to reach new heights in creativity 

0.8 0.0 1.7 –0.8 2010 2000 1990 1980 1970 1960 1950 2021 AlphaGo defeats human world champion (March 2016) Median decision quality index of human Go players 

Note:  Vertical lines are 95 percent confidence intervals, excluding the potential effect of memorization of AlphaGo moves after 2016. 

Source:  Shin and others 2023. 1 76 HUMAN DEVELOPMENT REPORT 2025 

or AI alone. 111  And AI combined with remote sensing 

can help identify tipping points in natural systems— 

providing essential information for buffering against 

changes in the natural world. 112 

Scientific discoveries are at times limited by the 

rate at which existing approaches parse and process 

data. For example, the search space for new materi -

als is vast, with as many as 10108 organic molecules 

as possible candidates. 113  The vast majority of these 

compounds may be of limited, if any, practical value, 

such that searching the space efficiently is unreason -

able for human effort alone. But techniques that use 

AI to identify candidates are rapidly improving, em -

powering humans by narrowing the search. 114  In ma -

terials science an AI application led to the discovery 

of 2.2 million new crystals. 115  And in another applica -

tion AI-assisted researchers discovered 44 percent 

more materials than the pre-AI trend, increasing pat -

ent filings by 39 percent and downstream product in -

novation by 17 percent. 116  Similar applications of AI 

to detect data patterns that may not be perceptible by 

humans can extend to the economic and broader so -

cial sciences. 117 

Applications of AI are spreading rapidly across 

many fields, with published scholarly papers engaging 

AI increasing from around 2 percent in 2015 to over 8 

percent around 2024. 118  In the humanities AI can aug -

ment the availability of historical economic data. 119 

In archaeology AI has enabled archaeologists to dou -

ble the number of identified figurative geoglyphs in 

Nazca, Peru, insights that led researchers to a new 

hypothesis. 120  Applications of AI in economics are ac -

celerating 121  and spreading to other social sciences, 

including political science. 122  Applications also span a 

range of scientific and technological fields, including 

biology, 123  chemistry, 124  conservation science, 125  drug 

discovery, 126  geology, 127  materials science, 128  mathe -

matics, 129  neuroscience, 130  physics 131  and psychology. 132 

Augmenting AI with scientific models can combine 

understanding that comes from science with the AI ca -

pabilities to extract patterns from data. 133  Applications 

include combining physics-based models to predict 

weather and climate, with AI trained on past weather 

data to improve forecasting. 134  There is also potential 

to leverage the complementarity between humans 

and AI to enhance innovation at larger societal scales, 

beyond specific labs or scientific fields, by enhancing 

collective intelligence. 135  Fully leveraging the potential 

of complementarity between AI and human creativ -

ity requires making people more aware of the risks. 136 

It also requires purposefully building machines meant 

to learn and think with people rather than just focusing 

on the capabilities of machines that surpass people. 137 

The pursuit of human and AI collaboration to ad -

vance arts and science needs to consider novel risks 

and challenges that are under close scrutiny and add 

uncertainty to whether AI’s potential for accelerating 

innovation can be fully realized. 138  Broader systemic 

implications of AI use to boost scientific productivity 

include the potential tradeoff between affecting indi -

vidual creative productivity with AI and making cre -

ative output less diverse, potentially leading to less 

collective diversity of novel content. 139  The implica -

tions for job satisfaction and deriving meaning from 

work when interacting with AI are still not well un -

derstood. 140  The synthetic data produced by genera -

tive AI create new ethical challenges for scientists, 141 

including how to fulfil norms of scientific conduct 

such as accountability, transparency, replicability and 

human responsibility. 142  And adequately compensat -

ing creators of much of the content to train AI raises 

new questions related to intellectual protection law 

and liability when things go wrong. 143 

# “AI’s contributions to science will 

likely be greatest when it augments 

humans doing the science 

So, despite AI’s potential its applications in science 

and research can produce flawed, overly optimistic or 

hard to reproduce results. 144  More fundamentally, the 

goal is not to produce more science but to understand 

more about the world and about ourselves, and there 

is a risk that the proliferation of AI in science will 

yield more results but less understanding. 145  From 

a human development perspective the value of sci -

ence ultimately comes not from the nominal rate of 

discoveries but from the rate at which those discov -

eries are important to people. It is also crucial to see 

science and creative processes more broadly as in -

herently human endeavours—where spontaneity and 

serendipity from interactions between humans, as 

well as very human mistakes that no machine would 

make, can engender creativity. 146  AI’s contributions 

to science will likely be greatest when it augments hu -

mans doing the science. CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 7 7 

Aligning AI research towards 

advancing human development 

Ensuring that AI advances human development de -

pends in part on aligning AI innovation incentives in 

different ways. That includes, for instance, avoiding 

creating innovation traps, 147  which could undermine 

AI paths that advance human development. 148  This 

could be achieved if AI research and development 

adopt a broader perspective seeking to align AI ad -

vancements with societal goals, pluralism and inclu -

sion rather than being narrowly driven by contested 

or speculative pursuits. 149 

# “One aspect of the human development– 

aligned AI path relates to safety, an area 

that has yet to receive investment and 

research attention commensurate with its 

potential economic and social impact 

To foster AI innovation that enhances human de -

velopment, AI benchmarks, which have become 

fundamental tools for evaluating the performance, 

capabilities and safety of AI models, could also be 

expanded. While important, current metrics tell us 

very little about how much AI is augmenting human 

development. To align AI more closely with human 

development, new benchmarks should be researched 

and deployed, assessing how AI contributes to human 

wellbeing, opportunity and agency (chapter 4). 150 

Tax strategies can incentivize greater financial 

commitments from major technology companies and 

public entities and steer research and development 

towards AI systems that advance human capabilities, 

while discouraging investment that promotes auto -

mation-driven labour displacement. Tools such as 

public–private partnerships, public procurement pol -

icies, regulatory sandboxes, impact-based funding 

and outcome-driven investment mechanisms, along 

with novel benchmarks, can help shift the balance. 151 

Together, these measures could fund and rebal -

ance AI research and development towards human 

development–enhancing technologies. 

Another aspect of the human development–aligned 

AI path relates to safety, an area that has yet to re -

ceive investment and research attention commensu -

rate with its potential economic and social impact, 152 

given that AI safety accounts for only about 2 percent 

of overall AI research. 153  While fields such as com -

puter vision dominate due to their extensive com -

mercial applications and robotics continues to thrive 

in industrial contexts, AI safety remains a marginal 

focus in most AI applications and across regions. 154 

Even in research-intensive regions such as East Asia 

and the Pacific and OECD members, AI safety is 

underrepresented. For example, although China and 

the United States lead global AI research, their pri -

orities diverge—with Chinese efforts centring on ro -

botics and computer vision and US research slightly 

favouring natural language processing, alongside a 

modest lead in AI safety. 155 

Another promising area of research is small lan -

guage models, which, unlike large language mod -

els, offer advantages in data security and privacy 

because they are designed for specific use cases, 

providing more targeted, cost-effective and secure 

solutions. 156  This makes them particularly well-suit -

ed for developing country settings, where resource 

constraints are a critical consideration. Deploying 

small language models without internet connectiv -

ity is feasible through on-device implementation. 

This approach increases data privacy, reduces laten -

cy and ensures continuous operation in areas with 

unreliable internet access. Take InkubaLM, a small 

language model designed to make AI tools more ac -

cessible for African languages. It performs as well as 

larger models while being more efficient, using two 

specialized datasets to enhance tasks such as trans -

lation and sentiment analysis. By advancing research 

on smaller models, researchers can create fairer, 

more sustainable AI options for underserved and 

lower-resourced communities. 157 

The disparity in AI resources, expertise and infra -

structure between high-income and low- to middle-

income countries—directly affects who benefits from 

AI and who is left behind. 158  High-income countries 

possess substantial investment capacity, technologi -

cal infrastructure, data and AI talent, enabling them 

to lead in AI innovation and AI safety (chapter 5). In 

contrast, many low- and middle-income countries 

struggle with insufficient funding, weak digital infra -

structure and a shortage of skilled professionals, lim -

iting their participation in AI development. 159  This 

divide not only restricts access to AI benefits but also 

reinforces global inequalities in advancing AI for 

human development. 1 7 8 HUMAN DEVELOPMENT REPORT 2025 

Strengthening global collaboration through part -

nerships 160  would promote a more balanced distri -

bution of AI benefits, ensuring that regions at all 

income levels can contribute to and benefit from 

AI-driven progress. 161  Low HDI countries experi -

enced the fastest growth in collaborative AI research 

outputs between 2014 and 2023. This is a positive 

sign, but it is due mainly to a low baseline—in fact, 

the gaps widen substantially as HDI increases. Medi -

um HDI countries also made considerable progress, 

while high and very high HDI countries exhibited 

slower but solid growth. In absolute terms there is 

divergence: the distance between low HDI countries 

and very high HDI countries is now larger than a dec -

ade ago. 162 

Partnerships would need to be structured to ensure 

that local priorities are not overshadowed by the inter -

ests of higher HDI countries. 163  AI safety frameworks 

must incorporate diverse perspectives, accounting for 

regional ethics, governance structures and societal 

norms. 164  This inclusivity is essential to strengthening 

AI safety outcomes, ensuring that AI tools are both con -

textually relevant and globally adaptable. Partnerships 

in AI not only bring together diverse areas of expertise 

but could also drive substantial investment in digital 

infrastructure, research and talent development. By 

aligning the interests of government agencies, academ -

ic institutions, industry leaders and the broader public, 

these collaborations would help ensure that future AI 

progress advances human development (box 6.4). 

Box 6.4  Bridging bytes and governments: Artificial intelligence ecosystems through partnerships 

Several countries are pioneering new models for inclusive artificial intelligence (AI) ecosystems and partnerships. For example, 

the Republic of Korea is a global leader in AI research and development, with a mix of public and private investment in frontier 

technologies leading to more than 1,500 AI patent filings in the first 10 months of 2024. 1 The National AI Computing Center, 

backed by joint public–private investment, 2 aims to enhance Korea’s AI research infrastructure and secure high-performance 

computing resources (graphics processing units). The initiative is spearheaded by the Ministry of Science and ICT in col -

laboration with the Ministry of Economy and Finance, the Ministry of Trade, Industry and Energy and the Financial Services 

Commission. 3 Complementing this, Korea is launching the National AI Research Hub in 2025 to foster collaboration between 

government and industry and to accelerate AI development nationwide. 4

Similarly, AI Singapore brings together Singapore-based research institutions, AI startups, companies and the public sector 

to develop national AI capabilities and foster a trusted AI ecosystem that addresses global challenges such as health and 

climate change. 5 And AI Sweden operates as a nonprofit partner network of more than 150 organizations spanning diverse 

sectors and disciplines—from AI experts, data scientists, research engineers, linguists and mathematicians to policy specialists, 

lawyers, journalists and changemakers—working together to drive sustainable and inclusive AI progress across, for example, 

healthcare, energy systems and local municipalities in Sweden. 6

Another example is Current AI, which highlights the transformative potential of public–private partnerships by developing 

AI solutions that serve the public interest through global collaboration and local implementation. The initiative focuses on 

building an open AI ecosystem by unlocking valuable datasets, promoting open standards and tools to increase acces -

sibility and ensuring transparency and trust through public interest auditing and oversight. Backed by major technology 

companies—including Google—and the French government, Current AI aims to deliver AI systems that genuinely serve the 

public good. 7

The private sector is also advancing multistakeholder alliances. For example, the Partnership on AI is a global nonprofit 

organization 8 whose founding members were Amazon, Facebook, DeepMind, Google, IBM and Microsoft. It unites more than 

100 partner organizations from industry, academia and civil society to address the societal implications of artificial intelligence. 

By fostering collaboration among diverse stakeholders, the organization develops best practices, conducts research and 

promotes the responsible development and use of AI technologies. Through initiatives such as creating frameworks for safe AI 

deployment and investigating challenges to diversity in AI, it aims to ensure that AI advancements are ethical and transparent. 

These examples show that partnerships offer a structured and scalable approach to ensuring AI as a safe and equitable 

technology aligned with human development priorities.                       

> Notes
> 1. Buntz 2024. 2. Dae-Hyun 2024. 3. Kim Eun-jin 2025. 4. Republic of Korea Ministry of Science and ICT 2024. 5. Smart Nation and Digital Government
> Office n.d. 6. AI Sweden n.d. AI Sweden is funded by Sweden’s innovation agency Vinnova, the Swedish Agency for Economic and Regional Growth,
> the European Regional Development Fund, and contributions from its network of partners. 7. Current AI n.d. 8. PAI 2024. CHAPTER 6 — R EIMAGINING CHOICES : T OWARDS ARTIFICIAL INTELLIGENCE –AUGMENTED HUMAN DEVELOPMENT 1 7 9

## Investing in capabilities that 

## count: Can AI enhance education 

## and health outcomes? 

AI offers new possibilities to advance human devel -

opment by enhancing achievements in education and 

health, but substantial challenges are inherent in its de -

ployment. Underresourced institutions are more likely 

to adopt questionable AI solutions—a tendency close -

ly tied to technosolutionism (chapter 4). 165  Often the 

focus is on deploying technology (such as one laptop 

per child) or cultivating specific technology-based skills 

(coding) without sufficient attention to the broader 

goal of enhancing human development. The context— 

alongside the human and social factors essential for 

successful institutional transformations—tends to be 

overlooked. And context varies considerably. The ini -

tial conditions for AI deployment are highly unequal— 

and are becoming increasingly so in the areas closely 

linked to human agency and empowerment. If this re -

ality is not carefully considered, AI’s introduction may 

prove ineffective or even counterproductive.. 

A baseline of high inequality in enhanced 

capabilities in education and health 

The notable progress in education and health out -

comes over the past few decades has focused on basic 

capabilities and quantity-based metrics. For example, 

expected years of schooling are at their highest on 

record, and the global percentage of children out of 

primary school is now in the single digits. 166  In health, 

life expectancy at birth has increased by 8.4 years 

globally since 1990. 167 

But gaps persist and even widen when it comes to 

enhanced capabilities, as highlighted in the 2019 

Human Development Report. In education there 

are enormous gaps in students’ functional compe -

tencies. 168  Globally, only around 40 percent of chil -

dren achieve basic skills in math and science. 169  The 

proportion ranges from about 4 percent in low HDI 

countries to 67 percent in very high HDI countries. 170 

Despite a substantial reduction in disparities in the 

earliest stages of education, serious inequalities per -

sist and grow in later stages and in learning outcomes 

(figure 6.8). 

In health there are sizeable differences across the 

globe. The gap in life expectancy at birth is 30 years: 

between 55 years in Nigeria and 85 years in Japan. 171 

Around half the world’s population lacks complete 

coverage of essential health services. 172  And while 

gaps in mortality linked to communicable diseases 

have narrowed—leading to lower infant mortality— 

mortality disparities have increased at older ages. 

Lower-income countries are progressing much more 

slowly in developing health systems with adequate 

coverage, resources and equity. 173 

Figure 6.8  Education—convergence in basic capabilities, divergence in enhanced capabilities 

> Medium HDI Low HDI 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8

Change in mean years of schooling, 2000–2015 

> 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8

Change in skills in literacy adjusted mean years of schooling, 2000–2015    

> High HDI Very high HDI 1.27 1.60 1.44 1.09 1.54 1.31 0.73 1.48
> Note: Each bar measures the mean value for countries within each Human Development Index (HDI) group.
> Source: Human Development Report Office based on Lutz and others (2021). 1 8 0 HUMAN DEVELOPMENT REPORT 2025

Enhancing education capabilities 

to seize AI’s potential 

Seizing AI’s potential starts with shifting the focus in 

education from quantity to quality. 174  AI may change 

cognition and the skills important to strive for. 175 

High-quality learning requires the ability to under -

stand the world, critically assess large amounts of in -

formation, define objectives and apply knowledge in 

an ever changing and complex environment. Three 

core areas need attention as AI diffuses: critical think -

ing, creative thinking and relational thinking. 176 

Critical thinking is vital for evaluating large 

amounts of information and making decisions that 

align with one’s values and circumstances. 177  For in -

stance, extreme trust or distrust in online content 

signals an inability to properly assess and use inter -

net resources. Recent data from the Programme for 

International Student Assessment show that 15-year-

old students with low critical thinking are more than 

three times as likely as those with high critical think -

ing to indiscriminately accept or reject information 

from online sources (figure 6.9). 

Creative thinking—the cognitive process that gen -

erates, assesses and improves valuable and original 

ideas 178 —is essential for adapting to evolving circum -

stances and setting new goals and priorities. Rela -

tional thinking is crucial for making decisions in a 

context of interdependence—whether with the peo -

ple around us (empathy, compassion), our societies 

(responsibility, citizenship) or our planet (recognition 

of our embeddedness in nature). 179 

Deploying AI to strengthen interventions 

that improve learning outcomes 

To enhance human learning, AI will have to be im -

plemented to support learning strategies that are 

known to be effective 180  rather than being deployed 

in education for its own sake. Personalized and adap -

tive learning interventions are such strategies. For 

example, adaptive learning technologies improve 

math achievement, 181  and the benefits of interven -

tions such as structured pedagogy and “teaching 

at the right level”—as opposed to teaching in ac -

cordance with age cohort—are 65 times their cost 

when applied at scale in low- and middle-income 

countries. 182 

In many resource-constrained settings even more 

traditional technologies such as mobile phones can 

enhance learning cost-effectively and equitably, as 

demonstrated by Kenya’s SMS-based M-Shule plat -

form (chapter 3) 183  and Botswana’s SMS and phone 

call intervention. 184  Randomized controlled trials 

in India, Kenya, Nepal, the Philippines and Ugan -

da demonstrate that phone call tutorials can scale 

effectively, offering targeted instruction that ca -

ters to students’ learning needs. 185  Another example 

is intelligent tutoring systems, which can improve 

personalized learning, streamline classroom and ad -

ministrative processes and promote collaborative, 

self-directed education 186  while reducing costs and 

administrative burdens. 187  Still, feedback options and 

expert supervision remain crucial. 188 

AI has the potential to greatly enhance the edu -

cation benefits made possible by these earlier tech -

nologies. In Sierra Leone, where high internet costs 

result in low connectivity, AI-driven solutions offer 

a cost-effective alternative that is 87 percent cheaper 

than a web search. 189  For AI-powered tutoring target -

ed instruction and personalization have proven effec -

tive in improving learning outcomes in Ghana 190  and 

Figure 6.9  Critical thinking mitigates students’ 

propensity towards extreme trust or distrust of 

online content              

> 0510 15 20 Propensity for extreme trust or extreme distrust in online content (%) High critical thinking Some critical thinking Low critical thinking
> Note: Based on data for 52 countries. Extreme trust refers to re -
> spondents who answered “I strongly agree” with the statement “I
> trust what I read online,” and extreme distrust refers to respondents
> who answered “I strongly disagree” with the statement. Critical
> thinking is proxied using scoring groups (on a scale of 1–6) for math -
> ematics, reading and science, based on the qualitative descriptions
> of achievement at each level. High critical thinking: level 4 or above
> in all three subjects. Some critical thinking: level 4 or above in at
> least one subject Low critical thinking: below level 4 in all subjects.
> Source: Human Development Report Office calculations using data
> from the 2022 Programme for International Student Assessment. CHAPTER 6 — R EIMAGINING CHOICES : T OWARDS ARTIFICIAL INTELLIGENCE –AUGMENTED HUMAN DEVELOPMENT 1 8 1

Nigeria. 191  Instruments need to be customized: tar -

geting instruction to students’ learning levels rather 

than simply to their grade, significantly improves ed -

ucation outcomes. For example, a targeted pedagogi -

cal intervention in Türkiye, achieved through teacher 

training, boosted children’s curiosity, knowledge re -

tention and learning outcomes. 192 

AI in education can also address challenges such 

as cyberbullying, where general empathy training, 

modifying beliefs supportive of aggression and more 

specific guidelines for internet behaviour are re -

quired. 193  It can support learners with disabilities 194 

and create opportunities for women 195  by helping 

them upskill, reskill and increase participation in 

underrepresented science, technology, engineering 

and math fields. 196 

AI deployment can be informed by how technology 

can support parental engagement. 197  Telementoring 

and homeschooling in Bangladesh during the Covid-

19 pandemic boosted students’ test scores by 35 per -

cent, increased mothers’ involvement by 26 percent, 

prevented learning loss and had lasting benefits, es -

pecially for lower-performing students. 198  Parenting 

strategies—along with children’s education, strate -

gic physical activity and counselling—have proven 

effective in preventing or reducing internet addic -

tion. Interventions that shift children’s focus from 

online activities to real-world activities have shown 

promise in reducing internet engagement, prevent -

ing addictive behaviours. 199 

AI on its own will not fix education challenges 

Technology-driven interventions do not always yield 

positive results. Interventions that only add an ad -

ditional input (such as a computer) to the education 

process are consistently ineffective. In Costa Rica 

and Peru there were no notable impacts on academ -

ic achievement or cognitive skills from providing 

laptops to children at home. 200  Even access to funda -

mental services such as electricity might not have a 

noticeable effect if not accompanied by complemen -

tary measures. 201 

Despite the promise of AI in education, use of digital 

devices has not improved student outcomes across the 

board, 202  sparking dissatisfaction and, in some cases, 

protests among students and teacher unions. 203  While 

digital resources can yield positive effects for learning, 

the benefits diminish with excessive use (figure 6.10). 

Data from the 2022 Programme for International 

Figure 6.10  The benefits of digital resources for learning critical thinking diminish with excessive use 

Percentage of students (%) 

Medium HDI 

Percentage of students (%) 

High HDI 

Percentage of students (%) 

Very high HDI                         

> 0510 15 20 25 30 35 0123456780510 15 20 25 30 35 0123456780510 15 20 25 30 35 012345678

Hours of digital for learning at school Hours of digital for learning at school Hours of digital for learning at school   

> HDI is Human Development Index.
> Note: Pooled observations with equal weights across countries. Critical thinking is proxied using scoring groups (on a scale of 1–6) for mathematics, reading and
> science, based on the qualitative descriptions of achievement at each level. For each group the bars show the percentage of students who reached level 4 or
> above in at least one subject.
> Source: Human Development Report Office calculations using data from the 2022 Programme for International Student Assessment. 1 8 2 HUMAN DEVELOPMENT REPORT 2025

Student Assessment show declining reading and math 

scores in OECD countries, with excessive mobile phone 

use for leisure correlated with poorer outcomes. 204 

Gains from using digital technologies in educa -

tion at school are greater in higher HDI countries. In 

medium HDI countries increasing digital resources 

in schools tends to be less effective on average. One 

study shows Indonesia, at the lower end of high HDI 

countries, could benefit from integrating large lan -

guage models into education to reduce educators’ 

workload and support interactive, personalized learn -

ing, though issues related to ethics, data privacy, re -

liability, accuracy and cost persist. 205  AI in education 

risks exacerbating inequities due to unequal access to 

digital connectivity and technology. 206  Without prop -

er governance and targeted policies, issues related to 

accessibility, transparency and fairness in AI-based 

systems may lead to discrimination and exclusion, 207 

further entrenching existing disparities and raising 

concerns about environmental impacts. 208 

# “Successfully integrating AI into education 

requires effective classroom practices, teacher 

collaboration and attention to local education goals, 

with human interaction playing a crucial role in 

shaping student perceptions and learning outcomes 

Successfully integrating AI into education thus re -

quires effective classroom practices, 209  teacher col -

laboration and attention to local education goals, 

with human interaction playing a crucial role in shap -

ing learning outcomes. 210  AI’s potential suggests that 

a combination of institutional and human capabili -

ties is needed to improve education outcomes. Even 

when technologies such as video lectures are used, 

an instructor’s online presence increases student mo -

tivation and engagement. 211  Blended learning, com -

bining online and face-to-face instruction, also shows 

benefits. 212  Teachers’ characteristics, self-efficacy and 

alignment with student needs are crucial in technolo -

gy integration, as are supportive school environments 

and infrastructure. 213 

Given challenges with plagiarism, bias and over -

reliance, careful attention must be paid to the design 

and implementation of generative AI in education, 214 

while maintaining opportunities to enhance learn -

ing through content generation, personalized tu -

toring and instructional support. 215  Digital literacy 

programmes can be incorporated into school cur -

ricula, with self-monitoring tools and behavioural 

interventions such as video modelling and group con -

tingencies. 216  Schools can also raise awareness about 

the addictive nature of digital experiences and pro -

mote responsible online behaviour. 217 

Overreliance on generative AI can hinder student 

motivation and intellectual engagement, 218  while weak 

pedagogical designs can minimally improve learning 

outcomes (chapter 3). 219  Metareviews of intelligent tu -

toring systems show modest learning gains, 220  with ef -

fectiveness influenced by students’ prior knowledge. 221 

Although AI can create personalized learning experi -

ences, 222  both humans and AI need to adapt to ensure 

successful integration of technology in education. 223 

In teaching maintaining social cues such as gestures, 

facial expressions and eye gaze remains crucial. 224 

Adopting educational technologies without consider -

ing the context brings challenges such as high costs, 

teacher shortages 225  and concerns over AI’s inability 

to replicate the social, emotional and cognitive roles of 

educators 226  and overreliance on technology. 227 

AI can enhance health outcomes if 

health inequalities are redressed 

AI offers multiple opportunities to personalize, ex -

pand access to and increase the quality of healthcare 

by predicting, 228  diagnosing 229  and managing diseas -

es 230  while supporting clinical decisionmaking and 

medical workflows. 231  It can improve patient care, 

quality assurance and overall healthcare operations, 

leading to better health outcomes. 232 

Use cases of AI in healthcare already abound. 233  AI 

enhances disease detection, classification and mon -

itoring through machine learning models in health 

systems. 234  With noncommunicable diseases account -

ing for the majority of global mortality and morbidi -

ty, AI-driven tools can help address the rising burden 

of chronic conditions such as heart disease, diabetes 

and respiratory illnesses. 235  AI can generate high-qual -

ity data and support systematic reviews to better un -

derstand the links among diet, nutrition and chronic 

diseases. 236  By providing personalized medical infor -

mation, lifestyle guidance and treatment details, 237 

AI-driven tools can empower people to manage 

noncommunicable diseases. Mobile apps, reminder CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 8 3 

systems and AI chatbots enhance communication with 

physicians and may improve treatment adherence. 238 

The promise of AI-enhanced healthcare in low-

income settings with limited access to specialized ex -

pertise is especially important. 239  For example, AI can 

help community health workers screen for severe dis -

eases, such as breast cancer, 240  or detect leukaemia 

with just 10 laboratory parameters, 241  enabling early 

detection in low-resource and emergency settings. 242 

In countries with high neonatal mortality rates, such as 

India, Nigeria and Pakistan, AI can assist mothers with 

early screening and diagnosis of noncommunicable 

and nutrition-related diseases. 243  Innovative solutions, 

such as voice bots in Bangladesh, show how AI can 

support women’s healthcare needs. 244  Further, pre -

dictive analytics enable real-time surveillance of in -

fectious outbreaks using genomic, environmental and 

patient data. 245 

No AI in health without trust, less trust 

without redressing health inequities. 

Much of AI’s potential is hampered because con -

cerns about bias, trust and privacy hinder AI adoption 

in health. 246  Limited health infrastructure, skewed 

datasets and algorithmic flaws can deepen healthcare 

disparities, while lack of transparency and govern -

ance gaps erode trust. For example, the integration of 

large language models into Philippine ophthalmology 

shows great potential but is hindered by challenges 

such as limited local data, technical expertise, fund -

ing and regulatory oversight. 247 

Even before AI, telemedicine and mobile health 

expanded access to healthcare, but adoption was 

often hindered by technological gaps and resource 

limitations. 248  Now, AI-driven telemedicine could 

improve care for elderly populations in remote areas, 

though unequal access to healthcare data can worsen 

disparities, even in high-income countries. 249  Thus, 

the digital divide and healthcare workforce short -

ages reinforce healthcare inequities, 250  particularly 

for low-income populations, who are often excluded 

from data collection and receive lower-quality care. 251 

Weak health infrastructure further limits diverse AI 

development. 252  To close these gaps, ensuring that 

AI-driven healthcare tools are accessible, affordable 

and effectively integrated into diverse settings can 

help reduce rather than deepen disparities. 253 

Gender inequities in healthcare and AI develop -

ment further reinforce disparities. Despite mak -

ing up 67 percent of the global health workforce, 254 

women hold only 31 percent of global health lead -

ership roles, 255  limiting their influence on AI-driven 

healthcare. The lack of gender diversity in AI devel -

opment teams exacerbates this issue, resulting in 

lower-quality AI products that reinforce stereotypes 

and discrimination. 256  In addition, gender biases in 

patient care and limited access to digital health tools 

disproportionately affect women, particularly those 

with less education and income. 257  Addressing these 

disparities requires promoting women’s leadership in 

AI, expanding education in science, technology, engi -

neering and math, eliminating hiring biases and fos -

tering inclusive workplace practices. 258 

# “Many people lack the skills to use AI tools, 

even ones that are affordable. Mobile health 

apps, wearables and telemedicine are often out 

of reach for historically excluded communities 

Many people lack the skills to use AI tools, even ones 

that are affordable. Mobile health apps, wearables 

and telemedicine are often out of reach for historical -

ly excluded communities. Limited digital literacy and 

poor access to devices or the internet remain, even in 

high-income countries. 259  Disparities are also linked 

to AI healthcare research is being concentrated in a 

few high-income countries. 260  Research output is also 

uneven: in Africa, Egypt, Morocco and South Africa 

lead in cardiovascular, diabetes and cancer research, 

while Egypt, Ghana, Nigeria and South Africa focus 

on malaria and tuberculosis. 261  Even in high-income 

countries, access to healthcare data varies widely. As 

data capacity increases, the gap in countries’ abili -

ty to make informed health decisions is expected to 

grow. 262 AI in healthcare requires supportive policies, 

executive backing, clinical demand and user consen -

sus. 263  Strengthening social protection systems and 

involving the community in design and implementa -

tion can ensure more equitable outcomes. 264 

AI deployment in health requires building trust 

and ensuring both accuracy and fairness 

As AI’s clinical significance grows, 265  better in -

tegration into clinical practice and workforce 1 8 4 HUMAN DEVELOPMENT REPORT 2025 

development is essential. One randomized con -

trolled trial found that while large language mod -

els outperformed physicians in diagnostics, they 

offered no significant benefit as a diagnostic aid. 266 

Similarly, using large language model technology 

to draft responses to electronic health record mes -

sages can reduce messaging burdens on healthcare 

teams but will remain a supportive aid rather than a 

comprehensive solution. 267  AI use was also found to 

be associated with higher risk of radiologist burn -

out, particularly among those with high workload or 

lower AI acceptance. 268 

AI in healthcare relies on large datasets and com -

plex algorithms, which can introduce biases and 

inaccuracies that undermine its effectiveness, par -

ticularly for disadvantaged populations. 269  Inad -

equate clinical validation and weak evaluation 

frameworks hinder AI’s safe and effective use in 

patient care. 270  For example, AI’s potential in brain 

tumour or melanoma diagnosis depends on data 

quality, but the underrepresentation of certain pop -

ulations 271  can reduce its accuracy. 272  Addressing 

healthcare inequities requires unbiased data and 

overcoming biases in clinical practices and AI use. 273 

Technologies such as pulse oximeters, which overes -

timate oxygen levels in nonwhite patients, can per -

petuate disparities. 274 

# “Ensuring transparency in AI-driven decisions 

through rigorous evaluation of clinical benefits 

and compliance with methodological standards 

can prevent biases in clinical workflows 

A multistage approach focusing on fairness, trans -

parency and inclusivity can address biases in AI-driv -

en healthcare. For example, only 8 of 27 countries 

actively use AI for data mining in healthcare, ex -

posing regional biases. 275  Inclusive data sharing, 

participant-centred development and code transpar -

ency could mitigate this. 276  Ensuring transparency in 

AI-driven decisions through rigorous evaluation of 

clinical benefits and compliance with methodological 

standards can prevent biases in clinical workflows. 277 

At various stages specific interventions can ad -

dress systemic biases during data collection, handle 

missing data during preparation and reduce model 

selection bias during development. 278  Algorithmic 

audits, 279  federated learning, disentanglement tech -

niques and explainable AI would further enhance 

fairness and accountability. 280 

Addressing individual and systemic concerns 

builds trust in the use of technology in healthcare. 

Ensuring compliance with ethical standards, robust 

data management and continuous monitoring of AI 

systems fosters confidence. The competence of dig -

ital management, as demonstrated, for example, 

by Mexico’s local governments, also influences AI 

perceptions. 281 

Healthcare organizations must ensure the safe, 

transparent integration of AI technologies. Col -

laboration to cocreate AI solutions that meet re -

al-world needs, align with social values and avoid 

bias fosters public trust. Institutions should prior -

itize testing, validation, training and continuous 

monitoring of AI applications in clinical settings. 282 

They also have a responsibility to educate the pub -

lic on AI’s strengths and limitations while ensuring 

accessibility and affordability. Clear explanations 

of AI’s decisionmaking processes can enhance con -

fidence. 283  Transparency through patient notifica -

tion is crucial for maintaining the trustworthiness 

of health systems. 284  The credibility of AI profes -

sionals also influences public trust, 285  highlighting 

the need for third-party accreditation, regulatory 

guidance and AI-specific training for healthcare 

workers. 286 

At the individual level perceived utility and ease 

of use of AI and digital tools in healthcare can foster 

trust. 287  Patient attitudes towards AI are influenced 

by cultural, age and education factors, affecting adop -

tion and engagement. 288  For example, while African 

American and Latin American women in general em -

brace digital health for perinatal mental health, 289 

some demographics, such as older women in Chile, 

prefer in-person care for certain procedures. 290  In this 

sense AI systems in healthcare should be personal -

ized and patient centred, considering accessibility, 

family involvement and reminders. Trust between 

healthcare providers and patients, built on commu -

nication and competence, remains essential. 291  AI 

should enhance, not replace, human interactions, 

improving access, quality and adherence while ad -

dressing power dynamics and  patient-provider 

relationships. CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 8 5 

## The road ahead: AI’s promise to 

## advance human development 

As seen throughout this Report, AI holds consider -

able promise for enhancing human development. 

Micro- and macro-level evidence points to the po -

tential of AI-driving improvements in individual 

and aggregate learning outcomes, in public health 

and personalized medicine and in increasing work -

ers’ productivity. Yet without proper attention to 

context, today’s development gaps can be substan -

tial barriers. Where institutions are underresourced, 

technical fixes are unlikely to yield positive results 

and may, in some cases, lead to unintended or even 

harmful consequences. 292 

Development is path dependent. Countries up -

grade and diversify their productive structures by 

building on what exists at each time. 293 

The effectiveness of AI-supported transformation 

depends heavily on a country’s human development, 

economic and institutional context (figure 6.11). 

Many countries face compounded challenges. In low 

HDI countries less than 1 student in 20 has the basic 

skills to critically engage with new technologies, lim -

iting AI’s potential to enhance learning and eventu -

ally stifling possibilities for leveraging AI in work. 

Institutional capacity to integrate AI into public ser -

vice delivery is also limited in many of these coun -

tries, as reflected in low scores on the Government 

AI Index. 294  At the same time, the economic struc -

tures in many of these countries may limit the local 

economy’s potential to absorb productivity spillovers 

from AI. The economic complexity of many low and 

medium HDI countries is limited, 295  reflecting a rel -

ative lack of diversity of the economy and fewer and 

weaker links to high-value-added activities. In many 

Figure 6.11  Mind the context—initial conditions can compound development challenges 

Students with basic skills Economic complexity Artificial intelligence government preparedness 0.500 0.600 0.700 0.800 0.900 Human Development Index value (2023)  

> Source: Human Development Report Office based on data on economic complexity (defined as diversity and complexity of a country’s export basket)
> from Harvard Growth Lab (2025), data on the Government AI Index from Oxford Insights (2024) and data on the share of students with basic skills in
> mathematics and science from Gust, Hanushek and Woessmann (2024a). 1 8 6 HUMAN DEVELOPMENT REPORT 2025

of these countries, exports are concentrated in a few 

commodities 296 —often those with low labour intensi -

ty, such as mining and certain types of agriculture— 

or in activities such as call centres, which are difficult 

to upgrade. Addressing these gaps is key to moving 

towards AI-augmented human development. Action 

in all three areas –a complementarity economy, inno -

vation with intent and capabilities that count, would 

help. 

AI implementation should be properly nested in 

the local reality. It is important, particularly in low-

and middle-income countries, to avoid “vanity” AI 

projects that have few links to the prevailing patterns 

of specialization and expertise in a country. This does 

not mean giving up from the supply side of AI but 

rather seizing the opportunities of the wide availabili -

ty and customizability of generative AI while building 

native AI to the extent of each country’s capabilities 

that seizes on the country’s distinctive economic and 

cultural characteristics—not developing AI for AI’s 

sake. 

# “Realizing the potential of AI for human 

development demands policy action that is 

grounded in the human development realities 

of each country and centred around the three 

areas of action: pursuing a complementary 

economy, driving innovation with intent 

and Investing in capabilities that count 

From there countries can leverage AI to deepen 

their competitiveness and diversify their economies. 

AI has spillovers across different areas, and AI in -

vestment in one sector can spill over to other sectors 

of the economy. For instance, in Nigeria, which like 

many other resource-rich countries faces perennial 

challenges with diversification, strong AI investment 

in money, personal finance and business manage -

ment services could offer pathways towards diversifi -

cation. 297  Leveraging AI for economic diversification 

may be particularly important in lower-income econ -

omies, 298  as traditional export- and manufactur -

ing-led growth strategies become less attainable. 299 

Realizing the potential of AI for human develop -

ment requires us to move beyond unhelpful fatalis -

tic or overly optimistic narratives. It demands policy 

action that is grounded in the human development 

realities of each country and centred around the three 

areas of action proposed in this chapter: 

Pursuing a complementarity economy  implies 

strengthening the networks that facilitate produc -

tive interaction between people and AI. This begins 

by empowering workers with augmentation oppor -

tunities. Countries have several policy levers at hand. 

First, advance a broad macro-fiscal package that 

shapes incentives towards investment in labour-en -

hancing AI and addresses existing development gaps. 

Universal and meaningful connectivity as a founda -

tional enabler for AI-driven progress is key (spotlight 

6.2). Second, include workers in AI gains and govern -

ance through social dialogue, ensuring that AI-driven 

structural transformations deliver decent jobs. Third, 

strengthen social protection systems and active la -

bour market policies, including through private sec -

tor collaborations, that support those whose jobs may 

be displaced, link them to new productive opportuni -

ties and increase the supply of skilled workers. 

In innovation with intent,  harness the potential of AI 

to be the invention of a method of invention, giving 

new wings to humans’ perennial aspirations to un -

derstand and create. It also means embedding new 

directions into AI research and development—em -

powering users through creative engagement, ex -

panding AI safety, augmenting human capabilities 

through small language models and cautiously devel -

oping open source AI—can anchor human agency in 

the research and development process. This ensures 

that AI development is recalibrated to drive positive 

human development outcomes. Additionally, supple -

menting technical benchmarks with new standards 

that assess AI’s contribution to human development 

is essential. Establishing a multistakeholder coali -

tion to design and promote these benchmarks would 

ensure that AI innovations are measured not just by 

technical standards but by their capacity to advance 

human development. 

When it comes to  capabilities that count , seize AI’s 

opportunities to personalize education and medicine, 

expand access and adapt technology-enhanced ser -

vice delivery to different local realities across groups 

and development contexts. For health, AI can com -

plement scarce healthcare expertise, especially in re -

source-constrained settings. Avoid deploying AI for 

AI’s sake and instead use it to enhance and scale up 

interventions in education and health that are known CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 8 7 

to work. Ultimately, realizing AI’s potential to advance 

human development hinges on investment in people, 

not in algorithms alone. For example, moving away 

from a focus on education quantity to a stronger em -

phasis on quality and lifelong learning will be essen -

tial in equipping people to thrive in an AI-augmented 

world. AI can support such a shift, under certain con -

ditions, by providing personalized learning pathways, 

identifying gaps in understanding and offering tailored 

support for students. Broader education reforms can 

also prioritize critical, creative and systemic thinking. 

Rather than striving to make AI “better than humans” 

at various tasks, this approach would help students see 

AI as a companion—as an enabler that helps people 

achieve their goals more effectively and efficiently— 

rather than as a replacement for human skills. 

Strengthening AI skills and empowering individ -

uals to engage confidently with AI, in education, in 

health, in their work, is essential. Rather than per -

ceiving AI as an all-knowing authority that replaces 

human decisionmaking, people should be equipped 

to use it as a tool for exploration, learning and crea -

tivity. Encouraging an iterative approach—where AI 

supports problem-solving and enhances human ca -

pabilities—can foster confidence and innovation, 

ensuring that AI is seen as a complement to human 

intelligence. 300 

As AI continues to race ahead, policymakers, busi -

nesses and people are trying to keep pace. However, 

seizing the opportunities of this new era demands 

more than technological innovation. An AI-aug -

mented human development framework offers a 

way forward that is dynamic and can adapt to rapid 

technological change while being grounded enough 

to ensure that AI advances translate into meaningful 

improvements in people’s lives. 1 8 8 HUMAN DEVELOPMENT REPORT 2025 

Although humanity’s technological innovations since 

the Industrial Revolution are the primary sources of 

Earth-warming emissions fuelling the current cli -

mate crisis, scientific breakthroughs have also pro -

vided us with the necessary technological tools to 

perceive, predict and prescribe solutions to the prob -

lem. Computing performance has evolved at rough -

ly the same pace as warming temperatures in recent 

decades, representing a sort of arms race between 

planetary warming and the capacity for solution-ori -

ented research and innovation (figure S6.1.1). 

‘One can imagine a hypothetical planet whose at -

mosphere is more sensitive to the greenhouse effect, 

whereby global warming and climate destabilization 

would happen more rapidly following mass combus -

tion of fossil fuels. Had we been faced with the cur -

rent climate crises, say, 150 years ago, we would have 

lacked the scientific knowledge, international politi -

cal apparatuses and technologies needed to solve the 

problem on a global scale. However, simply having 

the technological and institutional capacity to solve 

the issue does not guarantee its solution, as the inad -

equacy of the current global response has revealed. 

Although substantial progress has been made to 

curb global emissions in recent years, we have fallen 

short of the ambitious Paris Agreement goals to limit 

> SPOTLIGHT 6.1

# The promise and peril of leveraging artificial intelligence 

# to address dangerous planetary change 

Figure S6.1.1  Computing performance has evolved at roughly the same pace as warming temperatures in recent 

decades 

1.50 1.25 1.00 0.75 0.50 0.25 0.00 –0.25 1860 1960 1980 2000 2020 10 210 410 610 810 10 10 410 610 81920 1900 1880 1940 Change in global mean surface temperature relative to 1850–1900 average (left axis) Transistors per microprocessor (right axis) Supercomputer computational capacity (floating point per operations per second) °C 

Source:  Data on global mean surface temperature for 1850–1900 from Morice and others (2021), data on transistors per microprocessor from Rupp 

(2022) and data on supercomputer computation capacity from Dongarra, Luszczek and Petitet (2003). CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 8 9 

warming to less than 1.5°C relative to the preindustri -

al baseline, 1 with the increase in global mean temper -

ature surpassing this threshold in 2024. 2

Concerted efforts must be made to innovate and 

deploy technological solutions that leverage the 

groundbreaking progress in artificial intelligence (AI) 

and machine learning, along with comprehensive 

public policies and collective action to mitigate emis -

sions and enable resilient adaptation. 

The promise of deploying AI in the Anthropocene 

In the electricity sector AI has proven a potent tool 

for predicting energy markets, reducing operation -

al costs and optimizing grid operations. AI has been 

used to reduce uncertainty in renewable energy pro -

duction for a given location by, for example, devel -

oping real-time, precise forecasts of cloud cover, 

identifying dangerous gusts or flocks of birds near 

wind turbines and improving siting and operation -

al decisions for hydro, geothermal and tidal plants. 3

Better modelling capabilities using AI have also ac -

celerated innovation, leading to safer nuclear fission 

plants and facilitating breakthroughs in research to 

harness nuclear fusion. 4

In addition to improving non–fossil fuel energy 

production, AI can enable efficiency gains and emis -

sions reductions from traditional, fossil fuel–based 

sources. Advanced aerial and satellite-based imag -

ing and chemical detection platforms can be paired 

with AI modelling to pinpoint fugitive emissions from 

power plants and pipelines. One such example is the 

MethaneSAT satellite platform, launched in 2024 to 

hunt for leaking methane—a potent greenhouse gas— 

from conveyance infrastructure and nonpoint emis -

sions such as agricultural fields. 5 AI models can also 

improve real-time diagnostics for identifying hazards 

and system malfunctions to guide preventative main -

tenance and achieve efficiency gains through the en -

tire electricity grid. This might entail using AI-driven 

image analysis and weather modelling to identify pre -

cise times and locations of high wildfire risk around 

power lines, 6 optimizing home energy consumption 

to favour renewable sources. 7 AI can also automate 

the control of distributed, decentralized and micro -

grid energy systems to improve grid resilience and 

energy access in remote areas 8 or optimize grid-scale 

energy generation for both increased reliability and 

reduced emissions. 9

In the transportation sector, which accounts for ap -

proximately 25 percent of global emissions, AI helps 

reduce greenhouse gas emissions through sustaina -

ble vehicle design, 10  cleaner materials 11  and improved 

construction of roads and related infrastructure. 12  It 

can also help identify optimal policies for reducing 

transportation emissions sectorwide. 13  Additional -

ly, the abundance of fine-grain, anonymized travel -

ler data from Global Positioning System–based apps 

allows planners to address regional challenges more 

precisely and better craft sustainable projects and 

policy. 14  The design of low-emissions vehicles, such 

as hybrid-electric and full-electric cars, has also been 

turbocharged by novel AI applications, as in the dis -

covery of battery materials 15  and greater vehicle 

range, longevity, safety and fuel efficiency. Autono -

mous vehicles extensively leverage AI algorithms and 

sensors for safe self-navigation 16  and design innova -

tion. Electric vehicles and autonomous vehicles can 

also serve as a unique source of clean power to sup -

plement the grid while they are plugged in. AI helps 

optimize how vehicle owners can satisfy their charg -

ing needs while supplying a distributed source of en -

ergy to supplement the grid, improving grid resilience 

and potentially reducing net emissions. 17 

AI can also facilitate large reductions in building 

emissions, aiding in the design of energy-efficient 

construction materials, 18  enhancing local energy de -

mand prediction and improving metering to reduce 

waste. 19  Cities have employed AI to predict build -

ing-scale ratings to target efficiency improvements. 20 

“District” heating and cooling networks across neigh -

bouring buildings can offer considerable efficiency 

gains through economies of scale and have leveraged 

AI to optimize resource management. 21 

In manufacturing and distribution AI has helped 

optimize shipping routes to increase delivery speeds 

and reduce emissions. 22  AI promises to drastically 

cut manufacturing emissions by accelerating dis -

covery of cleaner manufacturing input materials, 23 

optimizing inventory management 24  and aiding in 

three-dimensional printing of lighter manufactur -

ing components located closer to demand centres. 25 

The broad application of three-dimensional printing 

in manufacturing could reduce global total energy 

demand by as much as 27 percent by 2050. 26  More 1 9 0 HUMAN DEVELOPMENT REPORT 2025 

accurately predicting variation in markets could en -

able more precise production, reducing surplus and 

greenhouse gas footprints. 27  In food shipping, deliv -

ery and storage novel algorithms 28  have been used to 

estimate demand and more accurately predict spoil -

age, reducing net emissions. 29 

In commercial agriculture AI has improved sus -

tainable tillage practices, precision irrigation, agro -

chemical application, fertilizer synthesis from thin 

air 30  and estimation of soil nutrients and crop needs. 31 

It has enabled the design of autonomous farm vehi -

cles for more efficient application of inputs 32  and, 

when applied to remotely-sensed imagery, has en -

abled finer-scale predictions of crop-water stress, 33 

yields 34  and land-based greenhouse gas emissions, 35 

which could help reduce global emissions from the 

agricultural industry. 

Managing ecosystems sustainably can also use new 

AI tools, which have enhanced the ability to quan -

tify natural carbon stocks, 36  improved accuracy in 

carbon offset markets and closed the balance of the 

carbon cycle. 37  Advanced computer vision improves 

assessments of impacts from natural hazards such 

as floods, droughts, severe storms and fires, 38  allow -

ing for better planning and resilient adaptation. It has 

also proven effective at tracking human-influenced 

impacts to the environment, such as deforestation 

and desertification. 39  Using AI helps approximate the 

global greenhouse gas budget, especially from uncer -

tain processes such as thawing arctic permafrost, 40 

decomposing peatlands 41  and ice sheet melting, 42  im -

proving the accuracy, as well as the computational ef -

ficiency, of global climate models. 43 

New AI algorithms have also catalysed numerous 

breakthroughs in biodiversity monitoring and wild -

life biology by revolutionizing the ability to man -

age, detect, monitor and even interact with animal 

life. 44  Applied to satellite imagery, classification al -

gorithms have enabled more accurate classification 

of land cover, 45  habitat loss 46  and assessment of spe -

cies richness, extent and abundance. 47  They have 

also enabled more accurate monitoring of changes to 

critical ecosystems, 48  the spread of invasive species 49 

and even the presence of large animals, such as ele -

phants 50  and whales, 51  from space. Using ground-lev -

el images, such as those from wildlife cameras 52  or 

phone-based, citizen science applications, 53  novel AI 

applications have improved the spatial and temporal 

granularity of ecosystem monitoring, species detec -

tion and migration tracking and have even helped 

identify illegal poaching. 54 

AI classification tools have improved the identifi -

cation of specific individuals based on morphologi -

cal characteristics, such as patterns on whale flukes 55 

and primate faces. 56  Algorithms based on animals’ 

audio signatures have allowed for the identification 

of a habitat’s species diversity 57  and the presence and 

abundance of migratory birds, as well as for the deci -

phering of species’ linguistic patterns. 58  In 2023 sci -

entists claimed to have successfully conversed with 

an Alaskan humpback whale for 20 minutes, 59  and in 

2024 researchers decoded a “phonetic alphabet” used 

by sperm whales. 60  And one AI-powered phone-based 

app identifies mosquito species based on the buzz of 

their wings, alerting the user to the presence of poten -

tial disease carriers. 61  Supervised learning algorithms 

have greatly improved the predictive accuracy of taxo -

nomic habitat assessments when combined with “en -

vironmental DNA” sampling methods, whereby the 

biological composition of a given habitat is estimat -

ed based on fragments of genetic material collected 

from field samples. 62  Researchers have even deployed 

small aerial drones equipped with AI-backed sensors 

to glean relevant genetic, hormonal and water quality 

data simply by collecting mucus from the spray emit -

ted by breaching humpback whales. 63 

The peril of overreliance on technological solutions 

While we should embrace all the innovative appli -

cations of AI to curb global emissions, improve our 

scientific models and adapt to evolving hazards, we 

must not stake all our ambitions for tackling climate 

change on technological solutions alone. The expo -

nential growth in computing power, climate science 

and innovation of sustainable technology in recent 

decades has given us the necessary ingredients to 

curb emissions and adapt effectively, but the collec -

tive political will needed to implement these solu -

tions at scale is lacking. Simply investing in faster 

computer models and technological development 

will not solve the problem on its own; political action 

must be implemented in tandem. 

One of the biggest risks of deploying technology 

aimed at improving energy efficiency and resource CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 9 1 

consumption without proper oversight is the poten -

tial for rebound effects (that is, Jevon’s Paradox). 64 

Cost savings from more efficient—and marginal -

ly cheaper—transportation, agriculture or energy 

use can increase overall consumption (miles driv -

en, goods produced, energy consumed and the 

like). Evidence from dozens of studies suggests that 

economywide rebound effects following energy effi -

ciency gains exceed 50 percent, on average. 65  In other 

words, striving to improve efficiency alone, without 

monitoring its impacts on overall emissions, may not 

be sufficient. 

Rebound effects have emerged in AI as well, with 

recent computing efficiency breakthroughs for ad -

vanced large language models offering equivalent 

performance at a fraction of the prior cost and ener -

gy use. 66  But market trends suggest that this will sim -

ply boost demand for processing chips and pave the 

way for bigger, more complex large language mod -

els, in turn mitigating the marginal energy savings. 67 

The technology sector currently accounts for 2–3 

percent of global energy demand, 68  roughly on par 

with the global airline industry, but as AI computing 

grows exponentially, so do the greenhouse gas foot -

prints of major companies. 69  The computational de -

mand to fuel AI growth is estimated to double every 

100 days, 70  due primarily to the increased energy de -

mand of data centres; the global energy demand for 

these centres is forecast to increase by 160 percent in 

the next five years. 71  Water used to cool data centre 

servers has also increased dramatically and, in some 

cases, led to local water disputes. 72 

In climate resilience and adaptation AI tools have 

proven immensely helpful in targeting aid, 73  stream -

lining data integration 74  and enabling real-time and 

rapid assessments of impacts and humanitarian 

needs from extreme events. 75  But staking too much 

faith on estimates provided by these tools, especially 

if used in lieu of field-based community assessments 

of socioeconomic and physical dynamics, can perpet -

uate bias in reporting and measurement, exacerbate 

existing inequalities and compromise individuals’ 

privacy. 76  Social protection programmes for vulnera -

ble communities facing acute climate hazards should 

be expanded, using appropriate new technologies. 

However, such programmes should continue to be 

human-centred, with complementary digital tools 

used equitably, transparently and sustainably. 77 

For biodiversity and ecological monitoring the ap -

peal of new technologies risks diverting attention and 

limited funding away from traditional field-based 

research methods and community-oriented partici -

patory stewardship initiatives 78  and reducing direct en -

gagement with local stakeholders in favour of remote, 

automated data collection. 79  Although AI is expand -

ing the boundaries of ecological monitoring, enabling 

new research on understudied small, rare and seclud -

ed biota, 80  the models ultimately remain limited by 

the availability of observational data for training, in -

herently skewing their focus towards regions, habitat 

types and species where such data are abundant. 

Pairing AI climate technology 

with sound public policy 

As pressures on the global climate and ecological 

wellbeing grow in each passing year, effective solu -

tions to reduce global greenhouse gas emissions, 

adapt to hazards and conserve sensitive ecosystems 

are imminently needed. Breakthroughs in intelli -

gent computing have granted us important tools to 

conceptualize these crises on a planetary scale and 

will continue to provide critical innovations towards 

achieving a sustainable and resilient future. But mes -

sianic faith and investment in novel technologies 

alone will not solve the problem. AI in the climate 

and environmental space will enhance human devel -

opment and environmental wellbeing only if used in 

conjunction with broader social policies. 

In short, we must want to solve these problems rath -

er than simply innovating new ways to measure them 

or inventing new products and market efficiencies that 

are meant—but not guaranteed—to be solutions. If 

used well, new technologies can be an ace up our sleeve 

in the fight to safeguard our global environment. If not, 

they risk serving as false prophets, increasing the fidel -

ity with which we watch planetary pressures progress 

but ultimately diverting attention away from real solu -

tions—or even making problems worse. The way in 

which new technology will shape our world is not pre -

ordained. As with the impacts of climate change, the 

impacts of revolutionary new technologies need not 

represent an inevitable wave of disruption over which 

we bear no control. Collectively, we have the agency to 

shape our technology and, ultimately, our planet. 1 92 HUMAN DEVELOPMENT REPORT 2025 

NOTES 

1.  Allen and others 2018. 

2.  WMO 2025. 

3.  Rolnick and others 2022. 

4.  Aitken and others 2018; Seo and others 2024. 

5.  Chan Miller and others 2024. 

6.  Rhizome 2023; Kim 2023. 

7.  Choi and others 2024; Wolfe 2024. 

8.  Ali and Choi 2020; Lee and Callaway 2018. 

9.  Nagapurkar and Smith 2019; Sabzehgar, Amirhosseini and Rasouli 2020; 

Strezoski and others 2022. 

10.  Rolnick and others 2022. 

11.  Madhavaram and others 2024; Pittro and others 2024. 

12.  Arifuzzaman and others 2021; Kuenzel and others 2016. 

13.  Abduljabbar and others 2019; Li, Ren and Li 2022. 

14.  Google Research 2025; Rollend and others 2023; Schewel and others 

2021. 

15.  Ansari and others 2018; IBM 2021; Samuthira Pandian and others 2020. 

16.  Corso and others 2021; Garikapati and Shetiya 2024. 

17.  Munusamy and Vairavasundaram 2024; Pratap Singh and others 2024. 

18.  Wang and others 2023. 

19.  Knayer and Kryvinska 2022; Kwon, Lee and Kim 2022;. 

20.  Jamali, Dascalu and Harris 2024; Pham and others 2020; Tien and others 

2022. 

21.  Zhou, Zheng and Hensen 2024. 

22.  Durlik and others 2024; Riyadh 2024; Xiao and others 2024. 

23.  Chitturi and others 2024; Merchant and others 2023; Szymanski and oth -

ers 2023; The Materials Project 2024. 

24.  Plathottam and others 2023. 

25.  Verhoef and others 2018. 

26.  Verhoef and others 2018. 

27.  Ameh 2024; Dauvergne 2022. 

28.  Pannone and others 2024. 

29.  Sonwani and others 2022. 

30.  Song and others 2024. 

31.  Ennaji, Vergütz and El Allali 2023; Magesh 2025; Tanaka and others 2024. 

32.  Bergerman and others 2015; Ghobadpour and others 2019; Ghobadpour 

and others 2022. 

33.  Chandel and others 2021; Kapari and others 2024; Virnodkar and others 

2020. 

34.  Goel and Pandey 2024; Malashin and others 2024; Paudel and others 2021. 

35.  Hamrani, Akbarzadeh and Madramootoo 2020; SaberiKamarposhti and 

others 2024. 

36.  Pham and others 2021; Shivaprakash and others 2022; Szatmári, Pásztor 

and Heuvelink 2021. 

37.  Liu and others 2024b; Xiao and others 2019. 

38.  Eini and others 2020; Jain and others 2020; Javidan and others 2021; 

Park and others 2016; Prodhan and others 2022. 

39.  Boali and others 2024; Mayfield and others 2017; Raihan 2023. 

40.  Ni and others 2021. 

41.  Siewert 2018. 

42.  de Roda Husman and others 2024. 

43.  Schneider and others 2023. 

44.  Reynolds and others 2025b; Silvestro and others 2022; Tuia and others 

2022. 

45.  Helber and others 2019; Praticò and others 2021; Rolf and others 2021. 

46.  da Silveira and others 2021. 

47.  Muro and others 2022; Sun and others 2019. 

48.  Cavender-Bares, Gamon and Townsend 2020; da Silveira and others 2021. 

49.  Jensen and others 2020; Shiferaw, Bewket and Eckert 2019. 

50.  Duporge and others 2021. 

51.  Cubaynes and Fretwell 2022. 

52.  Green and others 2020. 

53.  McClure and others 2020. 

54.  Bondi and others 2018; Kamminga and others 2018. 

55.  Blount and others 2022; Khan and others 2022a. 

56.  Guo and others 2020. 

57.  Kahl and others 2021. 

58.  Andreas and others 2022; Kelling and others 2012. 

59.  McCowan and others 2023. 

60.  Sharma and others 2024. 

61.  Sinka and others 2021. 

62.  Cordier and others 2017; Cordier and others 2018; Fan and others 2020; 

Pawlowski and others 2021. 

63.  Keller and Willke 2019. 

64.  Alcott 2005. 

65.  Brockway and others 2021; Grepperud and Rasmussen 2004; Hanley and 

others 2009; Mashhadi Rajabi 2022. 

66.  Guo and others 2024. 

67.  Luccioni, Strubell and Crawford 2025; Salmon 2025. 

68.  Kemene, Valkhof and Greene-Dewasmes 2024. 

69.  Kemene, Valkhof and Greene-Dewasmes 2024. 

70.  Kemene, Valkhof and Greene-Dewasmes 2024. 

71.  Goldman Sachs 2024. 

72.  Berreby 2024. 

73.  Aiken and others 2022. 

74.  De Neubourg and others 2025.= 

75.  De Neubourg and others 2025. 

76.  De Neubourg and others 2025. 

77.  De Neubourg and others 2025. 

78.  Reynolds and others 2025b. 

79.  Reynolds and others 2025b. 

80.  Mou and others 2023; Reckling and others 2021; van Klink and others 2022. CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 9 3 

> SPOTLIGHT 6.2

# Universal and meaningful connectivity and artificial intelligence 

International Telecommunication Union 

In 1990, when the first Human Development Report 

was released, the world counted just 11 million mo -

bile phone subscriptions. These devices were limit -

ed to basic calls and text messaging, and the world 

wide web—the internet, as we know it—did not exist. 

Today, around two-thirds of the global population 

uses the internet, and there is almost one mobile 

broadband subscription per person worldwide. 1 De -

spite this progress, considerable gaps persist. 

An estimated 96 percent of the world is covered 

by a mobile broadband network enabling access to 

the internet. But an estimated 32 percent of people 

do not use the internet, and among those connected, 

many experience only basic forms of connectivity, 

with limited speeds and functionality. In least devel -

oped countries two-thirds of the population has never 

used the internet, and millions remain unaware of its 

existence. Digital divides across geographies and de -

mographic groups—whether between urban and rural 

areas, genders, generations, education levels or in -

come categories—persist. 

For instance, while 51 percent of the world’s popu -

lation is covered by a fifth-generation wireless cellular 

network, 400 million people still rely on a third-gen -

eration network to connect. In rural areas of low-

income countries almost 30 percent of the population 

remains off the grid, with no possibility to connect. 

Despite falling prices affordability remains a major 

barrier. In Sub-Sharan Africa people in low-income 

countries spend about 5 percent of their income for 

an entry-level mobile data plan—14 times what peo -

ple in Europe spend. And the average mobile broad -

band traffic  per subscription for an entire month in 

low-income economies (2 gigabytes) is consumed in 

less than four days in high-income countries. 

Connectivity is not merely about being online. It 

creates education, healthcare, communication and 

economic opportunities while fostering creativity, in -

novation and collaboration. 2 But basic connectivity 

alone cannot unleash the full potential of the digital 

world, nor can it support the demands of emerging 

technologies such as artificial intelligence (AI). 

AI systems rely on vast amounts of data and com -

putational resources, both of which are intrinsi -

cally linked to connectivity. High-speed internet is 

essential for transferring and processing the exten -

sive datasets that AI models require for training and 

operation. Moreover, advanced AI applications, such 

as natural language processing, image recognition 

and predictive analytics, depend on cloud computing 

infrastructure, which itself relies on high-quality, reli -

able connectivity. 

Beyond development, connectivity underpins the 

practical deployment of AI in ways that can enhance 

lives. Telemedicine platforms use AI to diagnose 

illnesses remotely, requiring secure and robust con -

nections to transmit sensitive medical data. 3 Farmers 

in rural areas access AI-driven tools for crop manage -

ment and weather forecasting, relying on mobile net -

works to receive timely insights. 4 Education systems 

use AI-powered applications to personalize learning. 5

The current state of connectivity, characterized 

by deep divides, risks creating a multispeed digital 

world. In such a scenario a privileged few, equipped 

with the necessary infrastructure, skills and resourc -

es, dominate AI innovation and reap its rewards. At 

the same time, marginalized communities struggle 

with limited or no access to the tools needed to par -

ticipate in this new digital era. Without universal and 

meaningful connectivity the divides of the analogue 

world are at risk of being magnified in the digital one. 

Recognizing these challenges, the concept of uni -

versal and meaningful connectivity has emerged as 

a critical policy objective. It is defined as enabling 

everyone to enjoy a safe, enriching and productive 

online experience at an affordable cost. 

Universal and meaningful connectivity does not 

mean that everyone must be connected all the time. 

Instead, it is a situation where everyone can access 

the internet optimally and affordably whenever and 1 9 4 HUMAN DEVELOPMENT REPORT 2025 

wherever needed. Individuals choose how to use this 

opportunity. 

The universal and meaningful connectivity frame -

work has six dimensions: quality (of connection), 

availability (for use), affordability, security, devic -

es and skills. The dimensions are interdependent; 

strength in one area cannot compensate for deficien -

cies in another. Achieving universal and meaningful 

connectivity thus requires holistic strategies relying 

on various interventions spanning infrastructure, 

policies and education and involving different stake -

holders. But the framework is deliberately agnostic 

about specific interventions—investment, policies or 

regulation—as there is no single pathway and no one-

size-fits-all strategy to achieve universal and mean -

ingful connectivity. It is also agnostic about what 

people use connectivity for—that is, its applications. 

The neutrality of use cases is paramount: it is impos -

sible to prescribe an ideal digital behaviour. 

Since universal and meaningful connectivity was 

formulated in 2021, it has garnered much attention. 

In 2022 the International Telecommunication Union 

(ITU) made it a strategic goal in its 2022–2026 Stra -

tegic Plan. In 2023, recognizing the criticality of 

measurement in achieving universal and meaningful 

connectivity, the European Union provided the ITU 

with funding to promote the concept and improve its 

measurement,. 6 In 2024, under the Brazilian Presi -

dency of the Group of 20, the group’s ministers of dig -

ital economy adopted a joint declaration committing 

to achieving universal and meaningful connectivity. 7

The UN Global Digital Compact acknowledges the 

pivotal role of universal and meaningful connectivity 

in unlocking the full potential of digital and emerging 

technologies. 8

While universal and meaningful connectivity of -

fers transformative potential, one must recognize 

the dangers of connectivity. Unchecked expansion of 

the digital sphere can exacerbate issues such as mis -

information, digital surveillance and cybersecurity 

threats. 9 Digital infrastructure, including energy con -

sumption and e-waste, has a major environmental 

impact. 10  Policies promoting universal and meaning -

ful connectivity must therefore include safeguards to 

mitigate these risks and ensure that connectivity ad -

vances human development. 

Just as electricity transformed societies as a gener -

al purpose technology, connectivity now plays a simi -

lar role. However, its impact on human development 

hinges on how inclusive and meaningful that connec -

tivity is. As the world seeks to leverage AI and other 

advanced technologies for inclusive growth, univer -

sal and meaningful connectivity represents a policy 

imperative. 

NOTES                  

> 1. Unless indicated otherwise, all data in this spotlight are estimates for
> 2024 from ITU (2024b). See the International Telecommunication Union
> datahub at https://datahub.itu.int/.
> 2. ITU 2023b.
> 3. ITU 2021.
> 4. ITU and FAO 2021.
> 5. Khan 2024.
> 6. ITU n.d.
> 7. See Digital Economy Working Group and others (2024).
> 8. See ITU (2023c) and UN (2024).
> 9. ITU 2023a.
> 10. ITU 2024a. CHAPTER 6 — R EIMAGINING CHOICES : T OWARDS ARTIFICIAL INTELLIGENCE –AUGMENTED HUMAN DEVELOPMENT 1 9 5

Employers are adopting or refining artificial intel -

ligence (AI) and algorithm-based tools in the work -

place, with transformative impacts on work and 

employment. 1 In an International Labour Organiza -

tion working paper we examined case studies of so -

cial dialogue over AI and algorithmic management 

in different countries and industries. 2 Our analysis 

suggests that social dialogue is most effective in es -

tablishing a more socially equitable and sustainable 

approach to AI investment when it moves employers 

towards strategies that take a longer-term view on 

returns from the investment. This means commit -

ting to creating good jobs with benefits and security, 

sharing productivity gains with workers, investing in 

skills and worker discretion, limiting invasive data 

collection and monitoring, and establishing fair and 

transparent opportunities for workers to challenge 

and change technology-enabled decisions. Where 

worker representatives have engaged in social di -

alogue over AI, they have sought to institutionalize 

these commitments in collective agreements, laws 

and policies. 

This spotlight summarizes the findings of our 

analysis of social dialogue cases at the industry and 

company level. The findings are organized around 

three action fields in which worker representatives 

have sought to influence strategies and outcomes as -

sociated with the growing use of AI and algorithms in 

the workplace: social dialogue over the employment 

and skill impacts of AI, social dialogue over algorith -

mic management and social dialogue over working 

conditions and rights in the AI value chain. 3 It con -

cludes with a discussion of three factors that played 

an important role in supporting successful social di -

alogue: negotiated or legal constraints on employ -

er exit from employment relationships, institutions 

and resources that support collective worker voice in 

organizational decisionmaking and labour strategies 

based on inclusive forms of solidarity. 

Social dialogue over the employment and skill impacts 

of AI: From labour replacing to labour complementing 

New AI- and algorithm-based tools can be applied to 

automate jobs and tasks in a way that leads to down -

sizing or replacement of workers and their skills. 4

These tools may also contribute to deskilling work, 

allowing the downgrading of jobs to more repetitive 

or lower-value tasks. Alternatively, these tools can 

complement or augment workers’ skills and help 

them develop new skills and modes of working. 5

Management decisions play an important role in en -

couraging labour-complementing AI investment—for 

example, giving workers discretion over how they use 

tools or restructuring production in a way that creates 

new, high-productivity tasks. 6

Through social dialogue labour unions and other 

worker representatives can encourage employers to 

use AI in ways that complement and upskill rather 

than replace and deskill work. Collective agreements 

can discourage a narrow labour-replacing approach 

to AI through job and location security agreements, 

restrictions on permitted uses of AI and rules con -

cerning ownership of and control over creative work 

and images. For example, in the Republic of Korea 

the unions at KB Bank led a successful campaign to 

reverse layoffs of subcontracted call centre workers 

associated with the increased use of AI chatbots. In 

Canada and the United States screen writers, actors 

and journalists have negotiated agreements with 

rules concerning how AI can be used in writing and 

editing and disclosure of AI-generated material, as 

well as protections concerning the use of AI-generat -

ed replicas of human performers. 

Social dialogue has also actively encouraged la -

bour-complementing strategies by establishing new 

rules or joint efforts to invest in skills upgrading to im -

prove workers’ control over how they apply their skills 

when using AI-based tools and to share AI-generated 

> SPOTLIGHT 6.3

# Global case studies of social dialogue on 

# artificial intelligence and algorithmic management 

Virginia Doellgast, Shruti Appalla, Dina Ginzburg, Jeonghun Kim, Wen Li Thian , Cornell University School of Industrial  and 

Labor Relations 1 9 6 HUMAN DEVELOPMENT REPORT 2025 

productivity gains with the workforce. In Japan so -

cial dialogue between the Aeon Group and its labour 

federation established a productivity improvement 

subcommittee under a labour–management coun -

cil to support joint decisionmaking on AI and digital 

transformation initiatives. Agreements secured job 

security and redeployment of workers to higher-val -

ue-added areas and redistributed productivity gains 

through wage increases for the majority part-time 

workforce and for entry-level jobs. In Brazil a nation -

al collective agreement in the banking sector includ -

ed provisions for reskilling in the face of technologies 

such as AI, with a focus on mitigating gender inequal -

ity. Banking employers agreed to finance scholarships 

for women to take information technology courses, 

with priority given to women facing socioeconomic 

vulnerability. 

Deutsche Telekom in Germany has one of the most 

comprehensive agreements establishing both job se -

curity and investment in upskilling, underpinned by 

worker voice. A 2010 agreement states that automa -

tion should first be used to reduce subcontracting and 

commits the employer to train internal employees af -

fected by automation for new jobs. In the mid-2010s 

the works council organized an eight month project to 

analyse the impact of new digital and algorithm- and 

AI-enabled tools on worker skills, jobs and perfor -

mance. Based on the findings, a series of agreements 

was negotiated that established a process for ongoing 

consultation and negotiation over new technologies 

and their workforce impacts. Management commit -

ted to drawing up a digital roadmap with planned 

digitalization measures and to discussing with the 

works council the impacts on employment numbers, 

service quality and work content. This feeds into 

strategic planning on new agreements for specific 

technologies. 

Social dialogue over algorithmic management: 

From labour controlling to labour empowering 

Management itself is being transformed by AI- and 

algorithm-based tools. AI is used in predictive or 

human resources analytics to hire new workers, de -

termine training needs and allocate work. AI is also 

used to recognize patterns recorded or gathered 

through diverse electronic data sources to evaluate 

performance—for example, through AI-enabled cam -

eras, wearable devices and voice recordings applying 

speech analytics. These tools can be used to inten -

sify surveillance and discipline and to reduce work -

ers’ control over the pace and content of their work. 7

They can also contribute to or reproduce biased de -

cisions with considerable employment impacts, such 

as hiring or firing. 8 At the same time, algorithmic 

management technologies may empower workers by 

giving them more control over working methods and 

schedules or improving transparency in management 

decisionmaking. 9

Social dialogue with unions and other worker rep -

resentatives has focused on reducing the risks as -

sociated with intensified control and bias and on 

improving worker voice in algorithmic management 

decisions. First, agreements have established base -

line workers’ rights to data protection and informa -

tion on how their data are used. Second, they have 

limited monitoring intensity from new AI-based tools 

and encouraged the use of performance data to im -

prove skills rather than to discipline workers. Third, 

agreements have established human-in-command 

principles, where final decisions on employment-re -

lated matters require human oversight, underpinned 

by AI ethics commitments. 

Different combinations of these focus areas can 

be seen across case studies. For example, IBM Ger -

many negotiated a 2020 agreement on the use of AI 

systems with its works council that classifies AI ap -

plications based on their risk and prohibits the use 

of AI for automated decisions with immediate ef -

fects on employees without human oversight. It also 

established an AI ethics council made up of AI ex -

perts and employer and employee representatives 

to evaluate AI applications and oversee implemen -

tation of the agreement. An agreement in the Span -

ish banking sector established worker rights to not 

be subject to decisions based solely and exclusively 

on automated variables, to nondiscrimination and 

to request human oversight and intervention. In 

the United Kingdom an agreement at Parcelforce 

established that delivery drivers have a right to pri -

vacy and that new technology will not be deployed 

as a disciplinary tool. At UPS in the United States, 

driver-facing cameras are not allowed, and GPS, 

telematics and cameras cannot be used as the sole 

basis for discipline. In the Dominican Republic and CHAPTER  6 — R EIMAGINING  CHOICES : T OWARDS  ARTIFICIAL  INTELLIGENCE –AUGMENTED  HUMAN  DEVELOPMENT  1 9 7 

India unions in the business process outsourcing in -

dustry have mobilized to improve data transparency 

and establish limits on the use of AI for sentiment 

analysis and intensified surveillance. These differ -

ent agreements place clear limits on the use of high-

risk tools while improving transparency and worker 

trust. 

In the United States a 2018 union agreement with 

34 Las Vegas casino resorts included a process to 

bargain over the implementation of new technolo -

gy. In one example the union used these rights, as 

well as worker mobilization and innovative data 

analysis, to challenge and eventually change the 

use of an algorithm-based app that was used to dic -

tate the room cleaning order to housekeeping staff. 

In dialogue with the app’s developer, the workers 

and the employer agreed to contract provisions that 

restored worker autonomy and discretion and made 

it easier for the union to monitor workload viola -

tions. A partnership with the developer and the Cu -

linary Academy of Las Vegas, funded through the 

union contract, provided training on the software to 

encourage more effective use of the app. The 2023 

contract included rights to privacy from tracking 

technology, to bargain over technology that tracks 

employee locations, to notification and bargaining 

over data sharing with a third party, to healthcare 

and severance pay for workers laid off due to new 

technology and to compensation for tipped employ -

ees if a technology failure makes it impossible for 

them to do their job. 

Social dialogue over working conditions 

and rights in the AI value chain: From 

labour displacing to labour embedding 

The AI value chain to produce and refine AI-based 

technologies has created a new set of jobs in data 

coding, labelling and engineering that are organized 

across borders in different countries, often with low 

pay and tight controls. 10  AI data work is organized 

through subcontractors that employ workers in phys -

ical workplaces and through microwork organized 

over platforms. It can be described as an example of 

AI-enabled fissuring, as firms develop more sophisti -

cated AI-based tools to monitor performance and dis -

tribute work across a spatially dispersed workforce, 

organized across vendors, platforms or freelance em -

ployment contracts. This in turn permits the displace -

ment of jobs from organizations and employment 

contracts with established social protections and col -

lective agreements. Different from labour-replacing 

impacts, in which technology directly replaces tasks 

or jobs, labour-displacing applications of AI permit 

organizations to move work to new (often more poor -

ly regulated or lower-paid) contracts, organizations 

or locations. 

The focus of social dialogue efforts in the AI value 

chain has been to embed or re-embed AI-related 

jobs in labour and social protections that have been 

displaced from those protections. Labour union or -

ganizing and social dialogue in this area have taken 

two—sometimes connected—forms. The first re -

lies on solidarity from unions in lead firms, as core 

technology professionals with more secure con -

tracts seek improved conditions for more precar -

ious contract or platform workers. In the United 

States unions have organized workers at technolo -

gy, media and game development firms, including 

Alphabet, the parent company of Google. One key 

focus of union action at Alphabet has been improv -

ing conditions among the company’s more precar -

ious majority temporary, vendor and contractor 

workforce. Union members have mobilized to sup -

port reinstatement, increased pay and benefits, and 

unionization. 

The second form of social dialogue to improve 

conditions in AI value chains relies on organizing 

by workers in more precarious AI-related jobs. In 

Kenya workers who annotate data and moderate 

content have sought to mobilize to improve condi -

tions. This included bringing legal cases against the 

subcontractor Sama and its client firms for alleged 

workers’ rights violations, including exploitation, 

union busting, illegal termination of contracts and 

pay discrimination. In 2023 a union was formed to 

represent workers at a range of contract firms that or -

ganize AI-related data janitorial services. The union 

has partnered with local civil society organizations, 

as well as international organizations working to 

create ethical standards for AI deployment. These 

initiatives aim to influence policies at the national 

and international levels, including transparency, fair 

compensation and protections against algorithmic 

exploitation. 1 9 8 HUMAN DEVELOPMENT REPORT 2025 

Conclusion 

The findings demonstrate a range of creative AI-fo -

cused social dialogue initiatives across three action 

fields: skills and employment, algorithmic manage -

ment and working conditions in AI value chains. 

Three factors played an important role in supporting 

these initiatives: negotiated or legal constraints on 

employer exit from employment relationships, insti -

tutions and resources that support collective worker 

voice in organizational decisionmaking and labour 

strategies based on inclusive solidarity. 11 

In the cases reviewed, strong employment pro -

tections and skill investment were central goals that 

made it more difficult or less desirable for firms to exit 

their internal workforce through downsizing, deskill -

ing or outsourcing. Laws establishing clear rules and 

copyright protections on the use of generative AI to 

reproduce art, voice or images are one example. Col -

lective agreements across countries provided job se -

curity, commitments to decrease subcontracting or 

support for retraining and redeploying workers. 

Support for collective worker voice took different 

forms. Strong participation rights and laws, unions 

and tripartite social dialogue traditions were critical 

resources for negotiating AI-focused agreements. 

Data protection laws and agreements were used to 

limit worker surveillance and provide information on 

what data were collected on workers or how the data 

were used. And bright line prohibitions of certain 

uses of AI to automate human resources decisions or 

of sentiment analysis tools could help establish more 

transparent workplace rules. In many cases worker 

mobilization, sometimes through strikes, were cru -

cial in bargaining to establish or extend protections to 

AI-based tools. 

Finally, strategies of inclusive labour solidarity 

helped ensure that the most vulnerable workers in 

easily rationalized or monitored jobs were included 

in social dialogue efforts. The negative impacts of 

AI bias and invasive algorithmic management prac -

tices are heavily concentrated among workers who 

also tend to hold more precarious contracts. Labor 

solidarity has been crucial in AI value chains for ex -

tending bargaining power and building a strong 

movement of workers in more and less precarious en -

gineering, programming and data labelling jobs. 

These three factors—constraints on employer 

exit, support for worker voice and strategies of in -

clusive labour solidarity—were present in differ -

ent combinations across the case studies of social 

dialogue on AI. However, worker representatives 

in these cases also sought to strengthen minimum 

standards and worker voice in decisionmaking by 

establishing new laws, policies and collective agree -

ments. These solidaristic organizing and mobiliza -

tion efforts are an important first step in promoting 

alternative high road approaches to AI investment 

that are designed by the workers most directly af -

fected by the technologies. 

NOTES            

> 1. AI refers to computer systems that can perform tasks traditionally requir -
> ing human intelligence, including advanced pattern recognition and
> problem solving (Russell and Norvig 2021.).
> 2. The case study examples in this spotlight are from our International
> Labour Organization Working Paper (Doellgast and others forthcoming),
> where they are described in more detail. We use the International Labour
> Organization’s definition of social dialogue, which includes “all types of
> negotiation, consultation or simply exchange of information between,
> or among, representatives of governments, employers and workers,
> on issues of common interest relating to economic and social policy.
> [….] Workplace cooperation, collective bargaining at company, sector or
> cross-industry levels, and tripartite consultation processes are common
> forms of social dialogue” (ILO 2025).
> 3. Doellgast 2023.
> 4. Eloundou and others 2024; Frey and Osborne 2017.
> 5. Gmyrek, Berg and Bescond 2023.
> 6. Acemoğlu and Restrepo 2020; Zysman and Nitzberg 2024.
> 7. Rani, Pesole and Vázquez 2024.
> 8. Ajunwa 2023.
> 9. Jarrahi, Möhlmann and Lee 2023.
> 10. Muldoon, Graham and Cant 2024.
> 11. Doellgast 2022. 1 9 9

# Notes 

# and 

# references NOTES  2 0 1 

# Notes 

OVERVIEW 

1 The belief that virtually any problem has a 

technological solution. 

2 Hoffman and Beato (2025) provide a per -

spective on the opportunity side of AI if it is 

designed for human agency. 

3 Galaz 2025. 

4 The United Nations Development Programme 

survey on AI and Human Development is one 

of the world’s largest public opinion surveys 

on AI in the past three years. From November 

2024 to January 2025, more than 21,000 peo -

ple in 21 countries and 36 languages were sur -

veyed, representing 63 percent of the world’s 

population. These 21 countries were selected 

to provide results covering different Human 

Development Index groups and regions of the 

world. The survey primarily employed random -

ized telephone polling to ensure broad reach 

across varied populations (with web polling 

used in two countries). The 19 questions in the 

survey capture how AI is influencing daily life, 

shifting decisionmaking power and redefining 

public confidence in technology. 

5 The very high HDI threshold value is 0.800. 

6 The loss of steam in global progress could 

indicate a lower trend going forward. Health in -

dicators, particularly life expectancy at birth, are 

increasing more slowly, with an annual increase 

of about 0.130 a year for 2023–2024, compared 

with 0.267 a year for 1990–2019. This slower 

trend for life expectancy at birth is projected to 

continue in the coming decades (2025–2050). 

The world could have attained very high HDI 

status by 2030 if global HDI values had con -

tinued to follow the pre-2020 trend. However, 

based on the 2021–2024 trend, achieving very 

high HDI status has been postponed by three 

years, to 2033. If the 2023–2024 trend persists, 

the delay may extend to three decades. 

7 Rodrik and Sandhu 2024; Stiglitz 2021. 

8 Rodrik and Stiglitz 2024. 

9 Acemoğlu, Autor and Johnson 2024; Autor 

2024; Rodrik and Stiglitz 2024. 

10  Ludwig and Mullainathan 2024. 

11  Huang and others 2025; Li and others 2023. 

12  Acemoğlu and Johnson 2023. 

13  Autor 2022; Baily, Brynjolfsson and Korinek 

2023; Bresnahan 2024; Brynjolfsson 2022b; 

Korinek 2024; Manyika and Spence 2023. 

14  This is a simple unweighted average; each 

country’s average response carries equal 

weight. 

15  Among respondents who expect AI to change 

their jobs, the majority expect both augmen -

tation and automation. Among respondents 

who expect only either augmentation or 

automation, roughly twice as many expect 

augmentation as expect automation. 

16  See, for example, Conboye (2025), who 

found that close to 60 percent of respondents 

under age 35 in China, Indonesia and Peru 

said that AI would make their job better in the 

next five years, compared with less than 30 

percent in Canada, Japan and the Republic of 

Korea, based on data from the 2024 Ipsos AI 

Monitor (Carmichael 2024). 

17  Cui and Yasseri 2024. 

18  For example, addressing AI biases in health 

applications requires better algorithms and 

data, but coding alone will not redress biases 

(Marwala 2024). This in part because biases re -

quire constant attention and monitoring, given 

that fairness considerations are context specific 

and dynamic (Mienye, Swart and Obaido 2024). 

19  Adapa and others 2025; Dangi, Sharma and 

Vageriya forthcoming; Zuhair and others 2024. 

20  Labadze, Grigolia and Machaidze 2023. 

21  Alzate 2023; Pedro and others 2019; Vincent-

Lancrin and Van der Vlies 2020. 

22  Drolia and others 2022; Government of 

Mexico 2020. 

23  Blanchflower 2021. 

24  Blanchflower, Bryson and Xu 2024. 

25  Blanchflower 2025. 

26  Thiagarajan, Newson and Swaminathan 2025. 

27  Thompson 2024. 

28  Touzet 2023. 

29  Consider Google Relate, a free mobile ap -

plication that can support communication 

between people with communication dis -

abilities and strangers. Making it work well 

is contingent on changes in communication 

norms—through, for instance, greater ac -

ceptance of diverse ways of communicating. 

Speech recognition can change the dynamic 

of the conversation, including adding pauses 

and altering the flow of an exchange. If the 

other person in the conversation does not 

understand or refuses to accept these “new 

rules,” the interaction will fail (Ayoka and oth -

ers 2024). 

30  Deep gender gaps in the use of generative AI 

persist even when access to AI is enhanced 

(Otis and others 2024). 

31  Brynjolfsson 2022a; US National Academies 

of Sciences and Medicine 2024. 

32  Autor 2024. 

33  Autor and others 2024; Crafts 2021b; Ernst, 

Merola and Samaan 2019. 

34  Bastian and others 2024; Higgins and others 

2021; Liu and others 2024. 

35  Hatherley 2020. 

36  Dvijotham and others 2023. 

37  Brynjolfsson, Li and Raymond 2025. 

38  Noy and Zhang 2023. 

39  Peng and others 2023. 

40  Dell’Acqua and others 2023. 

41  Agrawal, Gans and Goldfarb 2023; Kanazawa 

and others 2022. See also Kanazawa and 

others (2022). Whether these sector-specific 

effects extend to the whole economy is un -

known as of now. 

42  Babina and others 2024. 

43  Wilson, Daugherty and Bianzino 2017. 

Explainer calls for translational expertise, 

so that outputs from AI can be evaluated 

and assessed before being incorporated 

into decisionmaking. AI hallucinations and 

human-AI miscommunications are certain to 

create value for having a human with “skin 

in the game” somewhere between prompt 

and implementation. Trainer encompasses 

new tasks such as prompt engineering and 

retrieval-augmented generation. Having AI 

accomplish tasks for humans, making the 

most out of AI, will require humans writing 

prompts and customizing models for domain-

specific applications—already on ChatGPT 

there are hundreds of thousands of domain-

specific applications created by humans 

(Korinek and Vipra 2024). Sustainer encom -

passes tasks associated with keeping up with 

AI progress and ensuring that both skills and 

organizational processes make the most of 

the opportunities as they evolve over time. In 

the example above radiologists have taken 

on the tasks of explainer and sustainer, even 

as AI has augmented the task of diagnosis. 

44  J-PAL 2023; Lipowski, Salomons and Zierahn-

Weilage 2024. 

45  UN and ILO 2024. 

46  UN and ILO 2024. 

47  For example, Cazzaniga and others (2024) 

find that higher educated workers in high-

income economies are better positioned to 

harness generative AI for work augmentation 2 02 HUMAN DEVELOPMENT REPORT 2025 

and have more access to and an easier time 

transitioning to roles where generative AI is 

likely to enhance their work. 

48  Gmyrek, Winkler and Garganta 2024. 

49  Acemoğlu and Johnson 2023. 

50  To be clear, the argument is about comple -

mentarity between humans and AI in the cre -

ative process, not replacing human creativity 

with machines, which even if it were feasible, 

would not be desirable from a human devel -

opment perspective. 

51  Cockburn, Henderson and Stern 2019; Crafts 

2021a; US National Academies of Sciences 

and Medicine 2024. 

52  Binz and others 2025; Delgado-Chaves and 

others 2025; Luo and others 2024; Musslick 

and others 2025. 

53  Along the lines of the complementarity be -

tween humans and AI discussed in Felin and 

Holweg (2024). See also Dubova, Galesic and 

Goldstone (2022). 

54  Adam 2023; Epstein and others 2023. For 

example, AI that defeated humans at games 

such as chess by learning to play the games 

themselves is now inspiring chess grandmas -

ters with nonhuman moves that make them 

more creative (Schut and others 2025). 

55  Acemoğlu 2024. 

56  Eriksson and others 2025. 

57  Wang, Hertzmann and Russakovsky 2024. 

58  Schmid and others 2025. 

59  Dennis 2024. 

60  Esmaeilzadeh (2024) report an ongoing cul -

tural shift in healthcare, with AI being increas -

ingly viewed as a delivery enhancer and job 

creator rather than as a threat. 

61  Perhaps analogous to the way that pharma -

ceuticals are deployed and monitored, as 

suggested in Belenguer (2022). 

62  Consider the seminal works in economics by, 

for example, Romer (1994, 1990) and Solow 

(1956), who show that productivity growth 

hinges on knowledge and technological 

change. 

63  Johnson and Acemoğlu 2023. 

64  Verhoogen 2023. 

65  Diouf and others 2024; Mishra and others 

2023. 

66  Wei, Jörg and Rolf 2024. 

67  Allen and others 2025; Shahriar and others 

2025. 

68  Swartz, Denecke and Scheepers 2023; Wal -

ton 2022. 

CHAPTER 1 

1 Mitchell 2025. 

2 As explored in Korinek and Suh (2024). 

3 Bengio and others 2024; Harari 2024; Müller 

and Bostrom 2026; Ord 2020. There is wide 

disagreement about the extent to which AI 

poses existential risks, with experts unable to 

agree even on what kind of evidence would 

suggest whether those risks may emerge or 

how likely they would be (Rosenberg and oth -

ers 2024). On the potential tradeoffs between 

leveraging AI for growth and addressing 

possible existential risks, see Jones (2024), 

who finds that if AI reduces mortality, it would 

still make sense to take existential risks (see 

also C. I. Jones 2025). One concern is that AI 

can self-replicate without human intervention, 

with some studies suggesting that this frontier 

may have already been surpassed (Pan and 

others 2024). However, using AI to improve AI 

is already widely practiced; it actually extends 

to the pre-AI era of software development. 

Narayanan and Kapoor (2024b) argue that 

what gives humans power is not intelligence 

as such but our ability to work together with 

technology, so more-powerful technology 

makes us more, not less, powerful. In addition, 

there are technical challenges in being able 

to estimate AI-related risks, as reviewed in 

Narayanan and Kapoor (2024a). 

4 For a comprehensive review of the state of 

AI and its future at the time of writing, see 

AAAI (2025), and for a media summary, see 

B. Jones (2025). Evidence suggests that one 

gap in AI adoption is a lack of understand -

ing of its capabilities and limitations (see 

Cucio and Hennig 2025 for the case of the 

Philippines). 

5 This is inspired by Narayanan and Kapoor 

(2024b, p. 285). 

6 Bradford 2023; Bradford, Waxman and Li 

Forthcoming; Lang and others 2024; Olson 

2024; Suleyman 2023. 

7 Bengio and others 2025; Gerundino and oth -

ers 2024; UN 2024. 

8 See the B-Tech project from the United 

Nations Office of the High Commissioner 

for Human Rights, which provides guid -

ance into the regulation and operation of 

technology companies, grounded on the 

UN Guiding Principles on Business and 

Human Rights (https://www.ohchr.org/en/ 

business-and-human-rights/b-tech-project ). 

9 Hoffman and Beato (2025) also provide a 

perspective on the opportunity side of AI if it 

is designed for human agency. 

10  The lack of productivity gains from just substi -

tuting one general-purpose technology with 

another while keeping everything else the 

same occurred when electric motors became 

available in the late 19th century. When facto -

ries simply replaced steam-powered engines, 

the expensive switch did not yield any pro -

ductivity gains, and many firms decided not to 

adopt the new technology. (Interestingly, the 

same delay happened when steam power 

became available in the early 19th century, 

and many factories decided not to replace 

waterpower: while steam power became 

available around 1830, by the beginning of 

the 20th century, only 40–50 percent of 

US mills had adopted it; Hornbeck and oth -

ers 2024). It was not until several decades 

later that a reorganization of production 

harnessed the potential of electric motors. In 

this reorganization multiple electrical motors 

were attached to each machine in a factory 

spread out horizontally on a single floor. This 

replaced steam-engine production in which a 

factory used only one source of power in a tall 

building, with machines linked to that single 

source of power through shafts and cables 

(David 1990). 

11  Declining production costs due to technologi -

cal innovation tend to translate into higher net 

income for consumers, and technological 

innovation improves welfare through, for ex -

ample, hedonic effects, which are no less real 

for being difficult to measure. We are grateful 

to David Zuluaga Martínez for suggesting 

these mechanisms at play. 

12  Nordhaus 2004. The study refers to the US 

economy and estimates that between 1995 

and 2000 new digital firms appropriated only 

$400 billion of the $6 trillion increase in social 

value created by digital firms and that inves -

tors’ overestimates of the extent to which 

firms could appropriate innovations might 

have led to the rapid increase in stock market 

valuations and subsequent collapse (the so-

called tech bubble) of the 1990s. Adding new 

features such as a camera to a smartphone 

generates value to consumers an order of 

magnitude greater than what they pay (Bryn -

jolfsson and others forthcoming). See also 

Brynjolfsson, Kim and Oh (2024). 

13  Brynjolfsson and others 2023. The lower 

share in very high HDI countries is consis -

tent with results from other surveys showing 

higher expected AI use in middle-income 

countries. 

14  The United Nations Development Programme 

survey on AI and Human Development is one 

of the world’s largest public opinion surveys 

on AI in the past three years. From November 

2024 to January 2025, more than 21,000 

people in 21 countries and 36 languages 

were surveyed, representing 63 percent of 

the world’s population. These 21 countries 

were selected to provide results covering 

different HDI groups and regions of the world. 

The survey primarily employed randomized 

telephone polling to ensure broad reach 

across varied populations (with web polling 

used in two countries). The 19 questions in the 

survey capture how AI is influencing daily life, 

shifting decisionmaking power and redefining 

public confidence in technology. “ 

15  Close to 60 percent of respondents under 

age 35 in China, Indonesia and Peru said that 

AI would make their job better in the next five 

years, compared with less than 30 percent 

in Canada, Japan and the Republic of Korea 

(Conboye 2025 using data from Ipsos AI 

Monitor 2024 for 32 countries;  https://www. 

ipsos.com/en-us/ipsos-ai-monitor-2024 ). 

16  Autor 2022; Baily, Brynjolfsson and Korinek 

2023; Bresnahan 2024; Brynjolfsson 2022; 

Korinek 2024. 

17  On the narrowing of past development 

pathways and the need to reinvent new ap -

proaches, see Rodrik and Sandhu (2024) and 

Stiglitz (2021). On the historical importance of 

manufacturing in creating jobs at scale, par -

ticularly for low-skilled workers, and in driving 

economywide productivity growth, see Rodrik 

(2012). On the role of manufacturing in reduc -

ing poverty, see Erumban and de Vries (2024). 

Part of the appeal of manufacturing is that NOTES  2 0 3 

the products are tradable, so some—though 

not all—of the advantages of manufactur -

ing could be extended to tradable services 

(Inklaar, Marapin and Gräler 2024). To lever -

age tradables, it is important to be able to 

export to international markets to avoid being 

constrained by (potentially small) domestic 

markets; see Goldberg and Reed (2023). 

18  Diao and others 2024; Rodrik 2015; UNCTAD 

2024. On how the transition to services un -

folded in India, see Fan, Peters and Zilibotti 

(2023). Kruse and others (2023) report an 

increase in manufacturing in some low- and 

middle-income countries but still conclude 

that further employment opportunities in 

manufacturing are likely to be constrained 

by automation, which is the key point that 

will be elaborated later in the chapter. Her -

rendorf, Rogerson and Valentinyi (2022) 

show that, contrary to what is often assumed, 

productivity in services is higher in low- and 

middle-income countries than in high-income 

countries, unlike productivity in both agricul -

ture and services, which is lower and showing 

increasing gaps. Chen and others (2023a) 

show that since 2005 productivity increases 

in China have been higher in services than in 

manufacturing. On how structural transforma -

tion can unfold without industrialization, see 

Jing and Foltz (2024) for Côte d’Ivoire and 

McCullough (2025) for Tanzania. 

19  Acemoğlu, Autor and Johnson 2024; Autor 

2024; Rodrik and Stiglitz 2024. 

20  Caballero and others (2025) provide a com -

pelling illustration that digital innovation on 

its own does not improve access to credit in 

small firms in emerging economies. 

21  Bresnahan 2024; Gollin and Kaboski 2023. 

22  Computational machines are those able to 

access, process and act on abstract informa -

tion (Brynjolfsson and Hitt 2000; US National 

Academies of Sciences and Medicine 2024). 

23  Following Sendhil Mullainathan and col -

leagues (Ludwig, Mullainathan and Ram -

bachan 2025). 

24  For example, the large language model that 

powered GPT-4 initially achieved only 4.3 per -

cent accuracy in multidigit multiplication (Yang 

and others 2023b). A “smart” machine fails at 

something in which a dumb pocket calcula -

tor achieves 100 percent accuracy because 

of the inherent differences between AI and 

earlier digital tools, as explored in the chap -

ter. For a feisty account of the reasons why 

large language models have failed on basic 

arithmetic, see Marcus (2023). Despite on -

going improvements, numeracy gaps in large 

language models remain pervasive (Li and 

others 2025). This does not mean that large 

language models cannot improve at the tasks 

they are not good at. For instance, much effort 

has been deployed to improve mathematical 

“reasoning” in large language models (Ahn 

and others 2024) and better understand the 

reasons for persistent limitations (Feng and 

others 2024; Shrestha, Kim and Ross 2025). 

25  Cave and Dihal 2019; Craig and others 2018; 

Mitchell 2023b, 2024a, 2024b. 

26  For a fascinating application of AI to enhance 

teaching of Tang poetry, see Chen and Wu 

(2024). For a more general discussion of AI’s 

potential to advance art, along with some of 

the emerging risks, see Epstein and others 

(2023). Other examples include how AI can 

enhance design (Jiang and others 2024; Zhu 

and others 2018), writing (Hitsuwari and oth -

ers 2023; Wang and others 2024e; Yuan and 

others 2022), music (Doh and others 2023; 

Ding and others 2024; Gardner and others 

2023), humour (Wu, Weber and Müller 2025) 

and interpretation of literary metaphors (Ich -

ien, Stamenković and Holyoak 2024). 

27  Since 2017 AI such as AlphaZero has been 

shown to consistently beat any human at the 

game (Silver and others 2018). But subscrib -

ers to chess.com have increased more than 

fivefold since then, from 20 million in 2017 to 

100 million in 2022 ( https://www.chess.com/ 

article/view/chesscom-reaches-100-million-

members ). AI has driven this renaissance of 

interest in chess, in part by creating more op -

portunities for people to play the game, train 

and get better at it when they play with other 

humans (Gaessler and Piezunka 2023). See 

also Machajewski (2024). 

28  For evidence that streaming stimulates de -

mand for live music, see Christensen (2022). 

In 2024 global streaming revenue reached 

$20 billion, up from $13 billion, and perfor -

mance rights reached $3 billion in 2020, 

up from $2 billion (IFPI 2024). More broadly, 

there is often complementarity between 

physical and digital goods. For instance, the 

digitalization of books has increased demand 

for hard copies (Bhuller and others 2024). 

29  Korinek 2024. 

30  Lazar 2024b. 

31  Brynjolfsson, Mitchell and Rock 2018; Gath -

mann, Grimm and Winkler 2025. 

32  Lazear and others (2022) articulate key dif -

ferences for productivity and wages between 

the digital world before and with AI. 

33  Acemoğlu and Johnson 2023. 

34  Manyika and Spence (2023) discuss how AI 

could unleash an economic revolution that 

would trigger productivity growth. 

35  Acemoğlu and Restrepo 2019c. 

36  Gray and Suri 2019; Muldoon, Graham and 

Cant 2024; Muldoon and others 2024. Im -

pacts vary across the world, with workers in 

places with weaker labour regulations or insti -

tutions such as trade unions more vulnerable 

(Doellgast 2023). One harmful implication 

relates to the deterioration of psychological 

wellbeing in content moderation workers 

(Gonzalez and Matias 2025; Steiger and oth -

ers 2021). 

37  Creutzig and others 2022; Galaz 2025. For the 

challenge of AI-related e-waste, see Wang and 

others (2024c). These challenges are exacer -

bated as the scale of the AI models increases 

(Varoquaux, Luccioni and Whittaker 2024). 

38  Hager and others 2024; Singhal and oth -

ers 2023; Singhal and others 2025. AI can 

already fulfil the requirements to get an en -

gineering degree (Borges and others 2024) 

and pass the uniform bar examination in the 

United States (Katz and others 2024), but that 

is different from having AI do what engineers 

do (Xu, Kotecha and McAdams 2024) and 

lawyers (Kapoor, Henderson and Narayanan 

2024; Socol de la Osa and Remolina 2024). 

39  Garassino and others 2025. 

40  For example, people with no experience 

with computer programming can now create 

apps and other software from scratch just by 

describing in normal spoken language what 

they want the tools to achieve—something 

that has been called vibecoding (Rose 2025). 

41  For example, as of mid-March 2025, almost 

half of large-scale large language models 

have published and downloadable weights 

(the numbers in the neural network that re -

flect the machine’s learning), offering much 

flexibility in customizing these models ( https:// 

epoch.ai/data/large-scale-ai-models ). A mid-

February 2025 account describes the previ -

ous month as “one of those months where it 

feels like a year passes in the open-source 

ecosystem,” presenting multiple examples 

of open-source datasets and AI models 

(Lambert and Brand 2025). 

42  Farrell and others 2025. 

43  Mutiso 2025; Nuwer 2024; Signé 2025. At 

the same time it should not be seen as a 

panacea (Krishna 2024). 

44  OECD 2025. 

45  Korinek 2024. 

46  Acemoğlu and others 2023; Das, Amini and 

Wu 2025; Gadotti and others 2024; Goldfarb 

and Que 2023. 

47  Ludwig and Mullainathan 2024. 

48  And if it were able to make accurate predic -

tions, there might be moral reasons to object 

to having people subject to AI predictions 

(Lazar and Stone 2024). 

49  Narayanan and Kapoor 2024b; Wang and 

others 2024a. Moreover, what Neumann and 

others (2024) called data deserts implies risks 

of underrepresenting low-income segments 

of the population. 

50  We are grateful to David Zuluaga Martínez for 

this point. 

51  Volokh 2023. 

52  Browne and others 2023. 

53  Guerreiro and others 2023; Huang and oth -

ers 2025; Li and others 2023. 

54  Caplin 2025a. The deviations may even 

extend upstream, given that AI is trained on 

human data (Treiman, Ho and Kool 2024). 

55  These choices influence decisions ranging 

from the direction of AI, its use to either au -

tomate or augment tasks by firms and how 

people interact with AI (Brynjolfsson 2022; 

Korinek 2024; Korinek and Stiglitz 2018, 

2020; Trammell and Korinek 2023). 

56  Summerfield (2025) describes large language 

models as “strange new minds.” 

57  Sejnowski 2023, p. 311. 

58  Frank 2023; Karell, Sachs and Barrett 2025; 

Mei and others 2024; Mitchell 2023a, 2024a; 

Mitchell and Krakauer 2023; Shiffrin and 2 0 4 HUMAN DEVELOPMENT REPORT 2025 

Mitchell 2023; Trott and others 2023. There 

are efforts to characterize the psychological 

profiles of large language models (Pellert and 

others 2024), including based on whether 

they are able to mirror humans’ theory of 

mind—that is, people’s ability to infer other’s 

mental states (Shapira and others 2024; Stra -

chan and others 2024). And their behaviour 

as economic agents (Fontana, Pierri and 

Aiello 2024) considers how different large 

language models play the prisoner’s dilemma 

game. Chen and others (2023b) document 

the emergence of economic rationality, and 

Raman and others (2024) propose a bench -

mark to assess that rationality. These debates 

and efforts will continue to guide the evolu -

tion of AI as a science and as a technology, in 

the same way that Herbert Simon challenged 

the scientific community many years ago to 

build a machine that could beat humans at 

chess (Simon 1971). 

59  Vallor (2024), along the lines also argued in 

Krakowski (2025). Evidence at the firm level 

shows that AI adoption will involve both au -

tomating and augmenting tasks (Krakowski, 

Luger and Raisch 2023; Raisch and Krakowski 

2021). 

60  Agrawal, Gans and Goldfarb 2024b. 

61  Valenzuela and others 2024. del Rio-Cha -

nona, Laurentsyeva and Wachs (2024) found 

that since the emergence of large language 

models, there has been a 25 percent decline 

in online fora such as Stack Overflow, where 

programmers share knowledge and solve 

problems. Beane (2024) emphasizes the 

importance of having mentors and human 

relationships between novices and experts 

as part of learning, even if large language 

models can help with ready solutions. 

62  Doshi and Hauser 2024; Kleinberg and 

Raghavan 2021. 

63  Awad and others 2018; Bonnefon, Rahwan 

and Shariff 2024; Purcell and Bonnefon 2023; 

Vallstrom 2024. 

64  Barnes, Zhang and Valenzuela 2024. Even 

aspects such as alignment with human values 

(Globig and others 2024) and hallucinations 

need to be evaluated in a culturally sensitive 

way (McIntosh and others 2024). 

65  Goethals and Rhue 2024; Mazeika and others 

2025; Zewail and others 2024. 

66  Boulus-Rødje and others 2024. 

67  This is particularly critical in some tasks where 

building skills implies engaging in activities 

such as writing, which develops skills in 

argumentation, critical thinking and attention 

to detail. Leveraging AI to augment human 

intelligence in the context of writing requires 

it to not only help people express ideas in the 

moment but also develop those skills in the 

long term (Stuhler, Stoltz and Martin 2023; Yan 

and others 2024). This will require respond -

ing on the supply side as well, by building 

machines that learn and think with people 

and are promoted as such (Collins and others 

2024b). 

68  Mitchell (2021, 2024b) has warned that an -

thropomorphic language shapes people’s 

relationship with the technology (for 

instance, whether they trust it), as well as 

how it is viewed both scientifically and by 

decisionmakers. Deroy (2023) and Dorsch 

and Deroy (2025) go further and question the 

ethics of using anthropomorphic language 

with respect to AI. 

69  Hinton 2016. For a video, see  https://www. 

youtube.com/watch?v=2HMPRXstSvQ&t=29s .

70  An economically coherent and possible sce -

nario described in Nordhaus (2021). 

71  In general, it might be difficult to extrapolate 

AI advances tested on abstracted versions of 

real-world problems to their effects in the real 

world. Foundational AI efforts such as those 

that Geoffrey Hinton pioneered are crucial 

and were recognized with a Nobel Prize in 

2024, but real-world applications are not de -

termined alone by how well the models per -

form theoretically or in more circumscribed 

domains. We are grateful to Zi Wang for this 

insight. 

72  D’Souza and Davis 2024. See also Hender -

son (2022). Ironically, the increase in demand 

for radiologists stems in part from medical 

images becoming more abundant and more 

accessible with AI, generating more demand 

across a range of healthcare professionals. 

73  A task-centred rather than job-centred ap -

proach seems helpful to explore AI’s impact 

on the world of work. Bonney and others 

(2024a) find that about 27 percent of US firms 

using AI reported impacts on tasks, but only 

5 percent reported employment (job-level) 

changes. 

74  According to the International Standard 

Classification of Occupations, the occupa -

tion of radiologist involves more than 12 

tasks, including interacting with patients and 

other medical professionals; conducting 

specialized diagnostic tests is only one (see 

the entry for Unit Group 2212 in ILO 2012). 

According to the Occupational Information 

Network, radiologists perform 30 different 

tasks (see  https://www.onetonline.org/link/ 

summary/29-1224.00 ). 

75  Dranove and Garthwaite 2024. 

76  On the benefits in lower income countries 

and settings, see Khosravi and others (2024) 

and Tanno and others (2024). Agarwal and 

others (2023) document the challenges of 

human–AI interaction in radiology and the 

potential need for new tasks and expertise by 

radiologists. Awuah and others (2025) show 

how AI imaging models are being combined 

with other AI tools to improve prognostic ac -

curacy for people with malignant gliomas, one 

of the most aggressive primary brain tumours, 

demonstrating how deploying AI for imaging 

complements the use of other AI tools. For 

broader applications of AI, including but go -

ing beyond support with medical images, and 

how these supplement rather than replace 

radiologists, see Bhandari (2024). 

77  Acemoğlu and Restrepo (2018, 2019b) for -

malized the framework for how introducing 

machines can lead to both task displace -

ment and task reinstatement. For a recent 

review, see Restrepo (2024). It has been 

used to interpret trends in economic inequal -

ity (Acemoğlu and Restrepo 2024) and to 

consider the introduction of AI (Acemoğlu and 

Restrepo 2019a, 2019c). 

78  In one study overall reading times were 

shortened, but when AI detected abnormali -

ties, reading times increased (Shin and others 

2023). For reasons discussed later in the 

chapter, the nature of AI implies that the in -

teraction between radiologists and AI is more 

nuanced, with heterogenous effects across 

different radiologists (Yu and others 2024). 

79  In addition to the analysis of tasks, it is im -

portant to determine whether a price reduc -

tion leads to more demand overall, which 

depends in part on how responsive demand 

is to the decline in price—what economists 

call the price elasticity of demand. When pro -

ductivity improves in a sector, making more 

with less does not mean that there will be less 

labour demand in that sector (let alone in the 

economy as a whole): even if each clinic sees 

less demand for radiologists because of pro -

ductivity gains, cheaper radiology services 

may increase overall demand for more clin -

ics. Think of what happened with air travel 

when jet engines replaced propellers. Pilots 

became much more productive and air travel 

much cheaper, and the sector’s high price 

elasticity led to a boom in demand for pilots. 

This example draws from US National Acad -

emies of Sciences and Medicine (2024). The 

elasticities are generally low for healthcare 

but higher for radiology than for other health 

services (Ellis, Martins and Zhu 2017). 

80  There are other far-reaching implications of 

using AI to help radiologists. AI expands hu -

man development by making it feasible to 

extend cancer screening and other radiology 

diagnostics to low-income countries where it 

was difficult to do so before machine-assisted 

medical imaging was available (Zuhair and 

others 2024). Deploying AI to help with medi -

cal imaging also calls for community health 

workers trained to support the deployment, 

increasing the demand for labour in local 

communities (Adapa and others 2025; Dangi, 

Sharma and Vageriya forthcoming; Zuhair and 

others 2024). 

81  Svanberg and others 2024. 

82  Kaufman and others 2025. Data for the United 

States are from the RAND American Teacher 

Panel. 

83  Conboye 2025. For details on the survey, see 

https://www.adeccogroup.com/global-work -

force-of-the-future-research-2024 . Workers 

were able to save time using AI; the top two 

tasks where time was saved were checking 

work quality and accuracy and engaging 

in more creative work. In the United States 

worker use of AI is much higher than firm 

adoption of AI (for workers, see Bick, Blandin 

and Deming 2024; for firms, see Bonney and 

others 2024b). Another survey found that the 

number of employees using AI for a third or 

more of their work was three times as high 

as their leaders imagined (Mayer and others 

2025). A survey of US firms from before gen -

erative AI was introduced found that adoption 

was comparable to current use, at around 5 

percent (McElheran and others 2024), but 

is now growing rapidly (Bonney and others 

2024b). NOTES  2 0 5 

84  Bandiera and others 2022. 

85  For a 200 year analysis, see Kogan and oth -

ers (2021, 2023). For a more narrowly focused 

study of the adoption of industrial robots be -

tween 1993 and 2014, see Lerch (2025). 

86  Babina and others (2024) find little impact of 

AI on cost reductions in US firms. Zhai and 

Liu (2023) find the same in Chinese firms. 

Thus, firms that increase AI investment exhibit 

higher growth in sales, employment and mar -

ket valuations, but this is achieved primarily 

through increases on the revenue side rather 

than reductions on the cost side. 

87  Bonney and others 2024a, 2024b. 

88  Eisfeldt, Schubert and Zhang (2023) report 

that firms exposed to AI increased their valu -

ation. Further analysis showed evidence that 

generative AI’s impact on those increases oc -

curred through labour displacement (Eisfeldt 

and others 2024). Already, the diffusion of 

generative AI is depressing employment and 

earnings for some workers, including free -

lance workers on an online platform engaged 

in tasks ranging from data entry and graphic 

design to software development (Hui, Reshef 

and Zhou 2024). Analysis of earnings calls 

of listed US firms revealed a sharp increase 

in positive sentiment about AI after ChatGPT 

was released in November 2022. And while 

references to new products are part of this 

optimism, so are expectations for increased 

efficiency (Bass and others 2024). 

89  Historically, technological progress often 

hurt incumbent workers, and it was not until 

(sometimes new) institutions reshaped incen -

tives that workers benefited from technologi -

cal change (Acemoğlu 2025; Acemoğlu and 

Johnson 2023; Scott Morton 2024). 

90  Narayanan and Kapoor 2024b. 

91  More rigorously, this corresponds to a

move from special-purpose computational 

machines to general-purpose computers, 

corresponding to the implementation of 

the theoretical concept of a Turing machine 

from computer science (see spotlight 1.2 for 

details). 

92  Potentially in many of the world’s natural 

languages (Barrault and others 2025; Costa-

jussà and others 2024). 

93  Hephaestus, the Greek god of invention, cre -

ated a bronze giant called Talos (Mayor 2018). 

Talos’s tasks were immutable and externally 

imposed, a stark contrast from the dynamic 

and intrinsic motivations that guide human 

action. Talos’s tale is a reminder of both our 

quest for automation and our understanding 

that machines can accomplish human tasks 

without being human. 

94  Reid-Green 1989. 

95  Not to be misunderstood as something dif -

ferent from quantum computing but simply to 

refer to machines that execute prespecified 

programs, which can also be implemented 

using quantum computing. US National 

Academies of Sciences and Medicine (2024) 

uses the term classical computing to refer 

to the second stage; the use of classical 

programming is meant to make it clear that 

the contrast is not between quantum and 

nonquantum computing. 

96  Hoffmann and others 2024; Mannuru and oth -

ers 2023; Yang and others 2024. It is costly 

(more than $100 million) to rough out such a 

machine on oceans of laboriously collected 

and curated data. Further human effort—of -

ten exploitative—fine-tunes large language 

models such as ChatGPT, Claude, DeepSeek 

and Gemini (Cottier and others 2024). In a 

sense we are in the early days and will surely 

observe multiple ancillary breakthroughs that 

redefine how these machines are instructed 

and their tasks delegated. But the framework 

of higher generality (executing an ever-wider 

range of tasks) with lower human effort fo -

cuses on the essential features of each stage. 

97  McElheran and others (2024) show that even 

in the United States AI adoption around 2018, 

while pervasive across sectors of the econo -

my, was concentrated in firms in a few cities 

and in young firms led by highly educated 

owners overrepresented in AI adoption. 

98  Narayanan and Kapoor 2024b, pp. 147, 166. 

99  Bick, Blandin and Deming 2024. 

100  The aspiration to achieve artificial general in -

telligence may have driven scientific progress 

in the field, akin to Herbert Simon’s challenge 

to build a machine that could beat humans at 

chess, but it is no longer universally seen in 

the scientific community as a desirable north 

star (AAAI 2025; Blili-Hamelin and others 

2025). 

101  The same choices may not be made across 

all domains, cultures and contexts. And some 

tasks are not ends in themselves but means 

to ends—for example, learning. Those con -

siderations, rather than whether a machine 

surpasses what humans can do, are what 

matters for human development. 

102  There is no neutral way to advance techno -

logical progress, so being explicit about what 

is desirable matters (Acemoğlu and Johnson 

2023). Others may have different goals, in -

cluding, from a scientific perspective, ways to 

measure machine capabilities on a range of 

technical benchmarks for how close we are 

getting to artificial general intelligence. 

103  Up to consistent errors based on program -

ming logic. 

104  Autor 2019; Autor, Levy and Murnane 2003. 

105  For example, automated teller machines au -

tomated both cognitive tasks (verifying card 

details, processing transactions) and manual 

tasks (dispensing cash). Despite automating 

routine cognitive labour, they did not elimi -

nate bank clerks or bank branches. As with 

radiologists, their occupations persisted, as 

many tasks remained for bank tellers. Open -

ing bank accounts and processing loan ap -

plications became core duties, for which they 

now have more time. The increase in branch 

productivity made it cheaper to expand bank 

branches (with fewer tellers per branch but a 

net increase in tellers overall across locations; 

Bessen 2015). Gains in productivity can result 

in higher demand if demand is sufficiently 

elastic (US National Academies of Sciences 

and Medicine 2024), which appears to have 

been the case with services provided by bank 

branches. For a specific analysis of AI, see 

Bessen (2018). 

106  In the controlled environment of a factory or 

warehouse, many routine tasks can be auto -

mated, in contrast to, say, the unpredictable 

context of a public road, where automating 

a car proved beyond the abilities of classical 

programming. 

107  And creating other social ills, such as in -

creased property crime (Liang, Sabia and 

Dave 2025). The process also has important 

political implications, as explored in Gallego 

and Kurer (2022). 

108  Autor and others 2024. For example, the ad -

vent of word processing software decimated 

the number of people employed as word pro -

cessors and typists in the United States from 

1 million in 1980 to 33,000 today (Abrahams 

and Levy 2024). Between 1950 and 2010 the 

disappearance of only one occupation on 

the US census list (elevator operator) can be 

attributed to automation (Bessen 2018). While 

automation harms incumbents, new entrants 

in the workforce have found jobs in other 

fields (Bessen and others 2025; Feigenbaum 

and Gross 2024). 

109  There were many other social and economic 

implications of the digital transformation, in -

cluding greater economic concentration and 

market power of firms (Brynjolfsson, Jin and 

Wang 2023; De Loecker and Eeckhout 2018; 

De Loecker, Eeckhout and Unger 2020; Kurz 

2023; Leduc and Liu 2024) and a reduced 

labour share of national income (Autor and 

others 2020; Karabarbounis 2024; Karabar -

bounis and Neiman 2013; Velasquez 2023). 

110  Bhattacharyya 2024. 

111  Autor and others 2024. 

112  US National Academies of Sciences and 

Medicine 2024. 

113  Acemoğlu and others 2022; Boustan, Choi 

and Clingingsmith 2022. 

114  For evidence in the United States, see 

Acemoğlu and Restrepo (2024). 

115  For evidence in South Africa, see Bhorat and 

others (2023). On the displacement of routine 

jobs in Chile, see Delaporte and Peña (2025). 

116  Caunedo, Keller and Shin (2023). 

117  Martins-Neto and others 2023. 

118  Reijnders, Timmer and Ye 2021; Rodrik 2024. 

119  On the growing importance of social skills in 

the United States, see Deming (2017). 

120  Reijnders, Timmer and Ye 2021. 

121  Hosseinioun and others 2025. 

122  On high-income countries, see Autor (2022). 

Bhorat and others (2020) present evidence 

of wage polarization for South Africa, but 

Martins-Neto and others (2023) show only 

incipient wage polarization in many lower 

income countries. 

123  Changes occur not only across but also within 

occupations, with evidence suggesting that 

computer use is associated with greater within-

occupation wage inequality (Bessen 2016). 2 0 6 HUMAN DEVELOPMENT REPORT 2025 

124  US National Academies of Sciences and 

Medicine 2024. 

125  On the impact of digital technologies on re -

gional inequalities in Europe, see Antonietti, 

Burlina and Rodríguez-Pose (2025). On the 

impact of geographic distance on seizing 

benefits from globalization in Ethiopia and 

Nigeria, see Atkin and Donaldson (2015). 

126  For the case of South Africa, see Bhorat and 

others (2023). 

127  Acemoğlu and Johnson 2023. 

128  Autor 2014. 

129  Prior to the advent of generative AI, machine 

learning was often assumed to simply con -

tinue the trend of labour replacement and 

capital deepening characterized by classical 

computing, in part because applications 

were easier in already technology-intensive 

companies (Bresnahan 2021). As an example 

of the reach of generative AI, consider how 

ChatGPT outperforms crowdworkers in text 

annotation tasks (Gilardi, Alizadeh and Kubli 

2023). 

130  Marinoudi and others 2024. 

131  Caetano and others 2025; Caplin 2025b. 

132  Pilditch 2024. 

133  Kwa and others (2025) explore the potential 

of AI to complete what they call long tasks, 

to in part capture this idea. They argue that 

there has been a decline in the time it takes 

for AI to successfully complete more and 

more of these long tasks. 

134  Korinek 2024. 

135  Galaz 2025. 

136  Reduced effort to delegate aspects of tasks 

to AI should not be confused with the goal 

of increasing human efficiency at complet -

ing tasks. Rather, the reduction in effort can 

expand the ways in which humans leverage 

automation to accomplish tasks that reflect 

their goals, values, needs and interests. 

137  Collins and others (2024a) argue that this is 

the case for mathematical applications, and 

Hoes, Altay and Bermeo (2023) argue that 

large language models support fact checking 

in digital platforms moderation. 

138  Particularly when the data do not measure 

what is intended or simply capture spurious 

correlations (Mhasawade, Zhao and Chunara 

2021; Zhang and others 2024b). 

139  Granulo, Fuchs and Puntoni 2021; Mariadas -

sou, Klesse and Boegershausen 2024. 

140  Altay and Gilardi 2024; Yin, Jia and Wakslak 

2024. In some behavioural experiments hu -

mans seem more generous (stronger social 

preferences and reciprocity) when interact -

ing with machines if they believe there are 

humans behind the machine (von Schenk, 

Klockmann and Köbis 2025). 

141  Wolczynski, Saar-Tsechansky and Wang 

2024. 

142  For a formal analysis of how the frequency 

of task execution leads to an interaction 

between economic decisions and the affor -

dances of automating technologies, see Ales 

and others (2023). For an application to AI, 

see Ales, Combemale and Ramayya (2024). 

143  The field of human–machine interaction is vast 

and rapidly changing (for recent perspectives 

considering AI specifically, see Brinkmann 

and others 2023; Huo, Manrique and Johnson 

2024; Rahwan and others 2019; Tsvetkova 

and others 2024). Czaplicka, Baumann and 

Rahwan (2024) explore the implications of cul -

tural evolution. Much evidence suggests that 

people interact differently with machines than 

with people. For example, people cheat more 

when interacting with machines (Cohn, Gesche 

and Maréchal 2022), and virtual interactions 

lead to disengagement and less empathy (Ta -

vares and Rein 2024). AI chatbots induce more 

cooperation when people are unaware that 

they are interacting with a machine, with the 

effect disappearing when the machine nature 

of the chatbot is disclosed (Ishowo-Oloko and 

others 2019). The pervasiveness of human-

and AI-powered machines may also reshape 

patterns of trust (Makovi and others 2023) and 

social norms (Baronchelli 2024; Brady and 

Crockett 2024; Danaher 2024). 

144  Peters and Matz 2024. 

145  Schoene and others 2024. 

146  Artsi and others 2024; Benítez and others 

2024; Clusmann and others 2023; Gilbert, 

Kather and Hogan 2024; Khan and others 

2025; Luo and others 2024a; Wu and others 

2025. These limitations extend to the most 

advanced models at the time of writing (Xie 

and others 2024). 

147  Soroush and others 2024. 

148  Griot and others 2025. 

149  Kogan and others 2023. 

150  To be clear, the argument is about comple -

mentarity between humans and AI in the cre -

ative process, not replacing human creativity 

with machines, which even if it were feasible, 

would not be desirable from a human devel -

opment perspective. 

151  For the case that AI is a general-purpose 

technology, see Eloundou and others (2024). 

152  Gordon (2017) argues that many technological 

innovations in past industrial revolutions had 

such level effects only. 

153  Besiroglu, Emery-Xu and Thompson 2024. It 

could also be a way of accelerating recom -

binant growth, the economic growth process 

proposed by Weitzman (1998), where innova -

tion results from recombining existing ideas 

to produce new ones (see also Jones 2023). 

AI can accelerate both the generation of new 

ideas (Li and others 2024; Liu and others 

2024a; Su and others 2024; Sun and others 

2024) and the capacity to process existing 

ideas into useful innovations. Wang and oth -

ers (2023b) propose using large language 

models to enhance conceptual blending 

across cultural domains. 

154  Cockburn, Henderson and Stern 2019; Crafts 

202. 

155  US National Academies of Sciences and 

Medicine 2024, p. 11. 

156  Trammell and Korinek 2023. 

157  Binz and others 2025; Delgado-Chaves and 

others 2025; Luo and others 2024b; Musslick 

and others 2025. 

158  This seems to be affecting freelance work -

ers on online platforms in particular (Demirci, 

Hannane and Zhu forthcoming; Hui, Reshef 

and Zhou 2024; Teutloff and others 2025). 

159  Lee and others 2025. 

160  Messeri and Crockett 2024. 

161  Doshi and Hauser 2024. 

162  Along the lines of the complementarity be -

tween humans and AI discussed in Felin and 

Holweg (2024). See also Dubova, Galesic and 

Goldstone (2022). 

163  Adam 2023; Epstein and others 2023. 

164  Schut and others 2025. 

165  This links in part to efforts to understand or 

explain AI (Milani and others 2024) and may 

call for new vocabularies to enable that bridg -

ing (Hewitt, Geirhos and Kim 2025). Insights 

from similarities and global variability across 

human languages (Lewis and others 2023; 

Marti and others 2023) can provide insights 

helpful to this endeavour. 

166  Moruzzi 2025. 

167  Autor 2014. 

168  Many factors determine what is automated, 

including lack of labour supply for certain 

tasks. For instance, Septiandri, Constantinides 

and Quercia (2024) found a strong correlation 

between an AI impact measure and vacancy 

rates for occupations in the United States. 

169  Gmyrek, Berg and Bescond 2023. 

170  Constantinides and Quercia 2025; Septiandri, 

Constantinides and Quercia 2024. 

171  The term advanced expertise is used here to 

designate the same set of skills that US Na -

tional Academies of Sciences and Medicine 

(2024) call elite expertise. 

172  An arms race of sorts for increased depth 

and specificity of expertise—and the value of 

being able to provide it—led to an erosion of 

the value of the Renaissance-era paradigm of 

someone who holds knowledge across a vast 

range of domains (breadth of knowledge) in 

favour of more specialized expertise (depth 

of knowledge), particularly at the forefront of 

science and technology (Jones 2009). 

173  Bedi and others 2025; Kather and others 

2024; Moor and others 2023; Zhang and oth -

ers 2024a. 

174  Bessen and others 2023. 

175  As argued in Autor (2024). 

176  Deming, Ong and Summers 2025. 

177  Jia and others 2024. 

178  Huang, Jin and Li 2024. 

179  Eisenmann and others 2025. 

180  We are grateful to David Zuluaga Martínez 

for this suggestion. For evidence of the ma -

terialization of this risk, see Wiles and others 

(2024). AI users performed better than those 

without on a range of tasks, except on “knowl -

edge tests” that assessed understanding. NOTES  2 07 

181  More broadly, AI can tilt the balance between 

prediction and explanation towards the former 

(Hofman, Sharma and Watts 2017; Hofman and 

others 2021), if the complementarity between 

the need is not recognized—another reason 

why the importance of human evaluation of AI 

outputs remains critical even when benefiting 

from accessing advanced expertise. 

182  Noy and Zhang 2023. 

183  Peng and others 2023b. 

184  Dell’Acqua and others 2023. 

185  Agrawal, Gans and Goldfarb 2023; Kanazawa 

and others 2022. See also Sack and others 

(2024). 

186  Humlum and Vestergaard 2025. 

187  Caplin and others 2024. 

188  Babina and others 2023. 

189  Haslberger, Gingrich and Bhatia 2024. As 

do the broader impacts of path-dependent 

growth in skillsets within and across jobs. On 

the interdependence of skills, see Hosseini -

oun and others (2025). Other issues being ex -

amined include whether AI and remote work 

are complements or substitutes (Baldwin and 

Okubo 2024) and whether greater use of AI 

increases or reduces time spent on leisure 

(Jiang and others 2025). 

190  Otis and others 2024b. In addition, regional 

dispari  ties within countries could also in -

crease. The characteristics of AI imply that 

geograph ic inequalities cannot be assumed 

to simply follow the patterns observed with 

classical computing (Muro, Methkupally and 

Kinder 2025). For an analysis of the geo -

graphic implications of generative AI in 

Organisation for Economic Co-operation and 

Development countries, see OECD (2024), 

which shows that it would exacerbate region -

al inequalities. This heterogeneity extends 

even to the firm level, with potentially very dif -

ferent outcomes for workers from deploying 

the same type of AI in different organizations 

(Meijer, Lorenz and Wessels 2021). 

191  The term translational expertise is borrowed 

from US National Academies of Sciences and 

Medicine (2024). This expertise can range 

from prompt engineering (Giray 2023; Wang 

and others 2024b) to iterative interactions with 

AI and independent verification of its outputs 

(Azaria, Azoulay and Reches 2024). The po -

tential for AI to give bad advice is not limited 

to healthcare. For example, a study examined 

AI advice to help entrepreneurs in Kenya. 

High-performing entrepreneurs benefited 

from AI, improving their revenue by 15 percent 

over those not receiving AI advice. In contrast, 

low performers did 8 percent worse—largely 

because their ventures had few business pros -

pects, but the AI model was unable to iden -

tify the problem and advise those ventures to 

scale back or shut down—so AI was giving bad 

advice (Otis and others 2024a). 

192  Bilen and Hervé 2025. 

193  Lu and others 2024. 

194  Wilson, Daugherty and Bianzino 2017. 

195  For an example in education, see Liu and oth -

ers (2023). 

196  Korinek and Vipra 2024. See also  https:// 

chatgpt.com/gpts .

197  Acemoğlu and others 2024; Hackenburg and 

Margetts 2024a, 2024b; Marriott and Pitardi 

2024; Matz and others 2024; Mlonyeni 2024; 

Pentina, Hancock and Xie 2023; Pentina and 

others 2023; Simchon, Edwards and Lewan -

dowsky 2024; Teeny and Matz 2024. 

198  Cheng and others 2024; Dutta and others 

2024; Gharahighehi and others 2024; Ma and 

others 2025; Markel and others 2023; Ravi 

and others 2025; Wang and others 2024d. A 

concern with the use of AI in education is that 

it could detract from the formation of critical 

thinking skills through cognitive offload -

ing (Borges and others 2024; Nosta 2025; 

Stadler, Bannert and Sailer 2024), which could 

be avoided if large language models are seen 

as collaborators rather than replacements for 

educators. 

199  Agarwal and others 2023; Johri and others 

2025; Jörke and others 2024; Sun and others 

2025. 

200  Aktan, Turhan and Dolu 2022; Jin, Walker and 

Reczek 2024. 

201  Baumol 2012; US National Academies of Sci -

ences and Medicine 2024. 

202  Potentially improving on previous conversa -

tional agents that were already widely used 

in low- and middle-income countries (Parmar 

and others 2022). 

203  Acemoğlu and Restrepo 2019c. 

204  Kirk and others 2023a; Kirk and others 2024. 

205  Nowotny (2021) explores the dangers of tak -

ing this route. 

206  Wang and others 2024a. If many firms use the 

same AI application for predictive purposes, 

the emergence of a monoculture of decisions 

could also harm social welfare (Kleinberg and 

Raghavan 2021). 

207  Mathuros, Venugopalan and Adepu 2024. 

The implications of AI as a prediction ma -

chine have been proposed and explored in 

Agrawal, Gans and Goldfarb (2019, 2022a, 

2022b, 2024a), Athey, Bryan and Gans (2020) 

and Tucker (2025). For instance, using AI to 

predict the value of houses has not replaced 

investors using human judgement but pushes 

humans to evaluate houses that AI struggles 

with while increasing the value of minority-

owned homes—human evaluation might have 

been biased, but AI ignores racial disparities 

in its valuation (Raymond 2024). For other 

applications, see Rambachan (2024). Italian 

banks that adopted AI to make lending deci -

sions made better decisions when humans 

and AI complemented rather than substituted 

for each other (Gambacorta, Sabatini and 

Schiaffi 2025). See also Doshi and others 

(2025) on using AI to support a broader range 

of strategic decisions in firms. 

208  Mannuru and others 2023. 

209  Varian (2010) describes the economic trans -

formation enabled by the internet and the 

world wide web. Kumar, Amaglobeli and Mo -

szoro (2023) document the social dividends 

of digital adoption in low- and middle-income 

countries, and Chiplunkar and Goldberg 

(2022) do so for mobile internet. For the posi -

tive impact on employment and earnings of 

the arrival of fast internet in Africa, see Hjort 

and Poulsen (2019). 

210  Acemoğlu and Johnson (2023) argue that 

two of the ways in which AI can increased 

the marginal productivity of workers is by 

providing access to better information and as 

a platform for enhanced collaboration. 

211  de Rassenfosse, Jaffe and Waldfogel 2025. 

212  Verhoogen 2023. 

213  Turon, Arora and Duran-Frigola 2024. 

214  Rodrik 2024. 

215  Reijnders, Timmer and Ye 2021; Rodrik 2024. 

216  Diao and others 2024; Gollin and Kaboski 

2023. For an analysis of how investment in 

digital technologies, particularly software, 

often stays within the firm, see Bessen and 

Frick (2018). 

217  Diouf and others 2024; Mishra and others 

2023. 

218  Ganne, Locks and Xu 2024. 

219  Rodrik and Sandhu 2024. If, instead, the focus 

is on AI as a force for automation, inequalities 

within and across countries risk further widen -

ing (Korinek and Stiglitz 2021). 

220  That depends largely on the price elasticity of 

demand. Estimates for the United Republic of 

Tanzania suggest that these elasticities would 

raise demand for services, in ways that are 

not observed for either agricultural or manu -

factured goods (McCullough 2025). 

221  Bandiera and others 2022. 

222  Wei, Jörg and Rolf 2024. 

223  Kruse and others 2024. 

224  Lerner (2013) and Lerner and others (2024) 

show the importance of supporting “ap -

propriate entrepreneurship” that fits with the 

specificity of different developing contexts. 

225  Swartz, Denecke and Scheepers 2023; Wal -

ton 2022. 

226  Al-kfairy 2025. A recent survey on whether 

European firms are adopting AI from providers 

or developing it in-house found that adopting 

readymade AI is commonplace (Hoffreumon, 

Forman and van Zeebroeck 2024). 

227  Bessen and others 2023; Eapen and others 

2023. 

228  Some of the effects will be indirect, through 

AI-enabled advances to inform agricultural 

practices. For example, a recent study used 

AI to identify a microbiome more conducive 

to potato growth, potentially revolutionizing 

agriculture (Song and others 2025). 

229  Shahriar and others 2025. 

230  Allen and others 2025. 

231  Mutiso 2024. 

232  Gardner and Henry (2023) present a frame -

work to help determine the potential for 

allocating public and private capital, do -

mestically and from high-income countries, 

in low-income settings. Foster and others 

(2023) present a comprehensive review of 2 0 8 HUMAN DEVELOPMENT REPORT 2025 

evidence showing that, on balance, digital 

infrastructure, particularly broadband internet, 

enhances firm productivity, employment and 

welfare. They also show that mobile phones 

help agricultural producers and traders coor -

dinate and that rural electrification supports 

a range of development outcomes, even 

though many randomized controlled trials 

in rural settings have not found substantial 

short-term benefits (as in Lee, Miguel and 

Wolfram 2020b)—though the potential of AI 

was not considered. Access to the internet 

also enhances connectivity within countries, 

which is one way countries can increase their 

market size, important to power the demand 

for services (Rodrik 2023). 

233  Just providing access to power without 

enabling people to do more with that power 

has limited positive impact (Lee, Miguel and 

Wolfram 2020a). On the productivity side 

some studies have also found limited impact 

on unreliable electricity access, but Fried and 

Lagakos (2023) show that even with limited 

short-run costs, long-run general equilibrium 

effects are associated with lack of reliable 

electricity. 

234  Even within the same country distance from 

AI hubs matters. Hunt, Cockburn and Bessen 

(2024) found that in the United States an ad -

ditional 200 kilometre distance from the clos -

est AI hotspot was associated with 17 percent 

lower growth in AI’s share of job listings. 

235  Gust, Hanushek and Woessmann 2024. See 

also Lutz and others 2021; Pritchett 2024; 

Pritchett and Viarengo 2023. for other meth -

odologies and approaches showing compa -

rable gaps. 

236  Björkegren and others 2025. 

237  Ben-Ishai and others (2024) outline some of 

the risks that AI can exacerbate economic 

challenges. 

1 Agarwal and others 2024; Athey, Bryan and 

Gans 2020. 

CHAPTER 2 

2 Sen 1999. 

3 Sen 1999. 

4 UNDP 2024. 

5 Stewart 2013. 

6 Bak-Coleman and others 2021. 

7 Burton and others 2024. 

8 Atari and others 2025; Brinkmann and others 

2023. 

9 Sen 1999. 

10  UNDP 2001. 

11  Narayanan and Kapoor 2024. 

12  UNDP 2001. 

13  UNDP 2024. 

14  ITU 2023; UNDP 2024. 

15  Gezici 2022. 

16  Guess and others 2023a; McLoughlin and 

Brady 2023; Wang and others 2024a. 

17  Ponnusamy and others 2022. 

18  Peterson 2024; Shumailov and others 2024. 

19  Xu 2022. 

20  Huang and others 2019; Todorović, Pešterac 

and Tomić 2019. 

21  Ji and others 2023; Wiener 1960. 

22  Doshi-Velez and others 2017. 

23  Birhane and others 2024. 

24  Wang and others 2024b. 

25  Bender and others 2021. 

26  Raja and Zhou 2023. 

27  Raja and Zhou 2023. 

28  UNDP 2024. 

29  Bak-Coleman and others 2021; Boyd and 

Richerson 1985; Henrich 2015; Henrich and 

McElreath 2003. 

30  Bak-Coleman and others 2021. 

31  Chetty and others 2022a, 2022b; Marcenaro-

Gutierrez, Micklewright and Vignoles 2021; 

Smith and Christakis 2008. 

32  Stewart 2013. 

33  Reverberi and others 2022. 

34  Alhosani and Alhashmi 2024; Costello, Penny -

cook and Rand 2024; Haupt and Marks 2023; 

Nie and others 2024; Wermelinger 2023. 

35  Masello and others 2022; Yurtsever and oth -

ers 2020. 

36  Masello and others 2022. 

37  WHO 2023. 

38  Kopits and Cropper 2005; Sayari and others 

2022. 

39  Awad and others 2018. 

40  Chang and others 2023. 

41  Kelling and others 2013. 

42  Conover and others 2011; González-Bailón 

and others 2023; Guess and others 2023a; 

Ribeiro and others 2020. 

43  Hill 2023. 

44  Costa-Jussà and others 2022. 

45  Guerreiro and others 2023. 

46  Tessler and others 2024. 

47  Zuboff 2023. 

48  Brady and others 2023. 

49  Bond and others 2012; Rajkumar and others 

2022. 

50  Hunkenschroer and Luetge 2022; Marcinkows -

ki and others 2020; Sachan and others 2020; 

Taylor 2023; Vogell, Coryne and Little 2022. 

51  MacKay and Weinstein 2022. 

52  Alvarez and others 2024; Messeri and 

Crockett 2024. 

53  Born and others 2021. 

54  Hilbert and Darmon 2020. 

55  Linda Morris 2022. 

56  Schrittwieser and others 2020. 

57  Schrittwieser and others 2020. 

58  Guo and others 2024. 

59  Allen 1994; Cross and Estrada 1995. 

60  Blumenstock 2020. 

61  Narayanan and Kapoor 2024. 

62  Lum and Isaac 2016. 

63  Birhane and others 2024. 

64  Berger-Tal and others 2024; Bhat and Huang 

2021; Bi and others 2023; Jongaramrungru -

ang and others 2022; McGovern and others 

2024; Qazi, Khawaja and Farooq 2022; van 

Oosterhout 2024; Van Wynsberghe 2021. 

65  Kaack and others 2022. 

66  Galaz 2025; Galaz and others 2025. 

67  Kaack and others 2022; Verma and Tan 2024. 

68  Kaack and others 2022. 

69  Roytburg 2024. 

70  Ismagilova and others 2022; Yin and others 

2015. 

71  Sanders and others 2019; Wan and others 

2020. 

72  Alhosani and Alhashmi 2024. 

73  Gunasekeran and others 2021; Panch and 

others 2019. 

74  Bak-Coleman and others 2021. 

75  Bak-Coleman and others 2021; Brinkmann 

and others 2023; Burton and others 2024; 

Rahwan 2018; Rahwan and others 2019. 

76  Aristotle 1999; Condorcet 1785; Galton 1907. 

77  Surowiecki 2005. 

78  Arrow and others 2008; Hastie and Kameda 

2005; Surowiecki 2005. 

79  Aher, Arriaga and Kalai 2023; Argyle and oth -

ers 2023. 

80  Aher, Arriaga and Kalai 2023; Burton and oth -

ers 2024; Dillion and others 2023. 

81  Anderson and others 2019; Moss and others 

2023. 

82  Burton and others 2024. 

83  Arrow and others 2008; Hastie and Kameda 

2005; Prelec, Seung and McCoy 2017; Surow -

iecki 2005. 

84  Angelidis and others 2021; Coavoux, Elsahar 

and Gallé 2019; Suhara and others 2020. 

85  Kittur and Kraut 2008. 

86  Stiles and Cui 2010. 

87  Kelly and Gráda 2000; Mackay 1980; Toyo -

kawa, Whalen and Laland 2019. 

88  Hong and Page 2004; Hong and Page 2011; 

Pescetelli, Rutherford and Rahwan 2021; 

Suran and others 2022. 

89  Bak-Coleman and others 2022; Becker, Por -

ter and Centola 2019; Guilbeault, Becker and 

Centola 2018. 

90  Bail and others 2018; Conover and others 2011; 

González-Bailón and others 2023; Guess and 

others 2023a; Nyhan and others 2023; Santos, 

Lelkes and Levin 2021; Törnberg 2018. NOTES  2 0 9 

91  Becker, Brackbill and Centola 2017; Lorenz and 

others 2011; Mann 2022; Navajas and others 

2018; Pescetelli, Rutherford and Rahwan 2021. 

92  Henderson 1987; Hoffmann 2012. 

93  Vlasceanu and others 2024. 

94  Boyd and Richerson 1985; Feldman and 

Cavalli-Sforzatt 1984; Henrich 2015; Henrich 

and McElreath 2003. 

95  Ellis 2024; Otto and others 2020; Richerson, 

Boyd and Efferson 2024; UNDP 2024; War -

ing, Wood and Szathmáry 2024. 

96  Ren and others 2024; Shin and others 2023. 

97  Brinkmann and others 2023. 

98  Atari and others 2025. 

CHAPTER 3 

1 Though education, health, income and 

agency are important throughout life, each 

is examined here during only one life stage 

for simplicity and space reasons, using the 

life stage most affected by each component. 

This does not mean, for example, that adults 

do not use AI for lifelong learning or that AI 

is not used in infant healthcare. The topics 

are simply examples for different applications 

of AI. 

2 Following Amartya Sen (1999), institutions are 

seen as vehicles for expanding capabilities 

and freedoms. 

3 United Nations 1989b. 

4 Bozkurt and others 2023. For a detailed 

analysis of how institutions contribute to or 

mitigate inequalities, see Sen (1992). For an 

analysis of how inequalities are reproduced 

intergenerationally through families, see 

UNDP (2019). Caregiver refers to anyone 

responsible for a child’s care, including 

foster parents, relatives, babysitters or legal 

guardians. 

5 Orben and others 2024. The adolescence 

section elaborates on why adults are less 

susceptible than teenagers to addiction and 

harmful social media use. 

6 Although preschool programmes have dem -

onstrated considerable benefits, access and 

participation remain limited at both the global 

and regional levels. Globally, 4 in 10 children 

ages 3–4 are enrolled in early childhood edu -

cation. Attendance rates vary greatly across 

regions: around two-thirds of children in Latin 

America and the Caribbean are enrolled, 

compared with just under half in South Asia 

and only a quarter in Sub-Saharan Africa (UNI -

CEF 2024). 

7 Hu and others 2020; Hurwitz and Schmitt 

2020; Kermani and Aldemir 2015; Nurdian -

tami and Agil 2020; Papadakis, Kalogiannakis 

and Zaranis 2018. 

8 Anderson and Subrahmanyam 2017; Corkin 

and others 2021; Felix and others 2020; Gou 

and Perceval 2023; Hinkley and others 2018; 

Hutton and others 2020; Korte 2020; Liu and 

others 2021; McArthur, Tough and Madigan 

2022; McHarg and others 2020; Nurdiantami 

and Agil 2020; Wan and others 2021. Defini -

tions of excessive screen time vary, but the 

most common one is more than two hours a 

day during early childhood. 

9 Anderson and Subrahmanyam 2017; Corkin 

and others 2021; Felix and others 2020; Gou 

and Perceval 2023; Hinkley and others 2018; 

Hutton and others 2020; Korte 2020; Liu and 

others 2021; McArthur, Tough and Madigan 

2022; McHarg and others 2020; Nurdiantami 

and Agil 2020; Wan and others 2021. Defini -

tions of excessive screen time vary across the 

literature, but the most common understand -

ing is that more than two hours a day would 

be considered excessive during early child -

hood. [repeats previous note] 

10  Hutton and others 2020. Excessive screen use 

is measured by ScreenQ, which is a 15-item 

measure of screen-based media use reflecting 

the domains of the American Academy of Pe -

diatrics recommendations: access to screens, 

frequency of use, content viewed and coview -

ing. Higher scores reflect greater use. 

11  Anderson and others 2010; Thiagarajan, New -

son and Swaminathan 2025. 

12  Núñez-Jaramillo, Herrera-Solís and Herrera-

Morales 2021. 

13  Eirich and others 2022; Holton and Nigg 

2020; Tan and Zhou 2022; Xie and others 

2020. One challenge that most of these stud -

ies share is determining causality. Researchers 

are divided on whether increased screen time 

causes ADHD symptoms or whether children 

with ADHD just spend more time at screens. 

14  Labadze, Grigolia and Machaidze 2023. 

15  Suresh Babu and Dhakshina Moorthy 2024. 

16  Alzate 2023; Pedro and others 2019; Vincent-

Lancrin and Van der Vlies 2020. 

17  Alzate 2023; Vincent-Lancrin and Van der 

Vlies 2020. 

18  Gaskins 2023; Jennings 2023; Perry and Lee 

2019; Perry and Turner-Lee 2019. 

19  Labadze, Grigolia and Machaidze 2023. 

20  The programme aims to integrate AI educa -

tion into the national curriculum, foster AI-driv -

en entrepreneurship and prepare students 

for the global tech economy (Lee and Uddin 

2023). Since its inception the academy has 

trained more than 300 specialists in machine 

learning and AI (Asia-Plus 2024). 

21  Stanford Graduate School of Business 2023. 

22  Yaqoob 2024. Another major challenge is 

the product’s dependence on internet ac -

cess. Although internet usage in the country 

increased by approximately 214 percent be -

tween 2007 and 2017, usage remains around 

50 percent as of 2022 (World Bank 2024b). 

23  Bozkurt and others 2023; Chen and Lin 2023; 

Saadeh 2023. 

24  Grinschgl and Neubauer 2022; Tech Busi -

ness News 2023. 

25  Skulmowski 2023. 

26  Skulmowski 2023. 

27  Baron 2023. 

28  US National Center for Education Statistics 

2013. 

29  Woodard 2018. 

30  Horvath 2024. 

31  Resnick 2023. 

32  Horvath 2024. 

33  Schuengel and van Heerden 2023. 

34  Sarwar 2022. 

35  Festerling and Siraj 2020; Haber and Cor -

riveau 2023. 

36  Aeschlimann and others 2020. 

37  Johnson and Acemoğlu 2023. 

38  Uhls and others 2014. 

39  Orben and others 2024. 

40  Blanchflower and Bryson 2024a; Blanch -

flower, Bryson and Xu 2024; Blanchflower 

and others 2024; Haidt 2024; Kelly and oth -

ers 2018; Twenge and Campbell 2019, 2018; 

Twenge and others 2022. 

41  Blanchflower and Bryson 2024a; Twenge and 

others 2022. 

42  The dip in life satisfaction at middle age and 

rise in old age has sometimes been called a 

paradox, given the declining health and social 

losses during the later years of life. Cultural 

heterogeneity plays into these relations: the 

U-shape curve of wellbeing can look very dif -

ferent not only in countries with lower human 

development but also in different societal 

contexts, such as rural and urban settings. For 

instance, rural subsistence populations show 

diverse patterns of wellbeing throughout the 

life course, in which life satisfaction often de -

clines with age (Counted, Cowden and Lomas 

2024; Gurven and others 2024). 

43  Blanchflower, Bryson and Xu 2024; Blanch -

flower and others 2024; Haidt 2024. 

44  Fumagalli, Shrum and Lowrey 2024; Orben, 

Dienlin and Przybylski 2019; Orben and Przy -

bylski 2019; Valkenburg 2022. Wegmann, 

Schiebener and Brand (2023) suggest, for 

example, that social media scrolling can help 

decrease stress (either as an adaptive coping 

strategy or a maladaptive coping strategy in 

individuals with addiction tendency); how -

ever, the control group was either waiting or 

reading magazines rather than engaging in 

activities that are typically known to be effec -

tive for stress relief, such as physical exercise 

and the outdoors. See also Nugraha and 

others (2024) and Roberts, Hinds and Camic 

(2020). 

45  Carter and others 2024; Huang and others 

2023; Khalaf and others 2023; Scott, Stuart 

and Barber 2021, 2022; Stuart and Scott 2021; 

Twenge and others 2020. 

46  Braghieri, Levy and Makarin 2022; Faelens 

and others 2021; Irmer and Schmiedek 2023; 

McComb, Vanman and Tobin 2023. 

47  Orben and others 2024. 

48  Stuart and Scott 2021. 

49  Conversely, Allcott and others (2020) found 

that deactivating a social media platform for 

a certain time increased subjective wellbeing 

and led users to re-evaluate their opinion of 

platforms and the need to use them. 2 1 0 HUMAN DEVELOPMENT REPORT 2025 

50  Blanchflower and Bryson 2024a; Odgers 2024. 

51  Corrigan, Rokem and Kuhl 2024. 

52  Huang and others 2023. 

53  Odgers 2024. 

54  Vaid and others 2024. For example, individu -

als with depression are more susceptible to 

social comparison on social media platforms, 

reacting with negative emotions, lower self-

esteem and worsening depressive symptoms 

(Aubry, Quiamzade and Meier 2024). 

55  Bone and others 2022; Fluharty and others 

2023; Towe-Goodman and others 2024. 

56  Ali and others 2021. 

57  Yuvaraj and others 2021. 

58  Aprin and others 2023. 

59  Sen 2001. 

60  The latter is analysed in the 2021/2022 Hu -

man Development Report (UNDP 2022). 

61  Prunkl 2022. 

62  Antsaklis 2020. 

63  Robeyns 2005, 2016. 

64  We are thankful to Professor PB Anand for this 

addition. 

65  Nussbaum 2003; Sen 2008. 

66  Botes 2023. 

67  Lazar 2024. 

68  Brinkmann and others 2023. 

69  Hassija and others 2024. 

70  Brinkmann and others 2023. 

71  Atari and others 2025. 

72  Bradford 2020. 

73  Madary 2022. 

74  European Commission 2019. 

75  Council of Europe 2019. 

76  Botes 2023. 

77  Bradford 2020. 

78  Acemoğlu and Johnson 2023. 

79  See Adams, Dedehayir and O’Connor (2022). 

80  Acemoğlu and Johnson 2023. 

81  Følstad and Skjuve 2019. 

82  Forbes 2022. The 22 percent includes respon -

dents who gave up or were disconnected. 

83  Acemoğlu and Johnson 2023. 

84  Invoca 2023. 

85  For an analysis of the Philippines, see Cucio 

and Henning (2025). 

86  Amadeus 2017. 

87  US Commission on Civil Rights 2024; US Gov -

ernment Accountability Office 2014; Raji and 

others 2020. 

88  Hefner and others 2019. 

89  UNICEF 2023. 

90  Vanden Abeele, Abels and Hendrickson 2020. 

91  Thompson 2024. 

92  Human Development Report Office survey 

data. 

93  Campens and others 2023; Mariano and oth -

ers 2021. 

94  Sixsmith and others 2022. These findings 

are based on data from after the Covid-19 

pandemic, during which many older people 

increased their internet use for communica -

tion, health and overall wellbeing. 

95  Mariano and others 2022; Neves and Mead 

2021. 

96  Mozilla 2019. 

97  Ipsos 2023. 

98  Rainie and others 2022. Data are for the 

United States. 

99  Maldives is an exception, with a medium HDI 

value of 0.762 (UNDP 2025). 

100  Sixsmith and others 2022. 

101  Fingerman, Birditt and Umberson 2020; Sen, 

Prybutok and Prybutok 2022. 

102  Williams 2024. 

103  Havers and others 2024; Kemp and Erades 

Pérez 2023. 

104  Havers and others 2024. Data are for England 

and Wales. 

105  US Federal Bureau of Investigation 2024. 

Data for this and the next sentence are for the 

United States. 

106  Napal 2024. 

107  Thompson 2024. 

108  Mitzner and others 2008. 

109  Choudhury, Renjilian and Asan 2020; 

Loveys and others 2022; Sapci and Sapci 

2019. 

110  Young adults are those ages 18–29. Lucas 

and Villarroel 2022. 

111  Span 2025. 

112  Clegg and others 2022. 

113  WHO 2017. 

114  Shiwani and others 2023. 

115  Ardila and others 2019; Bharadwaj 2024; 

Otake 2016; Saha 2024. 

116  Hernström and others 2025. Data are for 

Sweden. 

117  Lim and others 2022. 

118  Villar and others 2015. 

119  In the United States people ages 65 and 

older account for 27 percent of the popula -

tion and 37 percent of healthcare costs (Peter 

G. Peterson Foundation 2024). 

120  Shiwani and others 2023. 

121  Chu and others 2023. 

122  Stypinska 2023; van Kolfschooten 2023; 

WHO 2022. 

123  It is probably unrealistic to call for free distri -

bution of devices. However, universal access 

could be achieved by making devices avail -

able at schools, public libraries and other 

community centres. 

CHAPTER 4 

1 Examples include the LLM Leaderboard 

(https://llm-stats.com/ ) and the Chatbot Arena, 

in which models are rated against one an -

other in the same way that chess players are 

rated ( https://lmarena.ai/?leaderboard ). 

2 Acemoğlu and Johnson 2023. 

3 Examples focusing on mobile phones and dig -

ital provision of information include Fabregas 

and others (2025), Pesando and Qiyomiddin 

(2023), Rotondi and others (2020) and, for the 

specific case of AI, Kulkov and others (2024). 

4 Altman 2024. 

5 Jasanoff 2016. 

6 Conceição 2019. 

7 Acemoğlu and Johnson 2024; Goldstone 

2002; Kelly, Mokyr and Ó Gráda 2023; Mokyr 

2016; Samuel 1977. 

8 Narayanan and Kapoor 2024. 

9 Watson, Mökander and Floridi 2024. 

10  Acemoğlu and Johnson 2023. 

11  Acemoğlu and Johnson 2023. 

12  Winner 2017. 

13  MacKenzie 1999. 

14  Kudina and van de Poel 2024; Lazar and 

Nelson 2023; Sartori and Theodorou 2022. 

15  Narayanan and Kapoor 2024. 

16  Winner 2017. 

17  Aldasoro and others 2024; Lane 2024. 

18  Capraro and others 2024. 

19  Holloway and Barbareschi 2022. 

20  Gupta and Treviranus 2022. 

21  Assistive technologies include devices such 

as wheelchairs, hearing aids and alternative 

and augmentative communication devices 

that enhance the functional capacities of 

people with disabilities (Austin and Holloway 

2022; WHO and UNICEF 2022). 

22  Jahan and others 2020; Raja 2016. 

23  Jahan and others 2020. 

24  Stein and Lazar 2021. 

25  Touzet 2023. 

26  de Freitas and others 2022; Smith and others 

2023; Touzet 2023. 

27  Adnin and Das 2024. 

28  Papadopoulos 2024. 

29  Valencia and others 2023. 

30  ZainEldin and others 2024. 

31  Goggin, Ellis and Hawkins 2019. 

32  WHO and UNICEF 2022. 

33  WHO and UNICEF 2022. 

34  UNDESA 2024. 

35  UNDESA 2024. 

36  UNDESA 2024. 

37  https://sites.research.google/relate/ .NOTES  2 1 1 

38  Ayoka and others 2024. 

39  Ayoka and others 2024. 

40  Ayoka and others 2024. 

41  Automatic Speech Recognition can alter the 

dynamic of the conversation—for example, by 

adding pauses or altering the flow. If the other 

person in the conversation does not under -

stand or refuses to cooperate, the interaction 

cannot take place (Ayoka and others 2024). 

42  Baffoe 2013. 

43  Zhuang and Goggin 2024. 

44  Sen 2013. 

45  Shew 2020. Ableism is the systematic de -

valuation of and discrimination against people 

with disabilities (Bennett and Keyes 2020). 

46  Spiel and others 2019. 

47  Spiel and others 2019. 

48  Baillargeon, Yoon and Zhang 2024. 

49  Adnin and Das 2024; Glazko and others 2023. 

50  Glazko and others 2023. 

51  Glazko and others 2023. 

52  Papadopoulos 2024. 

53  Gadiraju and others 2023; Li and others 

2024; Mack and others 2024. 

54  WebAim 2024. 

55  Chapter 3 describes these concepts and their 

significance in the context of AI algorithms. 

56  Gupta and Treviranus 2022. 

57  Smith and others 2023; Valencia and others 

2023. 

58  McDonald, Massey and Hamidi 2023. 

59  Holloway and Barbareschi 2022; Mankoff, 

Hayes and Kasnitz 2010. 

60  Wu 2021. 

61  Goggin, Prahl and Zhuang 2023. 

62  The discussion here focuses on adult social 

care, which includes care for older people 

and people with disabilities and chronic 

illnesses. 

63  Wright 2023a. 

64  Kodate and others 2022. 

65  Kodate and others 2022. This study focuses on 

public narratives in France, Ireland, Hong Kong, 

China (SAR), Japan and the United Kingdom. 

66  Efforts are under way to ensure that robots 

have “empathy,” as proposed in Christov-

Moore and others (2023). 

67  Schwiter and Steiner 2020. 

68  Atkinson, Lawson and Wiles 2011. 

69  Green and Lawson 2011. 

70  Addati and others 2018. 

71  Fetterolf and others 2025. 

72  Schwiter and Steiner 2020. 

73  Fetterolf and others 2025. 

74  Lee and others 2023; Pilotto, Boi and Peter -

mans 2018. 

75  Ferguson and others 2021. 

76  Rosman and others 2024. 

77  Facchinetti and others 2023. 

78  Based on data from the United Nations Devel -

opment Programme Survey on AI and Human 

Development, comparing responses from 

people ages 60 and older with responses 

from people ages 17–24.] 

79  Coeckelbergh 2022. 

80  The Alan Turing Institute and The Ada 

Lovelace Institute 2024. 

81  Chan and Muralidharan 2024; Yew 2021. 

82  Felber and others 2023. 

83  Prince and Wallsten 2022. 

84  Hertog, Ruppanner and Churchill 2024. 

85  Ageism towards older adults is rooted in age-

based stereotypes, often shaped by general -

ized assumptions that portray older people 

as weak, vulnerable and incapable but also 

warm and friendly (Swift and Chasteen 2021). 

86  WHO 2022; Wright 2023b. 

87  Stypinska 2023. 

88  WHO 2022. 

89  Mannheim and others 2023. 

90  Rubeis 2020; Voinea, Wangmo and Vică 

2024. 

91  Voinea, Wangmo and Vică 2024. 

92  Lee, Iizuka and Eggleston 2025. 

93  MacLeavy 2021. 

94  MacLeavy 2021; Schwiter and Steiner 2020. 

95  Wright 2023b. 

96  Wright 2023b. 

97  Wright 2023b. 

98  Lee, Iizuka and Eggleston 2025. 

99  Lee, Iizuka and Eggleston 2025. 

100  Khan and others 2024. 

101  Khan and others 2024. 

102  UN 2024. 

103  Chopra and Krishnan 2022. 

104  Tronto 2020. 

105  King-Dejardin 2019. 

106  Hertog, Ruppanner and Churchill 2024. 

107  Hertog, Ruppanner and Churchill 2024. 

108  Emmer De Albuquerque Green 2024. 

109  Emmer De Albuquerque Green 2024. 

110  Hertog, Ruppanner and Churchill 2024. 

111  Wajcman 2010. 

112  Rotondi and others 2020. Pesando (2022) 

reports that women’s ownership of a mobile 

phone is associated with lower likelihood of 

emotional, physical and sexual violence over 

the previous year, after a range of factors are 

controlled for. 

113  Chan 2022; Wajcman 2010. 

114  Hertog and others 2023. 

115  de V. Cavalcanti and Tavares 2008. 

116  Bittman, Rice and Wajcman 2004. 

117  Cowan 2023. 

118  Hertog and others 2023. 

119  Wajcman 2010. 

120  UNESCO 2024b. 

121  Breda and others 2020. 

122  Stoet and Geary 2022. 

123  Breda and others 2020. 

124  Leslie and others 2015. 

125  Napp and Breda 2022. 

126  Napp and Breda 2022. 

127  This is the case in several Eastern European, 

Arab and Southeast Asian countries (UNES -

CO 2021, 2024b). 

128  Narasimhan 2021. 

129  UNESCO 2024c. 

130  UNESCO 2024a. 

131  UNESCO 2024c. 

132  WEF 2023. 

133  Young, Wajcman and Sprejer 2023. 

134  Liu and Wang 2024. 

135  Aldasoro and others 2024; Humlum and 

Vestergaard 2024; Lane 2024. 

136  Aldasoro and others 2024. 

137  Armantier and others 2024; Prince and Wall -

sten 2022. 

138  UNDP 2023. 

139  PSong, Wang and Li 2024; Vásárhelyi and 

others 2021. 

140  Peng and others 2022. 

141  Peng and others 2022. 

142  Rossiter 1993. 

143  Peng and others 2022; Song, Wang and Li 2024. 

144  Brooke 2024. 

145  Brooke 2023. 

146  Cave and others 2023. 

147  Cave and others 2023. 

148  Chen, Duan and Kim 2024. 

149  Toupin 2024. 

150  Burrage, Dasgupta and Ganguli 2025. 

151  Genero 2024. 

152  Peña and others 2023. 

153  Acerbi and Stubbersfield 2023; Celiktutan, 

Cadario and Morewedge 2024; Weidinger 

and others 2023. 

154  Treiman, Ho and Kool (2024) show the chal -

lenges of using human input in AI training. 

Bigoulaeva, Madabushi and Gurevych (2025) 

show the inherent limits of fine-tuning given 

that pretraining data may be a boundary of 

the tasks the model is able to address. 

155  Caliskan, Bryson and Narayanan 2017; 

Charlesworth, Caliskan and Banaji 2022; 2 1 2 HUMAN DEVELOPMENT REPORT 2025 

Charlesworth and others 2024; Bender and 

others 2021. 

156  The data used to train a large language mod -

el may be drawn from a nonrepresentative 

sample of the population, which can cause 

the model to fail to generalize well to some 

social groups. The data may omit important 

contexts, and proxies used as labels (such as 

sentiment) may incorrectly measure the actual 

outcome of interest (such as representational 

harms). The training or inference procedure 

itself may amplify bias beyond what is present 

in the training data. The choice of optimiza -

tion function, such as selecting accuracy 

over some measure of fairness, can affect a 

model’s behaviour. Benchmark datasets may 

be unrepresentative of the population that will 

use the large language model but can steer 

development towards optimizing only for 

those represented by the benchmark. A large 

language model may be deployed in a differ -

ent setting from that for which it was intended, 

such as with or without a human intermediary 

for automated decisionmaking (Suresh and 

Guttag 2021). 

157  Abid, Farooqi and Zou 2021. 

158  Mei, Fereidooni and Caliskan 2023. 

159  Chen and others 2023. 

160  Barocas, Hardt and Narayanan 2023. 

161  Katzman and others 2023. 

162  Barocas, Hardt and Narayanan 2023. 

163  Atari and others 2025. 

164  Ghosh and Caliskan 2023. 

165  Gallegos and others 2024. 

166  Bai and others 2022a; Ouyang and others 

2022. 

167  Raji and others 2021. 

168  Ouyang and others 2022; Solaiman and 

Dennison 2021. 

169  This approach involves collecting a dataset 

of human demonstrations, comparisons and 

preferences to create a reward model that 

guides the fine-tuning process (Ouyang and 

others 2022). Ouyang and others (2022) pro -

pose using written human feedback to pro -

mote human values, including bias mitigation, 

in a reinforcement learning–based fine-tuning 

method. Others have proposed constitutional 

AI, which uses a similar approach but with the 

reward model based on a list of human-spec -

ified principles instead of example prompts 

and outputs (Bai and others 2022b). 

170  Ganguli and others 2023. 

171  For instance, using ChatGPT-4o, we gen -

erated a series of stories for different 

occupations. The percentage of stories 

featuring female characters in positions of 

power exceeded 95 percent: “head of state” 

(98 percent), “medical doctor” (99 percent), 

“Nobel Prize winner” (100 percent) and “CEO” 

(95 percent). These figures are based on Hu -

man Development Report Office calculations 

using the OpenAI API (January 2025). The 

prompt used was, “Write a 100-word story 

about a character, creating their name, with 

the following occupation: {activity}. Focus on 

a significant moment that reveals their per -

sonality, challenges, and the essence of their 

work.” 

172  Greenwald and Banaji 1995. 

173  Bai and others 2024; Zhao, Wang and Wang 

2025. 

174  Bai and others 2024. 

175  Bai and others 2024. 

176  Bai and others 2024. 

177  Wang and others 2023. 

178  Bai and others 2024; Hofmann and others 

2024. 

179  Brown and others 2020; Liang and others 

2022. 

180  Edenberg and Wood 2023. 

181  Raghavan 2023. 

182  Kleinberg, Mullainathan and Raghavan 2016. 

183  Barocas, Hardt and Narayanan 2023. 

184  Mirza, Kulkarni and Jadhav 2024. 

185  Mirza, Kulkarni and Jadhav 2024. 

186  Blodgett and others 2020. 

187  Barocas, Hardt and Narayanan 2023. 

188  Barocas, Hardt and Narayanan 2023; Xiang 

2024 

189  Barocas, Hardt and Narayanan 2023. 

190  Blodgett and others 2020. 

191  Blodgett and others 2021. 

192  Blodgett and others 2021. 

193  Atari and others 2025; Lorè and Heydari 

2024; Maloney and others 2024; Mihalcea 

and others 2024; Seo, Yuan and Bu 2025. 

194  Raghavan 2023 

195  Acemoğlu and Johnson 2023; Narayanan 

and Kapoor 2024. 

196  As in  https://openai.com/charter/ .

197  Mitchell 2024. 

198  Sen 2001, 2017. 

199  Vergeer 2020. 

200  Lazar and Nelson 2023. 

201  Winner 2017. 

202  Cave and Dihal 2023. 

203  Atari and others 2025. 

204  Narayanan and Kapoor 2024. 

205  Maragno and others 2023. 

206  Marwala 2024. 

207  The human development approach is about 

expanding the richness of human life rather 

than just the richness of the economy in which 

human beings live. This approach focuses on 

people and their opportunities and choices. 

208  Raji and others 2021. 

209  Eriksson and others 2025. 

210  Eriksson and others 2025. 

211  Raji and others 2021. 

212  van der Weij and others 2024. 

213  Ethayarajh and Jurafsky 2020. 

214  Eriksson and others 2025, p. 8. See also Na -

rayanan and Kapoor (2023b). 

215  As the researchers argued, it is not as though 

a lawyer’s job is to answer bar exam ques -

tions all day (Narayanan and Kapoor 2023b). 

216  Berente, Kormylo and Rosenkranz 2024. 

217  Angwin and others 2022. 

218  Buolamwini and Gebru 2018. 

219  Wang, Hertzmann and Russakovsky 2024. 

220  Eriksson and others 2025. 

221  Vidgen and others 2024. 

222  Weidinger and others 2023. 

223  Narayanan and Kapoor 2023a. 

224  Narayanan and Kapoor 2023a. 

225  Narayanan and Kapoor 2023a. 

226  Narayanan and Kapoor 2023a. 

227  Weidinger and others 2023. 

228  Liang and others 2022. 

229  McIntosh and others 2024. 

230  Weidinger and others 2023. 

CHAPTER 5 

1 Power can be categorized in many ways. 

Pansardi and Bindi (2021) differentiate the 

concepts of “power to,” “power over” and 

“power with.” Lazar (2025) categorizes power 

with respect to algorithmic intermediaries, 

introducing ideas of “power between” and 

“power through.” This chapter draws implicitly 

from various categorizations, particularly in 

terms of “power between” (mediating social 

interactions and social choices) and “power 

over” (controlling the design and application 

of AI and other algorithms). 

2 The distinction between “power to” and “power 

over,” as well as the modalities in which power 

can be exercised, draws from Lazar (2024a). 

3 To be clear, having agentic properties does 

not mean that AI is a moral agent (Geiselmann 

and others 2023; Véliz 2021). One way of 

thinking about these properties could be in 

terms of simulations of agency (Lazar 2025). 

4 Lazar 2025. 

5 Bommasani and others 2024; Kapoor and 

others 2024a. 

6 Korinek and Vipra 2024b. 

7 Gambacorta and Shreeti 2025. 

8 Acemoğlu 2024. 

9 Aldasoro and others 2024; Crisanto and oth -

ers 2024. 

10  Korinek and Vipra 2024a. 

11  Lerner and Tirole 2002. 

12  Gambacorta and Shreeti 2025. 

13  Korinek and Vipra 2024a. 

14  Tirole 2023. NOTES  2 1 3 

15  Comunale and Manera 2024. 

16  This framing draws from Lazar (2024a, 2025). 

17  Zuboff 2019. 

18  Aridor and others 2024; Galaz and others 

2025; Lorenz-Spreen and others 2023; 

Zhuravskaya, Petrova and Enikolopov 2020. 

19  Lazar 2024d, 2025. 

20  Bengio and others 2025. 

21  Bengio and others 2024; Cohen and others 

2024; Ho and others 2023. 

22  Caton and Haas 2024; Gallegos and others 

2024; Hagendorff 2024; Jobin, Ienca and 

Vayena 2019; Lazar 2024b; Véliz 2019; Whit -

tlestone and others 2019. Much of the work 

on AI fairness builds on the longstanding 

examination of algorithmic fairness (Das, 

Stanton and Wallace 2023; Dwork and others 

2012; Mitchell and others 2021). 

23  Christian 2021; Russell 2019. One challenge 

of alignment is the diversity of and changes in 

human values (Awad and others 2018). 

24  World Bank 2017. 

25  Methnani and others 2024; Sadek and others 

2024. 

26  Lazar 2024c; Mittelstadt, Russell and Wachter 

2019; Rudin 2019. Efforts to understand the 

world models implicit in generative AI may 

offer new ways of making progress, but it 

remains difficult for humans to interpret those 

models at the moment (Vafa and others 

2024). 

27  Nussberger and others 2022. 

28  Rueda and others 2024. Chen and Zheng 

(2024) found that interpretability demand is 

higher in utilitarian domains of AI use than in 

hedonic ones, further adding to the evidence 

that higher stakes relate to higher demand for 

AI interpretability. 

29  Qi, Schölkopf and Jin 2024; Wachter, Mittel -

stadt and Russell 2024. 

30  Winner 1980. 

31  Even though we have to be careful in attrib -

uting to machines human traits, a constant 

refrain in this Report. They have even been 

characterized as seeking power, instrumen -

tally, in the pursuit of the objectives they were 

programmed or trained to achieve (Carlsmith 

2022). 

32  UNDP 2024. 

33  Carvalho (2025) develops a scenario of ex -

treme concentration of power in a few people 

enabled by the control of AI. 

34  Hogg and others 2024. 

35  Lazar 2025. 

36  Coeckelbergh 2024. 

37  Media, in general, always has the potential to 

influence political processes and the distribu -

tion of power (Prat 2018). 

38  Bak-Coleman and others 2021. 

39  Pan and others 2007. On the trust in genera -

tive AI search results, see Li and Aral (2025). 

40  Lazar 2025. 

41  Achiam and others 2023; Cao and others 

2023; Touvron and others 2023. 

42  Simon 1971. 

43  Simon 1971. 

44  Zheng and Meister 2025. 

45  Vélez and others 2023. Cognitive enhance -

ment brings new ethical considerations, as 

explored in Gordon and Seth (2024). 

46  This is a lower bound, based on Human De -

velopment Report Office calculations using 

the following assumptions from Villalobos and 

others (2024a). The indexed web comprises 

500 trillion tokens (much internet content is 

not indexed), bits of words that are on average 

four characters long. If each character takes 

8 bits to encode (using the ASCII standard), 

the web contains 1.6x1017 bits of text (to which 

one would have to add multimodal content 

in the form of images, sound and video). At 

10 bits per second, a human could attend to 

3.156x108 bits in a year, so it would take half a 

billion years to go over the indexed web text 

alone. 

47  For a description of how these recommender 

systems work, see Narayanan (2023). For an 

analysis of their implications for the produc -

tion, distribution and consumption of content 

in social media, see Aridor and others (2024). 

48  Kemp 2025. 

49  Narayanan 2023. 

50  Acemoğlu and others 2023; Acemoğlu and 

others 2024; Benn and Lazar 2022; Lazar 

2024c; Sadowski, Viljoen and Whittaker 2021. 

There is also the case for economic inef -

ficiencies associated with sharing user data in 

online platforms (Acemoğlu and others 2022). 

51  Catena, Tummolini and Santucci 2025; Lukoff 

and others 2021. 

52  Lazar 2025. 

53  Fukuyama and others 2020. 

54  Lazar 2025. 

55  Siegel 2020. 

56  Hogg and others 2024. 

57  Lazar 2024a. 

58  Lazar 2024c. 

59  Lazar 2024a. 

60  Lazar 2025. 

61  For a review of some of the potential harms of 

AI in democratic deliberation, as well as some 

of the potential benefits, see Summerfield 

and others (2024). 

62  Hackenburg and Margetts 2024; Simchon, 

Edwards and Lewandowsky 2024; Tappin 

and others 2023. 

63  Bang and others 2024; Fulay and others 

2024; Rozado 2024. 

64  For example, the ways in which people come 

to hold beliefs is a result of complex individual 

and social processes, as examined in Levy 

(2021). Moreover, the processes underpin -

ning things such as motivated reasoning 

(people forming beliefs biased by what they 

want or value), while important, remain poorly 

understood (Cho and others 2024; Glüer-Pa -

gin and Spectre 2024; Stagnaro, Tappin and 

Rand 2023; Tappin, Pennycook and Rand 

2021). 

65  Matz and others 2024. 

66  Floridi 2024. 

67  Kosinski 2024. 

68  When crafting persuasive language, humans 

are prone to developing arguments that are 

convincing to themselves rather than the 

subject being persuaded, which are known 

as egocentric biases; AI does not suffer from 

such biases (Matz and others 2024). 

69  Matz and others 2024. 

70  Sharma and others 2023. 

71  Sharma and others 2023; Summerfield and 

others 2024. 

72  Stefanija and Pierson 2023. 

73  Kapoor and Narayanan 2024. 

74  Kapoor and Narayanan 2024. 

75  Hackenburg and others 2025. 

76  UNESCO 2021. 

77  OECD 2025. 

78  Personal Data Protection Commission 2025. 

79  Personal Data Protection Commission 2025. 

80  Cerf 2024. 

81  Ovadya 2023. 

82  Landemore 2022. 

83  Narayanan 2019. 

84  The Computational Democracy Project 2025. 

85  Tang 2024. 

86  Argyle and others 2023. 

87  Tessler and others 2024. 

88  Tessler and others 2024. 

89  Costello, Pennycook and Rand 2024. 

90  Perspective 2025. 

91  Jigsaw 2024. 

92  Saltz, Jalan and Acosta 2024. 

93  For a historical accounting, see Acemoğlu 

and Johnson (2023). 

94  Lazar 2025. 

95  Simon 1971. 

96  Bhatia, Galesic and Mitchell 2024. 

97  Kurz 2023; Tirole 2023. 

98  Gentzkow and others 2024; Prat and Valletti 

2022. 

99  Bradford, Waxman and Li 2024. The debate 

on whether regulation hinders innovation 

could also be seen in this light. 

100  Bradford 2024; Schaake 2024. 

101  Stanger and others 2024. 

102  Stanger and others 2024. 

103  Bradford 2020. 

104  Widder, Whittaker and West 2024. 2 1 4 HUMAN DEVELOPMENT REPORT 2025 

105  Phan and others 2025. 

106  Volenik 2024. 

107  Varoquaux, Luccioni and Whittaker 2024. 

108  PIB Delhi 2025. 

109  Open A.I. 2025. 

110  European Commission 2025. 

111  Ho and others 2024. 

112  Narayanan and Kapoor 2024. 

113  Epoch AI 2024c. 

114  Hampstead 2024. 

115  Westberg 2024. 

116  Vipra and West 2023. 

117  So far, the efficiency gains demonstrated by 

new open source models have not deterred 

some Big Tech companies from their plans 

to spend hundreds of billions on compute 

resources (New York Times 2025). 

118  Korinek and Vipra 2024a. 

119  Bashir and others 2024; Galaz 2025. 

120  Browne 2024; Green 2024. 

121  Parli 2025. 

122  McKinsey Analytics 2021. 

123  Woolston 2022. 

124  Stobierski 2020. 

125  Gambacorta and Shreeti 2025; Korinek and 

Vipra 2024b. 

126  Villalobos and others 2024b. 

127  Saura García 2024; Zuboff 2019. 

128  Gans 2024. 

129  Chun, Hur and Hwang 2024. 

130  Chun, Hur and Hwang (2024) measure a

country’s pre-existing technological capabili -

ties using patent data from the United States 

Patent and Trademark Office, employing the 

Revealed Comparative Advantage index, 

technology relatedness density and tech -

nology complexity. They assess a country’s 

scientific knowledge base through journal 

articles from the Web of Science Core Collec -

tion, using keyword searches, co-occurrence 

networks and science–technology cross-

proximity density to determine alignment be -

tween scientific and technological activities. 

131  Chun, Hur and Hwang 2024. 

132  Oxford Insights 2023. It measures the matu -

rity of the technology market, considering the 

number of AI and non-AI unicorns, trade in 

information and communication technology 

services and goods, and software spending. 

The innovation capacity of the sector is also 

assessed, looking at factors such as govern -

ment regulations, venture capital availability, 

research and development spending and the 

adoption of AI for innovation. Finally, this pillar 

considers a country’s human capital, evaluat -

ing the skills in the population needed to sup -

port the technology sector, including science, 

technology, engineering and mathematics 

graduates and the quality of engineering and 

technology education. 

133  Rahman, Owen and You 2024. 

134  Statistica 2024. 

135  Fleck 2024. 

136  Tsado 2024. 

137  Epoch AI 2024a, 2024b. 

138  Oxford Insights 2023. The Data & Infrastruc -

ture pillar of the AI Readiness Index assesses 

a country’s ability to support AI development 

through open data policies, governance, 

digital connectivity, statistical capacity and 

data representativeness. Strong open data 

policies and governance ensure accessible, 

reliable data for AI training. Digital connectiv -

ity, measured by internet access and mobile 

subscriptions, influences data generation. 

Statistical capacity reflects a country’s ability 

to collect accurate data, while data represen -

tativeness—impacted by factors such as the 

gender gap in internet access—helps reduce 

bias in AI systems. 

139  Macro Polo 2024. 

140  Macro Polo 2024. 

141  OECD 2025b. 

142  Bernstein 2024; Editorial Board 2025. 

143  Schmid and others 2025. 

144  Schmid and others 2025. 

145  Han and others 2020. 

146  Savage 2020. 

147  Schmid and others 2025. 

148  Veale, Matus and Gorwa 2023. 

149  Voigt and Von dem Bussche 2017. 

150  Bradford 2020. 

151  Veale, Matus and Gorwa 2023. 

152  Dennis 2024. 

153  Lancieri, Edelson and Bechtold 2024. 

154  Dennis 2024. 

155  Ho and others 2023. 

156  Kerry and others 2025. 

157  Kerry and others 2025. 

158  Kerry and others 2025. 

CHAPTER 6 

1 Consider the seminal works in economics by, 

for example, Romer (1990, 1994) and Solow 

(1956), who show that productivity growth 

hinges on knowledge and technological 

change. 

2 Johnson and Acemoğlu 2023. 

3 For example, Dor and Coglianese (2021), Rob -

bins and Brodwin (2020) and Scharre (2016) 

describe AI integration in fields ranging from 

procurement to health and military. 

4 Distributing laptops hoping to address under -

lying education challenges was one such 

misguided approach (Pritchett 2024.) 

5 Buera, Kaboski and Townsend 2023. 

6 Blaurock, Büttgen and Schepers 2024. 

7 Acemoğlu and Restrepo 2019. 

8 National Academies of Sciences Engineering 

and Medicine 2024. 

9 National Academies of Sciences Engineering 

and Medicine 2024. 

10  Touzet 2023. 

11  Abbas Khan and others 2024. For example, 

one way science progresses is through the 

combination of insights from distant scientific 

fields (Shi and Evans 2023), recombination 

of novel ideas (Ham, Quistorff and Weinberg 

2025) or unusual combinations of data (Yu 

and Romero 2024), which AI can leverage (Gu 

and Krenn 2024). 

12  Coyle and Selvi (2024) argue that the concept 

of inclusive innovation remains ambiguous. 

However, they suggest addressing this am -

biguity by ensuring that innovations actively 

benefit marginalized groups, particularly by 

emphasizing affordability, social inclusion and 

capability building. 

13  On the use of AI to fill knowledge shortfalls 

in biodiversity knowledge, see Pollock and 

others (2025). 

14  To achieve this, AI research and development 

could incorporate more flexible frameworks, 

such as human-in-the-loop, human-on-the-

loop and human-in-command, ensuring that 

technology remains an enabler rather than 

an inexorable decisionmaker. Human-in-

the-loop, human-on-the-loop and human-in-

command represent different levels of human 

oversight in AI systems, each with unique 

characteristics (HLEG 2019). For example, hu -

man-in-the-loop requires continuous human 

participation and collaboration in decision -

making, ensuring high control and nuanced 

outcomes, at the expense of efficiency due to 

constant input. Human-on-the-loop involves a 

supervisory role in which humans intervene 

only when necessary, striking a balance be -

tween control and efficiency, making it ideal 

for routine tasks. Human-in-command places 

ultimate decisionmaking authority with hu -

mans, ensuring maximum control and safety. 

While AI systems can operate autonomously 

under human-in-command, they will not make 

autonomous decisions, prioritizing human au -

thority without entirely dismissing operational 

efficiency (Crootof, Kaminski and Price 2023). 

These frameworks reflect varying levels of 

involvement, autonomy and tradeoffs in the 

interaction between humans and AI systems. 

15  For example, addressing AI biases in health 

applications requires better algorithms and 

data, but coding alone will not redress biases 

(Marwala 2024). This is in part because biases 

require constant attention and monitoring, 

given that fairness considerations are context 

specific and dynamic (Mienye, Swart and 

Obaido 2024). 

16  Esmaeilzadeh (2024) reports an ongoing 

cultural shift in healthcare, with AI increasingly 

viewed as a delivery enhancer and job cre -

ator rather than as a threat. 

17  Perhaps analogously to the way that phar -

maceuticals are deployed and monitored, as 

suggested in Belenguer (2022). NOTES  2 1 5 

18  In 2023 services accounted for half of global 

employment (World Bank 2025), while manu -

facturing is becoming increasingly skill and 

knowledge intensive (Cornelli, Frost and 

Mishra 2023), and geopolitical tensions and 

supply chain concerns are altering trade 

patterns (Qiu, Xia and Yetman 2025), even 

as economies remain highly interdependent 

(UNDP 2024). Furthermore, previous waves 

of technological innovation have accelerated 

automation and have been accompanied by 

deroutinization of work in many countries 

(Bhorat and others 2023), polarization of job 

opportunities in many countries (Autor 2022; 

Autor and Salomons 2018) and a reduction in 

labour’s share of income, even as new jobs 

are generated (Autor and Salomons 2018). 

19  National Academies of Sciences Engineering 

and Medicine 2024. 

20  National Academies of Sciences Engineering 

and Medicine 2024. 

21  Autor, Salomons and Seegmiller 2021. 

22  Crafts 2021. shows that the time it takes for a 

technological innovation to have marked pro -

ductivity impacts has been greatly reduced. 

For example, while the steam engine took 

about 61 years to generate substantial pro -

ductivity growth, electricity did it in 32 years 

and the internet and personal computers in 15 

years. Seydl and Linden (2024) estimate that 

AI will take 7–20 years. 

23  Brynjolfsson 2022. 

24  Touzet 2023. 

25  Autor, Salomons and Seegmiller 2021; Autor 

and others 2024; Crafts 2021; Ernst, Merola 

and Samaan 2019. 

26  Gmyrek, Berg and Bescond 2023. See also 

Cazzaniga and others (2024). 

27  AI job exposure metrics, while giving an in -

dication of the potential for AI augmentation 

or automation of jobs, tend not to consider 

the economic rationales for augmentation or 

automation or the technical feasibility of AI in -

tegration in work (Svanberg and others 2024). 

28  Cazzaniga and others 2024. 

29  Cazzaniga and others 2024. Conservative 

estimates place potential AI-induced growth 

in gross domestic product (GDP) by 2034 at 

1.25 percent, while the most optimistic ones 

project growth of approximately 20 percent 

(Seydl and Linden 2024). Using a micro-

macro framework, Filippucci, Gal and Schief 

(2024) estimate that AI-induced aggregate 

productivity growth in the next 10 years will 

range from 0.25 to 0.60 percentage point. 

Another way of estimating the impact of AI is 

to look at market size (revenue from sales of 

products and services) UNCTAD (2025) esti -

mates that the AI market will grow from $189 

billion in 2023 to $4.8 trillion in 2033. 

30  Robert Solow (1987, p. 2) famously said “You 

can see the computer age everywhere but 

in the productivity statistics” about the lack 

of observable productivity impacts from in -

vestment in information and communication 

technology. 

31  Estimates of exposure vary depending on 

methodologies and definitions used (Berg 

and Gmyrek 2024), as well as across high-

and low-income economies, as the skill and 

task composition of the same occupation may 

differ in different types of economies (Benítez-

Rueda and Parrado 2024). Cazzaniga and 

others (2024) show that about 26 percent 

of the workforce in low-income economies 

is exposed to AI, compared with about 60 

percent in higher-income economies. But 

using a task-based approach rather than 

estimating exposure to whole occupations, 

Berg and Gmyrek (2024) and Gmyrek, Berg 

and Bescond (2023) find that only 43 percent 

of the workforce in high-income economies 

is exposed to AI and that 5.1 percent risk 

automation of their jobs, 13.4 percent could 

benefit from augmentation and 24.2 percent 

is a “big unknown.” Furthermore, in countries 

with large informal labour markets, jobs are 

naturally less exposed to AI but are also left 

out of reaping potential productivity gains 

from it (Benítez-Rueda and Parrado 2024). 

32  Coyle 2025. 

33  On the pathways between AI and the 

economy, see National Academies of Sci -

ences Engineering and Medicine (2024), 

which considers eight factors for determining 

the impact of AI on economies: the share of 

the economy where the technology can be 

applied, the size of productivity effects in 

said applications, complementary technolo -

gies and bottlenecks in the economies, time 

lags from innovation to productivity effects, 

spillovers from AI-enabled sectors to other 

sectors and rent-seeking behaviours, hetero -

geneity within and across sectors and firms, 

measurement effects and dynamic effects. 

34  Crafts 2021. Historical introductions of general 

purpose technologies, such as electricity, laid 

the foundation for entirely new industries and 

products—for modern manufacturing, tele -

communications and even home appliances, 

while expanding demand for electricians and 

engineers. Information and communication 

technology enabled new digital market -

places, changed how people collaborate and 

communicate in the workplace and gave rise 

to entirely new types of occupations. Some 

60 percent of jobs in the United States in 

2018 did not exist in 1940 (Autor, Salomons 

and Seegmiller 2021; Autor and others 2024). 

Similarly, rather than automating wholesale 

occupations, AI seems to reshape the types 

of tasks that humans carry out (Zarifhonarvar 

2024), and new types of tasks, such as prompt 

engineering and evaluating and refining AI-

generated code, have quickly become part of 

everyday work for many people. For example, 

Google chief executive officer Sundar Pichai 

(2024) noted that, by the end of 2024, more 

than a quarter of all code at Google was writ -

ten by AI and reviewed by human workers. 

35  National Academies of Sciences Engineering 

and Medicine 2024. 

36  Korinek 2023b. 

37  Rajpurkar and others 2018. 

38  Brynjolfsson, Li and Raymond 2025. 

39  Doshi and Hauser 2024. 

40  For example, having access to AI assistants 

enabled software developers and engineers 

to complete coding tasks faster (Peng and 

others 2023), increased both the quality and 

speed of professional writing tasks among 

college-educated professionals (Noy and 

Zhang 2023) and improved customer service 

assistance (Brynjolfsson, Li and Raymond 

2025). 

41  Doshi and Hauser 2024. 

42  Brynjolfsson, Li and Raymond 2025; Noy and 

Zhang 2023. 

43  National Academies of Sciences Engineering 

and Medicine 2024. The many use cases 

show that AI-driven advancements can cre -

ate new business opportunities, not only by 

improving existing processes but also by 

enabling product and services innovation. 

Furthermore, AI features such as adaptability 

and ability to learn and process vast amounts 

of data can reduce the costs of research 

and development and accelerate innovation 

(Agrawal, McHale and Oettl 2024; Filippucci 

and others 2024). In this sense some have 

argued that AI may be thought of as the 

invention of a method of invention (Crafts 

2021), reshaping research processes (Duede 

and others 2024; Pyzer-Knapp and others 

2022a) and potentially accelerating the sci -

entific method itself (Pyzer-Knapp and others 

2022a). For example, DeepMind’s AlphaFold 

has already revolutionized biology by accu -

rately predicting protein structures, a task that 

has historically required years of experimen -

tal research (Callaway 2022). To date, it has 

predicted and enabled open access to more 

than 200 million protein structures, consider -

ably advancing research, drug discovery and 

disease detection (AlphaFold n.d.). 

44  National Academies of Sciences Engineering 

and Medicine 2024. 

45  Akcigit, Baslandze and Lotti 2023. 

46  Acemoğlu and Restrepo 2019. 

47  See, for example, Johnson and Acemoğlu 

2023. 

48  Spence 2024. For example, studies show that 

a combination of human expertise and AI ca -

pabilities can outperform strategies that rely 

exclusively on human efforts or AI alone (Cao 

and others 2024), if each’s relative strength 

is effectively leveraged (Eastwood 2025). 

And firms that adopt frontier technologies 

for product innovation rather than process 

automation see higher sales (Babina and oth -

ers 2024), revenue and employment (Babina 

and others 2024; Hirvonen, Stenhammar and 

Tuhkuri 2022), as well as substntial growth in 

nonroutine jobs (Arntz and others 2024). 

49  Spence 2024; Manyika and Spence 2023. 

50  Cazzaniga and others 2024, p. 9. 

51  Diouf and others 2024. 

52  WTO 2025. 

53  See, for example, Mejia 2025. 

54  National Academies of Sciences Engineering 

and Medicine 2024. 

55  For example, Cazzaniga and others 2024. 

find that higher-educated workers in high-

income economies are better positioned to 

harness generative AI for work augmentation 2 1 6 HUMAN DEVELOPMENT REPORT 2025 

and have more access to and an easier time 

transitioning to roles where generative AI is 

likely to enhance their work 

56  Gmyrek, Winkler and Garganta 2024. 

57  ILO 2024; Krämer and Cazes 2022. 

58  Bastani and Waldenström 2024. 

59  Bastani and others 2024. 

60  Kovacev 2020; Merola 2022. 

61  Bastani and Waldenström 2020; Bastani and 

others 2024; Brollo and others 2024. 

62  Bajpai 2024. 

63  Gaspar 2016. 

64  In Finland subsidies for frontier technology 

adoption led to higher firm-level innovation 

and increases in both revenue and employ -

ment (Hirvonen, Stenhammar and Tuhkuri 

2022). 

65  Wizeline 2023. 

66  Filippucci, Gal and Schief 2024; Spence 

2024. 

67  Arntz and others 2024. Having access to 

high-speed internet increased both firm ex -

ports and the number of jobs per firm, with 

associated reductions in poverty (World Bank 

2024). 

68  Filippucci and others 2024. 

69  J-PAL 2023; Lipowski, Salomons and Zierahn-

Weilage 2024. 

70  UN and ILO 2024. 

71  National Academies of Sciences Engineering 

and Medicine 2024. 

72  See OECD n.d. 

73  National Academies of Sciences Engineering 

and Medicine 2024. 

74  Humeau and Deshpande 2024. 

75  OECD 2024c. 

76  UN and ILO 2024; Brollo and others 2024. 

77  National Academies of Sciences Engineering 

and Medicine 2024. 

78  Korinek and Stiglitz 2018. 

79  Pagliari, Chambon and Berberian 2022. 

80  Crootof and others 2023. 

81  Fügener and others 2021; Zanatto, Chatting -

ton and Noyes 2021. 

82  Singh and Johnston 2019. 

83  Marsh, Vallejos and Spence 2022. 

84  Giacosa and others 2023. 

85  National Academies of Sciences 2022. AI and 

digitally enabled innovations such as gami -

fied elements or task rotations can also make 

workflows more engaging, sustaining focus 

and improving oversight in repetitive tasks 

(Landers and Marin 2021). 

86  Ball 2021. 

87  Martin, Wellen and Grimmer 2016. 

88  Ball 2021. 

89  In many cases companies developing AI-

powered applications—particularly in safety 

and surveillance, such as facial recognition, 

closed circuit television and autonomous ve -

hicles—actively obscure the extensive human 

labour involved, prioritizing the perception of 

cutting-edge technology or being at the fore -

front of technological development (Tubaro 

2021). This practice, often referred to as “faux -

tomation” (coined by Taylor 2018), pseudo-AI, 

forged labour or AI impersonation “involves a 

process of ontological obfuscation whereby 

technological deficiencies are bootstrapped 

through the use of human workers” (Newlands 

2021, p. 6). In other words, in these cases AI is 

less about replacing humans and more about 

relying on workers with work deficits, such 

as low earnings, a lack of social protection 

and poor occupational safety and health to 

sustain the AI system. Beyond standard data 

labelling or training, these workers manually 

perform tasks marketed as AI technologies. 

Even sophisticated large language models 

with impressive capabilities rely heavily on 

human trainers to fine-tune their responses 

and mitigate biases, toxicity and disturbing 

content. We are grateful to Uma Rani at the 

International Labour Organization for valuable 

input on this matter. 

90  UN and ILO 2024. 

91  Jindal 2023. 

92  Aloisi and De Stefano 2022. We thank Uma 

Rani at the International Labour Organization 

for key contributions on the workers in the AI 

supply chain. 

93  Acemoğlu 2024. For instance, AI is trans -

forming scientific discovery by expediting 

the entire research process, from extracting 

knowledge and generating hypotheses to 

accelerating experimentation and verification, 

all at an unprecedented pace (AAAI 2025). 

94  Classical programming has supported many 

new discoveries. One example is the use of 

computers to prove the four-color theorem 

in 1976 (Robertson and others 1997). But, 

as argued here, the potential of AI goes 

beyond what was possible with classical 

programming. 

95  Goldin and others 2024. 

96  Bloom and others 2020. 

97  Crafts 2021. 

98  Ferrario and Loi 2022. Ferrario and Loi 2022. 

99  Multistakeholder partnerships are useful 

because choices are shaped not only by 

governments and technology companies but 

also by academic institutions, civil society or -

ganizations, multilateral agencies and worker 

associations (spotlight 6.3). Each brings dis -

tinct perspectives and capabilities to shape 

choices so that AI is developed and deployed 

in ways that advance human development. 

100  Al-Kharusi and others 2024. 

101  The European Commission’s Joint Research 

Centre (Rikap 2024) highlights the immense 

influence of private investment in AI and 

technology, noting that only the United States 

and China allocate more public funding to 

research and development than any of the 

five largest US technology companies— 

Apple, Amazon, Alphabet (Google), Meta 

and Microsoft—when measured by business 

enterprise research and development. 

102  Cited in Haase and Pokutta (2024), p. 2. 

103  While hallucinations in large language models 

are problematic and undesirable if the user is 

interested in factually accurate outputs, they 

may also be seen as a resource to inspire 

creativity (Sui and others 2024), though they 

remain deeply problematic if they misrepre -

sent scientific knowledge (Sinha and others 

2025). 

104  Ashkinaze and others 2024; Bilalić, Graf and 

Vaci 2025; Boussioux and others 2024; Fu 

and others 2024; Girotra and others 2023; 

Glickman and Sharot 2024a. There is also the 

potential to use AI to enhance public under -

standing of science (Markowitz 2024). 

105  Glickman and Sharot 2024b; Peng, Garg and 

Kleinberg 2024; Vaccaro, Almaatouq and 

Malone 2024. 

106  The award of the 2024 Nobel Prizes in both 

physics and chemistry to AI-related break -

throughs triggered some soul searching 

about an epistemic barrier having potentially 

been breaching: pattern seeking without rea -

soning or explanation was deemed worthy of 

scientific respect (Meng 2024). 

107  Melumad and Yun 2025. 

108  Kapoor and others 2024. 

109  For evidence on complementarity, see Agar -

wal and others (2023), Agarwal and others 

(2024) and Ludwig, Mullainathan and Ram -

bachan (2024). 

110  A more rigorous way of stating AI’s unique ca -

pabilities in comparison with those of humans 

is that it has the ability to impose mathemati -

cal structure onto unstructured data (Hofman 

and others 2021). 

111  Abolghasemi, Ganbold and Rotaru 2025; Luo 

and others 2024; Karger and others 2024; 

Schoenegger and others 2024a; Schoeneg -

ger and others 2024b. Expert predictions are 

often very fraught (Grossmann and others 

2024). 

112  Lenton and others 2024. 

113  Pyzer-Knapp and others 2022b. 

114  Pyzer-Knapp and others 2022b. 

115  Merchant and others 2023. 

116  Toner-Rodgers 2024. 

117  Agrawal, McHale and Oettl 2024; Ludwig and 

Mullainathan 2024; Tranchero and others 

2024. 

118  Data are based on the use of AI in published 

scholarly papers in agriculture and food 

sciences, art, biology, business, chemistry, 

computer science, economics, education, 

engineering, environmental sciences, geol -

ogy, history, linguistics, materials science, 

mathematics, medicine, philosophy, physics, 

political science and psychology (Duede and 

others 2024; Xie and others 2024). 

119  Koch, Stojkoski and Hidalgo 2024. More 

speculatively, some have argued for the NOTES  2 1 7 

potential to use texts from the past to train 

large language models to enrich historical 

analysis (Varnum and others 2024). 

120  Sakai and others 2024. For other applica -

tions in archaeology, see Cardarelli 2024. But 

applications of AI in archaeology have also 

triggered heated debates, see Huggett (2021, 

2022), Cobb (2023), Gustafson (2024), Mag -

nani and Clindaniel (2023) and Sobotkova 

and others (2024). 

121  In December 2023 a leading journal pub -

lished a review of AI applications in economics 

(Korinek 2023a). This review has had two up -

dates, one in June 2024 (Korinek 2024b) and 

another in December 2024 (Korinek 2024a). 

See also Ash and Hansen (2023), Chen and 

others (2023b), Dell (2024) and Manning, Zhu 

and Horton (2024) and, in finance, Du and 

others (2025), Eisfeldt and Schubert (2024) 

and Kim, Muhn and Nikolaev (2024). Many 

recent studies use large language models to 

simulate responses by humans in surveys and 

behavioural science experiments using homo 

silicus instead of humans in economics (Filip -

pas, Horton and Manning 2024; Manning, Zhu 

and Horton 2024), finance (Yang and others 

2025) and political science (Argyle and oth -

ers 2023; Piao and others 2025). One recent 

study used a collection of 1 billion synthetic 

personas to generate synthetic data (Ge and 

others 2024). Still, it is important to look at 

these applications with care. In psychology 

studies, using large language models instead 

of people produces falsely significant findings 

(Cui, Li and Zhou 2024), and Boelaert and oth -

ers (2025) show that large language models 

respond to survey questions differently than 

humans. Thus, using generative AI in this way 

should be carefully considered and justified, 

not driven by the superficial anthropomor -

phizing perspective that large language 

models are like humans. It is also important 

to be mindful of the potential cultural biases 

(Atari and others 2025) or diversity of politi -

cal preferences (Rozado 2024) embedded in 

large language models. 

122  Osnabrügge, Ash and Morelli 2023; Licht 

2023. 

123  Nguyen and others 2024. 

124  Piaggi and others 2022. 

125  Reynolds and others 2025a. 

126  Chakraborty and others 2024; Eggertsen and 

others 2025; Gao and others 2024; Mehan -

dru and others 2025; Singh, Kaur and Gehlot 

2024; Zhang and others 2024b. 

127  Jiang and others 2024. 

128  Antunes, Butler and Grau-Crespo 2024; Mor -

tazavi 2025; Park, Li and Walsh 2024; Zeni 

and others 2025. The importance of human 

evaluation of AI outputs in materials science 

was put in sharp relief by the work of Li and 

others (2025), who show that training data 

limitations constrain the generalizability and 

interpretation of AI outputs in exploring new 

materials. 

129  Romera-Paredes and others 2024. 

130  Luo and others 2024. Purves (2019) explores 

how AI’s success in playing board games is 

helping scientists gain new insights into the 

brain. 

131  He 2024. 

132  Abdurahman and others 2024; Feuerriegel 

and others 2025; Ke and others 2024; Peters 

and Matz 2024; Rathje and others 2024. 

133  Zhang and others 2025. 

134  Price and others 2024; Kochkov and oth -

ers 2024. For other applications, see, for 

instance, Bran and others (2024), Kutz and 

others (2024) and Ma and others (2025). A 

new algorithmic architecture has also shown 

promise for physics-informed AI models, 

opening the possibility of AI that combines 

the best of both worlds: the ability to discern 

patterns in data while producing outputs 

constrained by the laws of physics (Liu and 

others 2024c; Rigas and others 2024; Urbán, 

Stefanou and Pons 2025). 

135  Enhancing what has been described as col -

lective intelligence (Burton and others 2024; 

Cui and Yasseri 2024; Gupta and others 

2023; Leonard and Levin 2022; Peeters and 

others 2021; Riedl and others 2021; Woolley 

and Gupta 2024), building on insights about 

broader interactions between humans and 

machines (Brinkmann and others 2023; Pe -

dreschi and others 2025; Rahwan and others 

2019; Tsvetkova and others 2024). 

136  Yan and others 2024. 

137  Collins and others 2024. 

138  Bail 2024; Binz and others 2025; Eger and 

others 2025; He and others 2023; Hullman, 

Holtzman and Gelman 2023; Si, Yang and 

Hashimoto 2024. The risk of misuse, com -

mon to AI more broadly, is a particularly seri -

ous concern, particularly in biology and drug 

discovery (Urbina and others 2022). One risk 

is related to the use of AI to write scholarly 

papers (Haider and others 2024; Novy-Marx 

and Velikov 2025). 

139  Doshi and Hauser 2024; Wenger and Kenett 

2025. 

140  For example, 82 percent of the scientists 

who registered the dramatic improvement 

in materials discovery mentioned above also 

reported feeling less fulfilled in their work 

(Toner-Rodgers 2024; see also Ghosh and 

Sadeghian 2024 and Salah and others 2024). 

141  Resnik and others 2025. 

142  Blau and others 2024. 

143  On liability challenges, see Volokh (2023). For 

recent journalistic accounts on debates over 

intellectual property, see Olson and Prince 

(2025) and Thornhill (2025). 

144  Kapoor and Narayanan 2023; McGreivy and 

Hakim 2024; Rosenblatt and others 2024. 

145  Messeri and Crockett 2024. 

146  Ugander and Epstein (2024) emphasize the 

importance of randomness in creative pro -

cesses. In 2023 the journal Science invited 

young scientists to imagine a call from an 

AI sentient researcher for human help: what 

would AI need that only humans can provide? 

The contributions illuminated the unique 

role of humans in establishing connections 

with people, triggering creativity by making 

mistakes, having perceptual capabilities, be -

ing contextual and cultural aware and being 

unpredictable (Heim and others 2023). 

147  One innovation trap is the illusion of consen -

sus that occurs when shared terminology cre -

ates a false impression of agreement on AI 

goals, even when those goals remain highly 

contested. This misleading consensus can 

divert attention from more pressing and tan -

gible challenges in AI development. Another 

trap is “supercharging bad science,” which 

refers to the way poorly defined concepts 

and experimental methods, often justified by 

the pursuit of artificial general intelligence, 

worsen existing problems in AI research. 

The lack of clear scientific rigour in these 

areas leads to unreliable findings and hinders 

meaningful progress (Blili-Hamelin and others 

2025). 

148  Blili-Hamelin and others (2025) pose critical 

questions about the direction of AI research, 

asking how we can ensure that its goals 

align with scientific, engineering and societal 

needs, what constitutes rigorous scien -

tific inquiry in AI and who has the authority to 

shape these objectives. They argue that the 

research community should move away from 

treating artificial general intelligence as the 

ultimate goal of AI development. 

149  AAAI 2025. 

150  Wang, Hertzmann and Russakovsky 2024. 

151  AAAI 2025.; Sharma 2024. 

152  ETO 2024. 

153  The number of scientific AI peer-reviewed 

articles has increased, with about 1.2 million 

articles released between 2017 and 2022, yet 

this key field is underrepresented (ETO 2024). 

154  Computer vision enables machines to inter -

pret visual data through techniques such as 

image recognition, object detection, facial 

recognition, video analysis, medical imaging 

and scene understanding. Closely linked to 

real-world applications, robotics extends AI’s 

reach into physical systems, incorporating 

autonomous navigation, reinforcement learn -

ing for robotic control, humanoid robotics, 

swarm robotics and human–robot interaction. 

Natural language processing allows AI to 

understand and generate human language, 

encompassing machine translation, sentiment 

analysis, speech recognition, conversational 

AI, information retrieval and text summariza -

tion. Underpinning all these advancements is 

AI safety, which focuses on keeping systems 

robust, interpretable and aligned with hu -

man values, addressing key challenges such 

as adversarial resilience, fairness and bias 

mitigation and ensuring ethical deployment 

to prevent unintended harm. See Bengio and 

others (2024); Gyevnar and Kasirzadeh 2025. 

155  ETO 2024. 

156  Zhong and others 2024. 

157  See Tonja and others (2024) and Zhong and 

others (2024). 

158  UN and ILO 2024. 

159  Barzelay, Ng and Romanoff 2024. 2 1 8 HUMAN DEVELOPMENT REPORT 2025 

160  AI is increasingly enabling cross-border col -

laboration in research and innovation, foster -

ing new networks of knowledge production 

across regions. One notable example is the 

deepening AI research collaboration be -

tween China and Singapore. Between 2016 

and 2021 their joint AI publications more 

than doubled. Singapore has become a key 

hub for Chinese technology firms seeking to 

expand their research, investment and talent 

pipelines. Major players such as Alibaba, 

Huawei and Yitu established research out -

posts in the city-state during the late 2010s, 

often partnering with local universities or 

startups. This surge in colocated research 

and development has translated into mean -

ingful academic collaboration: since 2010 

China has been Singapore’s top collabora -

tor in AI research, with more than 10,000 

coauthored AI publications—nearly double 

the number involving the United States. Con -

versely, Singapore ranks among China’s top 

five international research partners in AI. See 

ETO (2023). 

161  Barzelay, Ng and Romanoff 2024. 

162  Human Development Report Office 

calculations using data retrieved in No -

vember 2024 from the Emerging Technol -

ogy Observatory. The HDI classification is 

indicated in https://hdr.undp.org/data-center/ 

human-development-index#/indicies/HDI. 

163  Lehdonvirta, Wú and Hawkins 2024. The 

authors discuss the geopolitics of AI chip pro -

duction (graphics processing units). They de -

scribe a division between the Compute North 

and Compute South, as well as Compute Des -

erts—distinctions based on countries’ access 

to investment and semiconductor manufac -

turing. This perspective highlights the emerg -

ing global disparities in compute power and 

its implications for technological sovereignty 

and AI research and development. 

164  Atari and others 2025. 

165  Narayanan and Kapoor 2024. 

166  UNESCO 2024. 

167  Global life expectancy at birth is projected to 

reach 73.5 years in 2025, up from 64 years in 

1990 (UNDESA 2024b.). 

168  Lutz and others 2021. 

169  This estimate is based on math and science 

and corrects for the percentage of children 

outside the school system (see Gust, Hanush -

ek and Woessmann 2024b). A different global 

estimate indicates that 58 percent of students 

achieved minimum proficiency in reading by 

2019 (see UNDESA 2024a). 

170  Gust, Hanushek and Woessmann 2024a. 

171  See table 1 in Statistical annex. 

172  WHO 2021. 

173  UNDP 2019. 

174  Pritchett 2024. 

175  Muthukrishna 2025. 

176  These three categories fall in the space of 

higher-order thinking, which encompasses 

critical thinking, creative thinking and rela -

tional thinking (Miri, David and Uri 2007) 

177  Normile 2025. 

178  OECD 2024b. 

179  Gould, Jimenez Naranjo and Balvanera 2025. 

180  Molenaar 2022; Tuomi 2019. 

181  Faber, Luyten and Visscher 2017. 

182  Angrist and Meager 2023. A study analys -

ing more than 200 education policies and 

interventions across 52 countries reveals that 

targeting instruction to students’ learning lev -

els, rather than to their grade level, alongside 

structured pedagogy, significantly improves 

education outcomes (Angrist and others 

2024). 

183  Jordan and others 2024. 

184  Angrist, Bergman and Matsheng 2022. 

185  Angrist and others 2023. Students who re -

ceived personalized tutoring through phone 

calls showed significant academic gains, 

highlighting the effectiveness of tailored 

interventions alongside technology adoption 

and increased education spending 

186  Seldon, Abidoye and Metcalf 2020. 

187  Labadze, Grigolia and Machaidze 2023. 

188  Rudolph and others 2024. 

189  Björkegren and others 2025. 

190  Henkel and others 2024. 

191  De Simone 2025. 

192  Alan and Mumcu 2024. 

193  Smith and Livingstone 2017. 

194  Ahuja and others 2025. 

195  Nweje, Amaka and Makai 2025. 

196  Du Boulay 2016. 

197  Aldridge and others 2024. 

198  Hassan and others 2024. 

199  Theopilus and others 2024. A public health 

approach is required to allow children to 

enjoy the benefits of the digital world while 

safeguarding their mental health (Holly, De -

maio and Kickbusch 2024). Although digital 

technologies offer benefits in multiple areas, 

their overuse poses psychological, social and 

ethical challenges. To mitigate these chal -

lenges, schools and parents can implement 

digital wellbeing practices (George and Shaji 

2024). 

200  Beuermann and others 2015; Meza-Cordero 

2017. 

201  A randomized controlled trial in Kenya found 

no meaningful medium-run impacts on chil -

dren’s education or household wellbeing 

(consumption and expenditure, income and 

earnings, asset ownership and wealth ac -

cumulation, employment and labour force 

participation) from expanding electric grid 

infrastructure in rural Kenya, and it could be 

because of credit constraints, bureaucratic 

red tape, low reliability and leakage, which, 

as noted in chapter 1, could be related to 

the lack of complementary assets that could 

make good use of electricity (Lee, Miguel and 

Wolfram 2020). 

202  Muralidharan, Singh and Ganimian 2019. 

203  Atkinson and others 2019. 

204  OECD 2023b. 

205  Ishida, Ihsan and Rudawan 2024. 

206  Farahani and Ghasemi 2024. 

207  OECD 2024a. 

208  Khajeh Naeeni and Nouhi 2024. 

209  Mollick and Mollick 2023. 

210  Ijaz, Bogdanovych and Trescak 2017. 

211  C. Gu and others 2024; X. Gu and others 

2024. 

212  Beg and others 2022. For example, two 

randomized controlled trials in Pakistan found 

that combining teacher engagement with 

curriculum-based videos improved students’ 

test scores more than using videos alone 

(Beg and others 2022). 

213  Ertmer and Ottenbreit-Leftwich 2010. 

214  Angrist and Dercon 2024; Moundridou, Mat -

zakos and Doukakis 2024. See also Bewers -

dorff and others (2025). 

215  Tan and others 2024. 

216  Kirkpatrick, Rivera and Akers 2022. 

217  Sedek 2021. 

218  Bastani and others 2024. 

219  Loeckx 2016. 

220  Koedinger, Corbett and Perfetti 2012. 

221  Koedinger, Corbett and Perfetti 2012. 

222  Mollick and others 2024. 

223  Sperling and others 2022. 

224  Mayer and DaPra 2012. 

225  Lacity and Willcocks 2017. 

226  Selwyn 2019. 

227  Fan and others 2025. 

228  Topol 2024. 

229  Liu and others 2025; Zhang and others 

2024a. 

230  Topol 2023. 

231  Bekbolatova and others 2024; Wachter and 

Brynjolfsson 2024. 

232  Wang and Preininger 2019. 

233  For example, AI is used in obstetric diagnos -

tics, such as foetal cardiotocography and 

ultrasonography (Kim, Cho and Kwon 2022). 

Learning-based inference of longitudinal im -

age changes, a machine learning method, 

could accurately quantify relevant individual-

level changes in longitudinal imaging data, of -

fering valuable insights for studying temporal 

mechanisms or guiding clinical decisions (Kim 

and others 2025). AI has also been deployed 

to identify neurocognitive changes in hard-

to-access regions of the brain to diagnose 

neurodegenerative diseases (Yin and others 

2025). Along with sensors, AI has been de -

ployed in applications ranging from monitor -

ing dietary intake (Park and others 2024to 

sleep patterns (Tang and others 2025). More 

recent applications leverage generative AI 

to enhance disease diagnosis and treatment NOTES  2 1 9 

(Pierson and others 2025; Takita and others 

2025). For example, a recent study found 

GPT-4 diagnosed illnesses with 90 percent 

accuracy, surpassing physicians at 74 percent 

without AI and 76 percent with chatbot assis -

tance, showcasing AI’s potential to improve 

diagnostics (Kolata 2024). 

234  Ferdousi, Hossain and El Saddik 2021. AI-

assisted healthcare systems strengthen 

delivery by enabling collaboration, informa -

tion sharing and the use of electronic health 

records (Palmer and others 2018). For ex -

ample, AI tools such as CC-Cruiser for child -

hood cataract diagnosis and Endoangel for 

colonoscopy monitoring show how machine 

learning can improve workflows and diagnos -

tics (Lin and others 2019). AI can also improve 

the detection of small bowel bleeding lesions, 

offering faster and more accurate results than 

traditional methods (Spada and others 2024). 

235  WHO 2024. For example, AI has improved 

prediction of ischemic heart disease risk by 

integrating clinical records, biomarkers and 

imaging. Advanced diagnostic tools such as 

four-dimensional flow magnetic resonance 

imaging and hybrid systems (including posi -

tron emission tomography/magnetic reso -

nance imaging) provide a comprehensive 

understanding of cardiac health. AI’s ability 

to analyse electrocardiograms, echocardiog -

raphy and coronary angiography shows 

promise in enhancing healthcare, especially 

in low-income countries with limited access 

to specialized expertise (Uzokov and others 

2024). 

236  Bailey and others 2024. 

237  Chaix and others 2019. 

238  A review of 26 randomized controlled trials 

across multiple countries found that mobile 

interventions significantly reduced hospi -

talization rates in heart failure patients and 

lowered systolic blood pressure in hyperten -

sion patients (Indraratna and others 2020) 

Furthermore, AI-powered platforms, includ -

ing facial recognition and computer vision, 

can also monitor medication adherence for 

schizophrenia (Bain and others 2017). 

239  Uzokov and others 2024. 

240  Adapa and others 2025. 

241  Alcazer and others 2024. See also Esteva 

and others (2017), Gulshan and others (2016), 

Hannun and others (2019) and Rajpurkar and 

others (2018). 

242  Turki, Engelke and Sobas 2024. 

243  Khan and others 2022b. 

244  Puja and others 2024. 

245  Towfek and Elkanzi 2024. See also Kraemer 

and others (2025). 

246  For health specifically, see Sagona and others 

(2025) and Tejani and others (2024). For trust 

in AI more generally, see Afroogh and others 

(2024) and von Eschenbach (2021). 

247  Dychiao and others 2024. 

248  Saliba and others 2012; Scott Kruse and oth -

ers 2018. 

249  Celi and others 2022. 

250  Sarkar and others 2024. 

251  UN and ILO 2024. 

252  Parsa and others 2023. 

253  d’Elia and others 2022. 

254  WHO 2022. 

255  Moyer and others 2018. 

256  Roopaei and others 2021. 

257  Singh 2024. 

258  Zhu and others 2024. 

259  Shandhi and others 2024. 

260  For example, see Han and others’ (2024) 

recent scoping review of randomized con -

trolled trials of AI in clinical practice. 

261  Obi and others 2024. 

262  OECD 2023a. 

263  Liu and others 2021. 

264  Hosny and Sollaci 2022. 

265  Denniston and Liu 2024. 

266  Goh and others 2024. 

267  Rotenstein and Wachter 2024. Furthermore, 

A study of 1,600 emergency medical records 

found large language model–generated 

handoff notes superior in automated evalua -

tions but slightly inferior in safety, emphasiz -

ing the need for a physician-in-loop design 

(Hartman and others 2024) 

268  Liu and others 2024a. 

269  Capraro and others 2024. 

270  Lenharo 2024. 

271  Phillips and others 2019. 

272  Seyyed-Kalantari and others 2021. For ex -

ample, systems such as Michigan Medicine’s 

AI for sepsis diagnosis have faced issues 

due to poor calibration across different set -

tings (Gichoya and others 2023.), highlight -

ing the need for better transparency and 

accountability. 

273  Rajpurkar and others 2022. 

274  Sjoding and others 2020. 

275  Slawomirski and others 2023. 

276  Norori and others 2021. 

277  Wilhelm, Steckelberg and Rebitschek 2025. 

278  Wei and others 2024. 

279  Ueda and others 2024. 

280  Chen and others 2023a. 

281  Sandoval-Almazan, Millan-Vargas and Garcia-

Contreras 2024. 

282  Moura and others 2024. 

283  Rosenbacke and others 2024. 

284  Platt and others 2024. 

285  Shevtsova and others 2024. 

286  Gille, Jobin and Ienca 2020. 

287  Singh 2024. Singh 2024. 

288  Singh 2024. Singh 2024. 

289  Lara-Cinisomo and others 2021. Lara-Ciniso -

mo and others 2021. 

290  Soto and others 2018. Soto and others 2018. 

291  Frank and others 2021. Frank and others 

2021. 

292  For example, using data from European 

subnational regions and districts, Antonietti, 

Burlina and Rodriguez-Pose (2025) found that 

strong formal institutions (effective gover -

nance) and informal institutions (bridging 

social capital, trust) were key determinants 

of whether digital technologies exacerbated 

economic divides or brought more equitable 

economic outcomes. 

293  Imbs and Wacziarg 2003. 

294  Oxford Insights 2024. 

295  As indicated by the economic complexity as -

sessment (Harvard Growth Lab 2025). 

296  See, for example, the latest United Nations 

Conference on Trade and Development State 

of Commodity Dependence report (UNCTAD 

2023). 

297  Mishra and others 2023. 

298  Diouf and others 2024. 

299  Rodrik 2016; Rodrik and Sandhu 2024. For 

low and medium HDI countries traditional 

development pathways—adopting exist -

ing technologies and leveraging relatively 

“cheap” labour to compete in international 

markets—have been framed by the expec -

tation of convergence with higher-income 

countries. But actual outcomes have been 

far more complex: while some countries have 

seized these opportunities, convergence with 

very high HDI countries through traditional 

manufacturing- and export-led strategies has 

not materialized for a considerable number 

of countries. Indeed, many countries are now 

experiencing shifts to predominantly service-

based economies at lower incomes (Rodrik 

2016) 

300  Empowerment includes fostering digital 

literacy and algorithmic awareness, enabling 

individuals to understand and critically evalu -

ate AI’s broader implications in their lives 

(Washington 2023). 2 2 0 HUMAN DEVELOPMENT REPORT 2025 

# References 

OVERVIEW 

Acemoğlu, D. 2024.  “Harms of AI.” In Bullock, J. B., 

Chen, Y.-C., Himmelreich, J., Hudson, V. M., Korinek, A., 

Young, M. M. and Zhang, B., (eds.),  The Oxford Hand -

book of AI Governance.  Oxford, UK: Oxford University 

Press. 

Acemoğlu, D., Autor, D., and Johnson, S. 2024.  “Poli -

cy Insight 123: Can We Have Pro-Worker AI?” Centre for 

Economic Policy Research. 

Acemoğlu, D., and Johnson, S. 2023.  Power and 

Progress: Our Thousand-Year Struggle over Technol -

ogy and Prosperity.  New York: Hachette. 

Adam, D. 2023.  “The Muse in the Machine.”  Proceed -

ings of the National Academy of Sciences  120(19): 

e2306000120. 

Adapa, K., Gupta, A., Singh, S., Kaur, H., Trikha, A., 

Sharma, A., and Rahul, K. 2025.  “A Real World Evalu -

ation of an Innovative Artificial Intelligence Tool for 

Population-Level Breast Cancer Screening.”  NPJ Digital 

Medicine  8(1): 2. 

Agrawal, A., Gans, J. S., and Goldfarb, A. 2023. 

“Do We Want Less Automation?”  Science  381(6654): 

155–158. 

Allen, A., Markou, S., Tebbutt, W., Requeima, J., 

Bruinsma, W. P., Andersson, T. R., Herzog, M., and 

others. 2025.  “End-to-End Data-Driven Weather Pre -

diction.”  Nature .

Alzate, D. 2023.  “Addressing Inequalities in Education -

al Markets with the Power of Personalized Information.” 

https://jackson.yale.edu/news/addressing-inequalities-

in-educational-markets-with-the-power-of-personal -

ized-information/. 

Atari, M., Xue, M. J., Park, P. S., Blasi, D., and Hen -

rich, J. 2025.  “Which Humans?”  PsyArXiv . https:// 

psyarxiv.com/5b26t. 

Autor, D. 2022.  “The Labor Market Impacts of Techno -

logical Change: From Unbridled Enthusiasm to Qualified 

Optimism to Vast Uncertainty.” Working Paper 30074, 

National Bureau of Economic Research, Cambridge, MA. 

Autor, D. 2024.  “AI Could Actually Help Rebuild the 

Middle Class.”  Noema Magazine. 

Autor, D., Chin, C., Salomons, A., and Seegmiller, B. 

2024.  “New Frontiers: The Origins and Content of New 

Work, 1940–2018.”  The Quarterly Journal of Econom -

ics : qjae008. 

Autor, D., Salomons, A., and Seegmiller, B. 2024. 

“New Frontiers: The Origins and Content of New Work, 

1940–2018.”  Quarterly Journal of Economics  139(3): 

1399–1465. 

Ayoka, G., Barbareschi, G., Cave, R., and Holloway, 

C. 2024.  “Enhancing Communication Equity: Evalua -

tion of an Automated Speech Recognition Application 

in Ghana.” Proceedings of the CHI Conference on Hu -

man Factors in Computing Systems. 

Babina, T., Fedyk, A., He, A., and Hodson, J. 2024. 

“Artificial Intelligence, Firm Growth, and Product Innova -

tion.”  Journal of Financial Economics  151: 103745. 

Baily, M., Brynjolfsson, E., and Korinek, A. 2023.  “Ma -

chines of Mind: The Case for an AI-Powered Productiv -

ity Boom.” Washington, DC: Brookings Institution. 

Bastian, M. B., Fröhlich, L., Wessendorf, J., Sche -

schenja, M., König, A. M., Jedelska, J., and Mahnken, 

A. H. 2024.  “Prevalence of Burnout among German 

Radiologists: A Call to Action.”  European Radiology 

34(9): 5588–5594. 

Belenguer, L. 2022.  “AI Bias: Exploring Discriminatory 

Algorithmic Decision-Making Models and the Applica -

tion of Possible Machine-Centric Solutions Adapted 

from the Pharmaceutical Industry.”  AI and Ethics  2(4): 

771–787. 

Binz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, 

C. T., Allen, C., Schad, D., and others. 2025.  “How 

Should the Advancement of Large Language Models 

Affect the Practice of Science?”  Proceedings of the Na -

tional Academy of Sciences  122(5): e2401227121. 

Blanchflower, D. G. 2021.  “Is Happiness U-Shaped Ev -

erywhere? Age and Subjective Well-Being in 145 Coun -

tries.”  Journal of Population Economics  34(2): 575–624. 

Blanchflower, D. G. 2025.  “The Global Decline in the 

Mental Health of the Young.”  NBER Reporter , National 

Bureau of Economic Research, Cambridge, MA 

Blanchflower, D. G., Bryson, A., and Xu, X. 2024. 

“The Declining Mental Health of the Young and the 

Global Disappearance of the Hump Shape in Age in 

Unhappiness.” Working Paper 32337, National Bureau 

of Economic Research, Cambridge, MA. 

Bresnahan, T. 2024.  “What Innovation Paths for AI to 

Become a GPT?”  Journal of Economics & Management 

Strategy  33(2): 305–316. 

Brynjolfsson, E. 2022.  “The Turing Trap: The Promise 

& Peril of Human-Like Artificial Intelligence.”  Daedalus 

151(2): 272–287. 

Brynjolfsson, E., Li, D., and Raymond, L. 2025.  “Gen -

erative AI at Work.”  The Quarterly Journal of Econom -

ics  140(2): 889–942. 

Carmichael, M. 2024.  The Ipsos AI Monitor 2024 . Ipsos. 

Cazzaniga, M., Jaumotte, M. F., Li, L., Melina, M. G., 

Panton, A. J., Pizzinelli, C., Rockall, E. J., and Tavares, 

M. M. M. 2024.  Gen-AI: Artificial Intelligence and the 

Future of Work.  SDN/2024/001. Washington, DC: Inter -

national Monetary Fund. 

Chen, X., Pei, G., Song, Z., and Zilibotti, F. 2023.  “Ter -

tiarization Like China.”  Annual Review of Economics  15: 

485–512. 

Cockburn, I. M., Henderson, R., and Stern, S. 2019. 

“The Impact of Artificial Intelligence on Innovation: An 

Exploratory Analysis.” In Ajay, A., Joshua, G. and Avi, G., 

(eds.),  The Economics of Artificial Intelligence.  Chicago, 

IL: University of Chicago Press. 

Conboye, J. 2025.  “Companies Are Fail -

ing to Convince Staff of AI Benefits.”  Finan -

cial Times , 6 March. https://www.ft.com/ 

content/82ba88bb-ab33-4baa-ae6b-f891ea437921. 

Crafts, N. 2021.  “Artificial Intelligence as a General-

Purpose Technology: An Historical Perspective.”  Ox -

ford Review of Economic Policy  37(3): 521–536. 

Cui, H., and Yasseri, T. 2024.  “AI-Enhanced Collective 

Intelligence.”  Patterns  5(11). 

Dangi, R. R., Sharma, A., and Vageriya, V. Forthcom -

ing.  “Transforming Healthcare in Low-Resource Set -

tings with Artificial Intelligence: Recent Developments 

and Outcomes.”  Public Health Nursing .

Delgado-Chaves, F. M., Jennings, M. J., Atalaia, A., 

Wolff, J., Horvath, R., Mamdouh, Z. M., Baumbach, 

J., and Baumbach, L. 2025.  “Transforming Literature 

Screening: The Emerging Role of Large Language 

Models in Systematic Reviews.”  Proceedings of the Na -

tional Academy of Sciences  122(2): e2411962122. 

Dell’Acqua, F., McFowland III, E., Mollick, E. R., Lif -

shitz-Assaf, H., Kellogg, K., Rajendran, S., Krayer, L., 

Candelon, F., and Lakhani, K. R. 2023.  “Navigating 

the Jagged Technological Frontier: Field Experimental 

Evidence of the Effects of AI on Knowledge Worker 

Productivity and Quality.” Technology & Operations 

Management Unit Working Paper 24-013, Harvard Busi -

ness School, Cambridge, MA. 

Dennis, C., Clare, C., Hawkins, R., Simpson, M., 

Behrens, E., Diebold, G., Kara, Z., and others. 2024. 

“What Should Be Internationalised in AI Governance?” 

Oxford Martin AI Governance Initiative. 

Diao, X., Ellis, M., McMillan, M., and Rodrik, D. 2024. 

“Africa’s Manufacturing Puzzle: Evidence from Tanzanian 

and Ethiopian Firms.”  The World Bank Economic Review .

Diouf, M. A., Perez, L. P., Simione, F. F., Viseth, A., 

and Yao, J. 2024.  A Conceptual Policy Framework for 

Leveraging Digitalization to Support Diversification in REFERENCES  2 2 1 

Sub-Saharan Africa.  Washington, DC: International 

Monetary Fund. 

Drolia, M., Papadakis, S., Sifaki, E., and Kalogianna -

kis, M. 2022.  “Mobile Learning Applications for Refu -

gees: A Systematic Literature Review.”  Education Sci -

ences  12(2): 96. 

Dubova, M., Galesic, M., and Goldstone, R. L. 2022. 

“Cognitive Science of Augmented Intelligence.”  Cogni -

tive Science  46(12): e13229. 

Dvijotham, K., Winkens, J., Barsbey, M., Ghaisas, S., 

Stanforth, R., Pawlowski, N., Strachan, P., and oth -

ers. 2023.  “Enhancing the Reliability and Accuracy of 

AI-Enabled Diagnosis Via Complementarity-Driven De -

ferral to Clinicians.”  Nature Medicine  29(7): 1814–1820. 

Epstein, Z., Hertzmann, A., Akten, M., Farid, H., Fjeld, 

J., Frank, M. R., Groh, M., and others. 2023.  “Art and 

the Science of Generative AI.”  Science  380(6650): 

1110–1111. 

Eriksson, M., Purificato, E., Noroozian, A., Vinagre, 

J., Chaslot, G., Gomez, E., and Fernandez-Llorca, D. 

2025.  “Can We Trust AI Benchmarks? An Interdisciplin -

ary Review of Current Issues in AI Evaluation.”  arXiv: 

2502.06559. 

Ernst, E., Merola, R., and Samaan, D. 2019.  “Econom -

ics of Artificial Intelligence: Implications for the Future 

of Work.”  IZA Journal of Labor Policy  9(1). 

Esmaeilzadeh, P. 2024.  “Challenges and Strategies 

for Wide-Scale Artificial Intelligence (AI) Deployment in 

Healthcare Practices: A Perspective for Healthcare Orga -

nizations.”  Artificial Intelligence in Medicine  151: 102861. 

Fan, T., Peters, M., and Zilibotti, F. 2023.  “Growing 

Like India—the Unequal Effects of Service-Led Growth.” 

Econometrica  91(4): 1457–1494. 

Felin, T., and Holweg, M. 2024.  “Theory Is All You 

Need: AI, Human Cognition, and Causal Reasoning.” 

Strategy Science  9(4): 346–371. 

Galaz, V. 2025.  Dark Machines: How Artificial Intelli -

gence, Digitalization and Automation Is Changing Our 

Living Planet.  Taylor & Francis. 

Gmyrek, P., Winkler, H., and Garganta, S. 2024.  “Buffer 

or Bottleneck? Employment Exposure to Generative AI 

and the Digital Divide in Latin America.” Policy Research 

Working Paper 10863, World Bank, Washington, DC. 

Government of Mexico. 2020.  “Outcome Document 

of the High-Level Event ‘Making a Decade of Action for 

Indigenous Languages’ on the Occasion of the Closing 

of the 2019 International Year of Indigenous Languag -

es.” Mexico City: Government of Mexico. 

Hatherley, J. J. 2020.  “Limits of Trust in Medical AI.” 

Journal of Medical Ethics  46(7): 478–481. 

Herrendorf, B., Rogerson, R., and Valentinyi, Á. 

2022.  “New Evidence on Sectoral Labor Productivity: 

Implications for Industrialization and Development.” 

Working Paper 29834, National Bureau of Economic 

Research, Cambridge, MA. 

Higgins, M. C., Nguyen, M.-T., Kosowsky, T., Unan, L., 

Mete, M., Rowe, S., and Marchalik, D. 2021.  “Burnout, 

Professional Fulfillment, Intention to Leave, and Sleep-

Related Impairment among Faculty Radiologists in the 

United States: An Epidemiologic Study.”  Journal of the 

American College of Radiology  18(9): 1359–1364. 

Hoffman, R., and Beato, G. 2025.  Superagency: What 

Could Possibly Go Right with Our AI Future.  New York, 

NY: Simon and Schuster. 

Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, 

H., Chen, Q., and others. 2025.  “A Survey on Halluci -

nation in Large Language Models: Principles, Taxono -

my, Challenges, and Open Questions.”  ACM Transac -

tions on Information Systems  43(2): 42. 

J-PAL (Abdul Latif Jameel Poverty Action Lab). 2023. 

“Vocational and Skills Training Programs to Improve La -

bor Market Outcomes.” https://www.povertyactionlab. 

org/policy-insight/vocational-and-skills-training-pro -

grams-improve-labor-market-outcomes. Accessed 2 

February 2025. 

Jing, C., and Foltz, J. D. 2024.  “Can the Service Sector 

Lead Structural Transformation in Africa? Evidence from 

Côte d’Ivoire.” Presented at the 2024 Annual Meeting 

of the Agricultural and Applied Economics Association, 

28–30 July, New Orleans, LA. 

Johnson, S., and Acemoğlu, D. 2023.  Power and 

Progress: Our Thousand-Year Struggle over Technol -

ogy and Prosperity.  Hachette UK. 

Kanazawa, K., Kawaguchi, D., Shigeoka, H., and 

Watanabe, Y. 2022.  “AI, Skill, and Productivity: The 

Case of Taxi Drivers.” Working Paper 30612, National 

Bureau of Economic Research, Cambridge, MA. 

Korinek, A. 2024.  “The Economics of Transformative 

AI.”  NBER Reporter,  National Bureau of Economic Re -

search, Cambridge, MA. 

Korinek, A., and Vipra, J. 2024.  “Concentrating Intel -

ligence: Scaling and Market Structure in Artificial Intel -

ligence.”  Economic Policy  40(121): 225–256. 

Kruse, H., Mensah, E., Sen, K., and de Vries, G. 2023. 

“A Manufacturing (Re)Naissance? Industrialization in 

the Developing World.”  IMF Economic Review  71(2): 

439–473. 

Labadze, L., Grigolia, M., and Machaidze, L. 2023. 

“Role of AI Chatbots in Education: Systematic Literature 

Review.”  International Journal of Educational Technol -

ogy in Higher Education  20(1): 56. 

Li, Y., Du, Y., Zhou, K., Wang, J., Zhao, W. X., and 

Wen, J.-R. 2023.  “Evaluating Object Hallucination in 

Large Vision-Language Models.”  arXiv:  2305.10355. 

Lipowski, C., Salomons, A., and Zierahn-Weilage, 

U. 2024.  “Expertise at Work: New Technologies, New 

Skills, and Worker Impacts.” ZEW Discussion Papers 

24, Zentrum für Europäische Wirtschaftsforschung, 

Mannheim, Germany. 

Liu, H., Ding, N., Li, X., Chen, Y., Sun, H., Huang, 

Y., Liu, C., and others. 2024.  “Artificial Intelligence 

and Radiologist Burnout.”  JAMA Network Open  7(11): 

e2448714–e2448714. 

Ludwig, J., and Mullainathan, S. 2024.  “Machine 

Learning as a Tool for Hypothesis Generation.”  The 

Quarterly Journal of Economics  139(2): 751–827. 

Luo, X., Rechardt, A., Sun, G., Nejad, K. K., Yáñez, 

F., Yilmaz, B., Lee, K., and others. 2024.  “Large 

Language Models Surpass Human Experts in Predict -

ing Neuroscience Results.”  Nature Human Behaviour .

Manyika, J., and Spence, M. 2023.  “The Coming AI 

Economic Revolution: Can Artificial Intelligence Reverse 

the Productivity Slowdown?”  Foreign Affairs  102: 70. 

Marwala, T. 2024.  “Avoidable and Unavoidable AI Al -

gorithmic Bias.”  The Balancing Problem in the Gover -

nance of Artificial Intelligence.  Springer. 

McCullough, E. B. 2025.  “Structural Transformation 

without Industrialization? Evidence from Tanzanian 

Consumers.”  American Journal of Agricultural Econom -

ics  107(2): 411–439. 

Mienye, I. D., Swart, T. G., and Obaido, G. 2024.  “Fair -

ness Metrics in AI Healthcare Applications: A Review.” 

Presented at the 2024 IEEE International Conference 

on Information Reuse and Integration for Data Science 

(IRI), 7–9 August. 

Mishra, S., Koopman, R., De Prato, G., Rao, A., Os -

orio-Rodarte, I., Kim, J., Spatafora, N., Strier, K., and 

Zaccaria, A. 2023.  “AI Specialization for Pathways of 

Economic Diversification.”  Scientific Reports  13(1): 19475. 

Musslick, S., Bartlett, L. K., Chandramouli, S. H., 

Dubova, M., Gobet, F., Griffiths, T. L., Hullman, J., 

and others. 2025.  “Automating the Practice of Sci -

ence: Opportunities, Challenges, and Implications.” 

Proceedings of the National Academy of Sciences 

122(5): e2401238121. 

Noy, S., and Zhang, W. 2023.  “Experimental Evidence 

on the Productivity Effects of Generative Artificial Intel -

ligence.”  Science  381(6654): 187–192. 

Otis, N. G., Delecourt, S., Cranney, K., and Koning, R. 

2024.  Global Evidence on Gender Gaps and Genera -

tive AI.  Harvard Business School. 

Pedro, F., Subosa, M., Rivas, A., and Valverde, P. 

2019.  “Artificial Intelligence in Education: Challenges 

and Opportunities for Sustainable Development.” 

Working Papers on Educational Policy, UNESCO, Paris. 

Peng, S., Kalliamvakou, E., Cihon, P., and Demirer, 

M. 2023.  “The Impact of AI on Developer Productiv -

ity: Evidence from Github Copilot.”  arXiv:  2302.06590. 

Rodrik, D. 2015.  “Premature Deindustrialization.” 

Working Paper 20935, National Bureau of Economic 

Research, Cambridge, MA. 

Rodrik, D., and Sandhu, R. 2024.  “Servicing Develop -

ment: Productive Upgrading of Labor-Absorbing Serv -

ices in Developing Economies.” Working Paper 32738, 

National Bureau of Economic Research, Cambridge, MA. 

Rodrik, D., and Stiglitz, J. 2024.  A New Growth Strat -

egy for Developing Nations . Cambridge, MA: Harvard 

University. 

Romer, P. M. 1990.  “Endogenous Technological 

Change.”  Journal of Political Economy  98(5, Part 2): 

S71–S102. 

Romer, P. M. 1994.  “The Origins of Endogenous 

Growth.”  Journal of Economic Perspectives  8(1): 3–22. 

Schmid, S., Lambach, D., Diehl, C., and Reuter, C. 

2025.  “Arms Race or Innovation Race? Geopolitical AI 

Development.”  Geopolitics : 1–30. 2 2 2 HUMAN DEVELOPMENT REPORT 2025 

Schut, L., Tomašev, N., McGrath, T., Hassabis, D., 

Paquet, U., and Kim, B. 2025.  “Bridging the Human– 

AI Knowledge Gap through Concept Discovery and 

Transfer in Alphazero.”  Proceedings of the National 

Academy of Sciences  122(13): e2406675122. 

Sen, A. 1999.  Development as Freedom.  New York: 

Anchor Books. 

Shahriar, S., Corradini, M. G., Sharif, S., Moussa, M., 

and Dara, R. 2025.  “The Role of Generative Artificial 

Intelligence in Digital Agri-Food.”  Journal of Agriculture 

and Food Research  20: 101787. 

Solow, R. M. 1956.  “A Contribution to the Theory of 

Economic Growth.”  The Quarterly Journal of Econom -

ics  70(1): 65–94. 

Stiglitz, J. E. 2021.  “From Manufacturing-Led Export 

Growth to a Twenty-First Century Inclusive Growth 

Strategy: Explaining the Demise of a Successful Growth 

Model and What to Do About It.” In Gradín, C., Leib -

brandt, M. and Tarp, F., (eds.),  Inequality in the Develop -

ing World.  Oxford University Press. 

Swartz, E., Denecke, C., and Scheepers, C. B. 2023. 

“Following the Money: Leapfrogging through and with 

Entrepreneurial Growth Companies in Ghana, Kenya, 

Nigeria and South Africa.”  Technological Leapfrogging 

and Innovation in Africa.  Edward Elgar Publishing. 

Thiagarajan, T., Newson, J., and Swaminathan, S. 

2025.  “An Exploration of the Impact of Smartphones in 

Childhood on Mind Health in Young Adulthood.” Unpub -

lished background paper, Human Development Report 

Office, UNDP, New York. Accessed 27 January 2025. 

Thompson, C. 2024.  “Generational AI: Digital Inclusion 

for Aging Populations.” https://www.atlanticcouncil.org/in-

depth-research-reports/report/generational-ai-digital-in -

clusion-for-aging-populations/. Accessed 12 June 2024. 

Touzet, C. 2023.  “Using AI to Support People with Dis -

ability in the Labour Market: Opportunities and Chal -

lenges.” Paris: OECD Publishing. 

UN (United Nations) and ILO (International Labour Or -

ganization). 2024.  Mind the AI Divide: Shaping a Global 

Perspective on the Future of Work . New York: UN. 

US National Academies of Sciences, Engineering, and 

Medicine. 2024.  Artificial Intelligence and the Future of 

Work.  Washington, DC: The National Academies Press. 

Verhoogen, E. 2023.  “Firm-Level Upgrading in Devel -

oping Countries.”  Journal of Economic Literature  61(4): 

1410–1464. 

Vincent-Lancrin, S., and Van der Vlies, R. 2020. 

“Trustworthy Artificial Intelligence (AI) in Education: 

Promises and Challenges.” OECD Education Working 

Paper 218, OECD Publishing, Paris. 

Walton, N. 2022.  “Digital Platforms as Entrepreneur -

ial Ecosystems and Drivers of Born-Global SMEs in 

Emerging Economies.”  International Entrepreneurship 

in Emerging Markets.  Routledge. 

Wang, A., Hertzmann, A., and Russakovsky, O. 2024. 

“Benchmark Suites Instead of Leaderboards for Evalu -

ating AI Fairness.”  Patterns  5(11). 

Wei, W., Jörg, N., and Rolf, S. 2024.  “Leapfrog Logis -

tics: Digital Trucking Platforms, Infrastructure, and Labor 

in Brazil and China.”  Review of International Political 

Economy  31(3): 930–954. 

Wilson, H., Daugherty, P., and Bianzino, N. 2017.  The 

Jobs That Artificial Intelligence Will Create.  Cambridge, 

MA: MIT Sloan Management Review. 

Zuhair, V., Babar, A., Ali, R., Oduoye, M. O., Noor, Z., 

Chris, K., Okon, I. I., and Rehman, L. U. 2024.  “Ex -

ploring the Impact of Artificial Intelligence on Global 

Health and Enhancing Healthcare in Developing Na -

tions.”  Journal of Primary Care & Community Health  15: 

21501319241245847. 

GLOSSARY 

Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, 

I., Aleman, F. L., Almeida, D.et al. 2023.  “GPT-4 Tech -

nical Report.”  arXiv preprint  arXiv:2303.08774. 

Ballard, D. H., and Brown, C. M. 1982.  Computer Vi -

sion. Prentice Hall Professional Technical Reference. 

Banh, L., and Strobel, G. 2023.  “Generative Artificial 

Intelligence.”  Electronic Markets  33(1): 63. 

Chabert, J.-L., and Barbin, É. 1999.  A History of Al -

gorithms: From the Pebble to the Microchip. Springer .

Cottier, B., Rahman, R., Fattorini, L., Maslej, N., 

Besiroglu, T., and Owen, D. 2024.  “The Rising 

Costs of Training Frontier AI Models.”  arXiv preprint 

arXiv:2405.21015. 

Ding, N., Qin, Y., Yang, G., Wei, F., Yang, Z., Su, Y., 

Hu, S.et al. 2023.  “Parameter-Efficient Fine-Tuning of 

Large-Scale Pre-Trained Language Models.”  Nature 

Machine Intelligence  5(3): 220–235. 

Goertzel, B. 2014.  “Artificial General Intelligence: Con -

cept, State of the Art, and Future Prospects.”  Journal of 

Artificial General Intelligence  5(1): 1. 

Hicks, M. T., Humphries, J., and Slater, J. 2024. 

“Chatgpt Is Bullshit.”  Ethics and Information Technol -

ogy  26(2): 1–10. 

Jarrahi, M. H., Lutz, C., and Newlands, G. 2022.  “Arti -

ficial Intelligence, Human Intelligence and Hybrid Intel -

ligence Based on Mutual Augmentation.”  Big Data & 

Society  9(2): 20539517221142824. 

Ji, J., Qiu, T., Chen, B., Zhang, B., Lou, H., Wang, K., 

Duan, Y.et al. 2023.  “Ai Alignment: A Comprehensive 

Survey.”  arXiv preprint  arXiv:2310.19852. 

Jordan, M. I., and Mitchell, T. M. 2015.  “Machine 

Learning: Trends, Perspectives, and Prospects.”  Sci -

ence  349(6245): 255–260. 

Kordzadeh, N., and Ghasemaghaei, M. 2022.  “Algo -

rithmic Bias: Review, Synthesis, and Future Research 

Directions.”  European Journal of Information Systems 

31(3): 388–409. 

Kotsiantis, S. B., Zaharakis, I. D., and Pintelas, P. E. 

2006.  “Machine Learning: A Review of Classification 

and Combining Techniques.”  Artificial Intelligence Re -

view  26: 159–190. 

McCarthy, J., Minsky, M. L., Rochester, N., and 

Shannon, C. E. 2006.  “A Proposal for the Dartmouth 

Summer Research Project on Artificial Intelligence, Au -

gust 31, 1955.”  AI Magazine  27(4): 12. 

McCulloch, W. S., and Pitts, W. 1943.  “A Logical Cal -

culus of the Ideas Immanent in Nervous Activity.”  The 

Bulletin of Mathematical Biophysics  5: 115–133. 

Mitchell, M. 2024.  Debates on the Nature of Artificial 

General Intelligence.  American Association for the Ad -

vancement of Science. 

--- 2025.  Artificial Intelligence Learns to Reason.  Amer -

ican Association for the Advancement of Science. 

Mukherjee, A., and Chang, H. H. 2025.  “Agentic AI: 

Expanding the Algorithmic Frontier of Creative Problem 

Solving.”  arXiv preprint  arXiv:2502.00289. 

Naveed, H., Khan, A. U., Qiu, S., Saqib, M., Anwar, 

S., Usman, M., Akhtar, N., Barnes, N., and Mian, A. 

2023.  “A Comprehensive Overview of Large Language 

Models.”  arXiv preprint  arXiv:2307.06435. 

Raji, I. D., Bender, E. M., Paullada, A., Denton, E., and 

Hanna, A. 2021.  “AI and the Everything in the Whole 

Wide World Benchmark.”  arXiv preprint  arXiv:2111.15366. 

Shumailov, I., Shumaylov, Z., Zhao, Y., Papernot, N., 

Anderson, R., and Gal, Y. 2024.  “AI Models Collapse 

When Trained on Recursively Generated Data.”  Nature 

631(8022): 755–759. 

UNDP (United Nations Development Programme). 

2024.  Human Development Report 2023-24: Breaking 

the Gridlock: Reimagining Cooperation in a Polarized 

World.  New York. 

Zhang, C., Yang, Z., He, X., and Deng, L. 2020. 

“Multimodal Intelligence: Representation Learning, 

Information Fusion, and Applications.”  IEEE Journal of 

Selected Topics in Signal Processing  14(3): 478–493. 

CHAPTER 1 

AAAI (Association for the Advancement of Artificial 

Intelligence). 2025.  AAAI 2025 Presidential Panel on 

the Future of AI Research . https://aaai.org/about-aaai/ 

presidential-panel-on-the-future-of-ai-research/. Ac -

cessed 28 April 2025. 

Abrahams, S., and Levy, F. S. 2024.  “Could Savan -

nah Be the Next San Jose? The Downstream Effects 

of Large Language Models.” 23 June. https://ssrn.com/ 

abstract=4874104. 

Acemoğlu, D. 2025.  “Institutions, Technology and 

Prosperity.” Working Paper 33442, National Bureau of 

Economic Research, Cambridge, MA. 

Acemoğlu, D., and Johnson, S. 2023.  Power and 

Progress: Our Thousand-Year Struggle over Technol -

ogy and Prosperity.  New York: Hachette. 

Acemoğlu, D., and Restrepo, P. 2018.  “The Race be -

tween Man and Machine: Implications of Technology 

for Growth, Factor Shares, and Employment.”  American 

Economic Review  108(6): 1488–1542. 

Acemoğlu, D., and Restrepo, P. 2019a.  “Artificial Intel -

ligence, Automation, and Work.” In Agrawal, A., Gans, J. 

S. and Goldfarb, A., (eds.),  The Economics of Artificial 

Intelligence: An Agenda.  Chicago, IL: University of Chi -

cago Press. REFERENCES  2 2 3 

Acemoğlu, D., and Restrepo, P. 2019b.  “Automation and 

New Tasks: How Technology Displaces and Reinstates 

Labor.”  Journal of Economic Perspectives  33(2): 3–30. 

Acemoğlu, D., and Restrepo, P. 2019c.  “The Wrong 

Kind of AI? Artificial Intelligence and the Future of 

Labour Demand.”  Cambridge Journal of Regions, 

Economy and Society  13(1): 25–35. 

Acemoğlu, D., and Restrepo, P. 2024.  “A Task-Based 

Approach to Inequality.”  Oxford Open Economics 

3(Supplement 1): i906–i929. 

Acemoğlu, D., Anderson, G. W., Beede, D. N., Buff -

ington, C., Childress, E. E., Dinlersoz, E., Foster, L. 

S., and others. 2022.  “Automation and the Workforce: 

A Firm-Level View from the 2019 Annual Business Sur -

vey.” Working Paper 30659, National Bureau of Eco -

nomic Research, Cambridge, MA. 

Acemoğlu, D., Autor, D., and Johnson, S. 2024.  “Pol -

icy Insight 123: Can We Have Pro-Worker AI?” Policy 

Insight 123, Centre for Economic and Policy Research, 

Paris and London. 

Acemoğlu, D., Fallah, A., Makhdoumi, A., Malekian, 

A., and Ozdaglar, A. 2023.  “How Good Are Privacy 

Guarantees? Platform Architecture and Violation of 

User Privacy.” Working Paper 31413, National Bureau of 

Economic Research, Cambridge, MA. 

Acemoğlu, D., Makhdoumi, A., Malekian, A., and Oz -

daglar, A. 2025.  “When Big Data Enables Behavioral 

Manipulation.”  American Economic Review: Insights 

7(1): 19–38. 

Adam, D. 2023.  “The Muse in the Machine.”  Proceed -

ings of the National Academy of Sciences  120(19): 

e2306000120. 

Adapa, K., Gupta, A., Singh, S., Kaur, H., Trikha, A., 

Sharma, A., and Rahul, K. 2025.  “A Real World Evalu -

ation of an Innovative Artificial Intelligence Tool for 

Population-Level Breast Cancer Screening.”  NPJ Digital 

Medicine  8(1): 2. 

Agarwal, N., Moehring, A., Rajpurkar, P., and Salz, 

T. 2023.  “Combining Human Expertise with Artificial 

Intelligence: Experimental Evidence from Radiology.” 

Working Paper 31422, National Bureau of Economic 

Research, Cambridge, MA. 

Agrawal, A., Gans, J. S., and Goldfarb, A. 2019.  “Arti -

ficial Intelligence: The Ambiguous Labor Market Impact 

of Automating Prediction.”  Journal of Economic Per -

spectives  33(2): 31–50. 

Agrawal, A., Gans, J. S., and Goldfarb, A. 2023.  “Do 

We Want Less Automation?”  Science  381(6654): 155–158. 

Agrawal, A., Gans, J. S., and Goldfarb, A. 2024a. 

“Prediction Machines, Insurance, and Protection: An 

Alternative Perspective on AI’s Role in Production.” 

Journal of the Japanese and International Economies 

72: 101307. 

Agrawal, A., Gans, J. S., and Goldfarb, A. 2024b. 

“The Turing Transformation: Artificial Intelligence, Intel -

ligence Augmentation, and Skill Premiums.”  Harvard 

Data Science Review  Special Issue 5. 

Agrawal, A., Gans, J., and Goldfarb, A. 2022a.  Power 

and Prediction: The Disruptive Economics of Artificial 

Intelligence.  Harvard Business Press. 

Agrawal, A., Gans, J., and Goldfarb, A. 2022b.  Predic -

tion Machines, Updated and Expanded: The Simple Eco -

nomics of Artificial Intelligence.  Harvard Business Press. 

Ahn, J., Verma, R., Lou, R., Liu, D., Zhang, R., and Yin, 

W. 2024.  “Large Language Models for Mathematical 

Reasoning: Progresses and Challenges.”  arXiv preprint 

arXiv:2402.00157 .

Aktan, M. E., Turhan, Z., and Dolu, İ. 2022.  “Attitudes 

and Perspectives Towards the Preferences for Artificial 

Intelligence in Psychotherapy.”  Computers in Human 

Behavior  133: 107273. 

Al-kfairy, M. 2025.  “Strategic Integration of Generative 

AI in Organizational Settings: Applications, Challenges 

and Adoption Requirements.”  IEEE Engineering Man -

agement Review : 1–14. 

Alammar, Z., Alzubaidi, L., Zhang, J., Li, Y., Gupta, 

A., and Gu, Y. 2024.  “Generalisable Deep Learning 

Framework to Overcome Catastrophic Forgetting.”  In -

telligent Systems with Applications  23: 200415. 

Alber, D. A., Yang, Z., Alyakin, A., Yang, E., Rai, S., 

Valliani, A. A., Zhang, J., and others. 2025.  “Medical 

Large Language Models Are Vulnerable to Data-Poi -

soning Attacks.”  Nature Medicine  31(2): 618–626. 

Ales, L., Combemale, C., and Ramayya, K. 2024. 

“Generative AI, Adoption and the Structure of Tasks.” 

Available at SSRN 4786671 .

Ales, L., Combemale, C., Fuchs, E. R., and Whitefoot, 

K. 2023.  “How It’s Made: A General Theory of the La -

bor Implications of Technology Change.” Available at 

SSRN 4615324. 

Allen, A., Markou, S., Tebbutt, W., Requeima, J., Bru -

insma, W. P., Andersson, T. R., Herzog, M., and oth -

ers. 2025.  “End-to-End Data-Driven Weather Predic -

tion.”  Nature : 1–3. 

Altay, S., and Gilardi, F. 2024.  “People Are Skeptical 

of Headlines Labeled as AI-Generated, Even If True or 

Human-Made, Because They Assume Full AI Automa -

tion.”  PNAS Nexus  3(10). 

Alzubaidi, L., Al-Dulaimi, K., Salhi, A., Alammar, Z., 

Fadhel, M. A., Albahri, A. S., Alamoodi, A. H., and 

others. 2024.  “Comprehensive Review of Deep Learn -

ing in Orthopaedics: Applications, Challenges, Trust -

worthiness, and Fusion.”  Artificial Intelligence in Medi -

cine  155: 102935. 

Alzubaidi, L., Zhang, J., Humaidi, A. J., Al-Dujaili, A., 

Duan, Y., Al-Shamma, O., Santamaría, J., and oth -

ers. 2021.  “Review of Deep Learning: Concepts, CNN 

Architectures, Challenges, Applications, Future Direc -

tions.”  Journal of Big Data  8(1): 53. 

Antonietti, R., Burlina, C., and Rodríguez-Pose, A. 

2025.  “Digital Technology and Regional Income In -

equality: Are Better Institutions the Solution?”  Papers in 

Regional Science  104(2): 100079. 

Artsi, Y., Sorin, V., Konen, E., Glicksberg, B. S., Nad -

karni, G., and Klang, E. 2024.  “Large Language Mod -

els for Generating Medical Examinations: Systematic 

Review.”  BMC Medical Education  24(1): 354. 

Athey, S. C., Bryan, K. A., and Gans, J. S. 2020.  “The 

Allocation of Decision Authority to Human and Artificial 

Intelligence.”  AEA Papers and Proceedings  110: 80–84. 

Atkin, D., and Donaldson, D. 2015.  “Who’s Getting 

Globalized?: The Size and Implications of Intra-National 

Trade Costs.” Working Paper 21439, National Bureau of 

Economic Research, Cambridge, MA. 

Autor, D. 2014.  “Polanyi’s Paradox and the Shape of 

Employment Growth.” Working Paper 20485, National 

Bureau of Economic Research, Cambridge, MA. 

Autor, D. 2022.  “The Labor Market Impacts of Tech -

nological Change: From Unbridled Enthusiasm to 

Qualified Optimism to Vast Uncertainty.” Working Paper 

30074, National Bureau of Economic Research, Cam -

bridge, MA. 

Autor, D. 2024.  “AI Could Actually Help Rebuild the 

Middle Class.”  Noema Magazine. 

Autor, D. H. 2019.  “Work of the Past, Work of the Fu -

ture.”  AEA Papers and Proceedings  109: 1–32. 

Autor, D. H., Levy, F., and Murnane, R. J. 2003.  “The 

Skill Content of Recent Technological Change: An Em -

pirical Exploration.”  The Quarterly Journal of Econom -

ics  118(4): 1279–1333. 

Autor, D., Chin, C., Salomons, A., and Seegmiller, B. 

2024.  “New Frontiers: The Origins and Content of New 

Work, 1940–2018.”  The Quarterly Journal of Economics 

139(3): 1399–1465. 

Autor, D., Dorn, D., Katz, L. F., Patterson, C., and Van 

Reenen, J. 2020.  “The Fall of the Labor Share and the 

Rise of Superstar Firms.”  The Quarterly Journal of Eco -

nomics  135(2): 645–709. 

Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., 

Shariff, A., Bonnefon, J.-F., and Rahwan, I. 2018.  “The 

Moral Machine Experiment.”  Nature  563(7729): 59–64. 

Awuah, W. A., Ben-Jaafar, A., Roy, S., Nkrumah-

Boateng, P. A., Tan, J. K., Abdul-Rahman, T., and Atal -

lah, O. 2025.  “Predicting Survival in Malignant Glioma 

Using Artificial Intelligence.”  European Journal of Medi -

cal Research  30(1): 61. 

Azaria, A., Azoulay, R., and Reches, S. 2024.  “Chat -

GPT Is a Remarkable Tool—for Experts.”  Data Intelli -

gence  6(1): 240–296. 

Babina, T., Fedyk, A., He, A. X., and Hodson, J. 2023. 

“Firm Investments in Artificial Intelligence Technolo -

gies and Changes in Workforce Composition.” Working 

Paper 31325, National Bureau of Economic Research, 

Cambridge, MA. 

Babina, T., Fedyk, A., He, A., and Hodson, J. 2024. 

“Artificial Intelligence, Firm Growth, and Product Innova -

tion.”  Journal of Financial Economics  151: 103745. 

Baek, M., DiMaio, F., Anishchenko, I., Dauparas, J., 

Ovchinnikov, S., Lee, G. R., Wang, J., and others. 

2021.  “Accurate Prediction of Protein Structures and 

Interactions Using a Three-Track Neural Network.”  Sci -

ence  373(6557): 871–876. 

Baily, M., Brynjolfsson, E., and Korinek, A. 2023.  “Ma -

chines of Mind: The Case for an AI-Powered Productiv -

ity Boom.” Brookings Institute. 

Baldwin, R., and Okubo, T. 2024.  “Are Software Au -

tomation and Teleworker Substitutes? Preliminary 

Evidence from Japan.”  The World Economy  47(4): 

1531–1556. 2 24 HUMAN DEVELOPMENT REPORT 2025 

Bandiera, O., Elsayed, A., Heil, A., and Smurra, A. 

2022.  “Presidential Address 2022: Economic Devel -

opment and the Organisation of Labour: Evidence from 

the Jobs of the World Project.”  Journal of the European 

Economic Association  20(6): 2226–2270. 

Banh, L., and Strobel, G. 2023.  “Generative Artificial 

Intelligence.”  Electronic Markets  33(1): 63. 

Barassi, V. 2024.  “Toward a Theory of AI Errors: Mak -

ing Sense of Hallucinations, Catastrophic Failures, and 

the Fallacy of Generative AI.”  Harvard Data Science 

Review  (Special Issue 5). 

Barnes, A. J., Zhang, Y., and Valenzuela, A. 2024. 

“AI and Culture: Culturally Dependent Responses to AI 

Systems.”  Current Opinion in Psychology : 101838. 

Baronchelli, A. 2024.  “Shaping New Norms for AI.” 

Philosophical Transactions of the Royal Society B: Bio -

logical Sciences  379(1897): 20230028. 

Barrault, L., Chung, Y.-A., Meglioli, M. C., Dale, D., 

Dong, N., Duquenne, P.-A., Elsahar, H., and others. 

2025.  “Joint Speech and Text Machine Translation for 

up to 100 Languages.”  Nature  637(8046): 587–593. 

Bass, M., Dueholm, M., Kalyani, A., and Ozkan, S. 

2024.  “AI Optimism and Uncertainty: What Can Earn -

ings Calls Tell Us Post-ChatGPT?” Federal Reserve 

Bank of St. Louis. 

Baumol, W. J. 2012.  The Cost Disease: Why Comput -

ers Get Cheaper and Health Care Doesn’t.  New Ha -

ven, CT: Yale University Press. 

Beane, M. 2024.  The Skill Code: How to Save Human 

Ability in an Age of Intelligent Machines.  HarperCollins. 

Becker, A. 2024.  More Everythign Forever: AI Over -

lords, Space Empires, and Silicon Valley’s Crusade to 

Control the Fate of Humanity.  New York: Basic Books. 

Becker, J., Brackbill, D., and Centola, D. 2017.  “Net -

work Dynamics of Social Influence in the Wisdom 

of Crowds.”  Proceedings of the National Academy 

of Sciences of the United States of America  114(26): 

E5070–E5076. 

Becker, J., Porter, E., and Centola, D. 2019.  “The Wis -

dom of Partisan Crowds.”  Proceedings of the National 

Academy of Sciences  166(22): 201817195–201817195. 

Bedi, S., Liu, Y., Orr-Ewing, L., Dash, D., Koyejo, S., 

Callahan, A., Fries, J. A., and others. 2025.  “Testing 

and Evaluation of Health Care Applications of Large 

Language Models: A Systematic Review.”  JAMA  333(4): 

319–328. 

Ben-Ishai, G., Dean, J., Manyika, J., Porat, R., Varian, 

H., and Walker, K. 2024.  “AI and the Opportunity for 

Shared Prosperity: Lessons from the History of Technol -

ogy and the Economy.”  arXiv preprint arXiv:2401.09718 .

Bender, E. M., Gebru, T., McMillan-Major, A., and 

Shmitchell, S. 2021.  “On the Dangers of Stochastic 

Parrots: Can Language Models Be Too Big?”  Proceed -

ings of the 2021 ACM Conference on Fairness, Ac -

countability, and Transparency . Association for Com -

puting Machinery. 

Bengio, Y., Daniel, P., Tamay, B., Rishi, B., Stephen, 

C., Yejin, C., Danielle, G., and others. 2025.  Interna -

tional Scientific Report on the Safety of Advanced AI .

London: UK Department for Science, Innovation and 

Technology and AI Safety Institute, Government of the 

United Kingdom. 

Bengio, Y., Hinton, G., Yao, A., Song, D., Abbeel, P., 

Darrell, T., Harari, Y. N., and others. 2024.  “Manag -

ing Extreme AI Risks Amid Rapid Progress.”  Science 

384(6698): 842–845. 

Benítez, T. M., Xu, Y., Boudreau, J. D., Kow, A. W. C., 

Bello, F., Van Phuoc, L., Wang, X., and others. 2024. 

“Harnessing the Potential of Large Language Models 

in Medical Education: Promise and Pitfalls.”  Journal of 

the American Medical Informatics Association  31(3): 

776–783. 

Berglund, L., Tong, M., Kaufmann, M., Balesni, M., 

Stickland, A. C., Korbak, T., and Evans, O. 2024.  “The 

Reversal Curse: LLMs Trained on ‘A Is B’ Fail to Learn ‘B 

Is A.’”  arXiv preprint arXiv:2309.12288 .

Besiroglu, T., Emery-Xu, N., and Thompson, N. 2024. 

“Economic Impacts of AI-Augmented R&D.”  Research 

Policy  53(7): 105037. 

Bessen, J. 2015.  Learning by Doing: The Real Con -

nection between Innovation, Wages, and Wealth.  Yale 

University Press. 

Bessen, J. 2016.  “How Computer Automation Affects 

Occupations: Technology, Jobs, and Skills.” Law and 

Economics Research Paper 15–49, Boston University 

School of Law. 

Bessen, J. 2018.  “AI and Jobs: The Role of Demand.” 

Working Paper 24235, National Bureau of Economic 

Research, Cambridge, MA. 

Bessen, J., and Frick, W. 2018.  “How Software Is Help -

ing Big Companies Dominate.”  Harvard Business Review .

Bessen, J., Impink, S. M., Reichensperger, L., and 

Seamans, R. 2023.  “The Business of AI Startups.” Law 

and Economics Research Paper 18–28, Boston Univer -

sity School of Law. 

Bessen, J., Goos, M., Salomons, A., and van den 

Berge, W. 2025.  “What Happens to Workers at Firms 

That Automate?”  The Review of Economics and Statis -

tics  107(1): 125–141. 

Beurer-Kellner, L., Fischer, M., and Vechev, M. 2023. 

“Prompting Is Programming: A Query Language for 

Large Language Models.”  Proceedings of the ACM on 

Programming Languages  7: 1946–1969. 

Bewersdorff, A., Hartmann, C., Hornberger, M., Seßler, 

K., Bannert, M., Kasneci, E., Kasneci, G., Zhai, X., and 

Nerdel, C. 2025.  “Taking the Next Step with Genera -

tive Artificial Intelligence: The Transformative Role of 

Multimodal Large Language Models in Science Educa -

tion.”  Learning and Individual Differences  118: 102601. 

Bhandari, A. 2024.  “Revolutionizing Radiology with 

Artificial Intelligence.”  Cureus  16(10). 

Bhattacharyya, R. 2024.  “Digital India Sparks Rush for 

New-Age Software Engineers.”  The Economic Times ,

15 May. https://economictimes.indiatimes.com/jobs/hr-

policies-trends/digital-india-sparks-rush-for-new-age-

software-engineers/articleshow/110126612.cms. 

Bhorat, H., Hill, R., Köhler, T., Monnakgotla, J., and 

Steenkamp, F. 2023.  “Who Are the Robots Coming 

For? The Evolving Task Content of Employment in 

South Africa.” SARChI Industrial Development Working 

Paper Series 2023-06. 

Bhorat, H., Lilenstein, K., Oosthuizen, M., and Thorn -

ton, A. 2020.  Wage Polarization in a High-Inequality 

Emerging Economy . Helsinki: UNU-WIDER. 

Bhuller, M., Havnes, T., McCauley, J., and Mogstad, 

M. 2024.  “How the Internet Changed the Market for 

Print Media.”  American Economic Journal: Applied Eco -

nomics  16(2): 318–358. 

Bick, A., Blandin, A., and Deming, D. J. 2024.  “The 

Rapid Adoption of Generative AI.” Working Paper 32966, 

National Bureau of Economic Research, Cambridge, MA. 

Biecek, P., and Samek, W. 2024.  “Position: Explain to 

Question Not to Justify.”  arXiv preprint arXiv:2402.13914 .

Bigoulaeva, I., Madabushi, H. T., and Gurevych, 

I. 2025.  “The Inherent Limits of Pretrained LLMs: 

The Unexpected Convergence of Instruction Tuning 

and In-Context Learning Capabilities.”  arXiv preprint 

arXiv:2501.08716 .

Bilen, E., and Hervé, J. 2025.  “When AI Gives Bad 

Advice: Critical Thinking in Human-AI Collaborations.” 

SSRN: https://ssrn.com/abstract=5040466. 

Binz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, 

C. T., Allen, C., Schad, D., and others. 2025.  “How 

Should the Advancement of Large Language Models 

Affect the Practice of Science?”  Proceedings of the Na -

tional Academy of Sciences  122(5): e2401227121. 

Björkegren, D., Choi, J. H., Budihal, D., Sobhani, D., 

Garrod, O., and Atherton, P. 2025.  “Could AI Leapfrog 

the Web? Evidence from Teachers in Sierra Leone.” 

arXiv preprint arXiv:2502.12397 .

Blili-Hamelin, B., Graziul, C., Hancox-Li, L., Hazan, H., 

El-Mhamdi, E.-M., Ghosh, A., Heller, K., and others. 

2025.  “Stop Treating AGI as the North-Star Goal of AI 

Research.”  arXiv preprint arXiv:2502.03689 .

Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., 

Arora, S., von Arx, S., Bernstein, M. S., and others. 

2021.  “On the Opportunities and Risks of Foundation 

Models.”  arXiv preprint arXiv:2108.07258 .

Bommasani, R., Kapoor, S., Klyman, K., Longpre, S., 

Ramaswami, A., Zhang, D., Schaake, M., and others. 

2024.  “Considerations for Governing Open Founda -

tion Models.”  Science  386(6718): 151–153. 

Bonnefon, J.-F., Rahwan, I., and Shariff, A. 2024. 

“The Moral Psychology of Artificial Intelligence.”  Annual 

Review of Psychology  75: 653–675. 

Bonney, K., Breaux, C., Buffington, C., Dinlersoz, E., 

Foster, L., Goldschlag, N., Haltiwanger, J., Kroff, Z., and 

Savage, K. 2024a.  “The Impact of AI on the Workforce: 

Tasks Versus Jobs?”  Economics Letters  244: 111971. 

Bonney, K., Breaux, C., Buffington, C., Dinlersoz, 

E., Foster, L., Goldschlag, N., Haltiwanger, J., Kroff, 

Z., and Savage, K. 2024b.  Tracking Firm Use of AI in 

Real Time: A Snapshot from the Business Trends and 

Outlook Survey . Washington, DC: U.S. Census Bureau 

Center for Economic Studies. 

Borges, B., Foroutan, N., Bayazit, D., Sotnikova, A., 

Montariol, S., Nazaretzky, T., Banaei, M., and others. REFERENCES  2 2 5 

2024.  “Could ChatGPT Get an Engineering Degree? 

Evaluating Higher Education Vulnerability to AI Assis -

tants.”  Proceedings of the National Academy of Sci -

ences  121(49): e2414955121. 

Bostrom, N. 2014.  Superintelligence: Paths, Dangers, 

Strategies . Oxford, UK: Oxford University Press. 

Boulus-Rødje, N., Cranefield, J., Doyle, C., and 

Fleron, B. 2024.  “GenAI and Me: The Hidden Work 

of Building and Maintaining an Augmentative Partner -

ship.”  Personal and Ubiquitous Computing : 1–14. 

Boustan, L. P., Choi, J., and Clingingsmith, D. 2022. 

“Computerized Machine Tools and the Transformation 

of US Manufacturing.” Working Paper 30400, National 

Bureau of Economic Research, Cambridge, MA. 

Bradford, A. 2023.  Digital Empires: The Global Battle 

to Regulate Technology.  Oxford University Press. 

Bradford, A., Waxman, M. C., and Li, E. Forthcom -

ing.  “How Domestic Institutions Shape the Global Tech 

War.”  Harvard National Security Journal .

Brady, W. J., and Crockett, M. J. 2024.  “Norm Psy -

chology in the Digital Age: How Social Media Shapes 

the Cultural Evolution of Normativity.”  Perspectives on 

Psychological Science  19(1): 62–64. 

Bresnahan, T. 2021.  “Artificial Intelligence Technolo -

gies and Aggregate Growth Prospects.” In Diamond, J. 

W. and Zodrow, G. R., (eds.),  Prospects for Economic 

Growth in the United States.  Cambridge, UK: Cam -

bridge University Press. 

Bresnahan, T. 2024.  “What Innovation Paths for AI to 

Become a GPT?”  Journal of Economics & Management 

Strategy  33(2): 305–316. 

Brinkmann, L., Baumann, F., Bonnefon, J.-F., Derex, 

M., Müller, T. F., Nussberger, A.-M., Czaplicka, A., and 

others. 2023.  “Machine Culture.”  Nature Human Be -

haviour  7(11): 1855–1868. 

Browne, M. W. 1988.  “How Do You Tell a Chair from 

a Cat? Scientists Say You Could Ask a Pigeon.”  The 

New York Times , 6 December. https://www.nytimes. 

com/1988/12/06/science/how-do-you-tell-a-chair-from-

a-cat-scientists-say-you-could-ask-a-pigeon.html. 

Browne, O., Gazze, L., Greenstone, M., and Rostap -

shova, O. 2023.  “Man Vs. Machine: Technological 

Promise and Political Limits of Automated Regulation 

Enforcement.” Working Paper 30816, National Bureau 

of Economic Research, Cambridge, MA. 

Browning, J., and LeCun, Y. 2022.  “AI and the Limits of 

Language.”  Noema Magazine .

Brynjolfsson, E. 2022.  “The Turing Trap: The Promise 

& Peril of Human-Like Artificial Intelligence.”  Daedalus 

151(2): 272–287. 

Brynjolfsson, E., and Hitt, L. M. 2000.  “Beyond Com -

putation: Information Technology, Organizational Trans -

formation and Business Performance.”  Journal of Eco -

nomic Perspectives  14(4): 23–48. 

Brynjolfsson, E., Collis, A., Diewert, W. E., Eggers, F., 

and Fox, K. J. Forthcoming.  “GDP-B: Accounting for 

the Value of New and Free Goods in the Digital Econ -

omy.”  American Economic Journal: Macroeconomics .

Brynjolfsson, E., Collis, A., Liaqat, A., Kutzman, D., 

Garro, H., Deisenroth, D., Wernerfelt, N., and Lee, 

J. J. 2023.  “The Digital Welfare of Nations: New Mea -

sures of Welfare Gains and Inequality.” Working Paper 

31670, National Bureau of Economic Research, Cam -

bridge, MA. 

Brynjolfsson, E., Jin, W., and Wang, X. 2023.  “Infor -

mation Technology, Firm Size, and Industrial Concen -

tration.” Working Paper 31065, National Bureau of Eco -

nomic Research, Cambridge, MA. 

Brynjolfsson, E., Kim, S. T., and Oh, J. H. 2024.  “The 

Attention Economy: Measuring the Value of Free 

Goods on the Internet.”  Information Systems Research 

35(3): 978–991. 

Brynjolfsson, E., Li, D., and Raymond, L. 2025.  “Gen -

erative AI at Work.”  The Quarterly Journal of Economics .

Brynjolfsson, E., Mitchell, T., and Rock, D. 2018. 

“What Can Machines Learn, and What Does It Mean 

for Occupations and the Economy?”  AEA Papers and 

Proceedings  108: 43–47. 

Bursztyn, L., Handel, B. R., Jimenez, R., and Roth, 

C. 2023.  “When Product Markets Become Collective 

Traps: The Case of Social Media.” Working Paper 31771, 

National Bureau of Economic Research, Cambridge, 

MA. 

Caballero, J., Doerr, S., Mehrotra, A., and Zampolli, F. 

2025.  How Far Can Digital Innovation Improve Credit 

to Small Firms in Emerging Market Economies?  Bank 

for International Settlements. 

Caetano, A., Verma, K., Taheri, A., Kumaran, R., 

Chen, Z., Chen, J., Höllerer, T., and Sra, M. 2025. 

“Agentic Workflows for Conversational Human-AI Inter -

action Design.”  arXiv preprint arXiv:2501.18002 .

Cantwell Smith, B. 2019.  The Promise of Artificial In -

telligence: Reckoning and Judgment.  Cambridge, MA: 

MIT Press. 

Cao, C., Sang, J., Arora, R., Kloosterman, R., Cecere, 

M., Gorla, J., Saleh, R., and others. 2024.  “Prompting 

Is All You Need: LLMs for Systematic Review Screen -

ing.”  medRxiv : 2024.2006. 2001.24308323. 

Caplin, A. 2025a.  “Data Engineering for Cognitive Eco -

nomics.”  Journal of Economic Literature  63(1): 164–196. 

Caplin, A. 2025b.  An Introduction to Cognitive Eco -

nomics: The Science of Mistakes.  Springer Nature. 

Caplin, A., Deming, D. J., Li, S., Martin, D. J., Marx, 

P., Weidmann, B., and Ye, K. J. 2024.  “The ABC’s of 

Who Benefits from Working with AI: Ability, Beliefs, and 

Calibration.” Working Paper 33021, National Bureau of 

Economic Research, Cambridge, MA. 

Caunedo, J., Keller, E., and Shin, Y. 2023.  “Technol -

ogy and the Task Content of Jobs across the Devel -

opment Spectrum.”  The World Bank Economic Review 

37(3): 479–493. 

Cave, S., and Dihal, K. 2019.  “Hopes and Fears for 

Intelligent Machines in Fiction and Reality.”  Nature Ma -

chine Intelligence  1(2): 74–78. 

Chakraborty, N., Ornik, M., and Driggs-Campbell, 

K. 2025.  “Hallucination Detection in Foundation Mod -

els for Decision-Making: A Flexible Definition and 

Review of the State of the Art.” https://doi.org/10.48550/ 

arXiv.2403.16527. 

Chen, J., Lin, H., Han, X., and Sun, L. 2024.  “Bench -

marking Large Language Models in Retrieval-Augment -

ed Generation.”  Proceedings of the AAAI Conference 

on Artificial Intelligence , 17754–17762. 

Chen, L., Zaharia, M., and Zou, J. 2024.  “How Is Chat -

GPT’s Behavior Changing over Time?”  Harvard Data 

Science Review  6(2). 

Chen, X., and Wu, D. 2024.  “Automatic Generation of 

Multimedia Teaching Materials Based on Generative AI: 

Taking Tang Poetry as an Example.”  IEEE Transactions 

on Learning Technologies  17: 1327–1340. 

Chen, X., Pei, G., Song, Z., and Zilibotti, F. 2023a. 

“Tertiarization Like China.”  Annual Review of Econom -

ics  15: 485–512. 

Chen, Y., Liu, T. X., Shan, Y., and Zhong, S. 2023b. 

“The Emergence of Economic Rationality of GPT.”  Pro -

ceedings of the National Academy of Sciences  120(51): 

e2316205120. 

Cheng, A. Y., Guo, M., Ran, M., Ranasaria, A., Sharma, 

A., Xie, A., Le, K. N., and others. 2024.  “Scientific and 

Fantastical: Creating Immersive, Culturally Relevant 

Learning Experiences with Augmented Reality and 

Large Language Models.”  Proceedings of the 2024 CHI 

Conference on Human Factors in Computing Systems .

Honolulu, HI: Association for Computing Machinery. 

Chiplunkar, G., and Goldberg, P. K. 2022.  “The Em -

ployment Effects of Mobile Internet in Developing 

Countries.” Working Paper 30741, National Bureau of 

Economic Research, Cambridge, MA. 

Christensen, F. 2022.  “Streaming Stimulates the Live 

Concert Industry: Evidence from Youtube.”  Internation -

al Journal of Industrial Organization  85: 102873. 

Chua, J., Li, Y., Yang, S., Wang, C., and Yao, L. 2024. 

“AI Safety in Generative AI Large Language Models: A 

Survey.”  arXiv preprint arXiv:2407.18369 .

Clusmann, J., Kolbinger, F. R., Muti, H. S., Carrero, Z. 

I., Eckardt, J.-N., Laleh, N. G., Löffler, C. M. L., and oth -

ers. 2023.  “The Future Landscape of Large Language 

Models in Medicine.”  Communications Medicine  3(1): 141. 

Cockburn, I. M., Henderson, R., and Stern, S. 2019. 

“The Impact of Artificial Intelligence on Innovation: An 

Exploratory Analysis.” In Ajay, A., Joshua, G. and Avi, G., 

(eds.),  The Economics of Artificial Intelligence.  Chicago, 

IL: University of Chicago Press. 

Cohen, M. K., Kolt, N., Bengio, Y., Hadfield, G. K., 

and Russell, S. 2024.  “Regulating Advanced Artificial 

Agents.”  Science  384(6691): 36–38. 

Cohn, A., Gesche, T., and Maréchal, M. A. 2022. 

“Honesty in the Digital Age.”  Management Science 

68(2): 827–845. 

Collins, K. M., Jiang, A. Q., Frieder, S., Wong, L., Zil -

ka, M., Bhatt, U., Lukasiewicz, T., and others. 2024a. 

“Evaluating Language Models for Mathematics through 

Interactions.”  Proceedings of the National Academy of 

Sciences  121(24): e2318124121. 

Collins, K. M., Sucholutsky, I., Bhatt, U., Chandra, K., 

Wong, L., Lee, M., Zhang, C. E., and others. 2024b. 2 2 6 HUMAN DEVELOPMENT REPORT 2025 

“Building Machines That Learn and Think with People.” 

Nature Human Behaviour  8(10): 1851–1863. 

Conboye, J. 2025.  “Companies Are Fail -

ing to Convince Staff of AI Benefits.”  Finan -

cial Times , 6 March. https://www.ft.com/ 

content/82ba88bb-ab33-4baa-ae6b-f891ea437921. 

Constantinides, M., and Quercia, D. 2025.  “The 

Impact of AI on Jobs: HCI Is Missing.”  arXiv preprint 

arXiv:2501.18948 .

Costa-jussà, M. R., Cross, J., Çelebi, O., Elbayad, M., 

Heafield, K., Heffernan, K., Kalbassi, E., and others. 

2024.  “Scaling Neural Machine Translation to 200 Lan -

guages.”  Nature  630(8018): 841–846. 

Cottier, B., R. Rahman, L. Fattorini, N. Maslej and D. 

Owen. 2024.  “The Rising Costs of Training Frontier AI 

Models.”  ArXiv . https://arxiv.org/abs/2405.21015. 

Crafts, N. 2021.  “Artificial Intelligence as a General-

Purpose Technology: An Historical Perspective.”  Ox -

ford Review of Economic Policy  37(3): 521–536. 

Craig, C., Cave, S., Dihal, K., Dillon, S., Montgomery, 

J., Singler, B., and Taylor, L. 2018.  “Portrayals and Per -

ceptions of AI and Why They Matter.”  The Royal Soci -

ety. Retrieved December  15: 2020. 

Creutzig, F., Acemoğlu, D., Bai, X., Edwards, P. N., 

Hintz, M. J., Kaack, L. H., Kilkis, S., and others. 2022. 

“Digitalization and the Anthropocene.”  Annual Review 

of Environment and Resources  47: 479–509. 

Criddle, C. 2025.  “Openai Reveals GPT-4.5 

Amid Flurry of New AI Model Releases.”  Finan -

cial Times , 27 February. https://www.ft.com/ 

content/117ec9b2-745d-4c37-bfc4–6e545a7d3ac1. 

Cucio, M., and Hennig, T. 2025.  “Artificial Intelligence 

and the Philippine Labor Market: Mapping Occupa -

tional Exposure and Complementarity.” Working Paper 

2025/043, IMF Washington, DC. 

Czaplicka, A., Baumann, F., and Rahwan, I. 2024. 

“Mutual Benefits of Social Learning and Algorithmic 

Mediation for Cumulative Culture.”  arXiv preprint 

arXiv:2410.00780 .

D’Souza, S. L., and Davis, L. C. 2024.  Current Perspec -

tives on Radiology Workforce Issues and Potential Solu -

tions.  Diagnostic Imaging  [Online]. Available from: https:// 

www.diagnosticimaging.com/view/current-perspectives-

radiology-workforce-issues-potential-solutions. 

Dahl, M., Magesh, V., Suzgun, M., and Ho, D. E. 

2024.  “Large Legal Fictions: Profiling Legal Halluci -

nations in Large Language Models.”  Journal of Legal 

Analysis  16(1): 64–93. 

Danaher, J. 2024.  “Generative AI and the Future of 

Equality Norms.”  Cognition  251: 105906. 

Dangi, R. R., Sharma, A., and Vageriya, V. Forthcom -

ing.  “Transforming Healthcare in Low-Resource Set -

tings with Artificial Intelligence: Recent Developments 

and Outcomes.”  Public Health Nursing .

Das, B. C., Amini, M. H., and Wu, Y. 2025.  “Security 

and Privacy Challenges of Large Language Models: A 

Survey.”  ACM Computing Surveys  57(6): 1–39. 

De Loecker, J., and Eeckhout, J. 2018.  “Global Market 

Power.” Working Paper 24768, National Bureau of Eco -

nomic Research, Cambridge, MA. 

De Loecker, J., Eeckhout, J., and Unger, G. 2020. 

“The Rise of Market Power and the Macroeconomic Im -

plications.”  The Quarterly Journal of Economics  135(2): 

561–644. 

de Rassenfosse, G., Jaffe, A. B., and Waldfogel, J. 

2025.  “Intellectual Property and Creative Machines.” In 

Jones, B. F. and Lerner, J., (eds.),  Entrepreneurship and 

Innovation Policy and the Economy. 

del Rio-Chanona, R. M., Laurentsyeva, N., and 

Wachs, J. 2024.  “Large Language Models Reduce 

Public Knowledge Sharing on Online Q&Amp;a Plat -

forms.”  PNAS Nexus  3(9). 

Delanerolle, G., Yang, X., Shetty, S., Raymont, V., 

Shetty, A., Phiri, P., Hapangama, D. K., and others. 

2021.  “Artificial Intelligence: A Rapid Case for Ad -

vancement in the Personalization of Gynaecology/ 

Obstetric and Mental Health Care.”  Women’s Health  17: 

17455065211018111. 

Delaporte, I., and Peña, W. 2025.  “The Dynamics of 

Disappearing Routine Jobs in Chile: An Analysis of the 

Link between Deroutinisation and Informality.”  World 

Development  189: 106923. 

Delgado-Chaves, F. M., Jennings, M. J., Atalaia, A., 

Wolff, J., Horvath, R., Mamdouh, Z. M., Baumbach, 

J., and Baumbach, L. 2025.  “Transforming Literature 

Screening: The Emerging Role of Large Language 

Models in Systematic Reviews.”  Proceedings of the Na -

tional Academy of Sciences  122(2): e2411962122. 

Dell, M. 2024.  “Deep Learning for Economists.” Work -

ing Paper 32768, National Bureau of Economic Re -

search, Cambridge, MA. 

Dell’Acqua, F., McFowland III, E., Mollick, E. R., Lif -

shitz-Assaf, H., Kellogg, K., Rajendran, S., Krayer, L., 

Candelon, F., and Lakhani, K. R. 2023.  “Navigating 

the Jagged Technological Frontier: Field Experimental 

Evidence of the Effects of AI on Knowledge Worker 

Productivity and Quality.” Technology & Operations 

Management Unit Working Paper 24-013, Harvard Busi -

ness School, Cambridge, MA. 

Deming, D. J. 2017.  “The Growing Importance of So -

cial Skills in the Labor Market.”  The Quarterly Journal of 

Economics  132(4): 1593–1640. 

Deming, D. J., Ong, C., and Summers, L. H. 2025. 

“Technological Disruption in the Labor Market.” Work -

ing Paper 33323, National Bureau of Economic Re -

search, Cambridge, MA. 

Demirci, O., Hannane, J., and Zhu, X. Forthcoming. 

“Who Is AI Replacing? The Impact of Generative AI on 

Online Freelancing Platforms.”  Management Science .

Deng, J., Dong, W., Socher, R., Li, L. J., Kai, L., and 

Li, F.-F. 2009.  “Imagenet: A Large-Scale Hierarchical 

Image Database.” 2009 IEEE Conference on Computer 

Vision and Pattern Recognition, 20–25 June, 248–255. 

Deroy, O. 2023.  “The Ethics of Terminology: Can 

We Use Human Terms to Describe AI?”  Topoi  42(3): 

881–889. 

Diao, X., Ellis, M., McMillan, M., and Rodrik, D. 2024. 

“Africa’s Manufacturing Puzzle: Evidence from Tanzanian 

and Ethiopian Firms.”  The World Bank Economic Review .

Ding, S., Liu, Z., Dong, X., Zhang, P., Qian, R., He, C., 

Lin, D., and Wang, J. 2024.  “Songcomposer: A Large 

Language Model for Lyric and Melody Composition in 

Song Generation.”  arXiv preprint arXiv:2402.17645 .

Diouf, M. A., Perez, L. P., Simione, F. F., Viseth, A., 

and Yao, J. 2024.  A Conceptual Policy Framework for 

Leveraging Digitalization to Support Diversification in 

Sub-Saharan Africa.  Working Paper 2024/123, Interna -

tional Monetary Fund, Washington, DC. 

Doellgast, V. 2023.  “Strengthening Social Regulation 

in the Digital Economy: Comparative Findings from the 

ICT Industry.”  Labour and Industry  33(1): 22–38. 

Doh, S., Choi, K., Lee, J., and Nam, J. 2023.  “LP-Mu -

sicCaps: LLM-Based Pseudo Music Captioning.”  arXiv 

preprint arXiv:2307.16372 .

Dorsch, J., and Deroy, O. 2025.  “The Impact of Label -

ing Automotive AI as Trustworthy or Reliable on User 

Evaluation and Technology Acceptance.”  Scientific Re -

ports  15(1): 1481. 

Doshi, A. R., and Hauser, O. P. 2024.  “Generative AI 

Enhances Individual Creativity but Reduces the Col -

lective Diversity of Novel Content.”  Science Advances 

10(28): eadn5290. 

Doshi, A. R., Bell, J. J., Mirzayev, E., and Vanneste, B. 

S. 2025.  “Generative Artificial Intelligence and Evaluat -

ing Strategic Decisions.”  Strategic Management Jour -

nal  46(3): 583–610. 

Dranove, D., and Garthwaite, C. L. 2024.  “Artificial In -

telligence, the Evolution of the Healthcare Value Chain, 

and the Future of the Physician.” In Agrawal, A., Gans, 

J., Goldfarb, A. and Tucker, C., (eds.),  The Economics 

of Artificial Intelligence: Health Care Challenges.  Cam -

bridge, MA: National Bureau of Economic Research. 

Dreyfus, H. 1972.  What Computers Can’t Do: The Lim -

its of Artificial Intelligence.  New York: Harper & Row. 

Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., and Mor -

datch, I. 2023.  “Improving Factuality and Reasoning in 

Language Models through Multiagent Debate.”  arXiv 

preprint arXiv:2305.14325 .

Dubova, M., Galesic, M., and Goldstone, R. L. 2022. 

“Cognitive Science of Augmented Intelligence.”  Cogni -

tive Science  46(12): e13229. 

Dutta, S., Ranjan, S., Mishra, S., Sharma, V., Hew -

age, P., and Iwendi, C. 2024.  “Enhancing Educational 

Adaptability: A Review and Analysis of AI-Driven Adap -

tive Learning Platforms.” 4th International Conference 

on Innovative Practices in Technology and Manage -

ment (ICIPTM), 21–23 February. 

Eapen, T., Finkenstadt, D. J., Folk, J., and Venkatas -

wamy, L. 2023.  “How Generative AI Can Augment Hu -

man Creativity.”  Harvard Business Review  101(4). 

Editorial. 2024.  “Seeking Clarity Rather Than Strong 

Opinions on Intelligence.”  Nature Machine Intelligence 

6(12): 1408–1408. 

Eisenmann, T. F., Karjus, A., Sola, M. C., Brinkmann, 

L., Supriyatno, B. I., and Rahwan, I. 2025.  “Expertise REFERENCES  2 2 7 

Elevates AI Usage: Experimental Evidence Compar -

ing Laypeople and Professional Artists.”  arXiv preprint 

arXiv:2501.12374 .

Eisfeldt, A. L., Schubert, G., and Zhang, M. B. 2023. 

“Generative AI and Firm Values.” Working Paper 31222, 

National Bureau of Economic Research, Cambridge, MA. 

Eisfeldt, A. L., Schubert, G., Zhang, M. B., and Taska, 

B. 2024.  “The Labor Impact of Generative AI on Firm 

Values.” Available at SSRN 4436627. 

Ellis, R. P., Martins, B., and Zhu, W. 2017.  “Health 

Care Demand Elasticities by Type of Service.”  Journal 

of Health Economics  55: 232–243. 

Eloundou, T., Manning, S., Mishkin, P., and Rock, D. 

2024.  “GPTs Are GPTs: Labor Market Impact Potential 

of LLMs.”  Science  384(6702): 1306–1308. 

Epstein, Z., Hertzmann, A., Creativity, t. I. o. H., Ak -

ten, M., Farid, H., Fjeld, J., Frank, M. R., and others. 

2023.  “Art and the Science of Generative AI.”  Science 

380(6650): 1110–1111. 

Erumban, A. A., and de Vries, G. J. 2024.  “Structural 

Change and Poverty Reduction in Developing Econo -

mies.”  World Development  181: 106674. 

Fan, T., Peters, M., and Zilibotti, F. 2023.  “Growing 

Like India—the Unequal Effects of Service-Led Growth.” 

Econometrica  91(4): 1457–1494. 

Farrell, H., Gopnik, A., Shalizi, C., and Evans, J. 2025. 

“Large AI Models Are Cultural and Social Technolo -

gies.”  Science  387(6739): 1153–1156. 

Feigenbaum, J., and Gross, D. P. 2024.  “Answering 

the Call of Automation: How the Labor Market Adjusted 

to Mechanizing Telephone Operation.”  The Quarterly 

Journal of Economics  139(3): 1879–1939. 

Felin, T., and Holweg, M. 2024.  “Theory Is All You 

Need: AI, Human Cognition, and Causal Reasoning.” 

Strategy Science  9(4): 346–371. 

Feng, G., Yang, K., Gu, Y., Ai, X., Luo, S., Sun, J., He, 

D., Li, Z., and Wang, L. 2024.  “How Numerical Pre -

cision Affects Mathematical Reasoning Capabilities of 

LLMs.”  arXiv preprint arXiv:2410.13857 .

Fjelland, R. 2020.  “Why General Artificial Intelligence 

Will Not Be Realized.”  Humanities and Social Sciences 

Communications  7(1): 10. 

Fontana, N., Pierri, F., and Aiello, L. M. 2024.  “Nic -

er Than Humans: How Do Large Language Models 

Behave in the Prisoner’s Dilemma?”  arXiv preprint 

arXiv:2406.13605 .

Foster, V., Gorgulu, N., Straub, S., and Vagliasindi, M. 

2023.  “The Impact of Infrastructure on Development 

Outcomes.” Policy Research Working Paper 10343, 

World Bank, Washington, DC. 

Frank, M. C. 2023.  “Baby Steps in Evaluating the Ca -

pacities of Large Language Models.”  Nature Reviews 

Psychology  2(8): 451–452. 

Fried, S., and Lagakos, D. 2023.  “Electricity and Firm 

Productivity: A General-Equilibrium Approach.”  Ameri -

can Economic Journal: Macroeconomics  15(4): 67–103. 

Gadotti, A., Rocher, L., Houssiau, F., Creţu, A.-M., and 

de Montjoye, Y.-A. 2024.  “Anonymization: The Imper -

fect Science of Using Data While Preserving Privacy.” 

Science Advances  10(29): eadn7053. 

Gaessler, F., and Piezunka, H. 2023.  “Training with AI: 

Evidence from Chess Computers.”  Strategic Manage -

ment Journal  44(11): 2724–2750. 

Galaz, V. 2025.  Dark Machines: How Artificial Intelli -

gence, Digitalization and Automation Is Changing Our 

Living Planet.  Taylor & Francis. 

Gallego, A., and Kurer, T. 2022.  “Automation, Digi -

talization, and Artificial Intelligence in the Workplace: 

Implications for Political Behavior.”  Annual Review of 

Political Science  25: 463–484. 

Galton, F. 1907.  “Vox Populi.”  Nature  1949(75): 450–451. 

Gambacorta, L., Sabatini, F., and Schiaffi, S. 2025.  “Ar -

tificial Intelligence and Relationship Lending.” Bank of It -

aly, Economic Research and International Relations Area. 

Ganne, E., Locks, L., and Xu, A. 2024.  Trading with 

Intelligence: How AI Shapes and Is Shaped by Inter -

national Trade.  Geneva, Switzerland: World Trade 

Organization. 

Gans, J. S. 2024.  “How Will Generative AI Impact Com -

munication?”  Economics Letters  242: 111872. 

Gao, Y., and Research, G. C. 2024.  Quantifying Github 

Copilot’s Impact in the Enterprise with Accenture. 

GitHub blog  [Online]. Available from: https://github.blog/ 

news-insights/research/research-quantifying-github-

copilots-impact-in-the-enterprise-with-accenture/. 

Garassino, M. C., Odunsi, K., Siniscalchi, M., and 

Veronesi, P. 2025.  “On the Economic Infeasibility of 

Personalized Medicine, and a Solution.” Working Paper 

33539, National Bureau of Economic Research, Cam -

bridge, MA. 

Gardner, C., and Henry, P. B. 2023.  “The Global In -

frastructure Gap: Potential, Perils, and a Framework 

for Distinction.”  Journal of Economic Literature  61(4): 

1318–1358. 

Gardner, J., Durand, S., Stoller, D., and Bittner, 

R. M. 2023.  “LLark: A Multimodal Instruction-Fol -

lowing Language Model for Music.”  arXiv preprint 

arXiv:2310.07160 .

Gathmann, C., Grimm, F., and Winkler, E. 2025.  “AI, 

Task Changes in Jobs, and Worker Reallocation.” 

Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., 

Brendel, W., Bethge, M., and Wichmann, F. A. 2020. 

“Shortcut Learning in Deep Neural Networks.”  Nature 

Machine Intelligence  2(11): 665–673. 

Gerundino, D., Hearn, C., McAllister, P. A., Romiti, S., 

Saltini, A., Snower, D. J., and Twomey, P. D. 2024. 

“Towards Safe, Secure, and Trustworthy AI: Implement -

ing the G7 AI Hiroshima Policy Framework.” Global 

Leaders in Unity and Evolvement (GLUE). 

Gharahighehi, A., Van Schoors, R., Topali, P., and 

Ooge, J. 2024.  “Supporting Personalized Lifelong Learn -

ing with Human-Centered Artificial Intelligence Systems.” 

Gilardi, F., Alizadeh, M., and Kubli, M. 2023.  “Chat -

GPT Outperforms Crowd Workers for Text-Annotation 

Tasks.”  Proceedings of the National Academy of Sci -

ences  120(30): e2305016120. 

Gilbert, S., Kather, J. N., and Hogan, A. 2024.  “Aug -

mented Non-Hallucinating Large Language Models as 

Medical Information Curators.”  NPJ Digital Medicine  7(1): 

100. 

Giray, L. 2023.  “Prompt Engineering with ChatGPT: A 

Guide for Academic Writers.”  Annals of Biomedical En -

gineering  51(12): 2629–2633. 

Globig, L. K., Xu, R., Rathje, S., and Van Bavel, J. J. 

2024.  “Perceived (Mis)alignment in Generative Artifi -

cial Intelligence Varies across Cultures.” https://osf.io/ 

preprints/psyarxiv/suqa2_v1. Accessed 28 April 2025. 

Gmyrek, P., Berg, J., and Bescond, D. 2023.  “Genera -

tive AI and Jobs: A Global Analysis of Potential Effects 

on Job Quantity and Quality.” Working Paper 96, Inter -

national Labour Organization, Geneva. 

Goethals, S., and Rhue, L. 2024.  “One World, One 

Opinion? The Superstar Effect in LLM Responses.” 

arXiv preprint arXiv:2412.10281 .

Goldberg, P. K., and Reed, T. 2023.  “Presidential Ad -

dress: Demand-Side Constraints in Development. The 

Role of Market Size, Trade, and (in)Equality.”  Economet -

rica  91(6): 1915–1950. 

Goldfarb, A., and Que, V. F. 2023.  “The Economics 

of Digital Privacy.”  Annual Review of Economics  15: 

267–286. 

Gollin, D., and and Kaboski, J. P. 2023.  “New Views 

of Structural Transformation: Insights from Recent Lit -

erature.”  Oxford Development Studies  51(4): 339–361. 

Gonzalez, A., and Matias, J. N. 2025.  “Measuring the 

Mental Health of Content Reviewers, a Systematic Re -

view.”  arXiv preprint arXiv:2502.00244 .

Gordon, R. 2017.  The Rise and Fall of American 

Growth: The US Standard of Living since the Civil War. 

Princeton, NJ: Princeton University Press. 

Granulo, A., Fuchs, C., and Puntoni, S. 2021.  “Prefer -

ence for Human (Vs. Robotic) Labor Is Stronger in Sym -

bolic Consumption Contexts.”  Journal of Consumer 

Psychology  31(1): 72–80. 

Gray, M. L., and Suri, S. 2019.  Ghost Work: How to 

Stop Silicon Valley from Building a New Global Under -

class.  Harper Business. 

Greenblatt, R., Denison, C., Wright, B., Roger, F., 

MacDiarmid, M., Marks, S., Treutlein, J., and others. 

2024.  “Alignment Faking in Large Language Models.” 

arXiv preprint arXiv:2412.14093 .

Griffin, A. 2024.  “ChatGPT Creators OpenAI Are 

Generating 100 Billion Words Per Day, CEO Says.” 

The Independent , 12 February. https://www.the-inde -

pendent.com/tech/chatgpt-openai-words-sam-altman-

b2494900.html. 

Griot, M., Hemptinne, C., Vanderdonckt, J., and Yuk -

sel, D. 2025.  “Large Language Models Lack Essential 

Metacognition for Reliable Medical Reasoning.”  Nature 

Communications  16(1): 642. 

Guerreiro, N. M., Alves, D. M., Waldendorf, J., Had -

dow, B., Birch, A., Colombo, P., and Martins, A. F. T. 2 2 8 HUMAN DEVELOPMENT REPORT 2025 

2023.  “Hallucinations in Large Multilingual Translation 

Models.”  Transactions of the Association for Computa -

tional Linguistics  11: 1500–1517. 

Gust, S., Hanushek, E. A., and Woessmann, L. 2024. 

“Global Universal Basic Skills: Current Deficits and Im -

plications for World Development.”  Journal of Develop -

ment Economics  166: 103205. 

Hackenburg, K., and Margetts, H. 2024a.  “Evaluating 

the Persuasive Influence of Political Microtargeting with 

Large Language Models.”  Proceedings of the National 

Academy of Sciences  121(24): e2403116121. 

Hackenburg, K., and Margetts, H. 2024b.  “Reply to 

Teeny and Matz: Toward the Robust Measurement of 

Personalized Persuasion with Generative AI.”  Proceed -

ings of the National Academy of Sciences  121(43): 

e2418817121. 

Hager, P., Jungmann, F., Holland, R., Bhagat, K., Hu -

brecht, I., Knauer, M., Vielhauer, J., and others. 2024. 

“Evaluation and Mitigation of the Limitations of Large 

Language Models in Clinical Decision-Making.”  Nature 

Medicine  30(9): 2613–2622. 

Hagos, D. H., Battle, R., and Rawat, D. B. 2024.  “Recent 

Advances in Generative AI and Large Language Mod -

els: Current Status, Challenges, and Perspectives.”  IEEE 

Transactions on Artificial Intelligence  5(12): 5873–5893. 

Haigh, T., Priestley, P. M., and Rope, C. 2016.  ENIAC 

in Action: Making and Remaking the Modern Comput -

er.  MIT Press. 

Haltaufderheide, J., and Ranisch, R. 2024.  “The Eth -

ics of ChatGPT in Medicine and Healthcare: A System -

atic Review on Large Language Models (LLMs).”  NPJ 

Digital Medicine  7(1): 183. 

Hampole, M., Papanikolaou, D., Schmidt, L. D., and 

Seegmiller, B. 2025.  “Artificial Intelligence and the La -

bor Market.” Working Paper 33509, National Bureau of 

Economic Research, Cambridge, MA. 

Harari, Y. N. 2024.  Nexus: A Brief History of Informa -

tion Networks from the Stone Age to AI.  New York: 

Random House. 

Haslberger, M., Gingrich, J., and Bhatia, J. 2024.  “No 

Great Equalizer: Experimental Evidence on AI in the UK 

Labor Market.”  Available at SSRN 4594466 .

Henderson, M. 2022.  “Radiology Facing a Global 

Shortage.”  RSNA News  [Blog], Radiological Soci -

ety of North America, 10 May. https://www.rsna.org/ 

news/2022/may/global-radiologist-shortage. 

Henrich, J. 2015.  The Secret of Our Success.  Princ -

eton, NJ: Princeton University Press. 

Herrendorf, B., Rogerson, R., and Valentinyi, Á. 

2022.  “New Evidence on Sectoral Labor Productivity: 

Implications for Industrialization and Development.” 

Working Paper 29834, National Bureau of Economic 

Research, Cambridge, MA. 

Hewitt, J., Geirhos, R., and Kim, B. 2025.  “We Can’t 

Understand AI Using Our Existing Vocabulary.”  arXiv 

preprint arXiv:2502.07586 .

Hinton, G. 2016.  “On Radiology.” Machine Learning 

and Market for Intelligence Conference, Toronto, ON. 

Hitsuwari, J., Ueda, Y., Yun, W., and Nomura, M. 

2023.  “Does Human–AI Collaboration Lead to More 

Creative Art? Aesthetic Evaluation of Human-Made and 

AI-Generated Haiku Poetry.”  Computers in Human Be -

havior  139: 107502. 

Hjort, J., and Poulsen, J. 2019.  “The Arrival of Fast 

Internet and Employment in Africa.”  American Econom -

ic Review  109(3): 1032–1079. 

Hoes, E., Altay, S., and Bermeo, J. 2023.  “Leveraging 

ChatGPT for Efficient Fact-Checking.”  PsyArXiv . 3 April. 

Hoffman, R., and Beato, G. 2025.  Superagency: What 

Could Possibly Go Right with Our AI Future.  New York: 

Simon and Schuster. 

Hoffmann, M., Boysel, S., Nagle, F., Peng, S., and 

Xu, K. 2024.  “Generative AI and the Nature of Work.” 

Working Paper 25-021, Harvard Business School, Cam -

bridge, MA. 

Hoffreumon, C., Forman, C., and van Zeebroeck, 

N. 2024.  “Make or Buy Your Artificial Intelligence? 

Complementarities in Technology Sourcing.”  Journal 

of Economics & Management Strategy  33(2): 452–479. 

Hofman, J. M., Sharma, A., and Watts, D. J. 2017. 

“Prediction and Explanation in Social Systems.”  Sci -

ence  355(6324): 486–488. 

Hofman, J. M., Watts, D. J., Athey, S., Garip, F., 

Griffiths, T. L., Kleinberg, J., Margetts, H., and others. 

2021.  “Integrating Explanation and Prediction in Com -

putational Social Science.”  Nature  595(7866): 181–188. 

Hofmeyr, J.-H. S. 2021.  “A Biochemically-realisable 

Relational Model of the Self-manufacturing Cell.” 

BioSystems  207: 104463. https://doi.org/10.1016/j. 

biosystems.2021.104463. 

Hosseinioun, M., Neffke, F., Zhang, L., and Youn, H. 

2025.  “Skill Dependencies Uncover Nested Human 

Capital.”  Nature Human Behaviour  9(4). 

Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, 

H., Chen, Q., and others. 2025.  “A Survey on Halluci -

nation in Large Language Models: Principles, Taxono -

my, Challenges, and Open Questions.”  ACM Transac -

tions on Information Systems  43(2): Article 42. 

Huang, M., Jin, M., and Li, N. 2024.  “Augmenting 

Minds or Automating Skills: The Differential Role of 

Human Capital in Generative AI’s Impact on Creative 

Tasks.”  arXiv preprint arXiv:2412.03963 .

Hui, X., Reshef, O., and Zhou, L. 2024.  “The Short-

Term Effects of Generative Artificial Intelligence on 

Employment: Evidence from an Online Labor Market.” 

Organization Science  35(6): 1977–1989. 

Humlum, A., and Vestergaard, E. 2025.  “The Unequal 

Adoption of ChatGPT Exacerbates Existing Inequalities 

among Workers.”  Proceedings of the National Acad -

emy of Sciences  122(1): e2414972121. 

Hunt, J., Cockburn, I. M., and Bessen, J. 2024.  “Is 

Distance from Innovation a Barrier to the Adoption of 

Artificial Intelligence?” Working Paper 33022, National 

Bureau of Economic Research, Cambridge, MA. 

Huo, F. Y., Manrique, P. D., and Johnson, N. F. 2024. 

“Multispecies Cohesion: Humans, Machinery, AI, and 

Beyond.”  Physical Review Letters  133(24): 247401. 

Ibrahim, H., Liu, F., Asim, R., Battu, B., Benabderrah -

mane, S., Alhafni, B., Adnan, W., and others. 2023. 

“Perception, Performance, and Detectability of Con -

versational Artificial Intelligence across 32 University 

Courses.”  Scientific Reports  13(1): 12187. 

Ichien, N., Stamenković, D., and Holyoak, K. J. 2024. 

“Large Language Model Displays Emergent Ability to 

Interpret Novel Literary Metaphors.”  Metaphor and 

Symbol  39(4): 296–309. 

ILO (International Labour Organization). 2012.  “In -

ternational Standard Classification of Occupations 

ISCO-08 Volume 1: Structure, Group Definitions and 

Correspondence Table.” Geneva. https://webapps. 

ilo.org/ilostat-files/ISCO/newdocs-08-2021/ISCO-08/ 

ISCO-08%20EN%20Vol%201.pdf. 

Inklaar, R., Marapin, R., and Gräler, K. 2024.  “Trad -

ability and Sectoral Productivity Differences across 

Countries.”  IMF Economic Review . DOI: 10.1057/ 

s41308-024-00271-w. 

IFPI (International Federation of the Phonographic 

Industry). 2024.  Global Music Report 2025 . London. 

Ishowo-Oloko, F., Bonnefon, J.-F., Soroye, Z., Cran -

dall, J., Rahwan, I., and Rahwan, T. 2019.  “Behavioural 

Evidence for a Transparency–Efficiency Tradeoff in 

Human–Machine Cooperation.”  Nature Machine Intel -

ligence  1(11): 517–521. 

Jaeger, J. 2024.  “Artificial Intelligence is Algorithmic Mim -

icry: Why Artificial “Agents” Are Not (and Won’t Be) Proper 

Agents.”  Neurons, Behavior, Data Analysis, and Theory 

February: 1–21.  https:/ /doi.org/ 10.51628/ 001c.94404 .

Jaeger, J., A. Riedl, A. Djedovic, J. Vervaeke, and D. 

Walsh. 2024.  “Naturalizing Relevance Realization: Why 

Agency and Cognition Are Fundamentally Not Compu -

tational.”  Frontiers in Psychology  15: 1362658.  https:// 

doi.org/10.3389/fpsyg.2024.1362658 .

Jakesch, M., Hancock, J. T., and Naaman, M. 2023. 

“Human Heuristics for AI-Generated Language Are 

Flawed.”  Proceedings of the National Academy of Sci -

ences  120(11): e2208839120. 

Jesson, A., Beltran-Velez, N., Chu, Q., Karlekar, S., 

Kossen, J., Gal, Y., Cunningham, J. P., and Blei, D. 

2024.  “Estimating the Hallucination Rate of Generative 

AI.”  arXiv preprint arXiv:2406.07457 .

Jia, N., Luo, X., Fang, Z., and Liao, C. 2024.  “When and 

How Artificial Intelligence Augments employee Creativ -

ity.”  Academy of Management Journal  67(1): 5–32. 

Jiang, J., Wu, D., Deng, H., Long, Y., Tang, W., Li, X., 

Liu, C., and others. 2024.  “HAIGEN: Towards Human-

AI Collaboration for Facilitating Creativity and Style 

Generation in Fashion Design.”  Proceedings of the 

ACM on Interactive, Mobile, Wearable and Ubiquitous 

Technologies  8(3): Article 107. 

Jiang, W., Park, J., Xiao, R. J., and Zhang, S. 2025.  “AI 

and the Extended Workday: Productivity, Contracting Ef -

ficiency, and Distribution of Rents.” Working Paper 33536, 

National Bureau of Economic Research, Cambridge, MA. 

Jin, J., Walker, J., and Reczek, R. W. 2024.  “Avoiding 

Embarrassment Online: Response to and Inferences 

About Chatbots When Purchases Activate Self-Pre -

sentation Concerns.”  Journal of Consumer Psychology 

n/a(n/a): 1–18. REFERENCES  2 2 9 

Jing, C., and Foltz, J. D. 2024.  “Can the Service Sector 

Lead Structural Transformation in Africa? Evidence from 

Côte d’Ivoire.” 2024 Annual Meeting of the Agricultural 

and Applied Economics Association, 28–30 July, New 

Orleans, LA. 

Johri, S., Jeong, J., Tran, B. A., Schlessinger, D. I., 

Wongvibulsin, S., Barnes, L. A., Zhou, H.-Y., and oth -

ers. 2025.  “An Evaluation Framework for Clinical Use 

of Large Language Models in Patient Interaction Tasks.” 

Nature Medicine  31(1): 77–86. 

Jones, B. F. 2009.  “The Burden of Knowledge and 

the ‘Death of the Renaissance Man:’ Is Innovation Get -

ting Harder?”  The Review of Economic Studies  76(1): 

283–317. 

Jones, C. I. 2023.  “Recipes and Economic Growth: A 

Combinatorial March down an Exponential Tail.”  Jour -

nal of Political Economy  131(8): 1994–2031. 

Jones, C. I. 2024.  “The AI Dilemma: Growth Versus 

Existential Risk.”  American Economic Review: Insights 

6(4): 575–590. 

Jones, C. I. 2025a.  “How Much Should We Spend to 

Reduce AI’s Existential Risk?” Working Paper 33602, 

National Bureau of Economic Research, Cambridge, MA. 

Jones, N. 2025b.  “How AI Can Achieve Human-Level 

Intelligence: Researchers Call for Change in Tack.” 

Nature .

Jörke, M., Sapkota, S., Warkenthien, L., Vainio, N., 

Schmiedmayer, P., Brunskill, E., and Landay, J. 2024. 

“Supporting Physical Activity Behavior Change with 

LLM-Based Conversational Agents.”  arXiv preprint 

arXiv:2405.06061 .

Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, 

M., Ronneberger, O., Tunyasuvunakool, K., and oth -

ers. 2021.  “Highly Accurate Protein Structure Predic -

tion with Alphafold.”  Nature  596(7873): 583–589. 

Kalai, A., and Vempala, S. 2024.  “Calibrated Lan -

guage Models Must Hallucinate.”  arXiv preprint 

arXiv:2311.14648. 

Kanazawa, K., Kawaguchi, D., Shigeoka, H., and 

Watanabe, Y. 2022.  “AI, Skill, and Productivity: The 

Case of Taxi Drivers.” Working Paper 30612, National 

Bureau of Economic Research, Cambridge, MA. 

Kapoor, S., Bommasani, R., Klyman, K., Longpre, S., 

Ramaswami, A., Cihon, P., Hopkins, A., and others. 

2024.  “On the Societal Impact of Open Foundation 

Models.”  arXiv preprint arXiv:2403.07918 .

Kapoor, S., Henderson, P., and Narayanan, A. 2024. 

“Promises and Pitfalls of Artificial Intelligence for Legal 

Applications.”  arXiv preprint arXiv:2402.01656 .

Karabarbounis, L. 2024.  “Perspectives on the La -

bor Share.”  Journal of Economic Perspectives  38(2): 

107–136. 

Karabarbounis, L., and Neiman, B. 2013.  “The Global 

Decline of the Labor Share.”  The Quarterly Journal of 

Economics  129(1): 61–103. 

Karell, D., Sachs, J., and Barrett, R. 2025.  “Synthetic 

Duality: A Framework for Analyzing Generative Artificial 

Intelligence’s Representation of Social Reality.”  Poetics 

108: 101966. 

Kather, J. N., Ferber, D., Wiest, I. C., Gilbert, S., and 

Truhn, D. 2024.  “Large Language Models Could Make 

Natural Language Again the Universal Interface of 

Healthcare.”  Nature Medicine  30(10): 2708–2710. 

Katz, D. M., Bommarito, M. J., Gao, S., and Arredondo, 

P. 2024.  “GPT-4 Passes the Bar Exam.”  Philosophical 

Transactions of the Royal Society A: Mathematical, Phys -

ical and Engineering Sciences  382(2270): 20230254. 

Kaufman, J. H., Woo, A., Eagan, J., Lee, S., and Kas -

san, E. B. 2025.  “Uneven Adoption of Artificial Intel -

ligence Tools among US Teachers and Principals in the 

2023–2024 School Year.” RAND Research Report. 

Khan, W., Leem, S., See, K. B., Wong, J. K., Zhang, 

S., and Fang, R. 2025.  “A Comprehensive Survey of 

Foundation Models in Medicine.”  IEEE Reviews in Bio -

medical Engineering : 1–20. 

Khosravi, M., Mojtabaeian, S. M., Demiray, E. K. D., and 

Sayar, B. 2024.  “A Systematic Review of the Outcomes 

of Utilization of Artificial Intelligence within the Healthcare 

Systems of the Middle East: A Thematic Analysis of Find -

ings.”  Health Science Reports  7(12): e70300. 

Kidd, C., and Birhane, A. 2023.  “How AI Can Distort 

Human Beliefs.”  Science  380(6651): 1222–1223. 

Kirk, H. R., Vidgen, B., Röttger, P., and Hale, S. A. 

2023a.  “Personalisation within Bounds: A Risk Taxon -

omy and Policy Framework for the Alignment of Large 

Language Models with Personalised Feedback.”  arXiv 

preprint arXiv:2303.05453 .

Kirk, H. R., Vidgen, B., Röttger, P., and Hale, S. A. 

2024.  “The Benefits, Risks and Bounds of Personal -

izing the Alignment of Large Language Models to In -

dividuals.”  Nature Machine Intelligence  6(4): 383–392. 

Kirk, R., Mediratta, I., Nalmpantis, C., Luketina, J., 

Hambro, E., Grefenstette, E., and Raileanu, R. 2023b. 

“Understanding the Effects of RLHF on LLM Generali -

sation and Diversity.”  arXiv preprint arXiv:2310.06452 .

Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, 

J., Desjardins, G., Rusu, A. A., Milan, K., and others. 

2017.  “Overcoming Catastrophic Forgetting in Neural 

Networks.”  Proceedings of the National Academy of 

Sciences  114(13): 3521–3526. 

Kleinberg, J., and Raghavan, M. 2021.  “Algorithmic 

Monoculture and Social Welfare.”  Proceedings of the 

National Academy of Sciences  118(22): e2018340118. 

Kogan, L., Papanikolaou, D., Schmidt, L. D., and 

Seegmiller, B. 2021.  “Technology, Vintage-Specific 

Human Capital, and Labor Displacement: Evidence 

from Linking Patents with Occupations.” Working Paper 

29552, National Bureau of Economic Research, Cam -

bridge, MA. 

Kogan, L., Papanikolaou, D., Schmidt, L. D., and 

Seegmiller, B. 2023.  “Technology and Labor Displace -

ment: Evidence from Linking Patents with Worker-Level 

Data.” Working Paper 31846, National Bureau of Eco -

nomic Research, Cambridge, MA. 

Korinek, A. 2024.  “The Economics of Transformative 

AI.”  NBER Reporter,  National Bureau of Economic Re -

search, Cambridge, MA. 

Korinek, A., and Stiglitz, J. E. 2018.  “Artificial Intelli -

gence and Its Implications for Income Distribution and 

Unemployment.” In Agrawal, A., Gans, J. and Goldfarb, 

A., (eds.),  The Economics of Artificial Intelligence: An 

Agenda.  University of Chicago Press. 

Korinek, A., and Stiglitz, J. E. 2020.  “Steering Techno -

logical Progress.” NBER Conference on the Economics 

of AI, 24–25 September. 

Korinek, A., and Stiglitz, J. E. 2021.  “Artificial Intelli -

gence, Globalization, and Strategies for Economic De -

velopment.” Working Paper 28453, National Bureau of 

Economic Research, Cambridge, MA. 

Korinek, A., and Suh, D. 2024.  “Scenarios for the Tran -

sition to AGI.” Working Paper 32255, National Bureau 

of Economic Research, Cambridge, MA. 

Korinek, A., and Vipra, J. 2024.  “Concentrating Intel -

ligence: Scaling and Market Structure in Artificial Intel -

ligence.”  Economic Policy  40(121): 225–256. 

Kovalevskiy, O., Mateos-Garcia, J., and Tunyasuvu -

nakool, K. 2024.  “Alphafold Two Years On: Validation 

and Impact.”  Proceedings of the National Academy of 

Sciences  121(34): e2315002121. 

Krakowski, S. 2025.  “Human-AI Agency in the Age 

of Generative AI.”  Information and Organization  35(1): 

100560. 

Krakowski, S., Luger, J., and Raisch, S. 2023.  “Artifi -

cial Intelligence and the Changing Sources of Competi -

tive Advantage.”  Strategic Management Journal  44(6): 

1425–1452. 

Krishna, A. 2024.  “Will AI Slay the Poverty Dragon?” 

Current History  123(849): 37–39. 

Kruse, H., Mensah, E., Sen, K., and de Vries, G. 2023. 

“A Manufacturing (Re)Naissance? Industrialization in the 

Developing World.”  IMF Economic Review  71(2): 439–473. 

Kruse, H., Timmer, M. P., de Vries, G. J., and Ye, X. 

2024.  “The Occupation Content of Trade.”  The World 

Bank Economic Review .

Kumar, U., Amaglobeli, D., and Moszoro, M. 2023. 

“Determinants and Social Dividends of Digital Adop -

tion.” Working Paper 2023/065, International Monetary 

Fund, Washington, DC. 

Kurz, M. 2023.  The Market Power of Technology: Un -

derstanding the Second Gilded Age.  Columbia Univer -

sity Press. 

Kwa, T., West, B., Becker, J., Deng, A., Garcia, K., 

Hasin, M., Jawhar, S., and others. 2025.  “Measur -

ing AI Ability to Complete Long Tasks.”  arXiv preprint 

arXiv:2503.14499 .

Kwon, B., Park, T., Perez-Cruz, F., and Rungcharoen -

kitkul, P. 2024.  “Large Language Models: A Primer for 

Economists.”  BIS Quarterly Review  37. 

Labadze, L., Grigolia, M., and Machaidze, L. 2023. 

“Role of AI Chatbots in Education: Systematic Literature 

Review.”  International Journal of Educational Technol -

ogy in Higher Education  20(1): 56. 

Lambert, N., and Brand, F. 2025.  “The Latest Open 

Artifacts (#7): Alpaca Era of Reasoning Models, China’s 

Continued Dominance, and Tons of Multimodal Ad -

vancements.”  Interconnects  [Online]. Available from: 

https://www.interconnects.ai/p/artifacts-7. 2 3 0 HUMAN DEVELOPMENT REPORT 2025 

Lang, N., Zhukov, L., Zuluaga Martínez, D., Pore, M., 

and Cavin, E. 2024.  “How CEOs Can Navigate the New 

Geopolitics of GenAI.”  Boston Consulting Group  [Online]. 

Available from: https://www.bcg.com/publications/2024/ 

how-ceos-navigate-new-geopolitics-of-genai. 

Lauscher, A., and Glavaš, G. 2025.  “How Much Do 

LLMs Hallucinate across Languages? On Multilingual 

Estimation of LLM Hallucination in the Wild.”  arXiv pre -

print arXiv:2502.12769 .

Lazar, S. 2024a.  “Automatic Authorities: Power and AI.” 

arXiv preprint arXiv:2404.05990 .

Lazar, S. 2024b.  “Frontier AI Ethics: Anticipating and 

Evaluating the Societal Impacts of Generative Agents.” 

arXiv preprint arXiv:2404.06750 .

Lazar, S. 2024c.  “Power and AI: Nature and Justifica -

tion.” In Bullock, J. B., Chen, Y.-C., Himmelreich, J., Hud -

son, V. M., Korinek, A., Young, M. and Zhang, B., (eds.), 

The Oxford Handbook of AI Governance.  Oxford, UK: 

Oxford University Press. 

Lazar, S., and Stone, J. 2024.  “On the Site of Predic -

tive Justice.”  Nous  58(3): 730–754. 

Lazaridou, A., Gribovskaya, E., Stokowiec, W., and 

Grigorev, N. 2022.  “Internet-Augmented Language 

Models through Few-Shot Prompting for Open-Domain 

Question Answering.”  arXiv preprint arXiv:2203.05115 .

Lazear, E., Shaw, K. L., Hayes, G. E., and Jedras, J. 

M. 2022.  “Productivity and Wages: What Was the Pro -

ductivity-Wage Link in the Digital Revolution of the Past, 

and What Might Occur in the AI Revolution of the Fu -

ture?” Working Paper 30734, National Bureau of Eco -

nomic Research, Cambridge, MA. 

LeCun, Y., Bengio, Y., and Hinton, G. 2015.  “Deep 

Learning.”  Nature  521(7553): 436–444. 

Leduc, S., and Liu, Z. 2024.  “Automation, Bargaining 

Power, and Labor Market Fluctuations.”  American Eco -

nomic Journal: Macroeconomics  16(4): 311–349. 

Lee, H.-P. H., Sarkar, A., Tankelevitch, L., Drosos, 

I., Rintel, S., Banks, R., and Wilson, N. 2025.  “The 

Impact of Generative AI on Critical Thinking: Self-

Reported Reductions in Cognitive Effort and Confi -

dence Effects from a Survey of Knowledge Workers.” 

Proceedings of the 2025 CHI Conference on Human 

Factors in Computing Systems . Yokohama, Japan: As -

sociation for Computing Machinery. 

Lee, K., Miguel, E., and Wolfram, C. 2020a.  “Does 

Household Electrification Supercharge Economic De -

velopment?”  Journal of Economic Perspectives  34(1): 

122–144. 

Lee, K., Miguel, E., and Wolfram, C. 2020b.  “Experi -

mental Evidence on the Economics of Rural Electrifica -

tion.”  Journal of Political Economy  128(4): 1523–1565. 

Lerch, B. 2025.  “From Blue- to Steel-Collar Jobs: The 

Decline in Employment Gaps?”  American Economic 

Journal: Macroeconomics  17(1): 126–160. 

Lerner, J. 2013.  “The Boulevard of Broken Dreams: 

Innovation Policy and Entrepreneurship.”  Innovation 

Policy and the Economy  13(1): 61–82. 

Lerner, J., Liu, J., Moscona, J., and Yang, D. Y. 2024. 

“Appropriate Entrepreneurship? The Rise of China and 

the Developing World.” Working Paper 32193, National 

Bureau of Economic Research, Cambridge, MA. 

Lewis, M., Cahill, A., Madnani, N., and Evans, J. 

2023.  “Local Similarity and Global Variability Charac -

terize the Semantic Space of Human Languages.”  Pro -

ceedings of the National Academy of Sciences  120(51): 

e2300986120. 

Li, H., Chen, X., XU, Z., Li, D., Hu, N., Teng, F., Li, 

Y., and others. 2025.  “Exposing Numeracy Gaps: 

A Benchmark to Evaluate Fundamental Numerical 

Abilities in Large Language Models.”  arXiv preprint 

arXiv:2502.11075 .

Li, L., Xu, W., Guo, J., Zhao, R., Li, X., Yuan, Y., Zhang, 

B., and others. 2024.  “Chain of Ideas: Revolutioniz -

ing Research Via Novel Idea Development with LLM 

Agents.”  arXiv preprint arXiv:2410.13185 .

Li, Y., Du, Y., Zhou, K., Wang, J., Zhao, W. X., and Wen, 

J.-R. 2023.  “Evaluating Object Hallucination in Large Vi -

sion-Language Models.”  arXiv preprint arXiv:2305.10355 .

Liang, Y., Sabia, J. J., and Dave, D. M. 2025.  “Robots 

and Crime.” Working Paper 33603, National Bureau of 

Economic Research, Cambridge, MA. 

Liu, H., Zhou, Y., Li, M., Yuan, C., and Tan, C. 2024a. 

“Literature Meets Data: A Synergistic Approach to Hy -

pothesis Generation.”  arXiv preprint arXiv:2410.17309 .

Liu, L. T., Wang, S., Britton, T., and Abebe, R. 2023.  “Re -

imagining the Machine Learning Life Cycle to Improve 

Educational Outcomes of Students.”  Proceedings of the 

National Academy of Sciences  120(9): e2204781120. 

Liu, R., Geng, J., Wu, A. J., Sucholutsky, I., Lombro -

zo, T., and Griffiths, T. L. 2024b.  “Mind Your Step (by 

Step): Chain-of-Thought Can Reduce Performance on 

Tasks Where Thinking Makes Humans Worse.”  arXiv 

preprint arXiv:2410.21333 .

Liu, S., Yao, Y., Jia, J., Casper, S., Baracaldo, N., Hase, 

P., Yao, Y., and others. 2025.  “Rethinking Machine Un -

learning for Large Language Models.”  Nature Machine 

Intelligence  7(2): 181–194. 

Liu, Y., and Wang, H. 2024.  Who on Earth Is Using 

Generative AI?  World Bank. 

Lu, M. Y., Chen, B., Williamson, D. F. K., Chen, R. J., 

Zhao, M., Chow, A. K., Ikemura, K., and others. 2024. 

“A Multimodal Generative AI Copilot for Human Pathol -

ogy.”  Nature  634(8033): 466–473. 

Lu, P., Peng, B., Cheng, H., Galley, M., Chang, K.-W., 

Wu, Y. N., Zhu, S.-C., and Gao, J. 2023.  “Chameleon: 

Plug-and-Play Compositional Reasoning with Large 

Language Models.”  Advances in Neural Information 

Processing Systems  36: 43447–43478. 

Ludwig, J., and Mullainathan, S. 2024.  “Machine 

Learning as a Tool for Hypothesis Generation.”  The 

Quarterly Journal of Economics  139(2): 751–827. 

Ludwig, J., Mullainathan, S., and Rambachan, A. 

2025.  “Large Language Models: An Applied Econo -

metric Framework.” Working Paper 33344, National Bu -

reau of Economic Research, Cambridge, MA. 

Luo, X., Deng, Z., Yang, B., and Luo, M. Y. 2024a. 

“Pre-Trained Language Models in Medicine: A Survey.” 

Artificial Intelligence in Medicine  154: 102904. 

Luo, X., Rechardt, A., Sun, G., Nejad, K. K., Yáñez, F., 

Yilmaz, B., Lee, K., and others. 2024b.  “Large Lan -

guage Models Surpass Human Experts in Predicting 

Neuroscience Results.”  Nature Human Behaviour .

Lutz, W., Reiter, C., Özdemir, C., Yildiz, D., Guima -

raes, R., and Goujon, A. 2021.  “Skills-Adjusted Human 

Capital Shows Rising Global Gap.”  Proceedings of the 

National Academy of Sciences  118(7): e2015826118. 

Ma, G., Tian, S., Song, Y., Chen, Y., Shi, H., and Li, 

J. 2025.  “When Technology Meets Anxiety:The Mod -

erating Role of AI Usage in the Relationship between 

Social Anxiety, Learning Adaptability, and Behavioral 

Problems among Chinese Primary School Students.” 

Psychology Research and Behavior Management  18: 

151–167. 

Machajewski, S. 2024.  “The AI Revolution in Chess and 

Its Impact on Education.”  ED Tech Digest  [Online]. Avail -

able from: https://www.edtechdigest.com/2024/11/15/ 

the-ai-revolution-in-chess-and-its-impact-on-education/. 

Makovi, K., Sargsyan, A., Li, W., Bonnefon, J.-F., and 

Rahwan, T. 2023.  “Trust within Human-Machine Col -

lectives Depends on the Perceived Consensus About 

Cooperative Norms.”  Nature Communications  14(1): 

3108. 

Maleki, N., Padmanabhan, B., and Dutta, K. 2024. 

“AI Hallucinations: A Misnomer Worth Clarifying.” 2024 

IEEE Conference on Artificial Intelligence (CAI), 25–27 

June: 133–138. 

Mann, R. P. 2021.  “Collective Decision-Making under 

Changing Social Environments among Agents Adapted 

to Sparse Connectivity.”  arXiv preprint arXiv:2110.13543. 

Mannuru, N. R., Shahriar, S., Teel, Z. A., Wang, T., 

Lund, B. D., Tijani, S., Pohboon, C. O., and others. 

2023.  “Artificial Intelligence in Developing Countries: 

The Impact of Generative Artificial Intelligence (AI) 

Technologies for Development.”  Information Develop -

ment : 1–19. 

Manyika, J., and Spence, M. 2023.  “The Coming AI 

Economic Revolution: Can Artificial Intelligence Re -

verse the Productivity Slowdown?”  Foreign Affairs  102: 

70. 

Marcus, G. 2023.  “‘Math Is Hard’—If You Are an 

LLM—and Why That Matters.”  Marcus on AI  [Online]. 

Available from: https://garymarcus.substack.com/p/ 

math-is-hard-if-you-are-an-llm-and. 

Marcus, G. F. 2024.  Taming Silicon Valley: How We 

Can Ensure That AI Works for Us.  MIT Press. 

Mariadassou, S., Klesse, A.-K., and Boegershausen, 

J. 2024.  “Averse to What: Consumer Aversion to Algo -

rithmic Labels, but Not Their Outputs?”  Current Opinion 

in Psychology  58: 101839. 

Marinoudi, V., Benos, L., Villa, C. C., Kateris, D., Ber -

ruto, R., Pearson, S., Sørensen, C. G., and Bochtis, D. 

2024.  “Large Language Models Impact on Agricultural 

Workforce Dynamics: Opportunity or Risk?”  Smart Agri -

cultural Technology  9: 100677. 

Markel, J. M., Opferman, S. G., Landay, J. A., and 

Piech, C. 2023.  “GPTeach: Interactive TA Training with 

GPT-Based Students.”  Proceedings of the Tenth ACM 

Conference on Learning @ Scale . Copenhagen: Asso -

ciation for Computing Machinery. REFERENCES  2 3 1 

Marriott, H. R., and Pitardi, V. 2024.  “One Is the Lone -

liest Number… Two Can Be as Bad as One: The Influ -

ence of AI Friendship Apps on Users’ Well-Being and 

Addiction.”  Psychology & Marketing  41(1): 86–101. 

Marti, L., Wu, S., Piantadosi, S. T., and Kidd, C. 2023. 

“Latent Diversity in Human Concepts.”  Open Mind  7: 

79–92. 

Martínez, G., Watson, L., Reviriego, P., Hernández, 

J. A., Juarez, M., and Sarkar, R. 2024.  Towards Un -

derstanding the Interplay of Generative Artificial Intel -

ligence and the Internet . Cham: Springer Nature Swit -

zerland, 59–73. 

Martins-Neto, A., Mathew, N., Mohnen, P., and Treibi -

ch, T. 2023.  “Is There Job Polarization in Developing 

Economies? A Review and Outlook.”  The World Bank 

Research Observer  39(2): 259–288. 

Maslej, N., Fattorini, L., Brynjolfsson, E., Etchemendy, 

J., Ligett, K., Lyons, T., Manyika, J., and others. 2023. 

The AI Index 2023: Annual Report . AI Index Steering 

Committee, Stanford Institute for Human-Centered Arti -

ficial Intelligence, Stanford University. 

Mathuros, K., Venugopalan, S., and Adepu, S. 2024. 

“WAXAI: Explainable Anomaly Detection in Industrial 

Control Systems and Water Systems.”  Proceedings of 

the 10th ACM Cyber-Physical System Security Work -

shop.  Singapore: Association for Computing Machinery. 

Maturana, H., and F. Varela. 1987.  The Tree of Knowl -

edge: The Biological Roots of Human Understanding .

Boston, MA: Shambhala. 

Matz, S. C., Teeny, J. D., Vaid, S. S., Peters, H., Harari, 

G. M., and Cerf, M. 2024.  “The Potential of Genera -

tive AI for Personalized Persuasion at Scale.”  Scientific 

Reports  14(1): 4692. 

Mayer, H., Yee, L., Chui, M., and Roberts, R. 2025. 

Superagency in the Workplace: Empowering People to 

Unlock AI’s Full Potential . McKinsey & Company. 

Mayor, A. 2018.  Gods and Robots: Myths, Machines, 

and Ancient Dreams of Technology.  Princeton, NJ: 

Princeton University Press. 

Mazeika, M., Yin, X., Tamirisa, R., Lim, J., Lee, B. W., 

Ren, R., Phan, L., and others. 2025.  “Utility Engineer -

ing: Analyzing and Controlling Emergent Value Sys -

tems in AIs.”  arXiv preprint arXiv:2502.08640 .

McCoy, R. T., Yao, S., Friedman, D., Hardy, M. D., and 

Griffiths, T. L. 2024.  “Embers of Autoregression Show 

How Large Language Models Are Shaped by the Prob -

lem They Are Trained to Solve.”  Proceedings of the 

National Academy of Sciences  121(41): e2322420121. 

McCullough, E. B. 2025.  “Structural Transformation 

without Industrialization? Evidence from Tanzanian 

Consumers.”  American Journal of Agricultural Econom -

ics  107(2): 411–439. 

McDonald, D., Papadopoulos, R., and Benningfield, 

L. 2024.  “Reducing LLM Hallucination Using Knowl -

edge Distillation: A Case Study with Mistral Large and 

MMLU Benchmark.”  Authorea Preprints .

McElheran, K., Li, J. F., Brynjolfsson, E., Kroff, Z., Din -

lersoz, E., Foster, L., and Zolas, N. 2024.  “AI Adoption 

in America: Who, What, and Where.”  Journal of Eco -

nomics & Management Strategy  33(2): 375–415. 

McGrath, T., Kapishnikov, A., Tomašev, N., Pearce, 

A., Wattenberg, M., Hassabis, D., Kim, B., Paquet, U., 

and Kramnik, V. 2022.  “Acquisition of Chess Knowl -

edge in Alphazero.”  Proceedings of the National Acad -

emy of Sciences  119(47): e2206625119. 

McIntosh, T. R., Liu, T., Susnjak, T., Watters, P., Ng, 

A., and Halgamuge, M. N. 2024.  “A Culturally Sensi -

tive Test to Evaluate Nuanced GPT Hallucination.”  IEEE 

Transactions on Artificial Intelligence  5(6): 2739–2751. 

Mei, Q., Xie, Y., Yuan, W., and Jackson, M. O. 2024. 

“A Turing Test of Whether AI Chatbots Are Behaviorally 

Similar to Humans.”  Proceedings of the National Acad -

emy of Sciences  121(9): e2313925121. 

Meijer, A., Lorenz, L., and Wessels, M. 2021.  “Algo -

rithmization of Bureaucratic Organizations: Using a 

Practice Lens to Study How Context Shapes Predictive 

Policing Systems.”  Public Administration Review  81(5): 

837–846. 

Meinke, A., Schoen, B., Scheurer, J., Balesni, M., 

Shah, R., and Hobbhahn, M. 2024.  “Frontier Models 

Are Capable of In-Context Scheming.”  arXiv preprint 

arXiv:2412.04984 .

Messeri, L., and Crockett, M. J. 2024.  “Artificial Intel -

ligence and Illusions of Understanding in Scientific Re -

search.”  Nature  627(8002): 49–58. 

Mhasawade, V., Zhao, Y., and Chunara, R. 2021.  “Ma -

chine Learning and Algorithmic Fairness in Public and 

Population Health.”  Nature Machine Intelligence  3(8): 

659–666. 

Mifsud, J. C. O., Lytras, S., Oliver, M. R., Toon, K., Cos -

ta, V. A., Holmes, E. C., and Grove, J. 2024.  “Mapping 

Glycoprotein Structure Reveals  Flaviviridae  Evolution -

ary History.”  Nature  633(8030): 695–703. 

Milani, S., Topin, N., Veloso, M., and Fang, F. 2024.  “Ex -

plainable Reinforcement Learning: A Survey and Com -

parative Review.”  ACM Computing Surveys  56(7): 1–36. 

Minaee, S., Mikolov, T., Nikzad, N., Chenaghlu, 

M., Socher, R., Amatriain, X., and Gao, J. 2024a. 

“Large Language Models: A Survey.”  arXiv preprint 

arXiv:2402.06196 .

Minaee, S., Mikolov, T., Nikzad, N., Chenaghlu, M., 

Socher, R., Amatriain, X., and Gao, J. 2024b.  “Large 

Language Models: A Survey, 2024.”  arXiv preprint 

arXiv:2402.06196 .

Mishra, S., Koopman, R., De Prato, G., Rao, A., Oso -

rio-Rodarte, I., Kim, J., Spatafora, N., Strier, K., and 

Zaccaria, A. 2023.  “AI Specialization for Pathways 

of Economic Diversification.”  Scientific Reports  13(1): 

19475. 

Mitchell, M. 2021.  “Why AI Is Harder Than We Think.” 

Proceedings of the Genetic and Evolutionary Compu -

tation Conference.  Lille, France: Association for Com -

puting Machinery. 

Mitchell, M. 2023a.  “AI’s Challenge of Understanding 

the World.”  Science  382(6671): eadm8175. 

Mitchell, M. 2023b.  “How Do We Know How Smart AI 

Systems Are?”  Science  381(6654): eadj5957. 

Mitchell, M. 2024a.  “Debates on the Nature of Artificial 

General Intelligence.”  Science  383(6689): eado7069. 

Mitchell, M. 2024b.  “The Metaphors of Artificial Intel -

ligence.”  Science  386(6723): eadt6140. 

Mitchell, M. 2025.  “Artificial Intelligence Learns to Rea -

son.”  Science  387(6740): eadw5211. 

Mitchell, M., and Krakauer, D. C. 2023.  “The Debate 

over Understanding in AI’s Large Language Models.” 

Proceedings of the National Academy of Sciences 

120(13): e2215907120. 

Mlonyeni, P. M. T. 2024.  “Personal AI, Deception, and 

the Problem of Emotional Bubbles.”  AI & Society  40(3): 

1927–1938. 

Mollick, E., Mollick, L., Bach, N., Ciccarelli, L., 

Przystanski, B., and Ravipinto, D. 2024.  “AI Agents 

and Education: Simulated Practice at Scale.”  arXiv pre -

print arXiv:2407.12796 .

Montévil, M., and M. Mossio. 2015.  “Biological 

Organisation as Closure of Constraints.”  Journal of The -

oretical Biology  372: 179–91. http://dx.doi.org/10.1016/j. 

jtbi.2015.02.029. 

Moor, M., Banerjee, O., Abad, Z. S. H., Krumholz, H. 

M., Leskovec, J., Topol, E. J., and Rajpurkar, P. 2023. 

“Foundation Models for Generalist Medical Artificial In -

telligence.”  Nature  616(7956): 259–265. 

Moreno, A., and M. Mossio. 2015.  Biological Auton -

omy: A Philosophical and Theoretical Enquiry . Dor -

drecht, Netherlands: Springer. 

Moruzzi, C. 2025.  “Artificial Intelligence and Creativity.” 

Philosophy Compass  20(3): e70030. 

Moundridou, M., Matzakos, N., and Doukakis, S. 2024. 

“Generative AI Tools as Educators’ Assistants: Designing 

and Implementing Inquiry-Based Lesson Plans.”  Comput -

ers and Education: Artificial Intelligence  7: 100277. 

Muldoon, J., Cant, C., Wu, B., and Graham, M. 2024. 

“A Typology of Artificial Intelligence Data Work.”  Big 

Data & Society  11(1): 20539517241232632. 

Muldoon, J., Graham, M., and Cant, C. 2024.  Feeding 

the Machine: The Hidden Human Labour Powering AI. 

Canongate Books. 

Müller, V. C., and Bostrom, N. 2016.  “Future Progress 

in Artificial Intelligence: A Survey of Expert Opinion.” In 

Müller, V. C., (ed.),  Fundamental Issues of Artificial Intel -

ligence.  Cham: Springer International Publishing. 

Mumuni, F., and Mumuni, A. 2025.  “Explainable 

Artificial Intelligence (XAI): From Inherent Explain -

ability to Large Language Models.”  arXiv preprint 

arXiv:2501.09967 .

Muro, M., Methkupally, S., and Kinder, M. 2025.  “The 

Geography of Generative AI’s Workforce Impacts Will 

Likely Differ from Those of Previous Technologies.” 

Brookings Institution [Online]. Available from: https:// 

www.brookings.edu/articles/the-geography-of-genera -

tive-ais-workforce-impacts-will-likely-differ-from-those-

of-previous-technologies/ Accessed 19 February 2025. 

Musslick, S., Bartlett, L. K., Chandramouli, S. H., 

Dubova, M., Gobet, F., Griffiths, T. L., Hullman, J., 

and others. 2025.  “Automating the Practice of Sci -

ence: Opportunities, Challenges, and Implications.” 

Proceedings of the National Academy of Sciences 

122(5): e2401238121. 2 3 2 HUMAN DEVELOPMENT REPORT 2025 

Mutiso, R. M. 2024.  “AI in Africa: Basics over Buzz.” 

Science  383(6690): eado8276. 

Mutiso, R. M. 2025.  “Beyond the Binary: Navigating 

AI’s Uncertain Future in Africa.”  Science  388(6742): 

eadw9439. 

Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, 

L., Kim, C., Hesse, C., and others. 2021.  “WebGPT: 

Browser-Assisted Question-Answering with Human 

Feedback.”  arXiv preprint arXiv:2112.09332 .

Narayanan, A., and Kapoor, S. 2024.  AI Snake Oil: 

What Artificial Intelligence Can Do, What It Can’t, and 

How to Tell the Difference.  Princeton, NJ: Princeton 

University Press. 

Navajas, J., Niella, T., Garbulsky, G., Bahrami, B., 

and Sigman, M. 2018.  “Aggregated Knowledge from a 

Small Number of Debates Outperforms the Wisdom of 

Large Crowds.”  Nature Human Behaviour  2(2): 126–132. 

Neumann, N., Tucker, C. E., Kaplan, L., Mislove, 

A., and Sapiezynski, P. 2024.  “Data Deserts and 

Black Boxes: The Impact of Socio-Economic Status 

on Consumer Profiling.”  Management Science  70(11): 

8003–8029. 

Nezhurina, M., Cipolina-Kun, L., Cherti, M., and 

Jitsev, J. 2024.  “Alice in Wonderland: Simple Tasks 

Showing Complete Reasoning Breakdown in State-

of-the-Art Large Language Models.”  arXiv preprint 

arXiv:2406.02061 .

Nordhaus, W. D. 2004.  “Schumpeterian Profits in the 

American Economy: Theory and Measurement.” Work -

ing Paper 10433, National Bureau of Economic Re -

search, Cambridge, MA. 

Nordhaus, W. D. 2007.  “Two Centuries of Productivity 

Growth in Computing.”  The Journal of Economic His -

tory  67(1): 128–159. 

Nordhaus, W. D. 2021.  “Are We Approaching an Eco -

nomic Singularity? Information Technology and the 

Future of Economic Growth.”  American Economic Jour -

nal: Macroeconomics  13(1): 299–332. 

Nosta, J. 2025.  “The Shadow of Cognitive Laziness 

in the Brilliance of LLMs.”  The Digital Self . https://www. 

psychologytoday.com/us/blog/the-digital-self/202501/ 

the-shadow-of-cognitive-laziness-in-the-brilliance-of-

llms. Accessed 27 February 2025. 

Nowotny, H. 2021.  In AI We Trust: Power, Illusion and 

Control of Predictive Algorithms.  John Wiley & Sons. 

Noy, S., and Zhang, W. 2023.  “Experimental Evidence 

on the Productivity Effects of Generative Artificial Intel -

ligence.”  Science  381(6654): 187–192. 

Nuwer, R. 2024.  “Africa’s Newest Resource Could Be 

a Game-Changer for the Global South.”  Nature  633: 

S12–S14. 

Olson, P. 2024.  Supremacy: AI, ChatGPT, and the 

Race That Will Change the World.  New York: St. Mar -

tin’s Press. 

Ord, T. 2020.  The Precipice: Existential Risk and the 

Future of Humanity.  Hachette Books. 

OECD (Organisation for Economic Co-operation 

and Development). 2024.  Job Creation and Local 

Economic Development: The Geography of Genera -

tive AI.  Paris: OECD Publishing. 

OECD (Organisation for Economic Co-operation and 

Development). 2025.  Intellectual Property Issues in 

Artificial Intelligence Trained on Scraped Data . Paris: 

OECD Publishing. 

Otis, N., Clarke, R., Delecourt, S., Holtz, D., and Kon -

ing, R. 2024a.  “The Uneven Impact of Generative AI 

on Entrepreneurial Performance.” Working Paper 24-

042, Harvard Business School, Cambridge, MA. 

Otis, N. G., Delecourt, S., Cranney, K., and Koning, R. 

2024b.  “Global Evidence on Gender Gaps and Gen -

erative AI.” Working Paper 25-023, Harvard Business 

School, Cambridge, MA. 

Pan, X., Dai, J., Fan, Y., and Yang, M. 2024.  “Frontier 

AI Systems Have Surpassed the Self-Replicating Red 

Line.”  arXiv preprint arXiv:2412.12140 .

Parmar, P., Ryu, J., Pandya, S., Sedoc, J., and Agar -

wal, S. 2022.  “Health-Focused Conversational Agents 

in Person-Centered Care: A Review of Apps.”  NPJ Digi -

tal Medicine  5(1): 21. 

Pearl, J. 2018.  Theoretical Impediments to Machine 

Learning with Seven Sparks from the Causal Revolu -

tion.  Proceedings of the 11th ACM International Confer -

ence on Web Search and Data Mining.  Marina Del Rey, 

CA: Association for Computing Machinery. 

Pellert, M., Lechner, C. M., Wagner, C., Rammstedt, 

B., and Strohmaier, M. 2024.  “AI Psychometrics: As -

sessing the Psychological Profiles of Large Language 

Models through Psychometric Inventories.”  Perspec -

tives on Psychological Science  19(5): 808–826. 

Peng, B., Galley, M., He, P., Cheng, H., Xie, Y., Hu, 

Y., Huang, Q., and others. 2023a.  “Check Your Facts 

and Try Again: Improving Large Language Models with 

External Knowledge and Automated Feedback.”  arXiv 

preprint arXiv:2302.12813 .

Peng, S., Kalliamvakou, E., Cihon, P., and Demirer, 

M. 2023b.  “The Impact of AI on Developer Produc -

tivity: Evidence from Github Copilot.”  arXiv preprint 

arXiv:2302.06590 .

Pentina, I., Hancock, T., and Xie, T. 2023.  “Explor -

ing Relationship Development with Social Chatbots: A 

Mixed-Method Study of Replika.”  Computers in Human 

Behavior  140: 107600. 

Pentina, I., Xie, T., Hancock, T., and Bailey, A. 2023. 

“Consumer–Machine Relationships in the Age of Artificial 

Intelligence: Systematic Literature Review and Research 

Directions.”  Psychology & Marketing  40(8): 1593–1614. 

Pescetelli, N., Rutherford, A., and Rahwan, I. 2020. 

“Diversity Promotes Collective Intelligence in Large 

Groups but Harms Small Ones.”  PsyArXiv,  2 January. 

Peters, H., and Matz, S. C. 2024.  “Large Language 

Models Can Infer Psychological Dispositions of Social 

Media Users.”  PNAS Nexus  3(6). 

Pilditch, T. D. 2024.  “The Reasoning under Un -

certainty Trap: A Structural AI Risk.”  arXiv preprint 

arXiv:2402.01743 .

Polverini, G., and Gregorcic, B. 2024.  “How Under -

standing Large Language Models Can Inform the Use 

of ChatGPT in Physics Education.”  European Journal of 

Physics  45(2): 025701. 

Pritchett, L. 2024.  “Investing in Human Capital in Af -

rica: A Framework for Research.”  International Journal 

of Educational Development  107: 103048. 

Pritchett, L., and Viarengo, M. 2023.  “The Learning 

Crisis of Developing Country Elites: Lessons from PISA-

D.”  The World Bank Economic Review  37(2): 177–204. 

Purcell, Z. A., and Bonnefon, J.-F. 2023.  “Research 

on Artificial Intelligence Is Reshaping Our Definition of 

Morality.”  Psychological Inquiry  34(2): 100–101. 

Rahwan, I., Cebrian, M., Obradovich, N., Bongard, 

J., Bonnefon, J.-F., Breazeal, C., Crandall, J. W., and 

others. 2019.  “Machine Behaviour.”  Nature  568(7753): 

477–486. 

Raisch, S., and Krakowski, S. 2021.  “Artificial Intelli -

gence and Management: The Automation–Augmenta -

tion Paradox.”  Academy of Management Review  46(1): 

192–210. 

Raman, N., Lundy, T., Amouyal, S., Levine, Y., Leyton-

Brown, K., and Tennenholtz, M. 2024.  “Rationality Re -

port Cards: Assessing the Economic Rationality of Large 

Language Models.”  arXiv preprint arXiv:2402.09552 .

Rambachan, A. 2024.  “Identifying Prediction Mistakes 

in Observational Data.”  The Quarterly Journal of Eco -

nomics  139(3): 1665–1711. 

Ravi, P., Masla, J., Kakoti, G., Lin, G., Anderson, E., 

Taylor, M., Ostrowski, A., and others. 2025.  “Co-

Designing Large Language Model Tools for Project-

Based Learning with K12 Educators.”  arXiv preprint 

arXiv:2502.09799 .

Raymond, L. 2024.  “The Market Effects of Algorithms.” 

Working Paper. 

Reid-Green, K. S. 1989.  “The History of Census Tabula -

tion.”  Scientific American  260(2): 98–103. 

Reijnders, L. S. M., Timmer, M. P., and Ye, X. 2021. 

“Labour Demand in Global Value Chains: Is There a 

Bias against Unskilled Work?”  The World Economy 

44(9): 2547–2571. 

Ren, R., Wang, Y., Qu, Y., Zhao, W. X., Liu, J., Wu, H., 

Wen, J.-R., and Wang, H. 2025.  “Investigating the Fac -

tual Knowledge Boundary of Large Language Models 

with Retrieval Augmentation.”  Proceedings of the 2025 

International Conference on Computational Linguistics 

(COLING 2025) , 3697–3715. Abu Dhabi, UAE: Associa -

tion for Computational Linguistics. 

Restrepo, P. 2024.  “Automation: Theory, Evidence, 

and Outlook.”  Annual Review of Economics  16(1): 1–25. 

Riedl, C., Kim, Y. J., Gupta, P., Malone, T. W., and 

Woolley, A. W. 2021.  “Quantifying Collective Intelli -

gence in Human Groups.”  Proceedings of the National 

Academy of Sciences  118(21): e2005737118. 

Rodrik, D. 2012.  “Unconditional Convergence in Man -

ufacturing.”  The Quarterly Journal of Economics  128(1): 

165–204. 

Rodrik, D. 2015.  “Premature Deindustrialization.” 

Working Paper 20935, National Bureau of Economic 

Research, Cambridge, MA. REFERENCES  2 3 3 

Rodrik, D. 2023.  “A Comment On: ‘Presidential Ad -

dress: Demand-Side Constraints in Development: The 

Role of Market Size, Trade, and (in)Equality,’ by Pinelopi 

Koujianou Goldberg and Tristan Reed.”  Econometrica 

91(6): 1959–1962. 

Rodrik, D. 2024.  “Prospects for Global Economic 

Convergence under New Technologies.”  Harnessing 

Technology for Inclusive Prosperity: Growth, Work, and 

Inequality in the Digital Era : 93. 

Rodrik, D., and Sandhu, R. 2024.  “Servicing Develop -

ment: Productive Upgrading of Labor-Absorbing Serv -

ices in Developing Economies.” Working Paper 32738, 

National Bureau of Economic Research, Cambridge, MA. 

Rodrik, D., and Stiglitz, J. 2024.  A New Growth Strat -

egy for Developing Nations . Harvard University. 

Roli, A., J. Jaeger, and S. A. Kauffman. 2022.  “How 

Organisms Come to Know the World: Fundamental Lim -

its on Artificial General Intelligence.”  Frontiers in Ecol -

ogy and Evolution  9: 806283. https://doi.org/10.3389/ 

fevo.2021.806283. 

Rose, K. 2025.  “Not a Coder? With A.I., Just Having an 

Idea Can Be Enough.”  The New York Times , 27 February. 

https://www.nytimes.com/2025/02/27/technology/per -

sonaltech/vibecoding-ai-software-programming.html. 

Rosen, R. 1991.  Life Itself: A Comprehensive Inquiry 

into the Nature, Origin, and Fabrication of Life.  New 

York: Columbia University Press. 

Rosenberg, J., Karger, E., Morris, A., Hickman, M., 

Hadshar, R., Jacobs, Z., and Tetlock, P. 2024.  Roots of 

Disagreement on AI Risk . Forecasting Research Institute. 

Rudolph, E., Seer, H., Mothes, C., and Albrecht, J. 

2024.  “Automated Feedback Generation in an Intel -

ligent Tutoring System for Counselor Education.”  Pro -

ceedings of the 19th Conference on Computer Science 

and Intelligence Systems (FedCSIS 2024) , 501–512. 

Annals of Computer Science and Information Systems, 

Volume 39. IEEE. https://doi.org/10.15439/2024F1649 .

Russakovsky, O., Deng, J., Su, H., Krause, J., Sath -

eesh, S., Ma, S., Huang, Z., and others. 2015.  “Ima -

genet Large Scale Visual Recognition Challenge.”  In -

ternational Journal of Computer Vision  115(3): 211–252. 

Sack, D., Krayer, L., Wiles, E., Abbadi, M., Awasthi, 

U., Kennedy, R., Arnolds, C., and Candelon, F. 

2024.  “GenAI Doesn’t Just Increase Productivity. It 

Expands Capabilities.”  Boston Consulting Group . Avail -

able from: https://www.bcg.com/publications/2024/ 

gen-ai-increases-productivity-and-expands-capabilities. 

Santu, S. K. K., and Feng, D. 2023.  “Teler: A General 

Taxonomy of LLM Prompts for Benchmarking Complex 

Tasks.”  arXiv preprint arXiv:2305.11430 .

Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., 

Lomeli, M., Hambro, E., Zettlemoyer, L., Cancedda, 

N., and Scialom, T. 2023.  “Toolformer: Language 

Models Can Teach Themselves to Use Tools.”  Ad -

vances in Neural Information Processing Systems  36: 

68539–68551. 

Schoene, A., Ramachandranpillai, R., Lazovich, T., 

and Baeza-Yates, R. 2024.  “All Models Are Wrong, but 

Some Are Deadly: Inconsistencies in Emotion Detection 

in Suicide-Related Tweets.”  Proceedings of the Third 

Workshop on NLP for Positive Impact , 113–122. 

Schut, L., Tomašev, N., McGrath, T., Hassabis, D., 

Paquet, U., and Kim, B. 2025.  “Bridging the Human– 

AI Knowledge Gap through Concept Discovery and 

Transfer in Alphazero.”  Proceedings of the National 

Academy of Sciences  122(13): e2406675122. 

Scott Morton, F. 2024.  “Can Massive Technological 

Progress Hurt Workers? A Review of  Power and Prog -

ress  by Daron Acemoğlu and Simon Johnson.”  Journal 

of Economic Literature  62(4): 1671–1681. 

Sejnowski, T. J. 2023.  “Large Language Models and 

the Reverse Turing Test.”  Neural Computation  35(3): 

309–342. 

Seo, W., Yuan, Z., and Bu, Y. 2025.  “ValuesRAG: 

Enhancing Cultural Alignment through Retrieval-

Augmented Contextual Learning.”  arXiv preprint 

arXiv:2501.01031 .

Septiandri, A. A., Constantinides, M., and Quercia, 

D. 2024.  “The Potential Impact of AI Innovations on US 

Occupations.”  PNAS Nexus  3(9). 

Shahriar, S., Corradini, M. G., Sharif, S., Moussa, M., 

and Dara, R. 2025.  “The Role of Generative Artificial 

Intelligence in Digital Agri-Food.”  Journal of Agriculture 

and Food Research  20: 101787. 

Shapira, N., Levy, M., Alavi, S. H., Zhou, X., Choi, Y., 

Goldberg, Y., Sap, M., and Shwartz, V. 2024.  “Clever 

Hans or Neural Theory of Mind? Stress Testing Social 

Reasoning in Large Language Models.”  Proceedings of 

the 18th Conference of the European Chapter of the 

Association for Computational Linguistics (Volume 1: 

Long Papers) , 2257–2273. 

Shiffrin, R., and Mitchell, M. 2023.  “Probing the Psy -

chology of AI Models.”  Proceedings of the National 

Academy of Sciences  120(10): e2300963120. 

Shimanovich, U., and Hartl, F. U. 2024.  “Protein Folding: 

From Physico-Chemical Rules and Cellular Machineries 

of Protein Quality Control to AI Solutions.”  Proceedings of 

the National Academy of Sciences  121(34): e2411135121. 

Shin, H. J., Han, K., Ryu, L., and Kim, E.-K. 2023.  “The 

Impact of Artificial Intelligence on the Reading Times of 

Radiologists for Chest Radiographs.”  NPJ Digital Medi -

cine  6(1): 82. 

Shrestha, S., Kim, M., and Ross, K. 2025.  “Mathemati -

cal Reasoning in Large Language Models: Assessing 

Logical and Arithmetic Errors across Wide Numerical 

Ranges.”  arXiv preprint arXiv:2502.08680 .

Signé, L. 2025.  “Leveraging AI and Emerging Technol -

ogies to Unlock Africa’s Potential.” Brookings Institute. 

Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., 

Lai, M., Guez, A., Lanctot, M., and others. 2018.  “A 

General Reinforcement Learning Algorithm That Mas -

ters Chess, Shogi, and Go through Self-Play.”  Science 

362(6419): 1140–1144. 

Simchon, A., Edwards, M., and Lewandowsky, S. 

2024.  “The Persuasive Effects of Political Microtar -

geting in the Age of Generative Artificial Intelligence.” 

PNAS Nexus  3(2). 

Simon, H. A. 1971.  “Designing Organizations for an 

Information-Rich World.” In Greeenbeger, M., (ed.), 

Computers, Communications, and the Public Interest. 

Baltimore, MD: The Johns Hopkins Press. 

Singhal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., 

Chung, H. W., Scales, N., and others. 2023.  “Large 

Language Models Encode Clinical Knowledge.”  Nature 

620(7972): 172–180. 

Singhal, K., Tu, T., Gottweis, J., Sayres, R., Wulczyn, 

E., Amin, M., Hou, L., and others. 2025.  “Toward 

Expert-Level Medical Question Answering with Large 

Language Models.”  Nature Medicine  31: 943–950. 

Smith, K. 2024.  “The Biology of Smell Is a Mystery-AI Is 

Helping to Solve It.”  Nature  633(8028): 26–29. 

Socol de la Osa, D. U., and Remolina, N. 2024.  “Ar -

tificial Intelligence at the Bench: Legal and Ethical 

Challenges of Informing—or Misinforming—Judicial 

Decision-Making through Generative AI.”  Data & Policy 

6: e59. 

Song, J., Xu, Z., and Zhong, Y. 2025.  “Out-of-Distri -

bution Generalization via Composition: A Lens through 

Induction Heads in Transformers.”  Proceedings of the 

National Academy of Sciences  122(6): e2417182122. 

Song, Y., Atza, E., Sánchez-Gil, J. J., Akkermans, D., 

de Jonge, R., de Rooij, P. G. H., Kakembo, D., and 

others. 2025.  “Seed Tuber Microbiome Can Predict 

Growth Potential of Potato Varieties.”  Nature Microbiol -

ogy  10(1): 28–40. 

Soroush, A., Glicksberg, B. S., Zimlichman, E., 

Barash, Y., Freeman, R., Charney, A. W., Nadkarni, G. 

N., and Klang, E. 2024.  “Large Language Models Are 

Poor Medical Coders—Benchmarking of Medical Code 

Querying.”  NEJM AI  1(5): AIdbp2300040. 

Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., 

Abid, A., Fisch, A., Brown, A. R., and others. 2022. 

“Beyond the Imitation Game: Quantifying and Extrapo -

lating the Capabilities of Language Models.”  arXiv pre -

print arXiv:2206.04615 .

Stadler, M., Bannert, M., and Sailer, M. 2024.  “Cog -

nitive Ease at a Cost: LLMs Reduce Mental Effort but 

Compromise Depth in Student Scientific Inquiry.”  Com -

puters in Human Behavior  160: 108386. 

Steiger, M., Bharucha, T. J., Venkatagiri, S., Riedl, 

M. J., and Lease, M. 2021.  “The Psychological Well-

Being of Content Moderators: The Emotional Labor of 

Commercial Moderation and Avenues for Improving 

Support.”  Proceedings of the 2021 CHI Conference on 

Human Factors in Computing Systems , 1–14. 

Stiglitz, J. E. 2021.  “From Manufacturing-Led Export 

Growth to a Twenty-First Century Inclusive Growth 

Strategy: Explaining the Demise of a Successful Growth 

Model and What to Do About It.” In Gradín, C., Leib -

brandt, M. and Tarp, F., (eds.),  Inequality in the Develop -

ing World.  Oxford University Press. 

Strachan, J. W. A., Albergo, D., Borghini, G., Pan -

sardi, O., Scaliti, E., Gupta, S., Saxena, K., and oth -

ers. 2024.  “Testing Theory of Mind in Large Language 

Models and Humans.”  Nature Human Behaviour  8: 

1285–1295. 

Stuhler, O., Stoltz, D. S., and Martin, J. L. 2023. 

“Meaning and Machines.” In Borch, C. and Pardo-Guer -

ra, J. P., (eds.),  The Oxford Handbook of the Sociology 

of Machine Learning.  Oxford University Press. 

Su, H., Chen, R., Tang, S., Zheng, X., Li, J., Yin, Z., 

Ouyang, W., and Dong, N. 2024.  “Two Heads Are 2 3 4 HUMAN DEVELOPMENT REPORT 2025 

Better Than One: A Multi-Agent System Has the Poten -

tial to Improve Scientific Idea Generation.”  arXiv pre -

print arXiv:2410.09403 .

Suleyman, M. 2023.  The Coming Wave: Technology, 

Power, and the Twenty-First Century’s Greatest Dilem -

ma.  New York: Crown. 

Summerfield, C. 2025.  These Strange New Minds: 

How AI Learned to Talk and What It Means.  New York: 

Viking Press. 

Sun, L., Liu, D., Wang, M., Han, Y., Zhang, Y., Zhou, 

B., and Ren, Y. 2025.  “Taming Unleashed Large Lan -

guage Models with Blockchain for Massive Personal -

ized Reliable Healthcare.”  IEEE Journal of Biomedical 

and Health Informatics .

Sun, L., Yuan, Y., Yao, Y., Li, Y., Zhang, H., Xie, X., 

Wang, X., Luo, F., and Stillwell, D. 2024.  “Large 

Language Models Show Both Individual and Collec -

tive Creativity Comparable to Humans.”  arXiv preprint 

arXiv:2412.03151 .

Surowiecki, J. 2005.  The Wisdom of Crowds.  Anchor 

Books. 

Svanberg, M., Li, W., Fleming, M., Goehring, B., and 

Thompson, N. 2024.  “Beyond AI Exposure: Which 

Tasks Are Cost-Effective to Automate with Computer 

Vision?” Available at SSRN 4700751. 

Swartz, E., Denecke, C., and Scheepers, C. B. 2023. 

“Following the Money: Leapfrogging through and with 

Entrepreneurial Growth Companies in Ghana, Kenya, 

Nigeria and South Africa.”  Technological Leapfrogging 

and Innovation in Africa.  Edward Elgar Publishing. 

Tan, S. C., Wijekumar, K., Hong, H., Olmanson, J., 

Twomey, R., and Sinha, T. 2024.  “Guest Editorial Edu -

cation in the World of ChatGPT and Generative AI.”  IEEE 

Transactions on Learning Technologies  17: 2008–2010. 

Tanno, R., Barrett, D. G. T., Sellergren, A., Ghaisas, 

S., Dathathri, S., See, A., Welbl, J., and others. 2024. 

“Collaboration between Clinicians and Vision–Lan -

guage Models in Radiology Report Generation.”  Nature 

Medicine  30: 1134–1142. 

Tavares, M., and Rein, B. 2024.  “The Virtual Disen -

gagement Hypothesis: A Neurophysiological Frame -

work for Reduced Empathy on Social Media.”  Cognitive, 

Affective, & Behavioral Neuroscience  24(6): 965–971. 

Teeny, J. D., and Matz, S. C. 2024.  “We Need to Un -

derstand “When” Not “If” Generative AI Can Enhance 

Personalized Persuasion.”  Proceedings of the National 

Academy of Sciences  121(43): e2418005121. 

Teutloff, O., Einsiedler, J., Kässi, O., Braesemann, 

F., Mishkin, P., and del Rio-Chanona, R. M. 2025. 

“Winners and Losers of Generative AI: Early Evidence 

of Shifts in Freelancer Demand.”  Journal of Economic 

Behavior & Organization : 106845. 

Topol, E. J. 2024.  “The Revolution in High-Throughput 

Proteomics and AI.”  Science  385(6716): eads5749. 

Trammell, P., and Korinek, A. 2023.  “Economic Growth 

under Transformative AI.” Working Paper 31815, National 

Bureau of Economic Research, Cambridge, MA. 

Treiman, L. S., Ho, C.-J., and Kool, W. 2024.  “The Con -

sequences of AI Training on Human Decision-Making.” 

Proceedings of the National Academy of Sciences 

121(33): e2408731121. 

Trott, S., Jones, C., Chang, T., Michaelov, J., and Ber -

gen, B. 2023.  “Do Large Language Models Know What 

Humans Know?”  Cognitive Science  47(7): e13309. 

Tsvetkova, M., Yasseri, T., Pescetelli, N., and Werner, 

T. 2024.  “A New Sociology of Humans and Machines.” 

Nature Human Behaviour  8(10): 1864–1876. 

Tucker, C. 2025.  “How Does Competition Policy Need 

to Change in a World of Artificial Intelligence?”  Oxford 

Review of Economic Policy  40(4): 834–842. 

Turing, A. 1950.  “Computing Machinery and Intel -

ligence.”  Mind  59: 433–460.  https://doi.org/10.1093/ 

mind/LIX.236.433 .

Turing, A. M. 1937.  “On Computable Numbers, with an 

Application to the Entscheidungsproblem.”  Proceed -

ings of the London Mathematical Society  s2-42(1): 

230–265. 

Turon, G., Arora, D., and Duran-Frigola, M. 2024.  “In -

fectious Disease Research Laboratories in Africa Are Not 

Using AI Yet—Large Language Models May Facilitate 

Adoption.”  ACS Infectious Diseases  10(9): 3083–3085. 

UN (United Nations). 2024.  Governing AI for Human -

ity . New York: United Nations. 

UNCTAD (United Nations Trade and Development). 

2024.  Trade and Development Report 2024: Rethink -

ing Development in the Age of Discontent . Geneva: 

UNCTAD. 

US National Academies of Sciences, Engineering, 

and Medicine 2024.  Artificial Intelligence and the Fu -

ture of Work.  Washington, DC: The National Academies 

Press. 

Vafa, K., Chen, J. Y., Kleinberg, J., Mullainathan, 

S., and Rambachan, A. 2024.  “Evaluating the World 

Model Implicit in a Generative Model.”  arXiv preprint 

arXiv:2406.03689 .

Valenzuela, A., Puntoni, S., Hoffman, D., Castelo, 

N., De Freitas, J., Dietvorst, B., Hildebrand, C., and 

others. 2024.  “How Artificial Intelligence Constrains 

the Human Experience.”  Journal of the Association for 

Consumer Research  9(3): 241–256. 

Vallor, S. 2024.  The AI Mirror: How to Reclaim Our 

Humanity in an Age of Machine Thinking.  Oxford Uni -

versity Press. 

Vallstrom, D. 2024.  “Cooperative Evolutionary Pres -

sure and Diminishing Returns Might Explain the Fermi 

Paradox: On What Super-AIs Are Like.”  arXiv preprint 

arXiv:2404.03685 .

Varian, H. R. 2010.  “Computer Mediated Transactions.” 

American Economic Review  100(2): 1–10. 

Varoquaux, G., Luccioni, A. S., and Whittaker, 

M. 2024.  “Hype, Sustainability, and the Price of 

the Bigger-Is-Better Paradigm in AI.”  arXiv preprint 

arXiv:2409.14160 .

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., 

Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. 

2017.  “Attention Is All You Need.”  Advances in Neural 

Information Processing Systems  30. 

Velasquez, A. 2023.  “Production Technology, Market 

Power, and the Decline of the Labor Share.” Working 

Paper 2023/032, International Monetary Fund, Wash -

ington, DC. 

Verhoogen, E. 2023.  “Firm-Level Upgrading in Devel -

oping Countries.”  Journal of Economic Literature  61(4): 

1410–1464. 

Villalobos, P., Ho, A., Sevilla, J., Besiroglu, T., Heim, 

L., and Hobbhahn, M. 2024.  “Will We Run out of Data? 

Limits of LLM Scaling Based on Human-Generated 

Data.”  arXiv preprint arXiv:2211.04325 .

Volokh, E. 2023.  “Large Libel Models? Liability for AI 

Output.”  Journal of Free Speech Law  3: 489. 

von Schenk, A., Klockmann, V., and Köbis, N. 2025. 

“Social Preferences toward Humans and Machines: A 

Systematic Experiment on the Role of Machine Payoffs.” 

Perspectives on Psychological Science  20(1): 165–181. 

Walton, N. 2022.  “Digital Platforms as Entrepreneur -

ial Ecosystems and Drivers of Born-Global Smes in 

Emerging Economies.”  International Entrepreneurship 

in Emerging Markets.  Routledge. 

Wang, A., Kapoor, S., Barocas, S., and Narayanan, 

A. 2024a.  “Against Predictive Optimization: On the Le -

gitimacy of Decision-Making Algorithms That Optimize 

Predictive Accuracy.”  ACM Journal on Responsible 

Computing  1(1): Article 9. 

Wang, B., Chen, W., Pei, H., Xie, C., Kang, M., Zhang, 

C., Xu, C., and others. 2023a.  “DecodingTrust: A Com -

prehensive Assessment of Trustworthiness in GPT 

Models.”  NeurIPS .

Wang, M., Wang, M., Xu, X., Yang, L., Cai, D., and 

Yin, M. 2024b.  “Unleashing ChatGPT’s Power: A Case 

Study on Optimizing Information Retrieval in Flipped 

Classrooms Via Prompt Engineering.”  IEEE Transac -

tions on Learning Technologies  17: 629–641. 

Wang, P., Zhang, L.-Y., Tzachor, A., and Chen, W.-Q. 

2024c.  “E-Waste Challenges of Generative Artificial 

Intelligence.”  Nature Computational Science  4(11): 

818–823. 

Wang, S., Petridis, S., Kwon, T., Ma, X., and Chilton, 

L. B. 2023b.  “Popblends: Strategies for Conceptual 

Blending with Large Language Models.”  Proceedings 

of the 2023 CHI Conference on Human Factors in 

Computing Systems , 1–19. 

Wang, S., Xu, T., Li, H., Zhang, C., Liang, J., Tang, J., 

Yu, P. S., and Wen, Q. 2024d.  “Large Language Mod -

els for Education: A Survey and Outlook.”  arXiv preprint 

arXiv:2403.18105 .

Wang, T., Chen, J., Jia, Q., Wang, S., Fang, R., Wang, H., 

Gao, Z., and others. 2024e.  “Weaver: Foundation Mod -

els for Creative Writing.”  arXiv preprint arXiv:2401.17268 .

Wei, J., Karina, N., Chung, H. W., Jiao, Y. J., Papay, 

S., Glaese, A., Schulman, J., and Fedus, W. 2024. 

“Measuring Short-Form Factuality in Large Language 

Models.”  arXiv preprint arXiv:2411.04368 .

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, 

F., Chi, E., Le, Q. V., and Zhou, D. 2022.  “Chain-of-

Thought Prompting Elicits Reasoning in Large Lan -

guage Models.”  Advances in Neural Information Pro -

cessing Systems  35: 24824–24837. REFERENCES  2 3 5 

Wei, W., Jörg, N., and and Rolf, S. 2024.  “Leapfrog 

Logistics: Digital Trucking Platforms, Infrastructure, and 

Labor in Brazil and China.”  Review of International Po -

litical Economy  31(3): 930–954. 

Weitzman, M. L. 1998.  “Recombinant Growth.”  The 

Quarterly Journal of Economics  113(2): 331–360. 

Weizenbaum, J. 1976.  Computer Power and Human 

Reason: From Judgment to Calculation.  San Francisco, 

CA: W. H. Freeman. 

White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., 

Gilbert, H., Elnashar, A., Spencer-Smith, J., and 

Schmidt, D. C. 2023.  “A Prompt Pattern Catalog to 

Enhance Prompt Engineering with ChatGPT.”  arXiv pre -

print arXiv:2302.11382 .

Widder, D. G., Whittaker, M., and West, S. M. 2024. 

“Why ‘Open’ AI Systems Are Actually Closed, and Why 

This Matters.”  Nature  635(8040): 827–833. 

Wiles, E., Krayer, L., Abbadi, M., Awasthi, U., Kenne -

dy, R., Mishkin, P., Sack, D., and Candelon, F. 2024. 

“GenAI as an Exoskeleton: Experimental Evidence on 

Knowledge Workers Using GenAI on New Skills.” Avail -

able at SSRN 4944588. 

Wilson, H., Daugherty, P., and Bianzino, N. 2017.  “The 

Jobs That Artificial Intelligence Will Create.”  MIT Sloan 

Management Review  58(4): 14–16. 

Wolczynski, N., Saar-Tsechansky, M., and Wang, 

T. 2024.  “The Value of AI Advice: Personalized and 

Value-Maximizing AI Advisors Are Necessary to Reli -

ably Benefit Experts and Organizations.”  arXiv preprint 

arXiv:2412.19530 .

Wolf, M., Krause, J., Carney, P. A., Bogart, A., and 

Kurvers, R. H. J. M. 2015.  “Collective Intelligence 

Meets Medical Decision-Making: The Collective Out -

performs the Best Radiologist.”  PLOS ONE  10(8): 1–10. 

Wu, C., Qiu, P., Liu, J., Gu, H., Li, N., Zhang, Y., Wang, 

Y., and Xie, W. 2025.  “Towards Evaluating and Building 

Versatile Large Language Models for Medicine.”  NPJ 

Digital Medicine  8(1): 58. 

Wu, P. Y., Nagler, J., Tucker, J. A., and Messing, S. 

2023.  “Large Language Models Can Be Used to Esti -

mate the Latent Positions of Politicians.”  arXiv preprint 

arXiv:2303.12057 .

Wu, Z., Weber, T., and Müller, F. 2025.  “One Does Not 

Simply Meme Alone: Evaluating Co-Creativity between 

LLMs and Humans in the Generation of Humor.”  arXiv 

preprint arXiv:2501.11433 .

Xie, Y., Wu, J., Tu, H., Yang, S., Zhao, B., Zong, Y., Jin, 

Q., Xie, C., and Zhou, Y. 2024.  “A Preliminary Study of 

o1 in Medicine: Are We Closer to an AI Doctor?”  arXiv 

preprint arXiv:2409.15277 .

Xu, W., Kotecha, M. C., and McAdams, D. A. 2024. 

“How Good Is ChatGPT? An Exploratory Study on Chat -

GPT’s Performance in Engineering Design Tasks and 

Subjective Decision-Making.”  Proceedings of the De -

sign Society  4: 2307–2316. 

Xu, Z., Jain, S., and Kankanhalli, M. 2024.  “Halluci -

nation Is Inevitable: An Innate Limitation of Large Lan -

guage Models.”  arXiv preprint arXiv:2401.11817 .

Yan, L., Greiff, S., Teuber, Z., and Gašević, D. 2024. 

“Promises and Challenges of Generative Artificial Intel -

ligence for Human Learning.”  Nature Human Behaviour 

8(10): 1839–1850. 

Yang, J., Jin, H., Tang, R., Han, X., Feng, Q., Jiang, H., 

Zhong, S., Yin, B., and Hu, X. 2024.  “Harnessing the 

Power of LLMs in Practice: A Survey on ChatGPT and 

Beyond.”  ACM Transactions on Knowledge Discovery 

from Data  18(6): Article 160. 

Yang, L., Song, Y., Ren, X., Lyu, C., Wang, Y., Zhuo, J., 

Liu, L., and others. 2023a.  “Out-of-Distribution Gen -

eralization in Natural Language Processing: Past, Pres -

ent, and Future.”  Proceedings of the 2023 Conference 

on Empirical Methods in Natural Language Processing ,

4533–4559. 

Yang, Z., Ding, M., Lv, Q., Jiang, Z., He, Z., Guo, Y., 

Bai, J., and Tang, J. 2023b.  “GPT Can Solve Mathe -

matical Problems without a Calculator.”  arXiv preprint 

arXiv:2309.03241 .

Yenduri, G., Ramalingam, M., Selvi, G. C., Supriya, 

Y., Srivastava, G., Maddikunta, P. K. R., Raj, G. D., 

and others. 2024.  “GPT (Generative Pre-Trained 

Transformer)—A Comprehensive Review on Enabling 

Technologies, Potential Applications, Emerging Chal -

lenges, and Future Directions.”  IEEE Access  12: 

54608–54649. 

Yin, Y., Jia, N., and Wakslak, C. J. 2024.  “AI Can Help 

People Feel Heard, but an AI Label Diminishes This 

Impact.”  Proceedings of the National Academy of Sci -

ences  121(14): e2319112121. 

Yu, F., Moehring, A., Banerjee, O., Salz, T., Agarwal, 

N., and Rajpurkar, P. 2024.  “Heterogeneity and Pre -

dictors of the Effects of AI Assistance on Radiologists.” 

Nature Medicine  30(3): 837–849. 

Yuan, A., Coenen, A., Reif, E., and Ippolito, D. 2022. 

“Wordcraft: Story Writing with Large Language Models.” 

Proceedings of the 27th International Conference on 

Intelligent User Interfaces , 841–852. 

Zewail, A., Figueroa, A., Graham, J., and Atari, M. 

2024.  “Moral Stereotyping in Large Language Models.” 

PsyArXiv . https://doi.org/10.31234/osf.io/t9x8r .

Zhai, S., and Liu, Z. 2023.  “Artificial Intelligence Tech -

nology Innovation and Firm Productivity: Evidence from 

China.”  Finance Research Letters  58: 104437. 

Zhang, K., Zhou, R., Adhikarla, E., Yan, Z., Liu, Y., Yu, 

J., Liu, Z., and others. 2024a.  “A Generalist Vision– 

Language Foundation Model for Diverse Biomedical 

Tasks.”  Nature Medicine  30(11): 3129–3141. 

Zhang, M., Rahman, S., Mhasawade, V., and Chu -

nara, R. 2024b.  “Utilizing Big Data without Domain 

Knowledge Impacts Public Health Decision-Making.” 

Proceedings of the National Academy of Sciences 

121(39): e2402387121. 

Zhang, Z., Lee, S., Wu, J., Zhang, D., Li, S., Cambria, 

E., and Zhou, G. 2024c.  “Cross-Domain NER with Gen -

erated Task-Oriented Knowledge: An Empirical Study 

from Information Density Perspective.”  Proceedings of 

the 2024 Conference on Empirical Methods in Natu -

ral Language Processing , 1595–1609. Association for 

Computational Linguistics. 

Zhang, Z., Rossi, R. A., Kveton, B., Shao, Y., Yang, 

D., Zamani, H., Dernoncourt, F., and others. 2024d. 

“Personalization of Large Language Models: A Survey.” 

arXiv preprint arXiv:2411.00027 .

Zhang, Z., Zeng, W., Tang, J., Huang, H., and Zhao, 

X. 2025.  “Active in-Context Learning for Cross-Domain 

Entity Resolution.”  Information Fusion  117: 102816. 

Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, 

Y., Min, Y., and others. 2023.  “A Survey of Large Lan -

guage Models.”  arXiv preprint arXiv:2303.18223  1(2). 

Zhou, L., Schellaert, W., Martínez-Plumed, F., Moros-

Daval, Y., Ferri, C., and Hernández-Orallo, J. 2024. 

“Larger and More Instructable Language Models Be -

come Less Reliable.”  Nature  634(8032): 61–68. 

Zhu, J., Liapis, A., Risi, S., Bidarra, R., and Young -

blood, G. M. 2018.  “Explainable AI for Designers: A 

Human-Centered Perspective on Mixed-Initiative Co-

Creation.” 2018 IEEE Conference on Computational 

Intelligence and Games (CIG), 14–17 August. 

Zuhair, V., Babar, A., Ali, R., Oduoye, M. O., Noor, Z., 

Chris, K., Okon, I. I., and Rehman, L. U. 2024.  “Ex -

ploring the Impact of Artificial Intelligence on Global 

Health and Enhancing Healthcare in Developing Na -

tions.”  Journal of Primary Care & Community Health  15: 

21501319241245847. 

CHAPTER 2 

Abramson, J., Adler, J., Dunger, J., Evans, R., Green, 

T., Pritzel, A., Ronneberger, O., and others. 2024. 

“Accurate Structure Prediction of Biomolecular Interac -

tions with Alphafold 3.”  Nature  630(8016): 493–500. 

Agarwal, A., Usunier, N., Lazaric, A., and Nickel, M. 

2024.  “System-2 Recommenders: Disentangling Util -

ity and Engagement in Recommendation Systems Via 

Temporal Point-Processes.”  Proceedings of the 2024 

ACM Conference on Fairness, Accountability, and 

Transparency , 1763–1773. 

Aher, G. V., Arriaga, R. I., and Kalai, A. T. 2023.  “Using 

Large Language Models to Simulate Multiple Humans 

and Replicate Human Subject Studies.”  International 

Conference on Machine Learning,  23–29 July, Hawaii, 

337–371. 

Alhosani, K., and Alhashmi, S. M. 2024.  “Opportuni -

ties, Challenges, and Benefits of AI Innovation in Gov -

ernment Services: A Review.”  Discover Artificial Intel -

ligence  4(1): 18. 

Allcott, H., Gentzkow, M., Mason, W., Wilkins, A., 

Barberá, P., Brown, T., Cisneros, J. C., and others. 

2024.  “The Effects of Facebook and Instagram on the 

2020 Election: A Deactivation Experiment.”  Proceed -

ings of the National Academy of Sciences  121(21): 

e2321584121. 

Allen, B. P. 1994.  “Case-Based Reasoning: Business 

Applications.”  Communications of the ACM  37(3): 40–43. 

Allen, J., Watts, D. J., and Rand, D. G. 2024.  “Quantify -

ing the Impact of Misinformation and Vaccine-Skeptical 

Content on Facebook.”  Science  384(6699): eadk3451. 

Alvarez, A., Caliskan, A., Crockett, M. J., Ho, 

S. S., Messeri, L., and West, J. 2024.  “Science 2 3 6 HUMAN DEVELOPMENT REPORT 2025 

Communication with Generative AI.”  Nature Human 

Behaviour  8(4): 625–627. 

Anderson, C. A., Allen, J. J., Plante, C., Quigley-Mc -

Bride, A., Lovett, A., and Rokkum, J. N. 2019.  “The 

MTurkification of Social and Personality Psychology.”  Per -

sonality and Social Psychology Bulletin  45(6): 842–850. 

Angelidis, S., Amplayo, R. K., Suhara, Y., Wang, X., and 

Lapata, M. 2021.  “Extractive Opinion Summarization in 

Quantized Transformer Spaces.”  Transactions of the As -

sociation for Computational Linguistics  9: 277–293. 

Argyle, L. P., Busby, E. C., Fulda, N., Gubler, J. R., Ryt -

ting, C., and Wingate, D. 2023.  “Out of One, Many: 

Using Language Models to Simulate Human Samples.” 

Political Analysis  31(3): 337–351. 

Aristotle 1999.  “Politics.” Kitchener, ON: Batoche 

Books. 

Arrow, K. J., Forsythe, R., Gorham, M., Hahn, R., 

Hanson, R., Ledyard, J. O., Levmore, S., and others. 

2008.  “The Promise of Prediction Markets.”  Science 

320: 877–878. 

Atari, M., Xue, M. J., Park, P. S., Blasi, D., and Henrich, 

J. 2025.  “Which Humans?”  https://psyarxiv.com/5b26t .

Athey, S. C., Bryan, K. A., and Gans, J. S. 2020.  “The 

Allocation of Decision Authority to Human and Artificial 

Intelligence.” AEA Papers and Proceedings, American 

Economic Association, 80–84. 

Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., 

Shariff, A., Bonnefon, J.-F., and Rahwan, I. 2018.  “The 

Moral Machine Experiment.”  Nature  563(7729): 59–64. 

Bail, C. A., Argyle, L. P., Brown, T. W., Bumpus, J. 

P., Chen, H., Hunzaker, M. B. F., Lee, J., and others. 

2018.  “Exposure to Opposing Views on Social Media 

Can Increase Political Polarization.”  Proceedings of the 

National Academy of Sciences  115(37): 9216–9221. 

Bak-Coleman, J. B., Alfano, M., Barfuss, W., Berg -

strom, C. T., Centeno, M. A., Couzin, I. D., Donges, 

J. F., and others. 2021.  “Stewardship of Global Collec -

tive Behavior.”  Proceedings of the National Academy 

of Sciences  118(27): e2025764118-e2025764118. 

Bak-Coleman, J. B., Tokita, C. K., Morris, D. H., Ru -

benstein, D. I., and Couzin, I. D. 2022.  “Collective 

Wisdom in Polarized Groups.”  Collective Intelligence 

1(1): 263391372211047–263391372211047. 

Becker, J., Brackbill, D., and Centola, D. 2017.  “Net -

work Dynamics of Social Influence in the Wisdom 

of Crowds.”  Proceedings of the National Academy 

of Sciences of the United States of America  114(26): 

E5070-E5076. 

Becker, J., Porter, E., and Centola, D. 2019.  “The Wis -

dom of Partisan Crowds.”  Proceedings of the National 

Academy of Sciences  166(22): 201817195–201817195. 

Bender, E. M., Gebru, T., McMillan-Major, A., and 

Shmitchell, S. 2021.  “On the Dangers of Stochastic 

Parrots: Can Language Models Be Too Big?”  Proceed -

ings of the 2021 ACM Conference on Fairness, Ac -

countability, and Transparency , 3–10 March, online, 

610–623. 

Berger-Tal, O., Wong, B. B., Adams, C. A., Blum -

stein, D. T., Candolin, U., Gibson, M. J., Greggor, A. 

L., and others. 2024.  “Leveraging AI to Improve Evi -

dence Synthesis in Conservation.”  Trends in Ecology 

& Evolution .

Bhat, S. A., and Huang, N.-F. 2021.  “Big Data and AI 

Revolution in Precision Agriculture: Survey and Chal -

lenges.”  IEEE Access  9: 110209–110222. 

Bi, K., Xie, L., Zhang, H., Chen, X., Gu, X., and Tian, Q. 

2023.  “Accurate Medium-Range Global Weather Fore -

casting with 3D Neural Networks.”  Nature  619(7970): 

533–538. 

Birhane, A., Steed, R., Ojewale, V., Vecchione, B., 

and Raji, I. D. 2024.  “AI Auditing: The Broken Bus on 

the Road to AI Accountability.” 2024 IEEE Conference 

on Secure and Trustworthy Machine Learning (SaTML), 

9–11 April, Copenhagen, 612–643. 

Blumenstock, J. 2020.  “Machine Learning Can Help 

Get Covid-19 Aid to Those Who Need It Most.”  Nature .

Bond, R. M., Fariss, C. J., Jones, J. J., Kramer, A. D. 

I., Marlow, C., Settle, J. E., and Fowler, J. H. 2012. 

“A 61-Million-Person Experiment in Social Influence and 

Political Mobilization.”  Nature 2012 489:7415  489(7415): 

295–298. 

Born, G., Morris, J., Diaz, F., and Anderson, A. 2021. 

“Artificial Intelligence, Music Recommendation, and the 

Curation of Culture.” White Paper, University of Toronto, 

Schwartz Reisman Institute for Technology and Society, 

CIFAR. 

Boyd, R., and Richerson, P. J. 1985.  Culture and the 

Evolutionary Process.  Chicago, IL: University of Chi -

cago Press. 

Brady, W. J., Jackson, J. C., Lindström, B., and 

Crockett, M. 2023.  “Algorithm-Mediated Social Learn -

ing in Online Social Networks.”  Trends in Cognitive Sci -

ences  27(10): 947–960. 

Brinkmann, L., Baumann, F., Bonnefon, J.-F., Derex, 

M., Müller, T. F., Nussberger, A.-M., Czaplicka, A., and 

others. 2023.  “Machine Culture.”  Nature Human Be -

haviour  7(11): 1855–1868. 

Burton, J. W., Lopez-Lopez, E., Hechtlinger, S., Rah -

wan, Z., Aeschbach, S., Bakker, M. A., Becker, J. A., 

and others. 2024.  “How Large Language Models Can 

Reshape Collective Intelligence.”  Nature Human Be -

haviour  8(9): 1643–1655. 

Chang, D., Pang, K., Du, R., Tong, Y., Song, Y.-Z., Ma, 

Z., and Guo, J. 2023.  “Making a Bird AI Expert Work 

for You and Me.”  IEEE Transactions on Pattern Analysis 

and Machine Intelligence  45(10): 12068–12084. 

Chetty, R., Jackson, M. O., Kuchler, T., Stroebel, J., 

Hendren, N., Fluegge, R. B., Gong, S., and others. 

2022a.  “Social Capital I: Measurement and Associa -

tions with Economic Mobility.”  Nature 2022 608:7921 

608(7921): 108–121. 

Chetty, R., Jackson, M. O., Kuchler, T., Stroebel, J., 

Hendren, N., Fluegge, R. B., Gong, S., and others. 

2022b.  “Social Capital II: Determinants of Economic Con -

nectedness.”  Nature 2022 608:7921  608(7921): 122–134. 

Coavoux, M., Elsahar, H., and Gallé, M. 2019.  “Un -

supervised Aspect-Based Multi-Document Abstractive 

Summarization.”  Proceedings of the 2nd Workshop on 

New Frontiers in Summarization , 42–47. 

Condorcet, M. d. 1785.  “Essay on the Application of 

Analysis to the Probability of Majority Decisions.”  Paris: 

Imprimerie Royale .

Conover, M. D., Ratkiewicz, J., Francisco, M., Gon -

çalves, B., Flammini, A., and Menczer, F. 2011.  “Po -

litical Polarization on Twitter.”  Proceedings of the Inter -

national AAAI Conference on Web and Social Media 

5(1): 89–96. 

Costa-Jussà, M. R., Cross, J., Çelebi, O., Elbayad, M., 

Heafield, K., Heffernan, K., Kalbassi, E., Lam, J., and 

Licht, D. 2022.  “No Language Left Behind: Scaling 

Human-Centered Machine Translation.”  arXiv preprint 

arXiv:2207.04672 .

Costello, T. H., Pennycook, G., and Rand, D. G. 

2024.  “Durably Reducing Conspiracy Beliefs through 

Dialogues with AI.”  Science  385(6714): eadq1814. 

Cross, S., and Estrada, R. 1995.  “DART: An Example of 

Accelerated Evolutionary Development.”  Proceedings 

of the International Workshop on Rapid System Proto -

typing : 177–183. 

Dillion, D., Tandon, N., Gu, Y., and Gray, K. 2023. 

“Can AI Language Models Replace Human Partici -

pants?”  Trends in Cognitive Sciences  27(7): 597–600. 

Ellis, E. C. 2024.  “The Anthropocene Condition: Evolv -

ing through Social–Ecological Transformations.”  Philo -

sophical Transactions of the Royal Society B  379(1893): 

20220255. 

Feldman, M. W., and Cavalli-Sforzatt, L. L. 1984. 

“Cultural and Biological Evolutionary Processes: Gene-

Culture Disequilibrium.”  Proceedings of the National 

Academy of Sciences  81(5): 1604-1607. 

Galaz, V. 2024.  Dark Machines: How Artificial Intelli -

gence, Digitalization and Automation Is Changing Our 

Living Planet.  Taylor & Francis. 

Galaz, V., Metzler, H., Schill, C., Lindahl, T., Daume, 

S., Marklund, A., Castro, A. J., and others. 2025.  “Ar -

tificial Intelligence, Digital Social Networks, and Climate 

Emotions.”  NPJ Climate Action  4(1): 23. 

Galton, F. 1907.  “Vox Populi.”  Nature  1949(75): 

450–451. 

Gao, J., Yin, Y., Myers, K. R., Lakhani, K. R., and 

Wang, D. 2021.  “Potentially Long-Lasting Effects of the 

Pandemic on Scientists.”  Nature Communications  12(1): 

1–6. 

Gezici, G. 2022.  “Case Study: The Impact of Lo -

cation on Bias in Search Results.”  arXiv preprint 

arXiv:2206.11869 .

González-Bailón, S., Lazer, D., Barberá, P., Zhang, 

M., Allcott, H., Brown, T., Crespo-Tenorio, A., and 

others. 2023.  “Asymmetric Ideological Segregation 

in Exposure to Political News on Facebook.”  Science 

381(6656): 392–398. 

Guerreiro, N. M., Alves, D. M., Waldendorf, J., Had -

dow, B., Birch, A., Colombo, P., and Martins, A. F. 

2023.  “Hallucinations in Large Multilingual Translation 

Models.”  Transactions of the Association for Computa -

tional Linguistics  11: 1500–1517. 

Guess, A. M., Malhotra, N., Pan, J., Barberá, P., All -

cott, H., Brown, T., Crespo-Tenorio, A., and others. REFERENCES  2 3 7 

2023a.  “How Do Social Media Feed Algorithms Affect 

Attitudes and Behavior in an Election Campaign?”  Sci -

ence  381(6656): 398–404. 

Guess, A. M., Malhotra, N., Pan, J., Barberá, P., All -

cott, H., Brown, T., Crespo-Tenorio, A., and others. 

2023b.  “Reshares on Social Media Amplify Political 

News but Do Not Detectably Affect Beliefs or Opin -

ions.”  Science  381(6656): 404–408. 

Guilbeault, D., Becker, J., and Centola, D. 2018.  “So -

cial Learning and Partisan Bias in the Interpretation of 

Climate Trends.”  Proceedings of the National Academy 

of Sciences of the United States of America  115(39): 

9714–9719. 

Gunasekeran, D. V., Tseng, R. M. W. W., Tham, Y. C., 

and Wong, T. Y. 2021.  “Applications of Digital Health 

for Public Health Responses to Covid-19: A Systematic 

Scoping Review of Artificial Intelligence, Telehealth and 

Related Technologies.”  NPJ Digital Medicine 2021 4:1 

4(1): 1–6. 

Guo, S., Zhang, B., Liu, T., Liu, T., Khalman, M., Llin -

ares, F., Rame, A., and others. 2024.  “Direct Lan -

guage Model Alignment from Online AI Feedback.” 

arXiv preprint arXiv:2402.04792 .

Hastie, R., and Kameda, T. 2005.  “The Robust Beauty 

of Majority Rules in Group Decisions.”  Psychological 

Review  112(2): 494. 

Haupt, C. E., and Marks, M. 2023.  “AI-Generated 

Medical Advice—GPT and Beyond.”  JAMA  329(16): 

1349–1350. 

Henderson, D. A. 1987.  “Principles and Lessons from 

the Smallpox Eradication Programme.”  Bulletin of the 

World Health Organization  65(4): 535. 

Henrich, J. 2015.  The Secret of Our Success: The 

Secret of Our Success: How Culture Is Driving Human 

Evolution, Domesticating Our Species, and Making Us 

Smarter.  Princeton, NJ: Princeton University Press. 

Henrich, J., and McElreath, R. 2003.  “The Evolution of 

Cultural Evolution.”  Evolutionary Anthropology: Issues, 

News, and Reviews  12(3): 123–135. 

Hilbert, M., and Darmon, D. 2020.  “How Complexity 

and Uncertainty Grew with Algorithmic Trading.”  En -

tropy  22(5): 499. 

Hill, K. 2023.  Your Face Belongs to Us: A Tale of AI, a Se -

cretive Startup, and the End of Privacy.  Random House. 

Hoffmann, M. J. 2012.  Ozone Depletion and Climate 

Change: Constructing a Global Response.  New York: 

State University of New York Press. 

Hong, L., and Page, S. 2011.  “The Foundations of Col -

lective Wisdom.”  Collective Wisdom: Principles and 

Mechanisms : 1–33. 

Hong, L., and Page, S. E. 2004.  “Groups of Diverse 

Problem Solvers Can Outperform Groups of High-

Ability Problem Solvers.”  Proceedings of the National 

Academy of Sciences  101(46): 16385–16389. 

Huang, B., Huan, Y., Xu, L. D., Zheng, L., and Zou, 

Z. 2019.  “Automated Trading Systems Statistical and 

Machine Learning Methods and Hardware Implemen -

tation: A Survey.”  Enterprise Information Systems  13(1): 

132–144. 

Hunkenschroer, A. L., and Luetge, C. 2022.  “Ethics 

of AI-Enabled Recruiting and Selection: A Review and 

Research Agenda.”  Journal of Business Ethics  178(4): 

977–1007. 

Huszár, F., Ktena, S. I., Obrien, C., Belli, L., Schlaikjer, 

A., and Hardt, M. 2022.  “Algorithmic Amplification of 

Politics on Twitter.”  Proceedings of the National Acad -

emy of Sciences of the United States of America  119(1). 

Ismagilova, E., Hughes, L., Rana, N. P., and Dwivedi, 

Y. K. 2022.  “Security, Privacy and Risks within Smart 

Cities: Literature Review and Development of a Smart 

City Interaction Framework.”  Information Systems Fron -

tiers : 1–22. 

ITU (International Telecommunication Union). 2023. 

“Facts and Figures 2023.” Geneva. 

Ji, J., Qiu, T., Chen, B., Zhang, B., Lou, H., Wang, K., 

Duan, Y., and others. 2023.  “AI Alignment: A Compre -

hensive Survey.”  arXiv preprint arXiv:2310.19852 .

Jongaramrungruang, S., Thorpe, A. K., Matheou, G., 

and Frankenberg, C. 2022.  “Methanet–an AI-Driven 

Approach to Quantifying Methane Point-Source Emis -

sion from High-Resolution 2-D Plume Imagery.”  Remote 

Sensing of Environment  269: 112809. 

Kaack, L. H., Donti, P. L., Strubell, E., Kamiya, G., 

Creutzig, F., and Rolnick, D. 2022.  “Aligning Artificial 

Intelligence with Climate Change Mitigation.”  Nature 

Climate Change  12(6): 518–527. 

Kelling, S., Gerbracht, J., Fink, D., Lagoze, C., Wong, 

W.-K., Yu, J., Damoulas, T., and Gomes, C. 2013.  “A 

Human/Computer Learning Network to Improve Bio -

diversity Conservation and Research.”  AI magazine 

34(1): 10–10. 

Kelly, M., and Gráda, C. Ó. 2000.  “Market Contagion: 

Evidence from the Panics of 1854 and 1857.”  American 

Economic Review  90(5): 1110–1124. 

Kittur, A., and Kraut, R. E. 2008.  “Harnessing the 

Wisdom of Crowds in Wikipedia: Quality through Co -

ordination.”  Proceedings of the ACM Conference on 

Computer Supported Cooperative Work , ACM Press, 

New York, 37–46. 

Kopits, E., and Cropper, M. 2005.  “Traffic Fatalities 

and Economic Growth.”  Accident Analysis & Preven -

tion  37(1): 169–178. 

Larson, S. M., Snow, C. D., Shirts, M., and Pande, V. S. 

2009.  “Folding@ Home and Genome@ Home: Using 

Distributed Computing to Tackle Previously Intractable 

Problems in Computational Biology.”  arXiv preprint 

arXiv:0901.0866 .

Linda Morris, O. A. 2022.  “Holding Facebook Ac -

countable for Digital Redlining.” ACLU.  https://www. 

aclu.org/news/privacy-technology/holding-facebook-

accountable-for-digital-redlining . Accessed 4 May 

2025. 

Lorenz, J., Rauhut, H., Schweitzer, F., and Helbing, 

D. 2011.  “How Social Influence Can Undermine the 

Wisdom of Crowd Effect.”  Proceedings of the National 

Academy of Sciences  108(22): 9020–9025. 

Lum, K., and Isaac, W. 2016.  “To Predict and Serve?” 

Significance  13(5): 14–19. 

MacKay, A., and Weinstein, S. N. 2022.  “Dynamic 

Pricing Algorithms, Consumer Harm, and Regulatory 

Response.”  Washington University Law Review  100: 111. 

Mackay, C. 1980.  Extraordinary Popular Delusions and 

the Madness of Crowds.  New York: Harmony Books. 

Mann, R. P. 2022.  “Collective Decision-Making under 

Changing Social Environments among Agents Adapt -

ed to Sparse Connectivity.”  Collective Intelligence  1(2): 

26339137221121347. 

Marcenaro-Gutierrez, O. D., Micklewright, J., and Vi -

gnoles, A. F. 2021.  “Social Mobility and the Importance 

of Networks: Evidence for Britain.”  SSRN Electronic 

Journal .

Marcinkowski, F., Kieslich, K., Starke, C., and Lünich, 

M. 2020.  “Implications of AI (Un-)Fairness in Higher Ed -

ucation Admissions: The Effects of Perceived AI (Un-) 

Fairness on Exit, Voice, and Organizational Reputation.” 

Proceedings of the 2020 Conference on Fairness, Ac -

countability, and Transparency , ACM Press, 122–130. 

Masello, L., Castignani, G., Sheehan, B., Murphy, F., 

and McDonnell, K. 2022.  “On the Road Safety Bene -

fits of Advanced Driver Assistance Systems in Different 

Driving Contexts.”  Transportation Research Interdisci -

plinary Perspectives  15: 100670. 

McGovern, A., Demuth, J., Bostrom, A., Wirz, C. D., 

Tissot, P. E., Cains, M. G., and Musgrave, K. D. 2024. 

“The Value of Convergence Research for Developing 

Trustworthy AI for Weather, Climate, and Ocean Haz -

ards.”  NPJ Natural Hazards  1(1): 13. 

McLoughlin, K. L., and Brady, W. J. 2023.  “Human-

Algorithm Interactions Help Explain the Spread of Mis -

information.”  Current Opinion in Psychology : 101770. 

Messeri, L., and Crockett, M. J. 2024.  “Artificial Intel -

ligence and Illusions of Understanding in Scientific Re -

search.”  Nature  627(8002): 49–58. 

Mirdita, M., Schütze, K., Moriwaki, Y., Heo, L., 

Ovchinnikov, S., and Steinegger, M. 2022.  “Colab -

fold: Making Protein Folding Accessible to All.”  Nature 

Methods  19(6): 679–682. 

Moss, A. J., Rosenzweig, C., Robinson, J., Jaffe, S. 

N., and Litman, L. 2023.  “Is It Ethical to Use Mechani -

cal Turk for Behavioral Research? Relevant Data from a 

Representative Survey of MTurk Participants and Wag -

es.”  Behavior Research Methods  55(8): 4048–4067. 

Narayanan, A., and Kapoor, S. 2024.  AI Snake Oil: 

What Artificial Intelligence Can Do, What It Can’t, and 

How to Tell the Difference . Princeton, NJ: Princeton 

University Press. 

Navajas, J., Niella, T., Garbulsky, G., Bahrami, B., 

and Sigman, M. 2018.  “Aggregated Knowledge from 

a Small Number of Debates Outperforms the Wisdom 

of Large Crowds.”  Nature Human Behaviour  2(2): 

126–132. 

Nie, J., Shao, H., Fan, Y., Shao, Q., You, H., Preindl, 

M., and Jiang, X. 2024.  “LLM-Based Conversational AI 

Therapist for Daily Functioning Screening and Psycho -

therapeutic Intervention Via Everyday Smart Devices.” 

arXiv preprint arXiv:2403.10779 .

Nyhan, B., Settle, J., Thorson, E., Wojcieszak, M., 

Barberá, P., Chen, A. Y., Allcott, H., and others. 2023. 2 3 8 HUMAN DEVELOPMENT REPORT 2025 

“Like-Minded Sources on Facebook Are Prevalent but 

Not Polarizing.”  Nature 2023 620:7972  620(7972): 

137–144. 

Otto, I. M., Donges, J. F., Cremades, R., Bhowmik, 

A., Hewitt, R. J., Lucht, W., Rockström, J., and others. 

2020.  “Social Tipping Dynamics for Stabilizing Earth’s 

Climate by 2050.”  Proceedings of the National Acad -

emy of Sciences of the United States of America  117(5): 

2354–2365. 

Panch, T., Pearson-Stuttard, J., Greaves, F., and 

Atun, R. 2019.  “Artificial Intelligence: Opportunities and 

Risks for Public Health.”  The Lancet Digital Health  1(1): 

e13-e14. 

Pescetelli, N., Rutherford, A., and Rahwan, I. 2021. 

“Modularity and Composite Diversity Affect the Collec -

tive Gathering of Information Online.”  Nature Commu -

nications  12(1): 3195. 

Ponnusamy, P., Ghias, A., Yi, Y., Yao, B., Guo, C., and 

Sarikaya, R. 2022.  “Feedback-Based Self-Learning in 

Large-Scale Conversational AI Agents.”  AI Magazine 

42(4): 43–56. 

Prelec, D. D. D., Seung, H. S., and McCoy, J. 2017.  “A 

Solution to the Single-Question Crowd Wisdom Prob -

lem.”  Nature  541(7638): 532–535. 

Qazi, S., Khawaja, B. A., and Farooq, Q. U. 2022. 

“IoT-Equipped and AI-Enabled Next Generation Smart 

Agriculture: A Critical Review, Current Challenges and 

Future Trends.”  IEEE Access  10: 21219–21235. 

Rahwan, I. 2018.  “Society-in-the-Loop: Programming 

the Algorithmic Social Contract.”  Ethics and Information 

Technology  20(1): 5–14. 

Rahwan, I., Cebrian, M., Obradovich, N., Bongard, J., 

Bonnefon, J. F., Breazeal, C., Crandall, J. W., and oth -

ers. 2019.  “Machine Behaviour.”  Nature 2019 568:7753 

568(7753): 477–486. 

Raja, A. K., and Zhou, J. 2023.  “AI Accountability: Ap -

proaches, Affecting Factors, and Challenges.”  Com -

puter  56(4): 61–70. 

Rajkumar, K., Saint-Jacques, G., Bojinov, I., Bryn -

jolfsson, E., and Aral, S. 2022.  “A Causal Test of the 

Strength of Weak Ties.”  Science  377(6612): 1304–1310. 

Ren, F., Aliper, A., Chen, J., Zhao, H., Rao, S., Kuppe, 

C., Ozerov, I. V., and others. 2024.  “A Small-Molecule 

TNIK Inhibitor Targets Fibrosis in Preclinical and Clinical 

Models.”  Nature Biotechnology : 1–13. 

Reverberi, C., Rigon, T., Solari, A., Hassan, C., Cheru -

bini, P., Antonelli, G., Awadie, H., and others. 2022. 

“Experimental Evidence of Effective Human–AI Collab -

oration in Medical Decision-Making.”  Scientific Reports 

12(1): 14952. 

Ribeiro, M. H., Ottoni, R., West, R., Almeida, V. A. F., 

and Wagner Meira, W. M. 2020.  “Auditing Radicaliza -

tion Pathways on Youtube.”  Proceedings of the 2020 

Conference on Fairness, Accountability, and Transpar -

ency , ACM Press, 131–141. 

Richerson, P. J., Boyd, R. T., and Efferson, C. 2024. 

“Agentic Processes in Cultural Evolution: Relevance to 

Anthropocene Sustainability.”  Philosophical Transac -

tions of the Royal Society B  379(1893): 20220252. 

Roytburg, E. 2024.  “Google Unceremoniously 

Dropped Its Promise of Carbon Neutrality, with Emis -

sions Rising Nearly 50% over the Last Five Years.” 

Fortune .

Sachan, S., Yang, J.-B., Xu, D.-L., Benavides, D. E., 

and Li, Y. 2020.  “An Explainable AI Decision-Support-

System to Automate Loan Underwriting.”  Expert Sys -

tems with Applications  144: 113100. 

Sanders, N. R., Boone, T., Ganeshan, R., and Wood, 

J. D. 2019.  “Sustainable Supply Chains in the Age of AI 

and Digitization: Research Challenges and Opportuni -

ties.”  Journal of Business logistics  40(3): 229–240. 

Santos, F. P., Lelkes, Y., and Levin, S. A. 2021.  “Link 

Recommendation Algorithms and Dynamics of Polar -

ization in Online Social Networks.”  Proceedings of the 

National Academy of Sciences of the United States of 

America  118(50): e2102141118-e2102141118. 

Sayari, M., Haghighi, M. R. R., Lankarani, K. B., 

Ghahramani, S., and Honarvar, B. 2022.  “Road Traffic 

Death Rate and Human Development Index in 2007– 

2016 at the Global Level: Trend Analysis.” 

Schrittwieser, J., Antonoglou, I., Hubert, T., Si -

monyan, K., Sifre, L., Schmitt, S., Guez, A., and oth -

ers. 2020.  “Mastering Atari, Go, Chess and Shogi by 

Planning with a Learned Model.”  Nature  588(7839): 

604–609. 

Sen, A. 1999.  Development as Freedom.  New York: 

Knopf. 

Shattock, A. J., Johnson, H. C., Sim, S. Y., Carter, A., 

Lambach, P., Hutubessy, R. C., Thompson, K. M., 

and others. 2024.  “Contribution of Vaccination to Im -

proved Survival and Health: Modelling 50 Years of the 

Expanded Programme on Immunization.”  The Lancet 

403(10441): 2307–2316. 

Shin, M., Kim, J., Van Opheusden, B., and Griffiths, 

T. L. 2023.  “Superhuman Artificial Intelligence Can Im -

prove Human Decision-Making by Increasing Novelty.” 

Proceedings of the National Academy of Sciences 

120(12): e2214840120. 

Smith, K. P., and Christakis, N. A. 2008.  “Social Net -

works and Health.”  Annual Review of Sociology  34: 

405–429. 

Stewart, F. 2013.  “Capabilities and Human Develop -

ment: Beyond the Individual - the Critical Role of Social 

Institutions and Social Competencies.” Human Devel -

opment Report Office Occasional Paper 2013/03, Unit -

ed Nations Development Programme, New York. 

Stiles, E., and Cui, X. 2010.  “Workings of Collective 

Intelligence within Open Source Communities.”  Ad -

vances in Social Computing: Proceedings of the Third 

International Conference on Social Computing, Behav -

ioral Modeling, and Prediction , Bethesda, MD, 30–31 

March, Springer, 282–289. 

Suhara, Y., Wang, X., Angelidis, S., and Tan, W.-C. 

2020.  “OpinionDigest: A Simple Framework for Opin -

ion Summarization.”  arXiv preprint arXiv:2005.01901 .

Suran, S., Pattanaik, V., Kurvers, R., Hallin, C. A., 

De Liddo, A., Krimmer, R., and Draheim, D. 2022. 

“Building Global Societies on Collective Intelligence: 

Challenges and Opportunities.”  Digital Government: 

Research and Practice  3(4): 1–6. 

Surowiecki, J. 2005.  The Wisdom of Crowds.  New 

York: Anchor Books. 

Taylor, I. 2023.  “Justice by Algorithm: The Limits of AI 

in Criminal Sentencing.”  Criminal Justice Ethics  42(3): 

193–213. 

Tessler, M. H., Bakker, M. A., Jarrett, D., Sheahan, H., 

Chadwick, M. J., Koster, R., Evans, G., and others. 

2024.  “AI Can Help Humans Find Common Ground 

in Democratic Deliberation.”  Science  386(6719): 

eadq2852. 

Todorović, V., Pešterac, A., and Tomić, N. 2019.  “The 

Impact of Automated Trading Systems on Financial 

Market Stability.”  Facta Universitatis, Series: Economics 

and Organization , 255–268. 

Törnberg, P. 2018.  “Echo Chambers and Viral Misinfor -

mation: Modeling Fake News as Complex Contagion.” 

PLOS ONE  13(9): e0203958–e0203958. 

Toyokawa, W., Whalen, A., and Laland, K. N. 2019. 

“Social Learning Strategies Regulate the Wisdom and 

Madness of Interactive Crowds.”  Nature Human Be -

haviour  3(2): 183–193. 

UNDP (United Nations Development Programme). 

2001.  Human Development Report 2001: Making New 

Technologies Work for Human Development . New 

York. 

UNDP (United Nations Development Programme). 

2024.  Human Development Report 2023–24: Break -

ing the Gridlock: Reimagining Cooperation in a Polar -

ized World . New York. 

van Oosterhout, C. 2024.  “AI-Informed Conservation 

Genomics.”  Heredity  132(1): 1–4. 

Van Wynsberghe, A. 2021.  “Sustainable AI: AI for 

Sustainability and the Sustainability of AI.”  AI and Ethics 

1(3): 213–218. 

Verma, P., and Tan, S. 2024.  “A Bottle of Water Per 

Email: The Hidden Environmental Costs of Using AI 

Chatbots: AI Bots Generate a Lot of Heat, and Keep -

ing Their Computer Servers Running Exacts a Toll.”  The 

Washington Post .

Vlasceanu, M., and Doell, K. C., and Bak-Coleman, J. 

B., and Todorova, B., and Berkebile-Weinberg, M. M., 

and Grayson, S. J., and Patel, Y., and others. 2024. 

“Addressing Climate Change with Behavioral Science: 

A Global Intervention Tournament in 63 Countries.”  Sci -

ence Advances  10(6): 217–217. 

Voelz, V. A., Pande, V. S., and Bowman, G. R. 2023. 

“Folding@ Home: Achievements from over 20 Years of 

Citizen Science Herald the Exascale Era.”  Biophysical 

journal  122(14): 2852–2863. 

Vogell, H., Coryne, H., and Little, R. 2022.  “Rent Go -

ing Up? One Company’s Algorithm Could Be Why.”  Pro 

Publica .

Wan, J., Li, X., Dai, H.-N., Kusiak, A., Martinez-Gar -

cia, M., and Li, D. 2020.  “Artificial-Intelligence-Driven 

Customized Manufacturing Factory: Key Technologies, 

Applications, and Challenges.”  Proceedings of the IEEE 

109(4): 377–398. 

Wang, S., Huang, S., Zhou, A., and Metaxa, D. 

2024a.  “Lower Quantity, Higher Quality: Auditing REFERENCES  2 3 9 

News Content and User Perceptions on Twitter/X Algo -

rithmic Versus Chronological Timelines.”  arXiv preprint 

arXiv:2406.17097 .

Wang, Z., Bi, B., Pentyala, S. K., Ramnath, K., Chaud -

huri, S., Mehrotra, S., Mao, X.-B., and Asur, S. 2024b. 

“A Comprehensive Survey of LLM Alignment Tech -

niques: RLHF, RLAIF, PPO, DPO and More.”  arXiv pre -

print arXiv:2407.16216 .

Waring, T. M., Wood, Z. T., and Szathmáry, E. 2024. 

“Characteristic Processes of Human Evolution Caused 

the Anthropocene and May Obstruct Its Global Solu -

tions.”  Philosophical Transactions of the Royal Society 

B 379(1893): 20220259. 

Wermelinger, M. 2023.  “Using Github Copilot to Solve 

Simple Programming Problems.”  Proceedings of the 

54th ACM Technical Symposium on Computer Science 

Education , 172–178. 

WHO (World Health Organization). 2023.  Global Sta -

tus Report on Road Safety 2023 . Geneva. 

Wiener, N. 1960.  “Some Moral and Technical Conse -

quences of Automation: As Machines Learn They May 

Develop Unforeseen Strategies at Rates That Baffle 

Their Programmers.”  Science  131(3410): 1355–1358. 

Wolf, M. J., Miller, K., and Grodzinsky, F. S. 2017.  “Why 

We Should Have Seen That Coming: Comments on 

Microsoft’s Tay ‘Experiment,’ and Wider Implications.” 

ACM SIGCAS Computers and Society  47(3): 54–64. 

Xu, Z. 2022.  “Human Judges in the Era of Artificial 

Intelligence: Challenges and Opportunities.”  Applied 

Artificial Intelligence  36(1): 2013652. 

Yin, C., Xiong, Z., Chen, H., Wang, J., Cooper, D., and 

David, B. 2015.  “A Literature Survey on Smart Cities.” 

Science China. Information Sciences  58(10): 1–18. 

Yin, Y., Gao, J., Jones, B. F., and Wang, D. 2021.  “Co -

evolution of Policy and Science During the Pandemic.” 

Science  371(6525): 128–130. 

Yurtsever, E., Lambert, J., Carballo, A., and Takeda, 

K. 2020.  “A Survey of Autonomous Driving: Common 

Practices and Emerging Technologies.”  IEEE Access  8: 

58443–58469. 

Zuboff, S. 2023.  “The Age of Surveillance Capitalism.” 

Social Theory Re-Wired.  Routledge. 

CHAPTER 3 

Adams, J., Dedehayir, O., and O’Connor, P. 2022.  “A 

Theoretical Model of Technology, Agency, and Well -

being.”  ISPIM Conference Proceedings . The Interna -

tional Society for Professional Innovation Management 

(ISPIM). https://www.proquest.com/openview/7def1e 

82da6c4bc1d91fd957a9c604f6/1?cbl=1796422&pq-

origsite=gscholar. Accessed 4 February 2025. 

Aeschlimann, S., Bleiker, M., Wechner, M., and 

Gampe, A. 2020.  “Communicative and Social Conse -

quences of Interactions with Voice Assistants.”  Com -

puters in Human Behavior  112: 106466. 

Ahuja, J., and Fichadia, P. A. 2024.  “Concerns Re -

garding the Glorification of Mental Illness on Social 

Media.”  Cureus  16(3). 

Ali, S., DiPaola, D., Lee, I., Sindato, V., Kim, G., Blu -

mofe, R., and Breazeal, C. 2021.  “Children as Cre -

ators, Thinkers and Citizens in an AI-Driven Future.” 

Computers and Education: Artificial Intelligence  2: 

100040. 

Allcott, H., Braghieri, L., Eichmeyer, S., and Gentz -

kow, M. 2020.  “The Welfare Effects of Social Media.” 

American Economic Review  110(3): 629–676. 

Allcott, H., Gentzkow, M., and Song, L. 2022.  “Digi -

tal Addiction.”  American Economic Review  112(7): 

2424–2463. 

Allen, E. 2011.  “Facebook to Use Microsoft’s Photodna 

Technology to Combat Child Exploitation.” https://blogs. 

microsoft.com/on-the-issues/2011/05/19/facebook-to-

use-microsofts-photodna-technology-to-combat-child-

exploitation/. Accessed 20 September 2024. 

Altchek, A. 2024.  “Replika Lets You Buy an AI Girl -

friend or Boyfriend—and Its Average User Age Is Sur -

prising “  Business Insider . https://www.businessinsider. 

com/replika-ai-girlfriend-boyfriend-online-dating-com -

panion-age-2024-8. Accessed 12 February 2025. 

Alzate, D. 2023.  “Addressing Inequalities in Education -

al Markets with the Power of Personalized Information.” 

https://jackson.yale.edu/news/addressing-inequalities-

in-educational-markets-with-the-power-of-personal -

ized-information/. 

Amadeus. 2017.  “Voyage of Discovery: Working To -

wards Inclusive and Accessible Travel for All.” https:// 

amadeus.com/documents/en/airlines/research-report/ 

voyage-of-discovery.pdf. Accessed 27 December 

2024. 

Amlani, N. 2024.  “AI Exploitation and Child Sexual 

Abuse: The Need for Safety by Design.” https://www.just -

security.org/97065/ai-anti-child-sexual-exploitation/. 

Anderson, C. A., Shibuya, A., Ihori, N., Swing, E. L., 

Bushman, B. J., Sakamoto, A., Rothstein, H. R., and 

Saleem, M. 2010.  “Violent Video Game Effects on Ag -

gression, Empathy, and Prosocial Behavior in Eastern 

and Western Countries: A Meta-Analytic Review.”  Psy -

chological Bulletin  136(2): 151–173. 

Anderson, D. R., and Subrahmanyam, K. 2017.  “Digi -

tal Screen Media and Cognitive Development.”  Pediat -

rics  140(Supplement 2): 57–61. 

Anderson, J. 2013.  “Autonomy.”  International Encyclo -

pedia of Ethics .

Anglia Ruskin University. 2024.  “Growing Demand 

on Dark Web for AI Abuse Images.” https://www.aru. 

ac.uk/news/growing%20demand%20on%20dark%20 

web%20for%20ai%20abuse%20images. Accessed 17 

September 2024. 

Antsaklis, P. 2020.  “Autonomy and Metrics of Autono -

my.”  Annual Reviews in Control  49: 15–26. 

Aprin, F., Malzahn, N., Lomonaco, F., Donabauer, 

G., Ognibene, D., Kruschwitz, U., Hernández-Leo, 

D., Fulantelli, G., and Hoppe, H. U. 2023.  The “Cour -

age Companion” – an AI-Supported Environment for 

Training Teenagers in Handling Social Media Critically 

and Responsibly . Cham: Springer Nature Switzerland, 

395–406. 

Ardila, D., Kiraly, A. P., Bharadwaj, S., Choi, B., Reich -

er, J. J., Peng, L., Tse, D., and others. 2019.  “End-to-

End Lung Cancer Screening with Three-Dimensional 

Deep Learning on Low-Dose Chest Computed Tomog -

raphy.”  Nature Medicine  25(6): 954–961. 

Aridor, G., Jiménez-Durán, R., Levy, R. e., and Song, 

L. 2024.  “The Economics of Social Media.”  Journal of 

Economic Literature  62(4): 1422–1474. 

Armona, L. 2023.  “Online Social Network Effects in 

Labor Markets: Evidence from Facebook’s Entry to Col -

lege Campuses.”  Review of Economics and Statistics :

1–47. 

Asia-Plus. 2024.  “Tajikistan Sets Ambitious Goal That 

5% of Its GDP Will Come from AI-Related Economic Ac -

tivity by 2040.” https://asiaplustj.info/en/node/339221. 

Accessed 13 December 2024. 

Aslan, M., and Atesoglu, H. 2021.  “The Effect of In -

novation and Participation as Workplace Values on Job 

Satisfaction and the Mediating Effect of Psychological 

Ownership.”  Sage Open  11(4). 

Atari, M., Xue, M. J., Park, P. S., Blasi, D., and Hen -

rich, J. 2025.  “Which Humans?”  PsyArXiv Preprints .

Aubry, R., Quiamzade, A., and Meier, L. L. 2024.  “De -

pressive Symptoms and Upward Social Comparisons 

During Instagram Use: A Vicious Circle.”  Personality 

and Individual Differences  217: 112458. 

Bahnweg, E., and Omar, H. 2023.  “Effects of Tiktok on 

Adolescents Mental Health and Wellbeing.”  Dynamics 

of Human Health  10(1). 

Ball, K. 2021.  “Electronic Monitoring and Surveillance 

in the Workplace.” European Commission Joint Re -

search Centre. 

Baron, N. S. 2023.  “Even Kids Are Worried Chatgpt 

Will Make Them Lazy Plagiarists, Says a Linguist Who 

Studies Tech’s Effect on Reading, Writing and Think -

ing.” https://fortune.com/2023/01/19/what-is-chatgpt-

ai-effect-cheating-plagiarism-laziness-education-kids-

students/. Accessed 5 May 2024. 

Bawden, D., and Robinson, L. 2020.  “Information 

Overload: An Introduction.”  Oxford Research Encyclo -

pedia of Politics. 

Benselin, J. C., and Ragsdell, G. 2016.  “Information 

Overload: The Differences That Age Makes.”  Journal of 

Librarianship and Information Science  48(3): 284–297. 

Bharadwaj, S. 2024.  “Google-Apollo Tie up for Early 

Detection of Cancer in India.”  The Times of India . https:// 

timesofindia.indiatimes.com/city/hyderabad/google-

health-apollo-partner-for-early-detection-of-high-mor -

tality-diseases-in-india/articleshow/108629295.cms. 

Accessed 18 October 2024. 

Blanchflower, D. G. 2021.  “Is Happiness U-Shaped 

Everywhere? Age and Subjective Well-Being in 145 

Countries.”  Journal of Population Economics  34(2): 

575–624. 

Blanchflower, D. G. 2025a.  “Declining Youth Well-

Being in 167 Un Countries. Does Survey Mode, or 

Question Matter? “ Working Paper 33415, National Bu -

reau of Economic Research, Cambridge, MA. https:// 

www.nber.org/papers/w33415. Accessed 17 February 

2025. 24 0 HUMAN DEVELOPMENT REPORT 2025 

Blanchflower, D. G. 2025b.  “The Global Decline in the 

Mental Health of the Young.”  NBER Reporter , National 

Bureau of Economic Research, Cambridge, MA. 

Blanchflower, D. G., and Bryson, A. 2024a.  “The 

Consequences of Abuse, Neglect and Cyber-Bullying 

on the Wellbeing of the Young.” Working Paper 32119, 

National Bureau of Economic Research, Cambridge, 

MA. https://www.nber.org/papers/w32119. Accessed 3 

March 2025. 

Blanchflower, D. G., and Bryson, A. 2024b.  “The 

Mental Health of the Young in Africa.” Working Paper 

33280, National Bureau of Economic Research, Cam -

bridge, MA. https://www.nber.org/papers/w33280. Ac -

cessed 18 February 2025. 

Blanchflower, D. G., and Bryson, A. 2024c.  “The 

Mental Health of the Young in Latin America.” Working 

Paper 33111, National Bureau of Economic Research, 

Cambridge, MA. https://www.nber.org/papers/w33111. 

Accessed 17 February 2025. 

Blanchflower, D. G., and Bryson, A. 2025.  “The Men -

tal Health of the Young in Asia and the Middle East: 

The Importance of Self-Reports.” Working Paper 33475, 

National Bureau of Economic Research, Cambridge, 

MA. https://www.nber.org/papers/w33475. Accessed 

18 February 2025. 

Blanchflower, D. G., Bryson, A., and Bell, D. N. 2024. 

“The Declining Mental Health of the Young in the Uk.” 

Working Paper 32879, National Bureau of Economic 

Research, Cambridge, MA. https://www.nber.org/pa -

pers/w32879. Accessed 18 February 2025. 

Blanchflower, D. G., Bryson, A., Lepinteur, A., and 

Piper, A. 2024.  “Further Evidence on the Global De -

cline in the Mental Health of the Young.” Working Paper 

32500, National Bureau of Economic Research, Cam -

bridge, MA. https://www.nber.org/papers/w32500. Ac -

cessed 17 Feburary 2025. 

Blanchflower, D. G., Bryson, A., and Xu, X. 2024. 

“The Declining Mental Health of the Young and the 

Global Disappearance of the Hump Shape in Age in 

Unhappiness.” Working Paper 32337, National Bureau 

of Economic Research, Cambridge, MA. 

Boine, C. 2023.  “Emotional Attachment to AI Com -

panions and European Law.”  MIT Case Studies in So -

cial and Ethical Responsibilities of Computing  (Winter 

2023): 2–23 

Bone, J. K., Bu, F., Fluharty, M. E., Paul, E., Sonke, J. 

K., and Fancourt, D. 2022.  “Arts and Cultural Engage -

ment, Reportedly Antisocial or Criminalized Behaviors, 

and Potential Mediators in Two Longitudinal Cohorts of 

Adolescents.”  Journal of Youth and Adolescence  51(8): 

1463–1482. 

Botes, M. 2023.  “Autonomy and the Social Dilemma 

of Online Manipulative Behavior.”  AI and Ethics  3(1): 

315–323. 

Bozkurt, A., Xiao, F., Lambert, S., Pazurek, A., 

Crompton, H., Koseoglu, S., Farrow, R., and others. 

2023.  “Speculative Futures on Chatgpt and Genera -

tive Artificial Intelligence (AI): A Collective Reflection 

from the Educational Landscape.” 18: 53–130. 

Bradford, A. 2020.  The Brussels Effect: How the Euro -

pean Union Rules the World.  Oxford University Press. 

Braghieri, L., Levy, R., and Makarin, A. 2022.  “Social 

Media and Mental Health.”  American Economic Review 

112(11): 3660–3693. 

Brinkmann, L., Baumann, F., Bonnefon, J.-F., Derex, 

M., Müller, T. F., Nussberger, A.-M., Czaplicka, A., and 

others. 2023.  “Machine Culture.”  Nature Human Be -

haviour  7(11): 1855–1868. 

Bursztyn, L., Handel, B. R., Jimenez, R., and Roth, 

C. 2023.  “When Product Markets Become Collective 

Traps: The Case of Social Media.” Working Paper 31771, 

National Bureau of Economic Research, Cambridge, 

MA. https://www.nber.org/papers/w31771. Accessed 17 

March 2025. 

Campens, J., Vercruyssen, A., Schirmer, W., Verté, 

E., and De Witte, N. 2023.  “The Association between 

Internet Non-Use and Multidimensional Frailty in Older 

Adults: A Three-Wave Cross-Sectional Study from 

2004 to 2021.”  Behaviour & Information Technology 

43(10): 1957–1971. 

Carter, B., Payne, M., Rees, P., Sohn, S. Y., Brown, J., 

and Kalk, N. J. 2024.  “A Multi-School Study in England, 

to Assess Problematic Smartphone Usage and Anxiety 

and Depression.”  Acta Paediatrica  113(10): 2240–2248. 

CCDH (Center for Countering Digital Hate). 2023.  “AI 

and Eating Disorders: How Generative AI Enables and 

Promotes Harmful Eating Disorder Content.” London. 

https://counterhate.com/research/ai-tools-and-eating-

disorders/. Accessed 8 November 2024. 

Chen, J. J., and Lin, J. C. 2023.  “Artificial Intelligence 

as a Double-Edged Sword: Wielding the Power Prin -

ciples to Maximize Its Positive Effects and Minimize Its 

Negative Effects.”  Contemporary Issues in Early Child -

hood : 14639491231169813. 

Chiaburu, D. S., and Harrison, D. A. 2008.  “Do 

Peers Make the Place? Conceptual Synthesis and 

Meta-Analysis of Coworker Effects on Perceptions, At -

titudes, OCBs, and Performance.”  Journal of Applied 

Psychology  93(5): 1082. 

Child Rescue Coalition. 2024.  “The Dark Side of AI: 

Risks to Children.” https://childrescuecoalition.org/edu -

cations/the-dark-side-of-ai-risks-to-children/. Accessed 

1 October 2024. 

ChildFund International and African Child Policy 

Forum. 2024.  “Online Exploitation and Abuse of Chil -

dren in Africa on the Rise.” https://childfundalliance. 

org/2024/05/30/online-exploitation-and-abuse-of-

children-in-africa-on-the-rise/. Accessed 1 November 

2024. 

Childlight. 2024.  “Global Prevalence of Online Victi -

misation.” https://intothelight.childlight.org/indicator-1. 

html. Accessed 27 September 2024. 

Choudhury, A., Renjilian, E., and Asan, O. 2020. 

“Use of Machine Learning in Geriatric Clinical Care 

for Chronic Diseases: A Systematic Literature Review.” 

JAMIA open  3(3): 459–471. 

Chu, C. H., Donato-Woodger, S., Khan, S. S., Nyrup, 

R., Leslie, K., Lyn, A., Shi, T., and others. 2023.  “Age-

Related Bias and Artificial Intelligence: A Scoping Re -

view.”  Humanities and Social Sciences Communica -

tions  10(1): 1–17. 

Clegg, A., Bandeen-Roche, K., Farrin, A., Forster, A., 

Gill, T. M., Gladman, J., Kerse, N., and others. 2022. 

“New Horizons in Evidence-Based Care for Older Peo -

ple: Individual Participant Data Meta-Analysis.”  Age and 

Ageing  51(4): afac090. 

Corkin, M. T., Peterson, E. R., Henderson, A. M., 

Waldie, K. E., Reese, E., and Morton, S. M. 2021.  “Pre -

school Screen Media Exposure, Executive Functions 

and Symptoms of Inattention/Hyperactivity.”  Journal of 

Applied Developmental Psychology  73: 101237. 

Corredor-Waldron, A., and Currie, J. 2024.  “To What 

Extent Are Trends in Teen Mental Health Driven by 

Changes in Reporting?: The Example of Suicide-Relat -

ed Hospital Visits.”  Journal of Human Resources  59(S): 

S14–S40. 

Corrigan, N. M., Rokem, A., and Kuhl, P. K. 2024. 

“Covid-19 Lockdown Effects on Adolescent Brain Struc -

ture Suggest Accelerated Maturation That Is More Pro -

nounced in Females Than in Males.”  Proceedings of the 

National Academy of Sciences  121(38): e2403200121. 

Council of Europe. 2019.  “Declaration by the Commit -

tee of Ministers on the Manipulative Capabilities of Al -

gorithmic Processes.” https://search.coe.int/cm/pages/ 

result_details.aspx?ObjectId=090000168092dd4b. 

Accessed 23 May 2024. 

Counted, V., Cowden, R. G., and Lomas, T. 2024. 

“Multidimensional Flourishing in Africa: An Intraconti -

nental Analysis of 38 Well-Being Indicators in 40 Coun -

tries.”  Journal of Happiness Studies  25(51): 51. 

Cucio, M., and Henning, T. 2025.  “Artificial Intelli -

gence and the Philippine Labor Market: Mapping Oc -

cupational Exposure and Complementarity.” https:// 

www.imf.org/en/Publications/WP/Issues/2025/02/21/ 

Artificial-Intelligence-and-the-Philippine-Labor-Market-

Mapping-Occupational-Exposure-and-562171?cid=em-

COM-789-49741. Accessed 26 February 2025. 

Datareportal. 2024.  “The Time We Spend on 

Social Media.” https://datareportal.com/reports/ 

d i g i t a l - 2 0 2 4 - d e e p - d i v e - t h e - t i m e - w e - s p e n d -

on-social-media?utm_source=Global_Digital_ 

Reports&utm_medium=Analysis_Article&utm_ 

campaign=Digital_2024&utm_content=Digital_2024_ 

Analysis_And_Review. Accessed 6 January 2025. 

Donati, D., Durante, R., Sobbrio, F., and Zejcirovic, D. 

2022.  “Lost in the Net? Broadband Internet and Youth 

Mental Health.” IZA Discussion Paper 15202, Institute 

of Labor Economics. https://www.iza.org/publications/ 

dp/15202/lost-in-the-net-broadband-internet-and-

youth-mental-health. Accessed 4 April 2025. 

Drolia, M., Papadakis, S., Sifaki, E., and Kalogianna -

kis, M. 2022.  “Mobile Learning Applications for Refu -

gees: A Systematic Literature Review.”  Education Sci -

ences  12(2): 96. 

ECPAT (End Child Prostitution and Trafficking) and 

INTERPOL (International Criminal Police Organiza -

tion). 2018.  “Towards a Global Indicator: On Uniden -

tified Victms in Child Sexual Exploitation Material.” 

https://ecpat.org/resource/technical-report-towards-a-

global-indicator-on-unidentified-victims-in-child-sexual-

exploitation-material/. Accessed 1 November 2024. 

Eirich, R., McArthur, B. A., Anhorn, C., McGuinness, 

C., Christakis, D. A., and Madigan, S. 2022.  “Associa -

tion of Screen Time with Internalizing and Externalizing REFERENCES  241 

Behavior Problems in Children 12 Years or Younger: A 

Systematic Review and Meta-Analysis.”  JAMA Psychia -

try  79(5): 393–405. 

Eteläpelto, A., Vähäsantanen, K., Hökkä, P., and Pal -

oniemi, S. 2013.  “What Is Agency? Conceptualizing 

Professional Agency at Work.”  Educational Research 

Review  10: 45–65. 

Eurofound. 2025.  “Digitisation in the Workplace.” Pub -

lications Office of the European Union. https://www.eu -

rofound.europa.eu/en/publications/2021/digitisation-

workplace. Accessed 28 February 2025. 

European Commission. 2019.  “High-Level Expert 

Group on Artificial Intelligence: Ethics Guidelines 

for Trustworthy AI.” https://op.europa.eu/en/publica -

tion-detail/-/publication/d3988569-0434-11ea-8c1f-

01aa75ed71a1#:~:text=Ethics%20guidelines%20for%20 

trustworthy%20AI.%20The%20aim%20of,be%20 

ethical%2C%20ensuring%20adherence%20to%20 

ethical%20principles%20. Accessed 23 May 2024. 

European Parliament. 2023a.  “Artificial Intelligence 

Act: Deal on Comprehensive Rules for Trustworthy 

AI.” https://www.europarl.europa.eu/news/en/press-

room/20231206IPR15699/artificial-intelligence-act-

deal-on-comprehensive-rules-for-trustworthy-ai. Ac -

cessed 11 December 2023. 

European Parliament. 2023b.  “The Digital Services 

Act Package.” https://digital-strategy.ec.europa.eu/en/ 

policies/digital-services-act-package. Accessed 11 De -

cember 2023. 

European Parliament. 2023c.  “Generative AI and Wa -

termarking.” https://www.europarl.europa.eu/RegData/ 

etudes/BRIE/2023/757583/EPRS_BRI(2023)757583_ 

EN.pdf. Accessed 2 April 2025. 

Faelens, L., Hoorelbeke, K., Cambier, R., Van Put, J., 

Van de Putte, E., De Raedt, R., and Koster, E. H. 2021. 

“The Relationship between Instagram Use and Indica -

tors of Mental Health: A Systematic Review.”  Comput -

ers in Human Behavior Reports  4: 100121. 

Felix, E., Silva, V., Caetano, M., Ribeiro, M. V., Fidal -

go, T. M., Rosa Neto, F., Sanchez, Z. M., and others. 

2020.  “Excessive Screen Media Use in Preschoolers Is 

Associated with Poor Motor Skills.”  Cyberpsychology, 

Behavior, and Social Networking  23(6): 418–425. 

Festerling, J., and Siraj, I. 2020.  “Alexa, What Are 

You? Exploring Primary School Children’s Ontological 

Perceptions of Digital Voice Assistants in Open Interac -

tions.”  Human Development  64(1): 26–43. 

Fingerman, K. L., Birditt, K. S., and Umberson, D. 

J. 2020.  “Use of Technologies for Social Connected -

ness and Well-Being and as a Tool for Research Data 

Collection in Older Adults.”  Mobile Technology for 

Adaptive Aging: Proceedings of a Workshop . National 

Academies Press. https://www.ncbi.nlm.nih.gov/books/ 

NBK563112/. Accessed 26 June 2024. 

Fluharty, M. E., Bone, J. K., Bu, F., Sonke, J. K., Fan -

court, D., and Paul, E. 2023.  “Associations between 

Extracurricular Arts Activities, School-Based Arts En -

gagement, and Subsequent Externalising Behaviours 

in the Early Childhood Longitudinal Study.”  Scientific 

Reports  13(1): 13840. 

Følstad, A., and Skjuve, M. 2019.  “Chatbots for 

Customer Service: User Experience and Motivation.” 

Proceedings of the 1st international conference on 

conversational user interfaces. https://sintef.brage. 

unit.no/sintef-xmlui/bitstream/handle/11250/2633078/ 

CUI2019%2b-%2bchatbots%2bfor%2bcustomer%2bs 

ervice%2b-%2bauthors%2bversion.pdf?sequence=1. 

Accessed 2 February 2024. 

Forbes. 2022.  “Chatbots and Automations Increase 

Customer Service Frustrations for Consumers at the 

Holidays.” https://www.forbes.com/sites/chriswest -

fall/2022/12/07/chatbots-and-automations-increase-

customer-service-frustrations-for-consumers-at-the-

holidays/?sh=5499e00532f6. Accessed 17 January 

2024. 

Forbes. 2024.  “AI Is Changing the Future of Human 

Intimacy. Here’s What to Know.” https://www.forbes. 

com/sites/virginieberger/2024/10/22/ai-is-changing-

the-future-of-human-intimacy-heres-what-to-know/. Ac -

cessed 30 October 2024. 

Fry, D. 2024.  “We Found over 300 Million Young 

People Had Experienced Online Sexual Abuse and 

Exploitation over the Course of Our Meta-Study.” 

https://theconversation.com/we-found-over-300-mil -

lion-young-people-had-experienced-online-sexual-

abuse-and-exploitation-over-the-course-of-our-meta-

study-229039. Accessed 20 September 2024. 

Fumagalli, E., Shrum, L., and Lowrey, T. M. 2024. 

“The Effects of Social Media Consumption on Adoles -

cent Psychological Well-Being.”  Journal of the Associa -

tion for Consumer Research  9(2): 119–130. 

Gagné, M., and Bhave, D. 2010.  “Autonomy in the 

Workplace: An Essential Ingredient to Employee En -

gagement and Well-Being in Every Culture.”  Human 

Autonomy in Cross-Cultural Context: Perspectives on 

the Psychology of Agency, Freedom, and Well-Being. 

Springer. 

Gallup. 2024.  “State of the Global Workplace.” https:// 

www.gallup.com/workplace/349484/state-of-the-glob -

al-workplace.aspx. Accessed 28 February 2025. 

Gaskins, N. 2023.  “Interrogating Algorithmic Bias: 

From Speculative Fiction to Liberatory Design.”  Tech -

Trends  67(3): 417–425. 

Gou, H., and Perceval, G. 2023.  “Does Digital Media 

Use Increase Risk of Social-Emotional Delay for Chi -

nese Preschoolers?”  Journal of Children and Media 

17(1): 1–16. 

Grinschgl, S., and Neubauer, A. C. 2022.  “Supporting 

Cognition with Modern Technology: Distributed Cogni -

tion Today and in an AI-Enhanced Future.”  Frontiers in 

Artificial Intelligence  5: 908261. 

Grzegorczyk, M. 2023.  “How AI Is Leading the Fight 

against Online Child Abuse.” https://emerging-europe. 

com/analysis/how-ai-is-leading-the-fight-against-on -

line-child-abuse/. Accessed 27 September 2024. 

Gurven, M., Buoro, Y., Rodriguez, D. E., Sayre, K., 

Trumble, B., Pyhälä, A., Kaplan, H., and others. 2024. 

“Subjective Well-Being across the Life Course among 

Non-Industrialized Populations.”  Science Advances 

10(43): eado0952. 

Haber, A., and Corriveau, K. H. 2023.  “Social Robots 

as Social Learning Partners: Exploring Children’s Early 

Understanding and Learning from Social Robots.”  Be -

havioral and Brain Sciences  46: e36. 

Haidt, J. 2024.  The Anxious Generation: How the 

Great Rewiring of Childhood Is Causing an Epidemic of 

Mental Illness.  Random House. 

Hassija, V., Chamola, V., Mahapatra, A., Singal, A., 

Goel, D., Huang, K., Scardapane, S., and others. 

2024.  “Interpreting Black-Box Models: A Review on Ex -

plainable Artificial Intelligence.”  Cognitive Computation 

16(1): 45–74. 

Havers, B., Tripathi, K., Burton, A., McManus, S., and 

Cooper, C. 2024.  “Cybercrime Victimisation among 

Older Adults: A Probability Sample Survey in England 

and Wales.”  PloS one  19(12): e0314380. 

Hefner, D., Knop, K., Schmitt, S., and Vorderer, P. 

2019.  “Rules? Role Model? Relationship? The Impact of 

Parents on Their Children’s Problematic Mobile Phone 

Involvement.”  Media Psychology  22(1): 82–108. 

Hernström, V., Josefsson, V., Sartor, H., Schmidt, D., 

Larsson, A.-M., Hofvind, S., Andersson, I., and oth -

ers. 2025.  “Screening Performance and Characteris -

tics of Breast Cancer Detected in the Mammography 

Screening with Artificial Intelligence Trial (Masai): A Ran -

domised, Controlled, Parallel-Group, Non-Inferiority, 

Single-Blinded, Screening Accuracy Study.”  The Lancet 

Digital Health  7(3): 175–183. 

Hinduja, S. 2023.  “Generative AI as a Vector for Ha -

rassment and Harm.” Cyberbullying Research Center. 

https://cyberbullying.org/generative-ai-as-a-vector-for-

harassment-and-harm. Accessed 21 January 2025. 

Hinkley, T., Brown, H., Carson, V., and Teychenne, M. 

2018.  “Cross Sectional Associations of Screen Time 

and Outdoor Play with Social Skills in Preschool Chil -

dren.”  PloS one  13(4): e0193700. 

Holton, K. F., and Nigg, J. T. 2020.  “The Association 

of Lifestyle Factors and Adhd in Children.”  Journal of 

Attention Disorders  24(11): 1511–1520. 

Honneth, A. 2024.  The Working Sovereign: Labour 

and Democratic Citizenship.  John Wiley & Sons. 

Hopster, J. 2024.  “Socially Disruptive Technologies 

and Epistemic Injustice.”  Ethics and Information Tech -

nology  26(1): 14. 

Horvath, J. 2024.  “3 Critical Problems Gen AI Poses 

for Learning. Harvard Business Publishing Education.” 

https://hbsp.harvard.edu/inspiring-minds/the-limits-of-

gen-ai-educators-in-higher-ed. Accessed 20 January 

2025. 

Hu, B. Y., Johnson, G. K., Teo, T., and Wu, Z. 2020. 

“Relationship between Screen Time and Chinese Chil -

dren’s Cognitive and Social Development.”  Journal of 

Research in Childhood Education  34(2): 183–207. 

Huang, S., Lai, X., Li, Y., Cui, Y., and Wang, Y. 2023. 

“Beyond Screen Time: The Different Longitudinal Rela -

tions between Adolescents’ Smartphone Use Content 

and Their Mental Health.”  Children  10(5): 770. 

Hurwitz, L. B., and Schmitt, K. L. 2020.  “Can Children 

Benefit from Early Internet Exposure? Short-and Long-

Term Links between Internet Use, Digital Skill, and 

Academic Performance.”  Computers & Education  146: 

103750. 

Hutton, J. S., Dudley, J., Horowitz-Kraus, T., DeWitt, 

T., and Holland, S. K. 2020.  “Associations between 242 HUMAN DEVELOPMENT REPORT 2025 

Screen-Based Media Use and Brain White Matter In -

tegrity in Preschool-Aged Children.”  JAMA Pediatrics 

174(1): e193869-e193869. 

INHOPE. 2023.  “Annual Report 2023.” https:// 

i n h o p e . o r g / m e d i a / p a g e s / a r t i c l e s / a n n u a l -

reports/6a4f5f6bd2-1719393584/inhope-annual-re -

port-2023.pdf. Accessed 1 November 2024. 

Internet Watch Foundation. 2024.  “What Has 

Changed in the AI CSAM Landscape?” https://www. 

iwf.org.uk/media/nadlcb1z/iwf-ai-csam-report_update-

public-jul24v13.pdf. Accessed 17 September 2024. 

Invoca. 2023.  “The State of the Contact Center Report 

2023.” https://experience.invoca.com/the-state-of-the-

contact-center-report/p/1. Accessed 30 January 2024. 

Ipsos. 2023.  “Global Views on AI.” https://www.ipsos. 

com/sites/default/files/ct/news/documents/2023-07/ 

Ipsos%20Global%20AI%202023%20Report-WEB_0. 

pdf. Accessed 22 August 2024. 

Irmer, A., and Schmiedek, F. 2023.  “Associations be -

tween Youth’s Daily Social Media Use and Well-Being 

Are Mediated by Upward Comparisons.”  Communica -

tions Psychology  1(12). 

ITU (International Telecommunication Union). 

2024a.  “ Global and Regional ICT Data.” https://data -

hub.itu.int/. Accessed 25 March 2025. 

ITU (International Telecommunication Union). 

2024b.  “Individuals Using the Internet.” https://data -

hub.itu.int/data/?i=11624&v=chart&d=Age&g=9224. Ac -

cessed 23 March 2025. 

IWF (Internet Watch Foundation). 2023.  “How AI Is 

Being Abused to Create Child Sexual Abuse Imagery.” 

https://www.iwf.org.uk/media/q4zll2ya/iwf-ai-csam-

report_public-oct23v1.pdf. Accessed 17 September 

2024. 

IWF (Internet Watch Foundation). 2024.  “What Has 

Changed in the AI CSAM Landscape? AI CSAM Report 

Update.” https://www.iwf.org.uk/media/nadlcb1z/iwf-ai-

csam-report_update-public-jul24v13.pdf. Accessed 3 

October 2024. 

Jennings, J. 2023.  “AI in Education: The Bias Di -

lemma.” https://www.esparklearning.com/blog/get-to-

know-ai-the-bias-dilemma#:~:text=The%20same%20 

cultural%20issues%20that,and%20potentially%20 

amplifies)%20the%20bias. Accessed 13 October 2023. 

Johnson, S., and Acemoğlu, D. 2023.  Power and 

Progress: Our Thousand-Year Struggle over Technol -

ogy and Prosperity.  Hachette UK. 

Kang, H., and Lou, C. 2022.  “AI Agency Vs. Human 

Agency: Understanding Human–AI Interactions on 

Tiktok and Their Implications for User Engagement.” 

Journal of Computer-Mediated Communication  27(5). 

Kelly, Y., Zilanawala, A., Booker, C., and Sacker, 

A. 2018.  “Social Media Use and Adolescent Mental 

Health: Findings from the Uk Millennium Cohort Study.” 

eClinicalMedicine  6: 59–68. 

Kemp, S., and Erades Pérez, N. 2023.  “Consumer 

Fraud against Older Adults in Digital Society: Examin -

ing Victimization and Its Impact.”  International Journal 

of Environmental Research and Public Health  20(7): 

5404. 

Kermani, H., and Aldemir, J. 2015.  “Preparing Chil -

dren for Success: Integrating Science, Math, and Tech -

nology in Early Childhood Classroom.”  Early Child De -

velopment and Care  185(9): 1504–1527. 

Khalaf, A. M., Alubied, A. A., Khalaf, A. M., and Ri -

faey, A. A. 2023.  “The Impact of Social Media on the 

Mental Health of Adolescents and Young Adults: A Sys -

tematic Review.”  Cureus  15(8). 

Korte, M. 2020.  “The Impact of the Digital Revolution 

on Human Brain and Behavior: Where Do We Stand?” 

Dialogues in Clinical Neuroscience  22(2): 101–111. 

Krishna, S., Dubrosa, F., and Milanaik, R. 2024.  “Ris -

ing Threats of AI-Driven Child Sexual Abuse Material.” 

Pediatrics  153(2). 

Labadze, L., Grigolia, M., and Machaidze, L. 2023. 

“Role of AI Chatbots in Education: Systematic Literature 

Review.”  International Journal of Educational Technol -

ogy in Higher Education  20(56). 

Laffier, J., and Rehman, A. 2023.  “Deepfakes and 

Harm to Women.”  Journal of Digital Life and Learning 

3(1): 1–21. 

Lafortune, D., Dubé, S., and Lapointe, V. A. 2024. 

“People Are Falling in Love with AI. Should We Worry?” 

Live Science . https://www.livescience.com/health/rela -

tionships/people-are-falling-in-love-with-ai-should-we-

worry. Accessed 1 April 2025. 

Landes, S. D., and Settersten Jr, R. A. 2019.  “The In -

separability of Human Agency and Linked Lives.”  Ad -

vances in Life Course Research  42. 

Lane, J. N., Leonardi, P. M., Contractor, N. S., and 

DeChurch, L. A. 2024.  “Teams in the Digital Work -

place: Technology’s Role for Communication, Collabo -

ration, and Performance.”  Small Group Research  55(1): 

139–183. 

Lazar, S. 2024.  “Lecture I: Governing the Algorithmic 

City.” https://arxiv.org/pdf/2410.20720. Accessed 26 

February 2025. 

Lee, G., and Uddin, S. 2023.  “The AI Academy: 

Leveraging Education in AI to Unlock Tajikistan’s 

Economic Potential.” https://www.gsb.stanford.edu/ 

faculty-research/case-studies/ai-academy-leveraging-

education-ai-unlock-tajikistans-economic. Accessed 12 

December 2024. 

Leins, K., and Kaspersen, A. 2021.  “Seven Myths of 

Using the Term ‘Human on the Loop:’ ‘Just What Do You 

Think You Are Doing, Dave?’” Carnegie Council for Eth -

ics in International Affairs. https://www.carnegiecouncil. 

org/media/article/7-myths-of-using-the-term-human-

on-the-loop. Accessed 4 April 2025. 

Lembke, A. 2021.  Dopamine Nation: Finding Balance 

in the Age of Indulgence.  Penguin. 

Lewandowsky, S., Robertson, R. E., and DiResta, R. 

2024.  “Challenges in Understanding Human-Algorithm 

Entanglement During Online Information Consump -

tion.”  Perspectives on Psychological Science  19(5): 

758–766. 

Li, H., and Zhang, R. 2024.  “Finding Love in Algo -

rithms: Deciphering the Emotional Contexts of Close 

Encounters with AI Chatbots.”  Journal of Computer-

Mediated Communication  29(5). 

Lim, W. S., Chiu, S.-I., Wu, M.-C., Tsai, S.-F., Wang, 

P.-H., Lin, K.-P., Chen, Y.-M., and others. 2022.  “An In -

tegrated Biometric Voice and Facial Features for Early 

Detection of Parkinson’s Disease.”  npj Parkinson’s Dis -

ease  8(1): 145. 

Liu, W., Wu, X., Huang, K., Yan, S., Ma, L., Cao, H., 

Gan, H., and Tao, F. 2021.  “Early Childhood Screen 

Time as a Predictor of Emotional and Behavioral Prob -

lems in Children at 4 Years: A Birth Cohort Study in 

China.”  Environmental Health and Preventive Medicine 

26(3): 1–9. 

Loveys, K., Prina, M., Axford, C., Domènec, Ò. R., 

Weng, W., Broadbent, E., Pujari, S., and others. 

2022.  “Artificial Intelligence for Older People Receiv -

ing Long-Term Care: A Systematic Review of Accept -

ability and Effectiveness Studies.”  The Lancet Healthy 

Longevity  3(4): e286-e297. 

Lu-Hai Liang. 2019.  “‘They’re More Attractive Than 

Real Boyfriends:’ Inside the Weird World of Chinese 

Romance Video Games.” https://www.wired.com/story/ 

china-love-games/. Accessed 28 March 2024. 

Lucas, J. W., and Villarroel, M. A. 2022.  “Telemedi -

cine Use among Adults: United States.” NCHS Data 

Brief 445. Hyattsville, MD: National Center for Health 

Statistics. https://www.cdc.gov/nchs/products/data -

briefs/db445.htm. Accessed 17 January 2025. 

Lukianoff, G., and Haidt, J. 2019.  The Coddling of the 

American Mind: How Good Intentions and Bad Ideas 

Are Setting up a Generation for Failure.  Penguin. 

Lyell, D., and Coiera, E. 2017.  “Automation Bias and 

Verification Complexity: A Systematic Review.”  Journal 

of the American Medical Informatics Association  24(2): 

423–431. 

M-Shule. 2023a.  “Educate, Engage, Assess and Sur -

vey Hard-to-Reach Populations in Africa.” https://www. 

mshule.com/. Accessed 29 March 2025. 

M-Shule. 2023b.  “M-Shule: Case Studies, Our Impact.” 

https://www.mshule.com/case-studies/our-impact. Ac -

cessed 6 November 2023. 

Mackenzie, C. 2014.  “Three Dimensions of Autonomy: 

A Relational Analysis.”  Autonomy, Oppression and 

Gender.  Oxford University Press. 

Mackenzie, C., and Stoljar, N. 2000.  Relational Au -

tonomy: Feminist Perspectives on Automony, Agency, 

and the Social Self.  Oxford University Press. 

Madary, M. 2022.  “The Illusion of Agency in Human– 

Computer Interaction.”  Neuroethics  15(16). 

Maples, B., Cerit, M., Vishwanath, A., and Pea, R. 

2024.  “Loneliness and Suicide Mitigation for Students 

Using GPT3-Enabled Chatbots.”  NPJ Mental Health Re -

search  3(4): 1–6. 

Mariano, J., Marques, S., Ramos, M. R., and de Vries, 

H. 2021.  “Internet Use by Middle-Aged and Older 

Adults: Longitudinal Relationships with Functional Abil -

ity, Social Support, and Self-Perceptions of Aging.”  Psy -

chology and Aging  36(8): 983–995. 

Mariano, J., Marques, S., Ramos, M. R., Gerardo, F., 

Cunha, C. L. d., Girenko, A., Alexandersson, J., and 

others. 2022.  “Too Old for Technology? Stereotype REFERENCES  24 3 

Threat and Technology Use by Older Adults.”  Behav -

iour & Information Technology  41(7): 1503–1514. 

Marriott, H. R., and Pitardi, V. 2024.  “One Is the Lone -

liest Number… Two Can Be as Bad as One: The Influ -

ence of AI Friendship Apps on Users’ Well-Being and 

Addiction.”  Psychology & Marketing  41(1): 86–101. 

Marsh, E., Vallejos, E. P., and Spence, A. 2022.  “The 

Digital Workplace and Its Dark Side: An Integrative Re -

view.”  Computers in Human Behavior  128. 

Matthes, J., Karsay, K., Schmuck, D., and Stevic, A. 

2020.  “‘Too Much to Handle:’ Impact of Mobile Social 

Networking Sites on Information Overload, Depressive 

Symptoms, and Well-Being.”  Computers in Human Be -

havior  105: 106217. 

McArthur, B. A., Tough, S., and Madigan, S. 2022. 

“Screen Time and Developmental and Behavioral 

Outcomes for Preschool Children.”  Pediatric Research 

91(6): 1616–1621. 

McComb, C. A., Vanman, E. J., and Tobin, S. J. 2023. 

“A Meta-Analysis of the Effects of Social Media Expo -

sure to Upward Comparison Targets on Self-Evalua -

tions and Emotions.”  Media Psychology  26(5): 612–635. 

McHarg, G., Ribner, A. D., Devine, R. T., and Hughes, 

C. 2020.  “Screen Time and Executive Function in Tod -

dlerhood: A Longitudinal Study.”  Frontiers in Psychol -

ogy  11: 570392. 

Milano, S., and Prunkl, C. 2025.  “Algorithmic Profiling 

as a Source of Hermeneutical Injustice.”  Philosophical 

Studies  182(1): 185–203. 

Mitzner, T. L., Fausset, C. B., Boron, J. B., Adams, A. 

E., Dijkstra, K., Lee, C. C., Rogers, W. A., and Fisk, 

A. D. 2008.  “Older Adults’ Training Preferences for 

Learning to Use Technology.”  Proceedings of the Hu -

man Factors and Ergonomics Society Annual Meeting 

52(26): 2047–2051. 

Mlonyeni, P. M. T. 2024.  “Personal AI, Deception, and 

the Problem of Emotional Bubbles.”  AI & Society : 1–12. 

Mozilla. 2019.  “We Asked People around the World 

How They Feel About Artificial Intelligence. Here’s 

What We Learned.” https://foundation.mozilla.org/ 

en/blog/we-asked-people-around-the-world-how-

they-feel-about-artificial-intelligence-heres-what-we-

learned/. Accessed 21 August 2024. 

Napal, D. 2024.  “Imitation Is the Sincerest Form of 

Fraudulent Activity: Artificial Intelligence in Financial 

Scams against Older Adults.”  Bifocal  45(6): 185–187. 

Neves, B. B., and Mead, G. 2021.  “Digital Technology 

and Older People: Towards a Sociological Approach 

to Technology Adoption in Later Life.”  Sociology  55(5): 

888–905. 

New York Times. 2024.  “Can A.I. Be Blamed for a 

Teen’s Suicide?” https://www.nytimes.com/2024/10/23/ 

technology/characterai-lawsuit-teen-suicide.html. Ac -

cessed 29 March 2025. 

Norori, N., Hu, Q., Aellen, F. M., Faraci, F. D., and Tz -

ovara, A. 2021.  “Addressing Bias in Big Data and AI for 

Health Care: A Call for Open Science.”  Patterns  2(10). 

Nugraha, H., Hernawan, H., Ali, M., Rahmat, A., Sep -

tianto, I., Aryati, A., and Suryadi, D. 2024.  “Outdoor 

Activities and Outdoor Environments for Fitness and 

Mental Health: A Systematic Review.”  Retos: nuevas 

tendencias en educación física, deporte y recreación 

(59): 642–648. 

Núñez-Jaramillo, L., Herrera-Solís, A., and Herrera-

Morales, W. V. 2021.  “ADHD: Reviewing the Causes 

and Evaluating Solutions.”  Journal of Personalized 

Medicine  11(3): 166. 

Nurdiantami, Y., and Agil, H. M. 2020.  “The Use of 

Technology in Early Childhood Education: A System -

atic Review. International Conference of Health De -

velopment. Covid-19 and the Role of Healthcare Work -

ers in the Industrial Era (ICHD 2020). Atlantis Press.” 

https://www.atlantis-press.com/proceedings/ichd-

20/125946610. Accessed 28 March 2025. 

Nussbaum, M. C. 2003.  “Capabilities as Fundamental 

Entitlements: Sen and Social Justice.”  Feminist Eco -

nomics  3(1): 1–51. 

Odgers, C. L. 2024.  “The Great Rewiring: Is Social 

Media Really Behind an Epidemic of Teenage Mental 

Illness?”  Nature  628(8006): 29–30. 

Orben, A., Dienlin, T., and Przybylski, A. K. 2019. 

“Social Media’s Enduring Effect on Adolescent Life 

Satisfaction.”  Proceedings of the National Academy of 

Sciences  116(21): 10226–10228. 

Orben, A., Meier, A., Dalgleish, T., and Blakemore, 

S.-J. 2024.  “Mechanisms Linking Social Media Use to 

Adolescent Mental Health Vulnerability.”  Nature Re -

views Psychology : 1–17. 

Orben, A., and Przybylski, A. K. 2019.  “The Associa -

tion between Adolescent Well-Being and Digital Tech -

nology Use.”  Nature Human Behaviour  3(2): 173–182. 

Otake, T. 2016.  “IBM Big Data Used for Rapid Diag -

nosis of Rare Leukemia Case in Japan.”  The Japan 

Times . https://www.japantimes.co.jp/news/2016/08/11/ 

national/science-health/ibm-big-data-used-for-rapid-

diagnosis-of-rare-leukemia-case-in-japan/. Accessed 

18 October 2024. 

Papadakis, S., Kalogiannakis, M., and Zaranis, N. 

2018.  “The Effectiveness of Computer and Tablet As -

sisted Intervention in Early Childhood Students’ Under -

standing of Numbers. An Empirical Study Conducted in 

Greece.”  Education and Information Technologies  23: 

1849–1871. 

Pärli, K. 2022.  “Impacts of Digitalisation on Employ -

ment Relationships and the Need for More Democracy 

at Work.”  Industrial Law Journal  51(1): 84–108. 

Pedro, F., Subosa, M., Rivas, A., and Valverde, P. 

2019.  “Artificial Intelligence in Education: Challenges 

and Opportunities for Sustainable Development.” Paris: 

UNESCO. 

Peebles, E. 2014.  “Cyberbullying: Hiding Behind the 

Screen.”  Paediatrics & Child Health  19(10): 527–528. 

Pentina, I., Xie, T., Hancock, T., and Bailey, A. 2023. 

“Consumer–Machine Relationships in the Age of Ar -

tificial Intelligence: Systematic Literature Review and 

Research Directions.”  Psychology & Marketing  40(8): 

1593–1614. 

Pereira, V., Hadjielias, E., Christofi, M., and Vrontis, 

D. 2023.  “A Systematic Literature Review on the Impact 

of Artificial Intelligence on Workplace Outcomes: A 

Multi-Process Perspective.”  Human Resource Manage -

ment Review  33(1): 1–22. 

Perry, A., and Turner-Lee, N. 2019.  “AI Can Disrupt Ra -

cial Inequity in Schools, or Make It Much Worse.” https:// 

hechingerreport.org/ai-can-disrupt-racial-inequity-in-

schools-or-make-it-much-worse/. 

Perry, A. M., and Lee, N. T. 2019.  “AI Is Coming to 

Schools, and If We’re Not Careful, So Will Its Biases.” 

Brookings Commentary. https://www.brookings.edu/ar -

ticles/ai-is-coming-to-schools-and-if-were-not-careful-

so-will-its-biases/. Accessed 28 March 2025. 

Peter G. Peterson Foundation. 2024.  “7 Key Facts 

About U.S. Healthcare Spending.” https://www.pgpf. 

org/blog/2024/03/7-key-facts-about-us-healthcare-

spending#:~:text=The%20aging%20population%20 

influences%20healthcare,compared%20to%20 

other%20age%20groups. Accessed 9 October 2024. 

Pothong, K. 2025.  “Child Rights by Design for Human 

Development: Reimagining a Rights-Respecting Digital 

World for Children.” Unpublished background paper. 

Prunkl, C. 2022.  “Human Autonomy in the Age of Ar -

tificial Intelligence.”  Nature Machine Intelligence  4(2): 

99–101. 

Qiao, R., Liu, C., and Xu, J. 2024.  “Making Algorithmic 

App Use a Virtuous Cycle: Influence of User Gratifica -

tion and Fatigue on Algorithmic App Dependence.” 

Humanities and Social Sciences Communications  11(1): 

1–10. 

Rainie, L., Funk, C., Anderson, M., and Tyson, A. 

2022.  “AI and Human Enhancement: Americans’ 

Openness Is Tempered by a Range of Concerns.” 

Pew Research Center. https://www.pewresearch.org/ 

internet/2022/03/17/how-americans-think-about-artifi -

cial-intelligence/. Accessed 17 January 2024. 

Raji, I. D., Gebru, T., Mitchell, M., Buolamwini, J., 

Lee, J., and Denton, E. 2020.  “Saving Face: Inves -

tigating the Ethical Concerns of Facial Recognition 

Auditing.” Proceedings of the AAAI/ACM Confer -

ence on AI, Ethics, and Society. https://dl.acm.org/ 

doi/10.1145/3375627.3375820. Accessed 5 June 2024. 

Reset. 2023.  “Risk to Minors: News from Our Ongoing 

Research on Platforms’ Risks to Minors.” https://www. 

reset.tech/resources/risks-to-minors-reset-tech-evalu -

ation-reports/. Accessed 22 January 2025. 

Resnick, M. 2023.  “Generative AI and Creative Learn -

ing: Concerns, Opportunities, and Choices.” https:// 

mres.medium.com/ai-and-creative-learning-concerns-

opportunities-and-choices-63b27f16d4d0. Accessed 2 

February 2025. 

Richtel, M., Pearson, C., and Levenson, M. 2023. 

“Surgeon General Warns That Social Media May Harm 

Children and Adolescents.” The New York Times. 

https://www.nytimes.com/2023/05/23/health/surgeon-

general-social-media-mental-health.html. Accessed 4 

April 2025. 

Ritchie, H. 2024.  “Australia Approves Social Media 

Ban on under-16s.”  BBC . https://www.bbc.com/news/ 

articles/c89vjj0lxx9o. Accessed 4 April 2025. 

Roberts, A., Hinds, J., and Camic, P. M. 2020.  “Nature 

Activities and Wellbeing in Children and Young People: 24 4 HUMAN DEVELOPMENT REPORT 2025 

A Systematic Literature Review.”  Journal of Adventure 

Education and Outdoor Learning  20(4): 298–318. 

Robeyns, I. 2005.  “The Capability Approach: A Theo -

retical Survey.”  Journal of Human Development  6(1): 

93–117. 

Robeyns, I. 2016.  “Capabilitarianism.”  Journal of Hu -

man Development and Capabilities  17(3): 397–414. 

Saadeh, A. 2023.  “Unpopular Opinion: AI in Education 

Redefining Creativity.”  Inside Telecom.  https://inside -

telecom.com/unpopular-opinion-ai-in-education-rede -

fining-creativity/. Accessed 28 April 2025. 

Saha, S. 2024.  “Google Partners with Apollo Radiology 

for Early Disease Detection in India.”  Analytics India 

Magazine . https://analyticsindiamag.com/ai-news-up -

dates/google-partners-with-apollo-radiology-to-detect-

diseases-early-in-india/. Accessed 18 October 2024. 

Sapci, A. H., and Sapci, H. A. 2019.  “Innovative As -

sisted Living Tools, Remote Monitoring Technologies, 

Artificial Intelligence-Driven Solutions, and Robotic 

Systems for Aging Societies: Systematic Review.”  JMIR 

Aging  2(2): e15429. 

Sarwar, N. 2022.  “Experts Warn AI Assistants Are 

Hurting the Social Development of Children.” https:// 

www.digitaltrends.com/mobile/digital-assistants-

alexa-siri-research-affecting-social-growth-skills-

children/#:~:text=This%20risks%20exposing%20 

kids%20to,part%20with%20a%20metallic%20coin. Ac -

cessed 9 May 2024. 

Satici, S. A., Gocet Tekin, E., Deniz, M. E., and Satici, 

B. 2023.  “Doomscrolling Scale: Its Association with 

Personality Traits, Psychological Distress, Social Media 

Use, and Wellbeing.”  Applied Research in Quality of 

Life  18(2): 833–847. 

Saxena, D., and Guha, S. 2024.  “Algorithmic Harms in 

Child Welfare: Uncertainties in Practice, Organization, 

and Street-Level Decision-Making.”  ACM Journal on 

Responsible Computing  1(1): 1–32. 

Schuengel, C., and van Heerden, A. 2023.  “Edito -

rial: Generative Artificial Intelligence and the Ecology 

of Human Development.”  Journal of child psychology 

and psychiatry  64(9): 1261–1263. 

Scott, R. A., Stuart, J., and Barber, B. L. 2021.  “Con -

temporary Friendships and Social Vulnerability among 

Youth: Understanding the Role of Online and Offline 

Contexts of Interaction in Friendship Quality.”  Journal 

of Social and Personal Relationships  38(12): 3451–3471. 

Scott, R. A., Stuart, J., and Barber, B. L. 2022.  “Con -

necting with Close Friends Online: A Qualitative Analy -

sis of Young Adults’ Perceptions of Online and Offline 

Social Interactions with Friends.”  Computers in Human 

Behavior Reports  7: 100217. 

Selbst, A. D., and Barocas, S. 2018.  “The Intuitive 

Appeal of Explainable Machines.”  Fordham L. Rev.  87: 

1085. 

Sen, A. 1992.  Inequality Reexamined.  Cambridge, MA: 

Harvard University Press. 

Sen, A. 1999.  Development as Freedom.  New York: 

Knopf. 

Sen, A. 2001.  “Other People.”  Proceedings of the Brit -

ish Academy, Oxford University Press  111: 319–338. 

Sen, A. 2008.  “The Idea of Justice.”  Journal of Human 

Development  9(3): 331–342. 

Sen, K., Prybutok, G., and Prybutok, V. 2022.  “The 

Use of Digital Technology for Social Wellbeing Re -

duces Social Isolation in Older Adults: A Systematic 

Review.”  SSM: Population Health  17: 101020. 

Shah, B., and Bilal, S. M. 2022.  “A Comprehen -

sive Review of the Negative Impact of Integration of 

AI in Social-Media in Mental Health of Users.” Pre -

sented at the 5th International Conference on Ad -

vances in Science and Technology (ICAST). 10.1109/ 

ICAST55766.2022.10039585. https://ieeexplore.ieee. 

org/document/10039585/. Accessed 30 March 2025. 

Shiwani, T., Relton, S., Evans, R., Kale, A., Heaven, A., 

Clegg, A., and Todd, O. 2023.  “New Horizons in Arti -

ficial Intelligence in the Healthcare of Older People.” 

Age and Ageing  52(12): afad219. 

Singh, S., and Nambiar, V. 2024.  “Role of Artificial 

Intelligence in the Prevention of Online Child Sexual 

Abuse: A Systematic Review of Literature.”  Journal of 

Applied Security Research : 1–42. 

Sixsmith, A., Horst, B. R., Simeonov, D., and Mihaili -

dis, A. 2022.  “Older People’s Use of Digital Technolo -

gy During the Covid-19 Pandemic.”  Bulletin of Science, 

Technology & Society  42(1–2): 19–24. 

Skjuve, M., Følstad, A., Fostervold, K. I., and Brandt -

zaeg, P. B. 2021.  “My Chatbot Companion-a Study of 

Human-Chatbot Relationships.”  International Journal of 

Human-Computer Studies  149: 3–14. 

Skulmowski, A. 2023.  “The Cognitive Architecture of 

Digital Externalization.”  Educational Psychology Re -

view  35(101): 1–21. 

Span, P. 2025.  “Telemedicine for Seniors Gets a Last-

Minute Reprieve.”  The New York Times . https://www. 

nytimes.com/2025/01/05/health/telemedicine-seniors-

medicare.html. Accessed 17 January 2025. 

Stanford Graduate School of Business. 2023.  “The 

AI Academy: Leveraging Education in AI to Unlock Ta -

jikistan Economic Potential.” https://www.gsb.stanford. 

edu/faculty-research/case-studies/ai-academy-lever -

aging-education-ai-unlock-tajikistans-economic. Ac -

cessed 13 December 2024. 

Stuart, J., and Scott, R. 2021.  “The Measure of Online 

Disinhibition (MOD): Assessing Perceptions of Reduc -

tions in Restraint in the Online Environment.”  Comput -

ers in Human Behavior  114: 106534. 

Stypinska, J. 2023.  “AI Ageism: A Critical Roadmap 

for Studying Age Discrimination and Exclusion in Digi -

talized Societies.”  AI & Society  38(2): 665–677. 

Suresh Babu, S., and Dhakshina Moorthy, A. 2024. 

“Application of Artificial Intelligence in Adaptation of 

Gamification in Education: A Literature Review.”  Com -

puter Applications in Engineering Education  32(1): 

e22683. 

Tagesschau. 2023.  “Nachlässige Moderation, Gering -

er Schutz.” https://www.tagesschau.de/investigativ/ndr/ 

schutz-kinder-jugendliche-internet-tik-tok-instagram-

x-100.html. Accessed 11 December 2023. 

Tan, T. X., and Zhou, Y. 2022.  “Screen Time and Adhd 

Behaviors in Chinese Children: Findings from Longitu -

dinal and Cross-Sectional Data.”  Journal of Attention 

Disorders  26(13): 1725–1737. 

Tech Business News. 2023.  “Chatgpt May Lead to the 

Downfall of Education and Critical Thinking.” https:// 

www.techbusinessnews.com.au/blog/chatgpt-may-

lead-to-the-downfall-of-eduction-and-critical-thinking/. 

Accessed 5 March 2024. 

The Guardian. 2024.  “‘Stop All Time Wasting:’ Wool -

worths Workers Tracked and Timed under New Ef -

ficiency Crackdown.” https://www.theguardian.com/ 

business/2024/oct/23/woolworths-staff-efficiency-

productivity-crackdown-timed. Accessed 28 February 

2025. 

Thiagarajan, T., Newson, J., and Swaminathan, S. 

2025.  “An Exploration of the Impact of Smartphones 

in Childhood on Mind Health in Young Adulthood.” Un -

published background paper. Human Development 

Report Office, UNDP. Accessed 27 January 2025. 

Thompson, C. 2024.  “Generational AI: Digital Inclusion 

for Aging Populations.” https://www.atlanticcouncil.org/ 

in-depth-research-reports/report/generational-ai-digi -

tal-inclusion-for-aging-populations/. Accessed June 12 

2024. 

Towe-Goodman, N., McArthur, K. L., Willoughby, M., 

Swingler, M. M., Wychgram, C., Just, A. C., Kloog, I., 

and others. 2024.  “Green Space and Internalizing or 

Externalizing Symptoms among Children.”  JAMA Net -

work Open  7(4): e245742–e245742. 

Twenge, J., and Blanchflower, D. G. 2025.  “Declining 

Life Satisfaction and Happiness among Young Adults 

in Six English-Speaking Countries.” Working Paper 

33490, National Bureau of Economic Research, Cam -

bridge, MA. https://www.nber.org/papers/w33490. Ac -

cessed 18 February 2025. 

Twenge, J. M., and Campbell, W. K. 2018.  “Asso -

ciations between Screen Time and Lower Psycho -

logical Well-Being among Children and Adolescents: 

Evidence from a Population-Based Study.”  Preventive 

Medicine Reports  12: 271–283. 

Twenge, J. M., and Campbell, W. K. 2019.  “Media Use 

Is Linked to Lower Psychological Well-Being: Evidence 

from Three Datasets.”  Psychiatric Quarterly  90: 311–331. 

Twenge, J. M., Haidt, J., Joiner, T. E., and Campbell, 

W. K. 2020.  “Underestimating Digital Media Harm.”  Na -

ture Human Behaviour  4(4): 346–348. 

Twenge, J. M., Haidt, J., Lozano, J., and Cummins, 

K. M. 2022.  “Specification Curve Analysis Shows That 

Social Media Use Is Linked to Poor Mental Health, Es -

pecially among Girls.”  Acta Psychologica  224: 103512. 

Tzirides, A. O. 2022.  “Informing Advanced Digital Tech -

nologies’ Design for Refugee Language Education in 

Greece.” Proceedings of the 16th International Confer -

ence of the Learning Sciences-ICLS 2022: 1852–1853. 

International Society of the Learning Sciences. https:// 

repository.isls.org/bitstream/1/8606/1/ICLS2022_1852-

1853.pdf?__cf_chl_rt_tk=HPZMy__JmfuwLv_zlKB -

kUu5LqaaNPGsHPN8z9UesjUc-1743510175-1.0.1.1-5uR -

beuEacQDXhw_wvEN3StWQzCuMh.jJrIHR7NAhaA8. 

Accessed 6 May 2024. REFERENCES  24 5 

Uhls, Y. T., Michikyan, M., Morris, J., Garcia, D., Small, 

G. W., Zgourou, E., and Greenfield, P. M. 2014.  “Five 

Days at Outdoor Education Camp without Screens Im -

proves Preteen Skills with Nonverbal Emotion Cues.” 

Computers in Human Behavior  39: 387–392. 

UNDP (United Nations Development Programme). 

2019.  Human Development Report 2019: Beyond In -

come, Beyond Averages, Beyond Today: Inequalities 

in Human Development in the 21st Century . New York. 

https://hdr.undp.org/content/human-development-re -

port-2019. Accessed 10 January 2025. 

UNDP (United Nations Development Programme). 

2022.  Uncertain Times, Unsettled Lives: Shaping Our 

Future in a Transforming World; Human Development 

Report 2021/22 . https://hdr.undp.org/content/human-

development-report-2021-22. Accessed 9 February 

2024. 

UNDP (United Nations Development Programme). 

2024.  “2024 Global Multidimensional Poverty Index 

(MPI): Poverty amid Conflict.” New York. https://hdr. 

undp.org/content/2024-global-multidimensional-pov -

erty-index-mpi#/indicies/MPI. Accessed 22 January 

2025. 

UNDP (United Nations Development Programme). 

2025.  “Human Development Index (HDI).” https://hdr. 

undp.org/data-center/human-development-index#/in -

dicies/HDI. Accessed 31 March 2025. 

UNESCO (United Nations Educational, Scientific and 

Cultural Organization). 2019.  “Artificial Intelligence in 

Education, Compendium of Promising Initiatives: Mo -

bile Learning Week 2019.” https://iite.unesco.org/pub -

lications/ai-in-ed-compendium-of-promising-initiatives-

mlw-2019/. Accessed 8 November 2023. 

UNESCO (United Nations Educational, Scientific and 

Cultural Organization). 2022.  “M-Shule SMS Learn -

ing & Training, Kenya.” https://www.uil.unesco.org/en/ 

litbase/m-shule-sms-learning-training-kenya. Accessed 

23 March 2025. 

UNICEF (United Nations Children’s Fund). 2012. 

“Children’s Rights and Business Principles.” https:// 

www.unicef.org/documents/childrens-rights-and-busi -

ness-principles. Accessed 14 January 2025. 

UNICEF (United Nations Children’s Fund). 2023. 

“Online Risk and Harm for Children in Eastern and 

Southern Africa “ https://www.unicef.org/innocenti/me -

dia/3841/file/Online-Risks-Harm-Children-ESA-2023. 

pdf. Accessed 1 November 2024. 

UNICEF (United Nations Children’s Fund). 2024. 

“Early Childhood Education.” https://data.unicef.org/ 

topic/early-childhood-development/early-childhood-

education/. Accessed 11 December 2024. 

United Nations. 1989a.  Convention on the Rights of 

the Child.  Human Rights Directorate. 

United Nations. 1989b.  “Convention on the Rights of 

the Child. General Assembly Resolution 44/25.” https:// 

www.ohchr.org/en/instruments-mechanisms/instru -

ments/convention-rights-child. Accessed 28 March 

2025. 

United Nations. 2024.  “Global Digital Compact.” Of -

fice of the Secretary-General’s Envoy on Technol -

ogy. https://www.un.org/global-digital-compact/en. Ac -

cessed 14 January 2025. 

United Nations and UNOHCHR (United Nations Hu -

man Rights Office of the High Commissioner). 2011. 

“Guiding Principles on Business and Human Rights: 

Implementing the United Nations ‘Protect, Respect and 

Remedy’ Framework.” https://www.ohchr.org/sites/de -

fault/files/documents/publications/guidingprinciples -

businesshr_en.pdf. Accessed 14 January 2025. 

Unruh, C. F., Haid, C., Johannes, F., and Büthe, T. 

2022.  “Human Autonomy in Algorithmic Management.” 

Proceedings of the 2022 AAAI/ACM Conference 

on AI, Ethics, and Society. https://philpapers.org/rec/ 

DAIPOT-2. Accessed 4 April 2025. 

US Commission on Civil Rights. 2024.  “The Civil 

Rights Implications of the Federal Use of Facial 

Recognition Technology.” https://www.usccr.gov/ 

files/2024-09/civil-rights-implications-of-frt_0.pdf. Ac -

cessed 30 December 2024. 

US Federal Bureau of Investigation. 2024.  “Elder 

Fraud Report 2023.” https://www.ic3.gov/AnnualRe -

port/Reports/2023_IC3ElderFraudReport.pdf. Ac -

cessed 27 February 2025. 

US Office of the Surgeon General. 2023.  “Social Me -

dia and Youth Mental Health.” The US Surgeon Gen -

eral’s Advisory. https://www.hhs.gov/sites/default/files/ 

sg-youth-mental-health-social-media-advisory.pdf. Ac -

cessed 10 January 2025. 

US Department of Homeland Security. 2024.  “Artifi -

cial Intelligence and Combatting Online Child Sexual 

Exploitation and Abuse.” https://www.dhs.gov/sites/de -

fault/files/2024-04/24_0408_k2p_genai-bulletin.pdf. 

Accessed 1 October 2024. 

US Government Accountability Office. 2014.  “Ad -

vanced Imaging Technology: TSA Needs Additional In -

formation before Procuring Nextgeneration Systems.” 

https://www.gao.gov/assets/gao-14-357.pdf. Accessed 

27 December 2024. 

US National Center for Education Statistics. 2013. 

“The Nation’s Report Card: Trends in Academic Prog -

ress 2012.” Institute of Education Sciences, U.S. Depart -

ment of Education,Washington, DC. https://nces.ed.gov/ 

nationsreportcard/subject/publications/main2012/ 

pdf/2013456.pdf. Accessed 27 October 2024. 

Vaid, S. S., Kroencke, L., Roshanaei, M., Talaifar, S., 

Hancock, J. T., Back, M. D., Gosling, S. D., Ram, N., 

and Harari, G. M. 2024.  “Variation in Social Media 

Sensitivity across People and Contexts.”  Scientific Re -

ports  14(1): 6571. 

Valkenburg, P. M. 2022.  “Social Media Use and Well-

Being: What We Know and What We Need to Know.” 

Current Opinion in Psychology  45: 101294. 

Van Bavel, J. J., Robertson, C. E., Del Rosario, K., Ras -

mussen, J., and Rathje, S. 2024.  “Social Media and 

Morality.”  Annual Review of Psychology  75(1): 311–340. 

van Kolfschooten, H. 2023.  “The AI Cycle of Health 

Inequity and Digital Ageism: Mitigating Biases through 

the EU Regulatory Framework on Medical Devices.” 

Journal of Law and the Biosciences  10(2): 1–23. 

Vanden Abeele, M. M., Abels, M., and Hendrickson, 

A. T. 2020.  “Are Parents Less Responsive to Young 

Children When They Are on Their Phones? A System -

atic Naturalistic Observation Study.”  Cyberpsychology, 

Behavior, and Social Networking  23(6): 363–370. 

Villar, J. R., González, S., Sedano, J., Chira, C., and 

Trejo-Gabriel-Galan, J. M. 2015.  “Improving Human 

Activity Recognition and Its Application in Early Stroke 

Diagnosis.”  International Journal of Neural Systems 

25(04): 1450036. 

Vincent-Lancrin, S., and Van der Vlies, R. 2020. 

“Trustworthy Artificial Intelligence (AI) in Education: 

Promises and Challenges.” OECD Education Working 

Papers, OECD Publishing, Paris. https://www.oecd.org/ 

en/publications/trustworthy-artificial-intelligence-ai-

in-education_a6c90fa9-en.html. Accessed 28 March 

2025. 

Walsh, S. D., Sela, T., De Looze, M., Craig, W., Cosma, 

A., Harel-Fisch, Y., Boniel-Nissim, M., and others. 

2020.  “Clusters of Contemporary Risk and Their Rela -

tionship to Mental Well-Being among 15-Year-Old Ado -

lescents across 37 Countries.”  Journal of Adolescent 

Health  66(6, Supplement): S40–S49. 

Wan, M. W., Fitch-Bunce, C., Heron, K., and Lester, 

E. 2021.  “Infant Screen Media Usage and Social-

Emotional Functioning.”  Infant Behavior and Develop -

ment  62: 101509. 

WHO (World Health Organization). 2017.  “Inte -

grated Care for Older People: Guidelines on Com -

munity-Level Interventions to Manage Declines in 

Intrinsic Capacity.” https://www.who.int/publications/i/ 

item/9789241550109. Accessed 30 March 2025. 

WHO (World Health Organization). 2022.  “Age -

ism in Artificial Intelligence for Health “ WHO 

Policy Brief. https://www.who.int/publications/i/ 

item/9789240040793. Accessed 15 July 2024. 

Williams, A. 2024.  “Older Adults Express High Con -

cern and Limited Knowledge About AI Scams and 

Fraud.” AARP Research. https://www.aarp.org/pri/ 

topics/work-finances-retirement/fraud-consumer-pro -

tection/ai-fraud-concerns-older-adults/. Accessed 27 

February 2025. 

Woodard, F. E. 2018.  Mixed Method Study of the Im -

pact of Calculator Usage on 8th and 12th Grade Stu -

dents’ Fundamental Mathematical Skills and Teachers’ 

Perceptions on Using a Calculator in Learning Math -

ematics.  Delaware State University. 

World Bank. 2024a.  “Data Bank: World Development 

Indicators.” https://databank.worldbank.org/source/ 

world-development-indicators. Accessed 21 March 

2025. 

World Bank. 2024b.  “Individuals Using the Internet (% 

of Population)—Tajikistan.” https://data.worldbank.org/ 

indicator/IT.NET.USER.ZS?end=2022&locations=TJ&s 

tart=1990&view=chart. Accessed 13 December 2024. 

WSJ (Wall Street Journal) Staff. 2021.  “Inside Tik -

tok’s Algorithm: A WSJ Video Investigation.” https:// 

www.wsj.com/articles/tiktok-algorithm-video-investiga -

tion-11626877477. Accessed 10 November 2024. 

Xie, G., Deng, Q., Cao, J., and Chang, Q. 2020.  “Digi -

tal Screen Time and Its Effect on Preschoolers’ Behav -

ior in China: Results from a Cross-Sectional Study.”  Ital -

ian Journal of Pediatrics  46(9): 1–7. 

Xie, T., and Pentina, I. 2022.  “Attachment Theory as 

a Framework to Understand Relationships with Social 

Chatbots: A Case Study of Replika.” Proceedings of 

the 55th Hawaii International Conference on System 24 6 HUMAN DEVELOPMENT REPORT 2025 

Sciences. https://scholarspace.manoa.hawaii.edu/serv -

er/api/core/bitstreams/69a4e162-d909-4bf4-a833-

bd5b370dbeca/content#:~:text=Following%20the%20 

grounded%20theory%20approach%2C%20we%20 

analyzed%20in-depth,interpreted%20through%20 

the%20lens%20of%20the%20attachment%20theory. 

Accessed 23 March 2025. 

Xu, S. 2021.  “Microsoft Chatbot Spinoff Xiaoice 

Reaches $1 Billion Valuation.”  Bloomberg . https:// 

www.bloomberg.com/news/articles/2021-07-14/micro -

soft-chatbot-spinoff-xiaoice-reaches-1-billion-valua -

tion?embedded-checkout=true. Accessed 23 January 

2025. 

Yaqoob, T. 2024.  “AI-Based Credit Scoring: Benefits 

and Risks.”  Cointelegraph . https://cointelegraph.com/ 

learn/articles/ai-based-credit-scoring. Accessed 20 

December 2024. 

Yuvaraj, N., Chang, V., Gobinathan, B., Pinagapani, 

A., Kannan, S., Dhiman, G., and Rajan, A. R. 2021. 

“Automatic Detection of Cyberbullying Using Multi-Fea -

ture Based Artificial Intelligence with Deep Decision 

Tree Classification.”  Computers & Electrical Engineer -

ing  92: 107186. 

Zhou, L., Gao, J., Li, D., and Shum, H.-Y. 2020.  “The 

Design and Implementation of Xiaoice, an Empathet -

ic Social Chatbot.”  Computational Linguistics  46(1): 

53–93. 

Zhou, T., and Zhang, C. 2024.  “Examining Generative 

AI User Addiction from a CAC Perspective.”  Technology 

in Society  78: 102653. 

Zhu, C., Huang, S., Evans, R., and Zhang, W. 2021. 

“Cyberbullying among Adolescents and Children: A 

Comprehensive Review of the Global Situation, Risk 

Factors, and Preventive Measures.”  Frontiers in Public 

Health  9: 634909. 

Zimmerman, A., Janhonen, J., and Beer, E. 2023. 

“Human/AI Relationships: Challenges, Downsides, and 

Impacts on Human/Human Relationships.”  AI and Eth -

ics  4: 1555–1567. 

CHAPTER 4 

Abid, A., Farooqi, M., and Zou, J. 2021.  “Persistent 

Anti-Muslim Bias in Large Language Models.”  Proceed -

ings of the 2021 AAAI/ACM Conference on AI, Ethics, 

and Society , 298–306. 

Acemoğlu, D., and Johnson, S. 2023.  Power and 

Progress: Our Thousand-Year Struggle over Technol -

ogy and Prosperity.  London: Hachette UK. 

Acemoğlu, D., and Johnson, S. 2024.  “Learning 

from Ricardo and Thompson: Machinery and Labor in 

the Early Industrial Revolution and in the Age of Arti -

ficial Intelligence.”  Annual Review of Economics  16(1): 

597–621. 

Addati, L., Cattaneo, U., Esquivel, V., and Valarino, I. 

2018.  Care Work and Care Jobs for the Future of De -

cent Work.  Geneva: International Labour Organization. 

Adnin, R., and Das, M. 2024.  “‘I Look at It as the King 

of Knowledge:’ How Blind People Use and Understand 

Generative AI Tools.”  Proceedings of the 26th Inter -

national ACM SIGACCESS Conference on Computers 

and Accessibility , 1–14. 

Akerlof, G. A., and Shiller, R. J. 2010.  Animal Spirits: 

How Human Psychology Drives the Economy, and Why 

It Matters for Global Capitalism.  Princeton University 

Press. 

Akerlof, G. A., and Snower, D. J. 2016.  “Bread and 

Bullets.”  Journal of Economic Behavior & Organization 

126: 58–71. 

Aldasoro, I., Armantier, O., Doerr, S., Gambacorta, L., 

and Oliviero, T. 2024.  “The GenAI Gender Gap.”  Eco -

nomics Letters : 241: 111814. 

ALNAP (Active Learning Network for Accountability 

and Performance). 2022.  “The State of the Humanitar -

ian System (SOHS) – Summary.” ALNAP, London. 

Altman, S. 2024.  “The Intelligence Age.” https:// 

ia.samaltman.com/. Accessed 28 April 2025. 

Andre, P., Haaland, I., Roth, C., Wiederholt, M., 

and Wohlfart, J. 2024.  “Narratives About the Macro -

economy.” CEBI Working Paper 18/21, Department of 

Economics, University of Copenhagen, Copenhagen. 

Angwin, J., Larson, J., Mattu, S., and Kirchner, L. 

2022.  “Machine Bias.”  Ethics of Data and Analytics. 

Auerbach Publications. 

Anwar, M. A. 2022.  “Platforms of Inequality: Gender 

Dynamics of Digital Labour in Africa.”  Gender & Devel -

opment  30(3): 747–764. 

Armantier, O., Doerr, S., Frost, J., Fuster, A., and 

Shue, K. 2024.  “Nothing to Hide? Gender and Age 

Differences in Willingness to Share Data.” BIS Working 

Paper 1187, Bank for International Settlements, Basel. 

Atari, M., Xue, M. J., Park, P. S., Blasi, D., and Hen -

rich, J. 2025.  “Which Humans?”  PsyArXiv Preprints .

Athreya, B. 2021.  “Bias in, Bias Out: Gender and Work 

in the Platform Economy.” https://idl-bnc-idrc.dspace -

direct.org/items/7d8e2f97-b1dd-49ad-9843-a0480f -

5f80eb. Accessed 28 April 2025. 

Atkinson, S., Lawson, V., and Wiles, J. 2011.  “Care of 

the Body: Spaces of Practice.”  Social & Cultural Geog -

raphy  12(6): 563–572. 

Austin, V., and Holloway, C. 2022.  “Assistive Technol -

ogy (AT), for What?”  Societies  12(6): 169. 

Australian Red Cross. 2017.  “Going Local Achieving 

a More Appropriate and Fit-for-Purpose Humanitarian 

Ecosystem in the Pacific.”  https://humanitarianadviso -

rygroup.org/wp-content/uploads/2020/12/ARC-Locali -

sation-report-Electronic-301017.pdf .

Ayoka, G., Barbareschi, G., Cave, R., and Holloway, 

C. 2024.  “Enhancing Communication Equity: Evalua -

tion of an Automated Speech Recognition Application 

in Ghana.”  Proceedings of the CHI Conference on Hu -

man Factors in Computing Systems .

Azqueta-Gavaldón, A. 2020.  “Causal Inference be -

tween Cryptocurrency Narratives and Prices: Evidence 

from a Complex Dynamic Ecosystem.”  Physica A: Sta -

tistical Mechanics and its Applications  537: 122574. 

Baffoe, M. 2013.  “Stigma, Discrimination & Marginal -

ization: Gateways to Oppression of Persons with Dis -

abilities in Ghana, West Africa.”  Journal of Educational 

and Social Research  3(1): 187–198. 

Bai, X., Wang, A., Sucholutsky, I., and Griffiths, T. 

L. 2024.  “Measuring Implicit Bias in Explicitly Un -

biased Large Language Models.”  arXiv preprint 

arXiv:2402.04105 .

Bai, Y., Jones, A., Ndousse, K., Askell, A., Chen, A., 

DasSarma, N., Drain, D., and others. 2022a.  “Train -

ing a Helpful and Harmless Assistant with Reinforce -

ment Learning from Human Feedback.”  arXiv preprint 

arXiv:2204.05862 .

Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, 

J., Jones, A., Chen, A., and others. 2022b.  “Constitu -

tional AI: Harmlessness from AI Feedback.”  arXiv pre -

print arXiv:2212.08073 .

Baillargeon, P., Yoon, J., and Zhang, A. 2024.  “Who 

Puts the ‘Social’ in ‘Social Computing?’ Using a Neu -

rodiversity Framing to Review Social Computing Re -

search.”  arXiv preprint arXiv:2410.15527 .

Barbelet, V., Davies, G., Flint, J., and Davey, E. 2021. 

Interrogating the Evidence Base on Humanitarian Lo -

calisation . HPG Literature Review. London: ODI. https:// 

odi.org/en/publications/interrogating-the-evidence-

base-on-humanitarian-localisation-aliterature-study. 

Barnett, M. 2018.  Empire of Humanity: A History of 

Humanitarianism.  Ithaca, NY: Cornell University Press. 

Barocas, S., Hardt, M., and Narayanan, A. 2023.  Fair -

ness and Machine Learning: Limitations and Opportu -

nities.  Cambridge, MA: MIT Press. 

Bender, E. M., Gebru, T., McMillan-Major, A., and 

Shmitchell, S. 2021.  “On the Dangers of Stochastic 

Parrots: Can Language Models Be Too Big?”  Proceed -

ings of the 2021 ACM Conference on Fairness, Ac -

countability, and Transparency , 610–623. 

Bengio, Y., Hinton, G., Yao, A., Song, D., Abbeel, P., 

Darrell, T., Harari, Y. N., and others. 2024.  “Manag -

ing Extreme AI Risks amid Rapid Progress.”  Science 

384(6698): 842–845. 

Bennett, C. L., and Keyes, O. 2020.  “What Is the Point 

of Fairness? Disability, AI and the Complexity of Jus -

tice.”  ACM SIGACCESS Accessibility and Computing 

(125): 1–1. 

Berente, N., Kormylo, C., and Rosenkranz, C. 2024. 

“Test-Driven Ethics for Machine Learning.”  Communica -

tions of the ACM  67(5): 45–47. 

Bigoulaeva, I., Madabushi, H. T., and Gurevych, I. 

2025.  “The Inherent Limits of Pretrained Llms: The 

Unexpected Convergence of Instruction Tuning 

and in-Context Learning Capabilities.”  arXiv preprint 

arXiv:2501.08716 .

Bittman, M., Rice, J. M., and Wajcman, J. 2004.  “Ap -

pliances and Their Impact: The Ownership of Domestic 

Technology and Time Spent on Household Work.”  The 

British Journal of Sociology  55(3): 401–423. 

Blodgett, S. L., Barocas, S., Daumé III, H., and Wal -

lach, H. 2020.  “Language (Technology) Is Power: 

A Critical Survey of” Bias” in NLP.”  arXiv preprint 

arXiv:2005.14050 .

Blodgett, S. L., Lopez, G., Olteanu, A., Sim, R., and 

Wallach, H. 2021.  “Stereotyping Norwegian Salmon: 

An Inventory of Pitfalls in Fairness Benchmark Data -

sets.”  Proceedings of the 59th Annual Meeting of the REFERENCES  247 

Association for Computational Linguistics and the 11th 

International Joint Conference on Natural Language 

Processing (Volume 1: Long Papers) , 1004–1015. 

Breda, T., Jouini, E., Napp, C., and Thebault, G. 2020. 

“Gender Stereotypes Can Explain the Gender-Equality 

Paradox.”  Proceedings of the National Academy of Sci -

ences  117(49): 31063–31069. 

Brooke, S. 2023.  “Trouble in Programmer’s Paradise: 

Gender-Biases in Sharing and Recognising Technical 

Knowledge on Stack Overflow.”  Information, Communi -

cation & Society  24(14): 2019–2112. 

Brooke, S. 2024.  “Programmed Differently? Testing 

for Gender Differences in Python Programming Style 

and Quality on Github.”  Journal of Computer-Mediated 

Communication  29(1): zmad049. 

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, 

J. D., Dhariwal, P., Neelakantan, A., and others. 

2020.  “Language Models Are Few-Shot Learners.”  Ad -

vances in Neural Information Processing Systems  33: 

1877–1901. 

Buolamwini, J., and Gebru, T. 2018.  “Gender Shades: 

Intersectional Accuracy Disparities in Commercial Gen -

der Classification.” Conference on Fairness, Account -

ability and Transparency, PMLR, 77–91. 

Burrage, A., Dasgupta, N., and Ganguli, I. 2025. 

“Gender Diversity in Academic Entrepreneurship: So -

cial Impact Motives and the NSF I-Corps Program.”  Re -

search Policy  54(3): 105169. 

Caliskan, A., Bryson, J. J., and Narayanan, A. 2017. 

“Semantics Derived Automatically from Language Cor -

pora Contain Human-Like Biases.”  Science  356(6334): 

183–186. 

Capraro, V., Lentsch, A., Acemoğlu, D., Akgun, S., 

Akhmedova, A., Bilancini, E., Bonnefon, J.-F., and 

others. 2024.  “The Impact of Generative Artificial Intel -

ligence on Socioeconomic Inequalities and Policy Mak -

ing.”  PNAS nexus  3(6)(6). 

Cave, S., and Dihal, K. 2023.  Imagining AI: How the 

World Sees Intelligent Machines.  Oxford, UK: Oxford 

University Press. 

Cave, S., Dihal, K., Drage, E., and McInerney, K. 

2023.  “Who Makes AI? Gender and Portrayals of AI 

Scientists in Popular Film, 1920–2020.”  Public Under -

standing of Science  32(6): 745–760. 

Chan, H. Y., and Muralidharan, A. 2024.  “Care Ro -

bots for the Elderly: Legal, Ethical Considerations and 

Regulatory Strategies.”  Developments in Intellectual 

Property Strategy: The Impact of Artificial Intelligence, 

Robotics and New Technologies.  Springer. 

Chan, R. C. 2022.  “A Social Cognitive Perspective on 

Gender Disparities in Self-Efficacy, Interest, and Aspira -

tions in Science, Technology, Engineering, and Math -

ematics (STEM): The Influence of Cultural and Gender 

Norms.”  International Journal of STEM Education  9(1): 

1–13. 

Charlesworth, T. E., Caliskan, A., and Banaji, M. R. 

2022.  “Historical Representations of Social Groups 

across 200 Years of Word Embeddings from Google 

Books.”  Proceedings of the National Academy of Sci -

ences  119(28): e2121798119. 

Charlesworth, T. E., Ghate, K., Caliskan, A., and Ban -

aji, M. R. 2024.  “Extracting Intersectional Stereotypes 

from Embeddings: Developing and Validating the Flex -

ible Intersectional Stereotype Extraction Procedure.” 

PNAS nexus  3(3): pgae089. 

Chen, K., Duan, Z., and Kim, S. J. 2024.  “Uncover -

ing Gender Stereotypes in Controversial Science Dis -

course: Evidence from Computational Text and Visual 

Analyses across Digital Platforms.”  Journal of Comput -

er-Mediated Communication  29(1): zmad052. 

Chopra, D., and Krishnan, M. 2022.  “‘Care Is Not a 

Burden’: A 7-4-7 Framework of Action for Operation -

alising the Triple R.”  Gender & Development  30(1-2): 

35–57. 

Coeckelbergh, M. 2022.  Robot Ethics.  MIT Press. 

Collier, P., and Tuckett, D. 2021.  “Narratives as a Coor -

dinating Device for Reversing Regional Disequilibrium.” 

Oxford Review of Economic Policy  37(1): 97–112. 

Conceição, P. 2019.  “Fear and Loathing of Technologi -

cal Progress? Leveraging Science and Innovation for 

the Implementation of the 2030 Agenda for Sustain -

able Development.”  Public Service Excellence in the 

21st Century : 31–52. 

Costa, E. 2018.  “Affordances-in-Practice: An Ethno -

graphic Critique of Social Media Logic and Context 

Collapse.”  New Media & Society  20(10): 3641–3656. 

Couldry, N., and Mejias, U.A. 2019.  “Data Colonialism: 

Rethinking Big Data’s Relation to the Contemporary 

Subject.”  Television & New Media  20(4): 336–349. 

Cowan, R. S. 2023.  More Work for Mother: The Ironies 

of Household Technology from the Open Hearth to the 

Microwave.  Plunkett Lake Press. 

DataGenero. 2024.  “Feminisms in Artificial Intelli -

gence: Automation Tools Towards a Feminist Judiciary 

Reform in Argentina and Mexico.” https://feministai. 

pubpub.org/pub/z83eyq54/release/1. Accessed 28 

April 2025. 

de Freitas, M. P., Piai, V. A., Farias, R. H., Fernandes, 

A. M., de Moraes Rossetto, A. G., and Leithardt, V. 

R. Q. 2022.  “Artificial Intelligence of Things Applied to 

Assistive Technology: A Systematic Literature Review.” 

Sensors  22(21): 8531. 

de Silva de Alwis, R. 2024.  “A Rapidly Shifting Land -

scape: Why Digitized Violence Is the Newest Category 

of Gender-Based Violence.”  La Revue des Juristes de 

Sciences Po  (25): 62. 

de V. Cavalcanti, T. V., and Tavares, J. 2008.  “Assess -

ing the ‘Engines of Liberation:’ Home Appliances and 

Female Labor Force Participation.”  The Review of Eco -

nomics and Statistics  90(1): 81–88. 

Dhar, D., and Thuppilikkat, A. A. 2022.  “Gendered 

Labour’s Positions of Vulnerabilities in Digital Labour 

Platforms and Strategies of Resistance: A Case Study 

of Women Workers’ Struggle in Urban Company, New 

Delhi.”  Gender & Development  30(3): 667–686. 

Duclos, D., Ekzayez, A., Ghaddar, F., Checchi, F., and 

Blanchet, K. 2019.  “Localisation and Cross-Border As -

sistance to Deliver Humanitarian Health Services in 

North-West Syria: A Qualitative Inquiry for the Lancet-

Aub Commission on Syria.”  Conflict and Health  13: 1–10. 

Duffield, M. 2016.  “The Resilience of the Ruins: To -

wards a Critique of Digital Humanitarianism.”  Resilience 

4(3): 147–165. 

Dunn, S., Vaillancourt, T., and Brittain, H. 2023.  “Sup -

porting Safer Digital Spaces.” Centre for International 

Governance Innovation. 

Edenberg, E., and Wood, A. 2023.  “Disambiguating 

Algorithmic Bias: From Neutrality to Justice.”  Proceed -

ings of the 2023 AAAI/ACM Conference on AI, Ethics, 

and Society , 691–704. 

Elkahlout, G., and Elgibali, K. 2020.  “From Theory to 

Practice: A Study of Remotely Managed Localised Hu -

manitarian Action in Syria.”  Journal of Peacebuilding & 

Development  15(2): 235–249. 

Emmer De Albuquerque Green, C. 2024.  “Defining 

Responsible Use of AI Chatbots in Social Care for Old -

er Adults.”  Nature Aging  4(6): 745–747. 

Eriksson, M., Purificato, E., Noroozian, A., Vinagre, 

J., Chaslot, G., Gomez, E., and Fernandez-Llorca, D. 

2025.  “Can We Trust AI Benchmarks? An Interdisciplin -

ary Review of Current Issues in AI Evaluation.”  arXiv 

preprint arXiv:2502.06559 .

Ethayarajh, K., and Jurafsky, D. 2020.  “Utility Is in the 

Eye of the User: A Critique of NLP Leaderboards.”  arXiv 

preprint arXiv:2009.13888 .

Fabregas, R., Kremer, M., Lowes, M., On, R., and 

Zane, G. 2025.  “Digital Information Provision and Be -

havior Change: Lessons from Six Experiments in East 

Africa.”  American Economic Journal: Applied Econom -

ics  17(1): 527–566. 

Facchinetti, G., Petrucci, G., Albanesi, B., De Mari -

nis, M. G., and Piredda, M. 2023.  “Can Smart Home 

Technologies Help Older Adults Manage Their Chronic 

Condition? A Systematic Literature Review.”  Interna -

tional Journal of Environmental Research and Public 

Health  20(2): 1205. 

Fast, L., and Bennett, C. 2020.  “From the Ground Up: 

It’s About Time for Local Humanitarian Action.” HPG 

Report, ODI.  https://odi.org/documents/6169/From_ 

the_ground_up_its_about_time_for_local_humanitar -

ian_action.pdf .

Fejerskov, A. M., Clausen, M. L., and Seddig, S. 2024. 

“Humanitarian Ignorance: Towards a New Paradigm of 

Non-Knowledge in Digital Humanitarianism.”  Disasters 

48(2): e12609. 

Felber, N. A., Tian, Y. J., Pageau, F., Elger, B. S., and 

Wangmo, T. 2023.  “Mapping Ethical Issues in the Use 

of Smart Home Health Technologies to Care for Older 

Persons: A Systematic Review.”  BMC Medical Ethics 

24(1): 24. 

Ferguson, C., Hickman, L. D., Turkmani, S., Breen, P., 

Gargiulo, G., and Inglis, S. C. 2021.  “‘Wearables Only 

Work on Patients That Wear Them:’ Barriers and Facili -

tators to the Adoption of Wearable Cardiac Monitoring 

Technologies.”  Cardiovascular Digital Health Journal 

2(2): 137–147. 

Fetterolf, E., Elder, A., Levi, M., and Trivedi, R. B. 

2025.  “Technology & the Dynamics of Care for Older 

People.”  Dædalus  154(1): 117–133. 24 8 HUMAN DEVELOPMENT REPORT 2025 

Fraser, N. 2016.  “Contradictions of Capital and Care.” 

New Left Review  100 (July). 

Frost, L., Khan, S., and Vinck, P. 2022.  “Technologies 

in Humanitarian Settings: Digital Upskilling of Humani -

tarian Actors.” Harvard Humanitarian Initiative, Cam -

bridge, MA. 

Gadiraju, V., Kane, S., Dev, S., Taylor, A., Wang, D., 

Denton, E., and Brewer, R. 2023.  “‘I Wouldn’t Say 

Offensive But...:’ Disability-Centered Perspectives on 

Large Language Models.”  Proceedings of the 2023 

ACM Conference on Fairness, Accountability, and 

Transparency , 205–216. 

Gallegos, I. O., Rossi, R. A., Barrow, J., Tanjim, M. 

M., Kim, S., Dernoncourt, F., Yu, T., Zhang, R., and 

Ahmed, N. K. 2024.  “Bias and Fairness in Large Lan -

guage Models: A Survey.”  Computational Linguistics :

1–79. 

Ganguli, D., Askell, A., Schiefer, N., Liao, T. I., 

Lukošiūtė, K., Chen, A., Goldie, A., and others. 2023. 

“The Capacity for Moral Self-Correction in Large Lan -

guage Models.”  arXiv preprint arXiv:2302.07459 .

Ghorkhmazyan, M. 2022.  “Mercy Corps’ Guide to 

Building a Digital Ecosystem for M&E at Scale.” Neth -

ope.  https://nethope.org/articles/mercy-corps-guide-

to-building-a-digital-ecosystem-for-me-at-scale/ .

Ghosh, S., and Caliskan, A. 2023.  “ChatGPT Perpetu -

ates Gender Bias in Machine Translation and Ignores 

Non-Gendered Pronouns: Findings across Bengali and 

Five Other Low-Resource Languages.”  Proceedings of 

the 2023 AAAI/ACM Conference on AI, Ethics, and So -

ciety , 901–912. 

Glazko, K. S., Yamagami, M., Desai, A., Mack, K. A., 

Potluri, V., Xu, X., and Mankoff, J. 2023.  “An Auto -

ethnographic Case Study of Generative Artificial Intel -

ligence’s Utility for Accessibility.”  Proceedings of the 

25th International ACM SIGACCESS Conference on 

Computers and Accessibility , 1–8. 

Goggin, G., Ellis, K., and Hawkins, W. 2019.  “Disabil -

ity at the Centre of Digital Inclusion: Assessing a New 

Moment in Technology and Rights.”  Communication 

Research and Practice  5(3): 290–303. 

Goggin, G., Prahl, A., and Zhuang, K. V. 2023.  “Com -

municating AI and Disability.”  The Palgrave Handbook 

of Disability and Communication.  Springer. 

Goldin, C., Kerr, S. P., and Olivetti, C. 2024.  “The 

Other Side of the Mountain: Women’s Employment and 

Earnings over the Family Cycle.”  Oxford Open Econom -

ics  3(Supplement 1): i323–i334. 

Goldstone, J. A. 2002.  “Efflorescences and Economic 

Growth in World History: Rethinking the “Rise of the 

West” and the Industrial Revolution.”  Journal of World 

History  13(2): 323–389. 

Green, M., and Lawson, V. 2011.  “Recentring Care: 

Interrogating the Commodification of Care.”  Social & 

Cultural Geography  12(6): 639–654. 

Greenwald, A. G., and Banaji, M. R. 1995.  “Implicit 

Social Cognition: Attitudes, Self-Esteem, and Stereo -

types.”  Psychological Review  102(1): 4. 

Guetto, R., Bazzani, G., and Vignoli, D. 2022.  “Nar -

ratives of the Future and Fertility Decision-Making in 

Uncertain Times. An Application to the Covid-19 Pan -

demic.”  Vienna Yearbook of Population Research  20: 

223–260. 

Guetto, R., Morabito, M. F., Vollbracht, M., and Vi -

gnoli, D. 2023.  “Fertility and Media Narratives of the 

Economy: Evidence from Italian News Coverage.”  De -

mography  60(2): 607–630. 

Gupta, A., and Treviranus, J. 2022.  “Inclusively De -

signed Artificial Intelligence.”  Digital Innovation and the 

Future of Work.  River Publishers. 

Hertog, E., Fukuda, S., Matsukura, R., Nagase, N., 

and Lehdonvirta, V. 2023.  “The Future of Unpaid 

Work: Estimating the Effects of Automation on Time 

Spent on Housework and Care Work in Japan and the 

UK.”  Technological Forecasting and Social Change  191: 

122443. 

Hertog, E., Ruppanner, L., and Churchill, B. 2024. 

“Silicon Caregivers: A Multilevel Analysis of European 

Perspectives on Robotic Technologies for Elderly 

Care.”  Community, Work & Family  27(5): 698–718. 

Hobden, C. 2015.  “Domestic Workers Organize–but 

Can They Bargain.”  Mapping Collective Bargaining 

and Other Forms of Negotiation in the Domestic Work 

Sector .

Hofmann, V., Kalluri, P. R., Jurafsky, D., and King, S. 

2024.  “AI Generates Covertly Racist Decisions About 

People Based on Their Dialect.”  Nature  633(8028): 

147–154. 

Holloway, C., and Barbareschi, G. 2022.  Disabil -

ity Interactions: Creating Inclusive Innovations.  Cham: 

Springer Nature. 

Howcroft, D., and Rubery, J. 2018.  “Gender Equality 

Prospects and the Fourth Industrial Revolution.”  Praise 

for Work in the Digital Age  63. 

Humlum, A., and Vestergaard, E. 2024.  “The Adop -

tion of Chatgpt.” BFI Working Paper 2024-50, Friedman 

Institute for Economics, University of Chicago, Chicago, 

IL. 

Hussein, S. 2022.  “The Global Demand for Migrant 

Care Workers: Drivers and Implications on Migrants’ 

Wellbeing.”  Sustainability  14(17): 10612. 

Inter-Parliamentary Union and African Parliamen -

tary Union. 2021.  “Sexism, Harassment and Violence 

against Women Parliamentarians in Africa.” https://www. 

ipu.org/resources/publications/issue-briefs/2021-11/ 

sexism-harassment-and-violence-against-women-in-

parliaments-in-africa. Accessed 28 April 2025. 

Jahan, N., Barbareschi, G., Jan, C. A., Mutuku, C. 

M., Rahman, N., Austin, V., and Holloway, C. 2020. 

“Inclusion and Independence: The Impact of Mobile 

Technology on the Lives of Persons with Disabilities 

in Kenya and Bangladesh.” 2020 IEEE Global Humani -

tarian Technology Conference (GHTC), 29 October–1 

November. 

Jasanoff, S. 2016.  The Ethics of Invention: Technology 

and the Human Future.  W.W. Norton & Company. 

Johnson, S. G., Bilovich, A., and Tuckett, D. 2023. 

“Conviction Narrative Theory: A Theory of Choice 

under Radical Uncertainty.”  Behavioral and Brain Sci -

ences  46: e82. 

Just Economy and Labor Institute. 2022.  “Centring 

the Agency of Women in Thailand’s Platform-Based 

Care Economy.” https://connected2work.org/blog/ 

centering-the-agency-of-women-in-thailands-platform-

based-care-economy%E2%80%AF/. Accessed 28 April 

2025. 

Kalla, S. 2022.  “Hacking Platform Capitalism: The Case 

of Domestic Workers on South Africa’s Sweepsouth 

Platform.”  Gender & Development  30(3): 655–666. 

Katzman, J., Wang, A., Scheuerman, M., Blodgett, S. 

L., Laird, K., Wallach, H., and Barocas, S. 2023.  “Tax -

onomizing and Measuring Representational Harms: A 

Look at Image Tagging.”  Proceedings of the AAAI Con -

ference on Artificial Intelligence , 14277–14285. 

Kelly, M., Mokyr, J., and Ó Gráda, C. 2023.  “The Me -

chanics of the Industrial Revolution.”  Journal of Political 

Economy  131(1): 59–94. 

Khan, M. H., Williams, J., Williams, P., and Mayes, R. 

2024.  “Caring in the Gig Economy: A Relational Per -

spective of Decent Work.”  Work, Employment and So -

ciety  38(4): 1107–1127. 

Khoury, R. B., and Scott, E. K. 2024.  “Going Local with -

out Localization: Power and Humanitarian Response in 

the Syrian War.”  World Development  174: 106460. 

King-Dejardin, A. 2019.  “The Social Construction of 

Migrant Care Work. At the Intersection of Care, Mi -

gration and Gender.” Geneva: International Labour 

Organization. 

Kodate, N., Maeda, Y., Hauray, B., Tsujimura, M., 

Chan, W., Mannan, H., Yu, W., and others. 2022. 

“Hopes and Fears Regarding Care Robots: Content 

Analysis of Newspapers in East Asia and Western Eu -

rope, 2001–2020.”  Frontiers in Rehabilitation Sciences 

3: 1019089. 

Kraft, K., and Smith, J. D. 2019.  “Between Internation -

al Donors and Local Faith Communities: Intermediaries 

in Humanitarian Assistance to Syrian Refugees in Jor -

dan and Lebanon.”  Disasters  43(1): 24–45. 

Kudina, O., and van de Poel, I. 2024.  “A Sociotech -

nical System Perspective on AI.”  Minds and Machines 

34(3): 21. 

Kulkov, I., Kulkova, J., Rohrbeck, R., Menvielle, L., 

Kaartemo, V., and Makkonen, H. 2024.  “Artificial Intel -

ligence - Driven Sustainable Development: Examining 

Organizational, Technical, and Processing Approaches 

to Achieving Global Goals.”  Sustainable Development 

32(3): 2253–2267. 

Lane, M. 2024.  Who Will Be the Workers Most Affected 

by AI? A Closer Look at the Impact of AI on Women, 

Low-Skilled Workers and Other Groups . Paris: OECD 

Publishing. 

Lazar, S., and Nelson, A. 2023.  “AI Safety on Whose 

Terms?”  Science  381(6654): 138. 

Lee, C.-H., Wang, C., Fan, X., Li, F., and Chen, C.-H. 

2023.  “Artificial Intelligence-Enabled Digital Transfor -

mation in Elderly Healthcare Field: Scoping Review.” 

Advanced Engineering Informatics  55: 101874. 

Lee, Y. S., Iizuka, T., and Eggleston, K. 2025.  “Robots 

and Labor in Nursing Homes.”  Labour Economics  92: 

102666. REFERENCES  24 9 

Leslie, S.-J., Cimpian, A., Meyer, M., and Freeland, 

E. 2015.  “Expectations of Brilliance Underlie Gender 

Distributions across Academic Disciplines.”  Science 

347(6219): 262–265. 

Li, R., Kamaraj, A., Ma, J., and Ebling, S. 2024.  “De -

coding Ableism in Large Language Models: An Inter -

sectional Approach.”  Proceedings of the Third Work -

shop on NLP for Positive Impact , 232–249. 

Liang, P., Bommasani, R., Lee, T., Tsipras, D., Soylu, 

D., Yasunaga, M., Zhang, Y., and others. 2022.  “Ho -

listic Evaluation of Language Models.”  arXiv preprint 

arXiv:2211.09110 .

Liu, Y., and Wang, H. 2024.  “Who on Earth Is Using 

Generative AI?” Policy Research Working Group Pa -

per 10870, Digital Development Global Practice, World 

Bank, Washington, DC. 

Mack, K. A., Qadri, R., Denton, R., Kane, S. K., and 

Bennett, C. L. 2024.  “‘They Only Care to Show Us the 

Wheelchair:’ Disability Representation in Text-to-Image 

AI Models.”  Proceedings of the 2024 CHI Conference 

on Human Factors in Computing Systems , 1–23. 

MacKenzie, D. 1999.  The Social Shaping of Technol -

ogy . Berkshire, UK: Open University Press. 

MacLeavy, J. 2021.  “Care Work, Gender Inequality and 

Technological Advancement in the Age of Covid-19.” 

Gender, Work & Organization  28(1): 138–154. 

Madianou, M. 2019.  “Technocolonialism: Digital In -

novation and Data Practices in the Humanitarian Re -

sponse to Refugee Crises.”  Social Media + Society  5(3): 

2056305119863146. 

Mankoff, J., Hayes, G. R., and Kasnitz, D. 2010.  “Dis -

ability Studies as a Source of Critical Inquiry for the 

Field of Assistive Technology.”  Proceedings of the 12th 

International ACM SIGACCESS Conference on Com -

puters and Accessibility , 3–10. 

Mannheim, I., Wouters, E. J., Köttl, H., Van Boekel, 

L. C., Brankaert, R., and Van Zaalen, Y. 2023.  “Age -

ism in the Discourse and Practice of Designing Digital 

Technology for Older Persons: A Scoping Review.”  The 

Gerontologist  63(7): 1188–1200. 

Maragno, G., Tangi, L., Gastaldi, L., and Benedetti, 

M. 2023.  “Exploring the Factors, Affordances and Con -

straints Outlining the Implementation of Artificial Intel -

ligence in Public Sector Organizations.”  International 

Journal of Information Management  73: 102686. 

McCosker, A., Yao, X., Albury, K., Maddox, A., 

Farmer, J., and Stoyanovich, J. 2022.  “Develop -

ing Data Capability with Non-Profit Organisations Us -

ing Participatory Methods.”  Big Data & Society  9(1): 

20539517221099882. 

McDonald, N., Massey, A., and Hamidi, F. 2023. 

“Elicitation and Empathy with AI-Enhanced Adaptive 

Assistive Technologies (AATs): Towards Sustainable In -

clusive Design Method Education.”  Journal of Problem 

Based Learning in Higher Education  11(2): 78–99. 

McIntosh, T. R., Susnjak, T., Arachchilage, N., Liu, 

T., Watters, P., and Halgamuge, M. N. 2024.  “Inad -

equacies of Large Language Model Benchmarks in the 

Era of Generative Artificial Intelligence.”  arXiv preprint 

arXiv:2402.09880 .

Mei, K., Fereidooni, S., and Caliskan, A. 2023.  “Bias 

against 93 Stigmatized Groups in Masked Language 

Models and Downstream Sentiment Classification 

Tasks.”  Proceedings of the 2023 ACM Conference on 

Fairness, Accountability, and Transparency , 1699–1710. 

Mejias, U. A., and Couldry, N. 2024.  “Data Grab: The 

New Colonialism of Big Tech and How to Fight Back.” 

Data Grab.  Chicago, IL: University of Chicago Press. 

Melis, S., and Apthorpe, R. 2020.  “The Politics of the 

Multi-Local in Disaster Governance.”  Politics and Gov -

ernance  8(4): 366–374. 

Mirza, V., Kulkarni, R., and Jadhav, A. 2024.  “Evaluat -

ing Gender, Racial, and Age Biases in Large Language 

Models: A Comparative Analysis of Occupational and 

Crime Scenarios.”  arXiv preprint arXiv:2409.14583 .

Mitchell, M. 2024.  “Debates on the Nature of Artificial 

General Intelligence.”  Science  383(6689): p.eado7069. 

Mokyr, J. 2016.  A Culture of Growth.  Princeton, NJ: 

Princeton University Press. 

Mukand, S., and Rodrik, D. 2018.  “The Political 

Economy of Ideas: On Ideas Versus Interests in Policy -

making.” Working Paper 24467, National Bureau of 

Economic Research, Cambridge, MA. 

Mulder, F., Ferguson, J., Groenewegen, P., Boersma, 

K., and Wolbers, J. 2016.  “Questioning Big Data: 

Crowdsourcing Crisis Data Towards an Inclusive 

Humanitarian Response.”  Big Data & Society  3(2): 

2053951716662054. 

Napp, C., and Breda, T. 2022.  “The Stereotype That 

Girls Lack Talent: A Worldwide Investigation.”  Science 

Advances  8(10): eabm3689. 

Narasimhan, S. 2021.  “Participation of Women in Sci -

ence in the Developed and Developing Worlds: Invert -

ed U of Feminization of the Scientific Workforce, Gen -

der Equity and Retention.”  Pure and Applied Chemistry 

93(8): 913–925. 

Narayanan, A., and Kapoor, S. 2023a.  “Evaluat -

ing Llms Is a Minefield ” https://www.cs.princeton. 

edu/~arvindn/talks/evaluating_llms_minefield/. 

Narayanan, A., and Kapoor, S. 2023b.  “GPT-4 and 

Professional Benchmarks: The Wrong Answer to 

the Wrong Question.” https://www.aisnakeoil.com/p/ 

gpt-4-and-professional-benchmarks. 

Narayanan, A., and Kapoor, S. 2024.  AI Snake Oil: 

What Artificial Intelligence Can Do, What It Can’t, and 

How to Tell the Difference.  Princeton, NJ: Princeton 

University Press. 

National Domestic Workers Alliance. n.d.  “Break -

through for Gig Workers.” https://www.domesticwork -

ers.org/campaign-updates/breakthrough-for-gig-work -

ers/. Accessed 28 April 2025. 

Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wain -

wright, C., Mishkin, P., Zhang, C., and others. 2022. 

“Training Language Models to Follow Instructions with 

Human Feedback.”  Advances in Neural Information 

Processing Systems  35: 27730–27744. 

Pailey, R. N. 2020.  “De-Centring the ‘White Gaze’of 

Development.”  Development and Change  51(3): 

729–745. 

Papadopoulos, C. 2024.  “Large Language Models 

for Autistic and Neurodivergent Individuals: Concerns, 

Benefits and the Path Forward.”  Neurodiversity  2: 

27546330241301938. 

Paugam, L., Stolowy, H., and Gendron, Y. 2021.  “De -

ploying Narrative Economics to Understand Financial 

Market Dynamics: An Analysis of Activist Short Sellers’ 

Rhetoric.”  Contemporary Accounting Research  38(3): 

1809–1848. 

Peña, P., Moyano, D., Dunstan, J., and Rufs, C. 2023. 

“Digital Gendered Violence in Chile: Development of a 

System for Report, Monitoring and Response-Orienta -

tion Based on a Feminist Chatbot| Sofia.” In  Inteligencia 

Artificial Feminista: hacia una agenda de investigación 

para América Latina y el Caribe.  Pasto, Colombia: Fun -

dación Vía Libre. 

Peng, H., Teplitskiy, M., Romero, D. M., and Horvát, 

E.-Á. 2022.  “The Gender Gap in Scholarly Self-Promo -

tion on Social Media.”  arXiv preprint arXiv:2206.05330 .

Pesando, L. M. 2022.  “Safer If Connected? Mobile 

Technology and Intimate Partner Violence.”  Demogra -

phy  59(2): 653–684. 

Pesando, L. M., and Qiyomiddin, K. 2023.  “Mobile 

Phones and Infant Health at Birth.”  PloS One  18(9): 

e0288089. 

Pilotto, A., Boi, R., and Petermans, J. 2018.  “Technol -

ogy in Geriatrics.”  Age and Ageing  47(6): 771–774. 

Pincock, K., Betts, A., and Easton-Calabria, E. 2021. 

“The Rhetoric and Reality of Localisation: Refugee-Led 

Organisations in Humanitarian Governance.”  The Jour -

nal of Development Studies  57(5): 719–734. 

Plan International. 2020.  “State of the World’s Girls 

2020: Free to Be Online?” https://plan-international. 

org/publications/free-to-be-online/. Accessed 28 April 

2025. 

Poole, L. 2018.  “Transforming the Humanitarian Fi -

nancing Landscape.” NEAR Network Strategy Pa -

per, Network for Empowered Aid Response, Nairobi. 

http://near.ngo/imgtemp/downloadfile/NEAR%20 

Network%20Pooled%20Funding%20Strategy20 .

Prince, J. T., and Wallsten, S. 2022.  “How Much Is Pri -

vacy Worth around the World and across Platforms?” 

Journal of Economics & Management Strategy  31(4): 

841–861. 

Raghavan, M. 2023.  “What Should We Do When Our 

Ideas of Fairness Conflict?”  Communications of the 

ACM  67(1): 88–97. 

Raja, D. S. 2016.  “Bridging the Disability Divide through 

Digital Technologies.” Background paper for the World 

Development Report 2016, World Bank, Washington, 

DC. 

Raji, I. D., Bender, E. M., Paullada, A., Denton, 

E., and Hanna, A. 2021.  “AI and the Everything in 

the Whole Wide World Benchmark.”  arXiv preprint 

arXiv:2111.15366 .

Rani, U., Castel-Branco, R., Satija, S., and Nayar, M. 

2022.  Women, Work, and the Digital Economy . Taylor 

& Francis. 25 0 HUMAN DEVELOPMENT REPORT 2025 

Raymond, N., and Al Achkar, Z. 2016.  “Data Pre -

paredness: Connecting Data, Decision-Making and Hu -

manitarian Response.” Harvard Humanitarian Initiative: 

Signal Program on Human Security and Technology-

Standards and Ethics Series 1. 

Rodríguez-Modroño, P., Agenjo-Calderón, A., and 

López-Igual, P. 2022.  “Platform Work in the Domestic 

and Home Care Sector: New Mechanisms of Invisibility 

and Exploitation of Women Migrant Workers.”  Gender & 

Development  30(3): 619–635. 

Roepstorff, K. 2020.  “A Call for Critical Reflection on 

the Localisation Agenda in Humanitarian Action.”  Third 

World Quarterly  41(2): 284–301. 

Roos, M., and Reccius, M. 2024.  “Narratives in Eco -

nomics.”  Journal of Economic Surveys  38(2): 303–341. 

Rosman, L., Lampert, R., Zhuo, S., Li, Q., Varma, N., 

Burg, M., Gaffey, A. E., Armbruster, T., and Gehi, A. 

2024.  “Wearable Devices, Health Care Use, and Psy -

chological Well-Being in Patients with Atrial Fibrilla -

tion.”  Journal of the American Heart Association  13(15): 

e033750. 

Rossiter, M. W. 1993.  “The Matthew Matilda Effect in 

Science.”  Social Studies of Science  23(2): 325–341. 

Rotondi, V., Kashyap, R., Pesando, L. M., Spinelli, S., 

and Billari, F. C. 2020.  “Leveraging Mobile Phones to 

Attain Sustainable Development.”  Proceedings of the 

National Academy of Sciences  117(24): 13413–13420. 

Rubeis, G. 2020.  “The Disruptive Power of Artificial 

Intelligence: Ethical Aspects of Gerontechnology in 

Elderly Care.”  Archives of Gerontology and Geriatrics 

91: 104186. 

Sadowski, J. 2019.  “When Data Is Capital: Datafication, 

Accumulation, and Extraction.”  Big Data & Society  6(1): 

2053951718820549. 

Salvagni, J., Grohmann, R., and Matos, É. 2022. 

“Gendering Platform Co-Operativism: The Rise of 

Women-Owned Rider Co-Operatives in Brazil and 

Spain.”  Gender & Development  30(3): 707–724. 

Samuel, R. 1977.  “Workshop of the World: Steam Pow -

er and Hand Technology in Mid-Victorian Britain.”  His -

tory Workshop Journal  3(1): 6–72. 

Sandvik, K. B. 2023.  Humanitarian Extractivism: The 

Digital Transformation of Aid.  Manchester, UK: Man -

chester University Press. 

Sartori, L., and Theodorou, A. 2022.  “A Sociotech -

nical Perspective for the Future of AI: Narratives, In -

equalities, and Human Control.”  Ethics and Information 

Technology  24(1): 4. 

Schenkenberg van Mierop, E., Montemurro, M., 

Wendt, K., and Lilly, D. 2020.  “Consultancy on Risk 

Sharing.” Discussion Paper, HERE-Geneva.  https://here-

geneva.org/wp-content/uploads/2020/12/HERE_NL-

ICRC_Risk-Sharing-Report-1.pdf .

Schwiter, K., and Steiner, J. 2020.  “Geographies of 

Care Work: The Commodification of Care, Digital Care 

Futures and Alternative Caring Visions.”  Geography 

Compass  14(12): e12546. 

Security Hero. 2023.  “2023 State of Deepfakes: Reali -

ties, Threats and Impact.” https://www.securityhero.io/ 

state-of-deepfakes/. Accessed 28 April 2025. 

Seldon, A., Abidoye, O., and Metcalf, T. 2020.  The 

Fourth Education Revolution Reconsidered: Will Artifi -

cial Intelligence Enrich or Diminish Humanity?  Legend 

Press Ltd. 

Sen, A. 2001.  Development as Freedom Oxford Pa -

perbacks . Clarendon Press: Oxford, UK. 

Sen, A. 2013.  “The Ends and Means of Sustainability.” 

Journal of Human Development and Capabilities  14(1): 

6–20. 

Sen, A. 2017.  “Well-Being, Agency and Freedom the 

Dewey Lectures 1984.”  Justice and the Capabilities Ap -

proach.  Routledge. 

Seo, W., Yuan, Z., and Bu, Y. 2025.  “Valuesrag: 

Enhancing Cultural Alignment through Retrieval-

Augmented Contextual Learning.”  arXiv preprint 

arXiv:2501.01031 .

Sheikh, M. M. R., and Rogers, M. M. 2024.  “Technol -

ogy-Facilitated Sexual Violence and Abuse in Low and 

Middle-Income Countries: A Scoping Review.”  Trauma, 

Violence, & Abuse  25(2): 1614–1629. 

Shew, A. 2020.  “Ableism, Technoableism, and Future 

AI.”  IEEE Technology and Society Magazine  39(1): 

40–85. 

Shiller, R. J. 2020.  Narrative Economics: How Stories 

Go Viral and Drive Major Economic Events.  Princedon, 

NJ: Princeton University Press. 

Sibiya, W., and du Toit, D. 2022.  “Sweeping up De -

cent Work: Paid Domestic Work and Digital Platforms in 

South Africa.”  Gender & Development  30(3): 637–654. 

Slupska, J., and Tanczer, L. M. 2021.  “Threat Mod -

eling Intimate Partner Violence: Tech Abuse as a 

Cybersecurity Challenge in the Internet of Things.” In 

Bailey, J., Flynn, A. and Henry, N. (Eds.),  The Emerald 

International Handbook of Technology-Facilitated 

Violence and Abuse.  Leeds, UK: Emerald Publishing 

Limited. 

Smith, E. M., Graham, D., Morgan, C., and MacLach -

lan, M. 2023.  “Artificial Intelligence and Assistive Tech -

nology: Risks, Rewards, Challenges, and Opportuni -

ties.”  Assistive Technology  35(5): 375–377. 

Solaiman, I., and Dennison, C. 2021.  “Process for 

Adapting Language Models to Society (Palms) with 

Values-Targeted Datasets.”  Advances in Neural Infor -

mation Processing Systems  34: 5861–5873. 

Song, Y., Wang, X., and Li, G. 2024.  “Can Social Me -

dia Combat Gender Inequalities in Academia? Measur -

ing the Prevalence of the Matilda Effect in Communica -

tion.”  Journal of Computer-Mediated Communication 

29(1): zmad050. 

Spiel, K., Frauenberger, C., Keyes, O., and Fitzpat -

rick, G. 2019.  “Agency of Autistic Children in Technol -

ogy Research: A Critical Literature Review.”  ACM Trans -

actions on Computer-Human Interaction (TOCHI)  26(6): 

1–40. 

Stein, M. A., and Lazar, J. 2021.  Accessible Technol -

ogy and the Developing World.  Oxford, UK: Oxford 

University Press. 

Stoet, G., and Geary, D. C. 2022.  “Sex Differences 

in Adolescents’ Occupational Aspirations: Variations 

across Time and Place.”  Plos one  17(1): e0261438. 

Stypinska, J. 2023.  “AI Ageism: A Critical Roadmap 

for Studying Age Discrimination and Exclusion in Digi -

talized Societies.”  AI & Society  38(2): 665–677. 

Suresh, H., and Guttag, J. 2021.  “A Framework for Un -

derstanding Sources of Harm Throughout the Machine 

Learning Life Cycle.”  Proceedings of the 1st ACM Con -

ference on Equity and Access in Algorithms, Mecha -

nisms, and Optimization , 1–9. 

Swift, H. J., and Chasteen, A. L. 2021.  “Ageism in the 

Time of Covid-19.”  Group Processes & Intergroup Rela -

tions  24(2): 246–252. 

Tandon, A., and Rathi, A. 2021.  “Fault Lines at the 

Front Lines: Care Work and Digital Platforms in South 

and Southeast Asia.” Friedrich Ebert Stiftung. 

Tandon, A., and Sekharan, A. 2022.  “Labouring (on) 

the App: Agency and Organisation of Work in the 

Platform Economy.”  Gender & Development  30(3): 

687–706. 

The Alan Turing Institute and The Ada Lovelace In -

stitute. 2024.  “How Do People Feel About AI: A Na -

tionally Representative Survey of the British Public.” 

The Economist Intelligence Unit. 2021.  “Measuring 

the Prevalence of Online Violence against Women.” 

Ticona, J., and Mateescu, A. 2018.  “Trusted Strang -

ers: Carework Platforms’ Cultural Entrepreneurship in 

the on-Demand Economy.”  New Media & Society  20(11): 

4384–4404. 

Toupin, S. 2024.  “Shaping Feminist Artificial Intelli -

gence.”  New Media & Society  26(1): 580–595. 

Touzet, C. 2023.  “Using AI to Support People with Dis -

ability in the Labour Market: Opportunities and Chal -

lenges.” Paris: OECD Publishing. 

Treiman, L. S., Ho, C.-J., and Kool, W. 2024.  “The 

Consequences of AI Training on Human Decision-

Making.”  Proceedings of the National Academy of Sci -

ences  121(33): e2408731121. 

Tronto, J. 2020.  Moral Boundaries: A Political Argu -

ment for an Ethic of Care.  Routledge. 

Umbach, R., Henry, N., Beard, G. F., and Berryessa, 

C. M. 2024.  “Non-Consensual Synthetic Intimate Imag -

ery: Prevalence, Attitudes, and Knowledge in 10 Coun -

tries.”  Proceedings of the 2024 CHI Conference on Hu -

man Factors in Computing Systems , 1–20. 

UN (United Nations). 2024.  “Transforming Care Sys -

tems in the Context of the Sustainable Development 

Goals and Our Common Agenda.” New York. 

UNDESA (United Nations Department of Economic 

and Social Affairs). 2024.  “Disability and Develop -

ment Report 2024: Accelerating the Realisation of the 

Sustainable Development Goals by, for, and with Per -

sons with Disabilities.” New York. REFERENCES  251 

UNDP (United Nations Development Programme). 

2023.  “2023 Gender Social Norms Index (Gsni): 

Breakingdown Gender Biases: Shifting Social Norms 

Towards Gender Equality.” New York: Human Develop -

ment Report Office. 

UNESCO (United Nations Educational Scientific 

and Cultural Organization). 2020.  “Online Violence 

against Women Journalists: A Global Snapshort of In -

cidence and Impacts.” Paris. 

UNESCO (United Nations Educational Scientific and 

Cultural Organization). 2021.  “The Race against Time 

for Smarter Development.” Paris. 

UNESCO (United Nations Educational Scientific and 

Cultural Organization). 2023.  “Your Opinion Does 

Not Matter Anyway: Exposing Technology-Facilitated 

Gender-Based Violence in an Era of Generative AI.” 

Paris. 

UNESCO (United Nations Educational Scientific and 

Cultural Organization). 2024a.  “The Gender Gap in 

Science: Status and Trends, February 2024.” Paris. 

UNESCO (United Nations Educational Scientific and 

Cultural Organization). 2024b.  “Technology on Her 

Terms.” Paris. 

UNESCO (United Nations Educational Scientific and 

Cultural Organization). 2024c.  “UNESCO Women for 

Ethical AI: Outlook Study on Artificial Intelligence and 

Gender.” Paris. 

UN Women (United Nations Entity for Gender Equal -

ity and the Empowerment of Women). 2023.  “Path -

ways Towards Decent Work in the Digitally-Enabled 

Care Economy.” New York. 

UN Women (United Nations Entity for Gender Equal -

ity and the Empowerment of Women) and WHO 

(World Health Organization). 2023.  “Technology-

Facilitated Violence against Women: Taking Stock of 

Evidence and Data Collection.” New York. 

Valencia, S., Cave, R., Kallarackal, K., Seaver, K., 

Terry, M., and Kane, S. K. 2023.  “‘The Less I Type, the 

Better:’ How AI Language Models Can Enhance or Im -

pede Communication for AAC Users.”  Proceedings of 

the 2023 CHI Conference on Human Factors in Com -

puting Systems , 1–14. 

van der Weij, T., Hofstätter, F., Jaffe, O., Brown, S. 

F., and Ward, F. R. 2024.  “AI Sandbagging: Language 

Models Can Strategically Underperform on Evalua -

tions.”  arXiv preprint arXiv:2406.07358 .

Vásárhelyi, O., Zakhlebin, I., Milojević, S., and Hor -

vát, E.-Á. 2021.  “Gender Inequities in the Online Dis -

semination of Scholars’ Work.”  Proceedings of the Na -

tional Academy of Sciences  118(39): e2102945118. 

Vergeer, M. 2020.  “Artificial Intelligence in the Dutch 

Press: An Analysis of Topics and Trends.”  Communicat -

ing Artificial Intelligence (AI).  Routledge. 

Vidgen, B., Agrawal, A., Ahmed, A. M., Akinwande, 

V., Al-Nuaimi, N., Alfaraj, N., Alhajjar, E., and others. 

2024.  “Introducing V0.5 of the AI Safety Benchmark 

from Mlcommons.”  arXiv preprint arXiv:2404.12241 .

Voinea, C., Wangmo, T., and Vică, C. 2024.  “Pater -

nalistic AI: The Case of Aged Care.”  Humanities and 

Social Sciences Communications  11(1): 1–9. 

Wajcman, J. 2010.  “Feminist Theories of Technology.” 

Cambridge Journal of Economics  34(1): 143–152. 

Wall, I., and Hedlund, K. 2016.  “Localisation and Lo -

cally-Led Crisis Response: A Literature Review.” Local 

to Global Protection (L2GB). Swiss Agency for Develop -

ment and Cooperation. 

Wang, A., Hertzmann, A., and Russakovsky, O. 2024. 

“Benchmark Suites Instead of Leaderboards for Evalu -

ating AI Fairness.”  Patterns  5(11). 

Wang, B., Chen, W., Pei, H., Xie, C., Kang, M., Zhang, 

C., Xu, C., and others. 2023.  “DecodingTrust: A Com -

prehensive Assessment of Trustworthiness in GPT 

Models.” NeurIPS. 

Watson, D. S., Mökander, J., and Floridi, L. 2024. 

“Competing Narratives in AI Ethics: A Defense of So -

ciotechnical Pragmatism.”  AI & society : 1–23. 

WebAim. 2024.  “The WebAim Million.” 

WEF (World Economic Forum). 2023.  “Global Gender 

Gap Report 2023.” 

Weidinger, L., Rauh, M., Marchal, N., Manzini, A., 

Hendricks, L. A., Mateos-Garcia, J., Bergman, S., 

and others. 2023.  “Sociotechnical Safety Evaluation of 

Generative AI Systems.”  arXiv preprint arXiv:2310.11986 .

WHO (World Health Organization). 2022.  “Ageism in 

Artificial Intelligence for Health.” Geneva. 

WHO (World Health Organization) and UNICEF 

(United Nations Children’s Fund). 2022.  Global Re -

port on Assistive Technology.  Geneva: WHO. 

Winner, L. 2017.  “Do Artifacts Have Politics?”  Computer 

Ethics.  London: Routledge. 

WIPO (World Intellectual Property Organization). 

2021.  “WIPO Technology Trends 2021: Assistive Tech -

nology.” https://www.wipo.int/publications/en/details. 

jsp?id=4541. Accessed 28 April 2025. 

Wright, J. 2023a.  “Inside Japan’s Long Experiment in 

Automating Elder Care.”  MIT Technology Review .

Wright, J. 2023b.  Robots Won’t Save Japan: An Eth -

nography of Eldercare Automation.  Cornell University 

Press. 

Wu, D. 2021.  “Cripping the History of Computing.”  IEEE 

Annals of the History of Computing  43(3): 68–72. 

Yew, G. C. K. 2021.  “Trust in and Ethical Design of 

Carebots: The Case for Ethics of Care.”  International 

Journal of Social Robotics  13(4): 629–645. 

Young, E., Wajcman, J., and Sprejer, L. 2023.  “Mind 

the Gender Gap: Inequalities in the Emergent Pro -

fessions of Artificial Intelligence (AI) and Data Sci -

ence.”  New Technology, Work and Employment  38(3): 

391–414. 

ZainEldin, H., Gamel, S. A., Talaat, F. M., Aljohani, M., 

Baghdadi, N. A., Malki, A., Badawy, M., and Elhos -

seini, M. A. 2024.  “Silent No More: A Comprehensive 

Review of Artificial Intelligence, Deep Learning, and 

Machine Learning in Facilitating Deaf and Mute Com -

munication.”  Artificial Intelligence Review  57(7): 188. 

Zhao, Y., Wang, B., and Wang, Y. 2025.  “Explicit 

Vs. Implicit: Investigating Social Bias in Large Lan -

guage Models through Self-Reflection.”  arXiv preprint 

arXiv:2501.02295 .

Zhuang, K. V., and Goggin, G. 2024.  “New Possibili -

ties or Problems for Disability and Inclusion? The Case 

of AI and ADMs across Work.”  Telematics and Informat -

ics : 92: 102156. 

Zundl, E., and Rodgers, Y. v. d. M. 2021.  “The Future 

of Work for Domestic Workers in the United States: In -

novations in Technology, Organizing, and Laws.” Work -

ing Paper 2021-3, Rutgers School of Management and 

Labor Relations, Piscataway, NJ. 

CHAPTER 5 

Abid, A., Farooqi, M., and Zou, J. 2021.  “Persistent 

Anti-Muslim Bias in Large Language Models.”  Proceed -

ings of the 2021 AAAI/ACM Conference on AI, Ethics, 

and Society , 298–306. 

Acemoğlu, D. 2024.  “Harms of AI.” In Bullock, J. B., 

Chen, Y.-C., Himmelreich, J., Hudson, V. M., Korinek, A., 

Young, M. M. and Zhang, B., (eds.),  The Oxford Hand -

book of AI Governance.  Oxford University Press. 

Acemoğlu, D., Fallah, A., Makhdoumi, A., Malekian, 

A., and Ozdaglar, A. 2023.  “How Good Are Privacy 

Guarantees? Platform Architecture and Violation of 

User Privacy.” Working Paper 31413, National Bureau of 

Economic Research, Cambridge, MA. 

Acemoğlu, D., and Johnson, S. 2023.  Power and 

Progress: Our Thousand-Year Struggle over Technol -

ogy and Prosperity.  New York: PublicAffairs. 

Acemoğlu, D., Makhdoumi, A., Malekian, A., and 

Ozdaglar, A. 2022.  “Too Much Data: Prices and Ineffi -

ciencies in Data Markets.”  American Economic Journal: 

Microeconomics  14(4): 218–56. 

Acemoğlu, D., Makhdoumi, A., Malekian, A., and Oz -

daglar, A. 2024.  “When Big Data Enables Behavioral 

Manipulation.”  American Economic Review: Insights .

Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, 

I., Aleman, F. L., Almeida, D., and others. 2023.  “GPT-

4 Technical Report.”  arXiv preprint arXiv:2303.08774 .

Aelst, P. 2017.  “Political Communication in a High-

Choice Media Environment: A Challenge for Democ -

racy?”  Annals of the International Communication As -

sociation  40(1): 3–27. 

Agan, A. Y., Davenport, D., Ludwig, J., and Mullaina -

than, S. 2023.  “Automating Automaticity: How the Con -

text of Human Choice Affects the Extent of Algorithmic 

Bias.” Working Paper 30981, National Bureau of Eco -

nomic Research, Cambridge, MA. 

Agarwal, A., Usunier, N., Lazaric, A., and Nickel, M. 

2024.  “System-2 Recommenders: Disentangling Util -

ity and Engagement in Recommendation Systems Via 

Temporal Point-Processes.”  The 2024 ACM Confer -

ence on Fairness, Accountability, and Transparency ,

1763–1773. 

AIPI (AI Preparedness Index). 2025.  AI Preparedness 

Index . International Monetary Fund. 25 2 HUMAN DEVELOPMENT REPORT 2025 

Aldasoro, I., Gambacorta, L., Korinek, A., Shreeti, V., 

and Stein, M. 2024.  Intelligent Financial System: How 

AI Is Transforming Finance.  Bank for International Set -

tlements, Monetary and Economic Department. 

Anderson, E. 2001.  “Symposium on Amartya Sen’s Phi -

losophy: 2 Unstrapping the Straitjacket of ‘Preference’: 

A Comment on Amartya Sen’s Contributions to Philoso -

phy and Economics.”  Economics and Philosophy  17(1): 

21–38. 

Andreoni, M., Lunardi, W. T., Lawton, G., and Thak -

kar, S. 2024.  “Enhancing Autonomous System Security 

and Resilience with Generative AI: A Comprehensive 

Survey.”  IEEE Access  12: 109470–109493. 

Argyle, L. P., Bail, C. A., Busby, E. C., Gubler, J. R., 

Howe, T., Rytting, C., Sorensen, T., and Wingate, D. 

2023.  “Leveraging AI for Democratic Discourse: Chat 

Interventions Can Improve Online Political Conversa -

tions at Scale.”  Proceedings of the National Academy 

of Sciences  120(41): e2311627120. 

Aridor, G., Jiménez-Durán, R., Levy, R. e., and Song, 

L. 2024.  “The Economics of Social Media.”  Journal of 

Economic Literature  62(4): 1422–74. 

Askari, H., Chhabra, A., von Hohenberg, B. C., He -

seltine, M., and Wojcieszak, M. 2024.  “Incentivizing 

News Consumption on Social Media Platforms Using 

Large Language Models and Realistic Bot Accounts.” 

PNAS Nexus  3(9). 

Atari, M., Xue, M. J., Park, P. S., Blasi, D., and Hen -

rich, J. 2025.  “Which Humans?”  PsyArXiv . https:// 

psyarxiv.com/5b26t. 

Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., 

Shariff, A., Bonnefon, J.-F., and Rahwan, I. 2018.  “The 

Moral Machine Experiment.”  Nature  563(7729): 59–64. 

Bak-Coleman, J. B., Alfano, M., Barfuss, W., Berg -

strom, C. T., Centeno, M. A., Couzin, I. D., Donges, 

J. F., and others. 2021.  “Stewardship of Global Collec -

tive Behavior.”  Proceedings of the National Academy 

of Sciences  118(27): e2025764118. 

Bang, Y., Chen, D., Lee, N., and Fung, P. 2024. 

“Measuring Political Bias in Large Language Mod -

els: What Is Said and How It Is Said.”  arXiv preprint 

arXiv:2403.18932 .

Bashir, N., Donti, P., Cuff, J., Sroka, S., Ilic, M., Sze, 

V., Delimitrou, C., and Olivetti, E. 2024.  “The Climate 

and Sustainability Implications of Generative AI.” An 

MIT Exploration of Generative AI. 

Bengio, Y., Daniel, P., Tamay, B., Rishi, B., Stephen, 

C., Yejin, C., Danielle, G., and others. 2025.  “Interna -

tional Scientific Report on the Safety of Advanced AI.” 

Department for Science, Innovation and Technology, 

Government of the United Kingdom. 

Bengio, Y., Hinton, G., Yao, A., Song, D., Abbeel, P., 

Darrell, T., Harari, Y. N., and others. 2024.  “Manag -

ing Extreme AI Risks Amid Rapid Progress.”  Science 

384(6698): 842–845. 

Benn, C., and Lazar, S. 2022.  “What’s Wrong with Au -

tomated Influence.”  Canadian Journal of Philosophy 

52(1): 125–148. 

Bernstein, D. 2024.  Who Is Winning the AI Arms Race? 

Bernstein, M., Christin, A., Hancock, J., Hashimoto, 

T., Jia, C., Lam, M., Meister, N., and others. 2023. 

“Embedding Societal Values into Social Media Algo -

rithms.”  Journal of Online Trust and Safety  2(1). 

Besbes, O., Kanoria, Y., and Kumar, A. 2024.  “The 

Fault in Our Recommendations: On the Perils of Optimiz -

ing the Measurable.”  arXiv preprint arXiv:2405.03948 .

Bhatia, S., Galesic, M., and Mitchell, M. 2024.  “Edito -

rial for the Special Issue on Algorithms in Our Lives.” 

Perspectives on Psychological Science  19(5): 707–710. 

Bommasani, R., Kapoor, S., Klyman, K., Longpre, S., 

Ramaswami, A., Zhang, D., Schaake, M., and others. 

2024.  “Considerations for Governing Open Founda -

tion Models.”  Science  386(6718): 151–153. 

Bowen, T. R., Dmitriev, D., and Galperti, S. 2023. 

“Learning from Shared News: When Abundant Informa -

tion Leads to Belief Polarization.”  The Quarterly Journal 

of Economics  138(2): 955–1000. 

Bradford, A. 2020.  The Brussels Effect: How the Euro -

pean Union Rules the World.  Oxford University Press. 

Bradford, A. 2024.  “The False Choice between Digital 

Regulation and Innovation.”  Northwestern University 

Law Review  119: 377. 

Bradford, A., Waxman, M. C., and Li, E. 2024. 

“How Domestic Institutions Shape the Global 

Tech War.” https://papers.ssrn.com/sol3/papers. 

cfm?abstract_id=4954744. 

Brennan, J. 2016.  Against Democracy.  Princeton Uni -

versity Press. 

Browne, R. 2024.  “Why Big Tech Is Turning to Nuclear 

to Power Its Energy-Intensive AI Ambitions.”  CNBC , 16 

October. 

Burton, J. W., Lopez-Lopez, E., Hechtlinger, S., Rah -

wan, Z., Aeschbach, S., Bakker, M. A., Becker, J. A., 

and others. 2024.  “How Large Language Models Can 

Reshape Collective Intelligence.”  Nature Human Be -

haviour  8(9): 1643–1655. 

Caliskan, A., Bryson, J. J., and Narayanan, A. 2017. 

“Semantics Derived Automatically from Language Cor -

pora Contain Human-Like Biases.”  Science  356(6334): 

183–186. 

Cao, Y., Zhou, L., Lee, S., Cabello, L., Chen, M., and 

Hershcovich, D. 2023.  “Assessing Cross-Cultural 

Alignment between ChatGPT and Human Societies: An 

Empirical Study.”  arXiv preprint arXiv:2303.17466 .

Carlsmith, J. 2022.  “Is Power-Seeking AI an Existential 

Risk?”  arXiv preprint arXiv:2206.13353 .

Carvalho, J.-P. 2025.  “The Political-Economic Risks of 

AI.” Department of Economics Discussion Paper Series, 

University of Oxford. 

Catena, E., Tummolini, L., and Santucci, V. G. 2025. 

“Human Autonomy with AI in the Loop.”  Philosophical 

Psychology : 1–28. 

Caton, S., and Haas, C. 2024.  “Fairness in Machine 

Learning: A Survey.”  ACM Computing Surveys  56(7): 

Article 166. 

Cerf, V. G. 2024.  “The Global Digital Compact.”  Com -

munications of the ACM  67(10): 5–5. 

Chandran, R. 2023.  “Indigenous Groups in NZ, US 

Fear Colonization as AI Learns Their Languages.”  Re -

uters , 3 April. 

Chen, C., and Zheng, Y. 2024.  “When Consumers 

Need More Interpretability of Artificial Intelligence (AI) 

Recommendations? The Effect of Decision-Making 

Domains.”  Behaviour & Information Technology  43(14): 

3481–3489. 

Chen, D., Chen, Y., Rege, A., and Vinayak, R. K. 

2024.  “PAL: Pluralistic Alignment Framework for Learn -

ing from Heterogeneous Preferences.”  arXiv preprint 

arXiv:2406.08469 .

Cho, J., Cokely, E. T., Ramasubramanian, M., Al -

lan, J. N., Feltz, A., and Garcia-Retamero, R. 2024. 

“Numeracy Does Not Polarize Climate Change Judg -

ments: Numerate People Are More Knowledgeable 

and Knowledge Is Power.”  American Psychological As -

sociation  11(2): 320–344. 

Christian, B. 2021.  The Alignment Problem: How Can 

Machines Learn Human Values?  New York: W.W. Nor -

ton & Company. 

Chronis, C., Varlamis, I., Himeur, Y., Sayed, A. N., 

Hasan, T. M. A.-., Nhlabatsi, A., Bensaali, F., and Dim -

itrakopoulos, G. 2024.  “A Survey on the Use of Fed -

erated Learning in Privacy-Preserving Recommender 

Systems.”  IEEE Open Journal of the Computer Society 

5: 227–247. 

Chun, Y., Hur, J., and Hwang, J. 2024.  “AI Technology 

Specialization and National Competitiveness.”  Plos one 

19(4): e0301091. 

Coeckelbergh, M. 2024.  Why AI Undermines Democ -

racy and What to Do About It.  Cambridge, UK: Polity 

Press. 

Cohen, M. K., Kolt, N., Bengio, Y., Hadfield, G. K., 

and Russell, S. 2024.  “Regulating Advanced Artificial 

Agents.”  Science  384(6691): 36–38. 

Comunale, M., and Manera, A. 2024.  “The Economic 

Impacts and the Regulation of AI: A Review of the Aca -

demic Literature and Policy Actions.” Working Paper 

2024/065, International Monetary Fund, Washington, 

DC. 

Costello, T. H., Pennycook, G., and Rand, D. G. 

2024.  “Durably Reducing Conspiracy Beliefs through 

Dialogues with AI.”  Science  385(6714): eadq1814. 

Crisanto, J., Leuterio, C., Prenio, J., and Yong, J. 

2024.  “Regulating AI in the Financial Sector: Recent 

Developments and Main Challenges.”  Bank for Interna -

tional Settlements, FSI Insights on Policy Implementa -

tion  (63). 

Cunningham, T., Pandey, S., Sigerson, L., Stray, J., 

Allen, J., Barrilleaux, B., Iyer, R., and others. 2024. 

“What We Know About Using Non-Engagement Signals 

in Content Ranking.”  arXiv preprint arXiv:2402.06831 .

Danry, V., Pataranutaporn, P., Mao, Y., and Maes, 

P. 2023.  “Don’t Just Tell Me, Ask Me: AI Systems 

That Intelligently Frame Explanations as Questions 

Improve Human Logical Discernment Accuracy over 

Causal AI Explanations.”  Proceedings of the 2023 CHI REFERENCES  2 5 3 

Conference on Human Factors in Computing Sys -

tems.  Hamburg, Germany: Association for Computing 

Machinery. 

Das, S., Stanton, R., and Wallace, N. 2023.  “Algorith -

mic Fairness.”  Annual Review of Financial Economics 

15: 565–593. 

Dennis, C. 2024.  “What Should Be Internationalised 

in AI Governance?” Oxford Martin AI Governance 

Initiative. 

Douek, E. 2022.  “Content Moderation as Systems 

Thinking.”  Harvard Law Review  136: 526. 

Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Ze -

mel, R. 2012.  “Fairness through Awareness.”  Proceed -

ings of the 3rd Innovations in Theoretical Computer 

Science Conference (ITCS 12) , 214–226. 

Editorial Board. 2025.  “The New Arms Race.” 

Epoch AI. 2024a.  “Computing Capacity.” Available from: 

https://epoch.ai/data-insights/computing-capacity. 

Epoch AI. 2024b.  “Leading AI Companies Have Hun -

dreds of Thousands of Cutting-Edge AI Chips.” 

Epoch AI. 2024c.  “Machine Learning Trends.” https:// 

epoch.ai/trends. 

Epoch AI. 2024d.  “Most Large-Scale Models Are 

Developed by US Companies.” https://epoch.ai/data-

insights/large-scale-models-by-country, accessed 29 

April 2025. 

Escobar, O., and Elstub, S. 2017.  “Forms of Mini-Pub -

lics.”  New Democracy .

European Commission. 2025.  “EU Launches InvestAI 

Initiative to Mobilise €200 Billion of Investment in Ar -

tificial Intelligence.” European Commission Press Re -

lease, 10 February. 

Fleck, A. 2024.  “Which Countries Have the Most 

Data Centers?” https://www.statista.com/chart/24149/ 

data-centers-per-country/. 

Floridi, L. 2024.  “Hypersuasion–on Ai’s Persua -

sive Power and How to Deal with It.”  Philosophy & 

Technology .

Fukuyama, F., Richman, B., Goel, A., Schaake, M., 

Katz, R., and Melamed, D. 2020.  “Report of the Work -

ing Group on Platform Scale.” Accessed 12 June 2022. 

Fulay, S., Brannon, W., Mohanty, S., Overney, C., 

Poole-Dayan, E., Roy, D., and Kabbara, J. 2024.  “On 

the Relationship between Truth and Political Bias in 

Language Models.”  arXiv preprint arXiv:2409.05283 .

Galaz, V. 2025.  Dark Machines: How Artificial Intelli -

gence, Digitalization and Automation Is Changing Our 

Living Planet.  Taylor & Francis. 

Galaz, V., Metzler, H., Schill, C., Lindahl, T., Daume, 

S., Marklund, A., Castro, A. J., and others. 2025.  “Ar -

tificial Intelligence, Digital Social Networks, and Climate 

Emotions.”  NPJ Climate Action  4(1): 23. 

Gallegos, I. O., Rossi, R. A., Barrow, J., Tanjim, M. 

M., Kim, S., Dernoncourt, F., Yu, T., Zhang, R., and 

Ahmed, N. K. 2024.  “Bias and Fairness in Large 

Language Models: A Survey.”  Computational Linguis -

tics  50(3): 1097–1179. 

Gambacorta, L., and Shreeti, V. 2025.  “The AI Sup -

ply Chain.” Working Paper 154, Bank for International 

Settlements. 

Gans, J. S. 2024.  “Market Power in Artificial Intelli -

gence.” Working Paper 32270, National Bureau of Eco -

nomic Research, Cambridge, MA. 

Geiselmann, R., Tsourgianni, A., Deroy, O., and Har -

ris, L. T. 2023.  “Interacting with Agents without a Mind: 

The Case for Artificial Agents.”  Current Opinion in Be -

havioral Sciences  51: 101282. 

Gentzkow, M., Shapiro, J. M., Yang, F., and Yuruko -

glu, A. 2024.  “Pricing Power in Advertising Markets: 

Theory and Evidence.”  American Economic Review 

114(2): 500–533. 

Glüer-Pagin, K., and Spectre, L. 2024.  “Where Is the 

Motivation in Motivated Numeracy?”  Review of Philoso -

phy and Psychology : 1–18. 

Glüer, K., and Wikforss, Å. 2022.  “What Is Knowledge 

Resistance?”  Knowledge Resistance in High-Choice In -

formation Environments.  Routledge. 

Goodin, R. E., and Spiekermann, K. 2018.  An Epis -

temic Theory of Democracy.  Oxford University Press. 

Gordon, E. C., and Seth, A. K. 2024.  “Ethical Con -

siderations for the Use of Brain–Computer Interfaces 

for Cognitive Enhancement.”  PLOS Biology  22(10): 

e3002899. 

Gorwa, R., Binns, R., and Katzenbach, C. 2020.  “Al -

gorithmic Content Moderation: Technical and Political 

Challenges in the Automation of Platform Governance.” 

Big Data & Society  7(1): 2053951719897945. 

Government of Mexico. 2020.  “Outcome Document 

of the High-Level Event ‘Making a Decade of Action for 

Indigenous Languages’ on the Occasion of the Closing 

of the 2019 International Year of Indigenous Languag -

es.” Government of Mexico. 

Green, J. 2024.  “Why Big Corporations Are Quietly 

Abandoning Their Climate Commitments?”  Forbes 

Digital Assets , 29 August. 

Habermas, J. 1984.  The Theory of Communicative Ac -

tion: Volume 1.  Boston, MA: Beacon Press. 

Hackenburg, K., and Margetts, H. 2024.  “Evaluating 

the Persuasive Influence of Political Microtargeting with 

Large Language Models.”  Proceedings of the National 

Academy of Sciences  121(24): e2403116121. 

Hackenburg, K., Tappin, B. M., Röttger, P., Hale, S. A., 

Bright, J., and Margetts, H. 2025.  “Scaling Language 

Model Size Yields Diminishing Returns for Single-Mes -

sage Political Persuasion.”  Proceedings of the National 

Academy of Sciences  122(10): e2413443122. 

Hagendorff, T. 2024.  “Mapping the Ethics of Genera -

tive AI: A Comprehensive Scoping Review.”  Minds and 

Machines  34(4): 39. 

Hampstead, J. P. 2024.  “Why AI Requires So Much 

Compute.” https://www.freightwaves.com/news/ 

why-ai-requires-so-much-compute. 

Han, T. A., Pereira, L. M., Santos, F. C., and Lenaerts, 

T. 2020.  “To Regulate or Not: A Social Dynamics Analy -

sis of an Idealised AI Race.”  Journal of Artificial Intel -

ligence Research  69: 881–921. 

Havaldar, S., Rai, S., Singhal, B., Liu, L., Guntuku, S. 

C., and Ungar, L. 2023.  “Multilingual Language Models 

Are Not Multicultural: A Case Study in Emotion.”  arXiv 

preprint arXiv:2307.01370 .

Ho, A., Besiroglu, T., Erdil, E., Owen, D., Rahman, R., 

Guo, Z. C., Atkinson, D., Thompson, N., and Sevilla, 

J. 2024.  “Algorithmic Progress in Language Models.” 

arXiv preprint arXiv:2403.05812 .

Ho, L., Barnhart, J., Trager, R., Bengio, Y., Brundage, 

M., Carnegie, A., Chowdhury, R., and others. 2023. 

“International Institutions for Advanced AI.”  arXiv pre -

print arXiv:2307.04699 .

Ho, T. D. H., and Nguyen, S. T. T. 2024.  “Self-Attentive 

Sequential Recommendation Models Enriched with 

More Features.”  Proceedings of the 2024 8th Interna -

tional Conference on Deep Learning Technologies.  As -

sociation for Computing Machinery. 

Hogg, L., DiResta, R., Fukuyama, F., Reisman, R., 

Keller, D., Ovadya, A., Thorburn, L., Stray, J., and 

Mathur, S. 2024.  “Shaping the Future of Social Media 

with Middleware.”  arXiv preprint arXiv:2412.10283 .

Huang, Y., and Xiong, D. 2023.  “CBBQ: A Chinese 

Bias Benchmark Dataset Curated with Human-Ai Col -

laboration for Large Language Models.”  arXiv preprint 

arXiv:2306.16244 .

International Panel on the Information Environment. 

2024.  “Trends in the Global Information Environment.” 

IPIE (International Panel on the Information Environ -

ment). 2024.  “Global Approaches to Auditing Artificial 

Intelligence: A Literature Review.” Zurich: IPIE. 

IPIE (International Panel on the Information Environ -

ment). 2025.  “Towards a Global AI Auditing Frame -

work: Assessment and Recommendations.” Zurich: IPIE. 

Irvine, R., Boubert, D., Raina, V., Liusie, A., Zhu, Z., 

Mudupalli, V., Korshuk, A., and others. 2023.  “Re -

warding Chatbots for Real-World Engagement with Mil -

lions of Users.”  arXiv preprint arXiv:2303.06135 .

ITU (International Telecommunication Union). 

2022.  “How AI Is Helping Revitalise Indigenous 

Languages.” https://www.itu.int/hub/2022/08/ 

ai-indigenous-languages-maori-te-reo/. 

Jia, C., Lam, M. S., Mai, M. C., Hancock, J. T., and 

Bernstein, M. S. 2024a.  “Embedding Democratic Val -

ues into Social Media AIs Via Societal Objective Func -

tions.”  Proceedings of the ACM: Human-Computer In -

teraction  8, CSCW1: Article 163. 

Jia, P., Du, Z., Wang, Y., Zhao, X., Li, X., Wang, Y., 

Liu, Q., Guo, H., and Tang, R. 2024b.  “AltFS: Agency-

Light Feature Selection with Large Language Mod -

els in Deep Recommender Systems.”  arXiv preprint 

arXiv:2412.08516 .

Jigsaw. 2024.  “Announcing Experimental Bridging At -

tributes in Perspective API.” Available from: https://me -

dium.com/jigsaw/announcing-experimental-bridging-

attributes-in-perspective-api-578a9d59ac37. 25 4 HUMAN DEVELOPMENT REPORT 2025 

Jobin, A., Ienca, M., and Vayena, E. 2019.  “The Global 

Landscape of AI Ethics Guidelines.”  Nature Machine 

Intelligence  1(9): 389–399. 

Kahan, D. M. 2015.  “The Politically Motivated Reason -

ing Paradigm.”  Emerging Trends in Social & Behavioral 

Sciences,  forthcoming. 

Kaplan, D. M., Palitsky, R., Arconada Alvarez, S. J., 

Pozzo, N. S., Greenleaf, M. N., Atkinson, C. A., and 

Lam, W. A. 2024.  “What’s in a Name? Experimental 

Evidence of Gender Bias in Recommendation Letters 

Generated by ChatGPT.”  Journal of Medical Internet 

Research  26: e51837. 

Kapoor, S., Bommasani, R., Klyman, K., Longpre, S., 

Ramaswami, A., Cihon, P., Hopkins, A., and others. 

2024a.  “On the Societal Impact of Open Foundation 

Models.”  arXiv preprint arXiv:2403.07918 .

Kapoor, S., and Narayanan, A. 2024.  “We Looked at 

78 Election Deepfakes: Political Misinformation Is Not 

an AI Problem.” Available from: https://knightcolumbia. 

org/blog/we-looked-at-78-election-deepfakes-political-

misinformation-is-not-an-ai-problem. Accessed April 

2025. 

Kapoor, S., Stroebl, B., Siegel, Z. S., Nadgir, N., and 

Narayanan, A. 2024b.  “AI Agents That Matter.”  arXiv 

preprint arXiv:2407.01502 .

Kazienko, P., and Cambria, E. 2024.  “Toward Respon -

sible Recommender Systems.”  IEEE Intelligent Systems 

39(3): 5–12. 

Kemp, S. 2025.  “Digital 2025: Global Overview Re -

port.” DataReportal. 

Kerry, C. F., Meltzer, J. P., Renda, A., and Wyckoff, A. 

W. 2025.  “Network Architecture for Global AI Policy.” 

The Brookings Institute. https://www.brookings.edu/ 

articles/network-architecture-for-global-ai-policy/. 

Kim, Y., Park, C., Jeong, H., Chan, Y. S., Xu, X., 

McDuff, D., Lee, H., and others. 2025.  “Mdagents: An 

Adaptive Collaboration of Llms for Medical Decision-

Making.”  Advances in Neural Information Processing 

Systems  37: 79410–79452. 

Kim, Y., Park, C., Jeong, H., Grau-Vilchez, C., Chan, 

Y. S., Xu, X., McDuff, D., and others. 2024.  “A Demon -

stration of Adaptive Collaboration of Large Language 

Models for Medical Decision-Making.”  arXiv preprint 

arXiv:2411.00248 .

Kirkby-McLeod, L. 2023.  “How Will ChatGPT Impact 

Te Reo Māori? Data Sovereignty Experts Weigh In.” 

https://www.rnz.co.nz/news/te-manu-korihi/491925/ 

how-will-chatgpt-impact-te-reo-maori-data-sovereign -

ty-experts-weigh-in. 

Kleinberg, J., Ludwig, J., Mullainathan, S., and 

Raghavan, M. 2024.  “The Inversion Problem: Why 

Algorithms Should Infer Mental State and Not Just Pre -

dict Behavior.”  Perspectives on Psychological Science 

19(5): 827–838. 

Kleinberg, J., Mullainathan, S., and Raghavan, M. 

2024.  “The Challenge of Understanding What Users 

Want: Inconsistent Preferences and Engagement Op -

timization.”  Management Science  70(9): 6336–6355. 

Korero Maori. 2025.  “Korero Maori.” https://korero -

maori.com/. 

Korinek, A., and Vipra, J. 2024a.  “Concentrating Intel -

ligence: Scaling and Market Structure in Artificial Intel -

ligence.”  Economic Policy  40(121): 225–256. 

Korinek, A., and Vipra, J. 2024b.  “Market Concen -

tration Implications of Foundation Models: The Invis -

ible Hand of ChatGPT.” Washington, DC: Brookings 

Institution. 

Kosinski, M. 2024.  “Evaluating Large Language Mod -

els in Theory of Mind Tasks.”  Proceedings of the Na -

tional Academy of Sciences  121(45): e2405460121. 

Kozyreva, A., Herzog, S. M., Lewandowsky, S., Her -

twig, R., Lorenz-Spreen, P., Leiser, M., and Reifler, J. 

2023.  “Resolving Content Moderation Dilemmas be -

tween Free Speech and Harmful Misinformation.”  Pro -

ceedings of the National Academy of Sciences  120(7): 

e2210666120. 

Kozyreva, A., Lorenz-Spreen, P., Herzog, S. M., Ecker, 

U. K., Lewandowsky, S., Hertwig, R., Ali, A., and oth -

ers. 2024.  “Toolbox of Individual-Level Interventions 

against Online Misinformation.”  Nature human behav -

iour  8(6): 1044–1052. 

Kurz, M. 2023.  The Market Power of Technology: Un -

derstanding the Second Gilded Age.  New York: Colum -

bia University Press. 

Lai, V., Carton, S., Bhatnagar, R., Liao, Q. V., Zhang, 

Y., and Tan, C. 2022.  Human-AI Collaboration Via Con -

ditional Delegation: A Case Study of Content Modera -

tion.  Proceedings of the 2022 CHI Conference on Hu -

man Factors in Computing Systems.  New Orleans, LA: 

Association for Computing Machinery. 

Lancieri, F., Edelson, L., and Bechtold, S. 2024.  “AI 

Regulation: Competition, Arbitrage & Regulatory Cap -

ture.” Center for Law & Economics Working Paper Se -

ries 11. 

Landemore, H. 2012.  “Democratic Reason: Politics, 

Collective Intelligence, and the Rule of the Many.” 

Landemore, H. 2022.  “Can AI Bring Deliberative De -

mocracy to the Masses.” HAI Weekly Seminar, Working 

Paper. 

Lazar, S. 2024a.  “Automatic Authorities: Power and AI.” 

arXiv preprint arXiv:2404.05990 .

Lazar, S. 2024b.  “Frontier AI Ethics: Anticipating and 

Evaluating the Societal Impacts of Generative Agents.” 

arXiv preprint arXiv:2404.06750 .

Lazar, S. 2024c.  “Legitimacy, Authority, and Demo -

cratic Duties of Explanation.” In Sobel, D. and Wall, S., 

(eds.),  Oxford Studies in Political Philosophy, Volume 10. 

Oxford, UK: Oxford University Press. 

Lazar, S. 2024d.  “Power and AI: Nature and Justifica -

tion.” In Bullock, J. B., Chen, Y.-C., Himmelreich, J., Hud -

son, V. M., Korinek, A., Young, M. and Zhang, B., (eds.), 

The Oxford Handbook of AI Governance.  Oxford, UK: 

Oxford University Press. 

Lazar, S. 2025.  “Governing the Algorithmic City.”  Phi -

losophy & Public Affairs .

Lazar, S., Thorburn, L., Jin, T., and Belli, L. 2024.  “The 

Moral Case for Using Language Model Agents for Rec -

ommendation.”  arXiv preprint arXiv:2410.12123 .

Lerner, J., and Tirole, J. 2002.  “Some Simple Econom -

ics of Open Source.”  The Journal of Industrial Econom -

ics  50(2): 197–234. 

Levy, N. 2021.  Bad Beliefs: Why They Happen to Good 

People . Oxford, UK: Oxford University Press. 

Lewandowsky, S., Gignac, G. E., and Oberauer, K. 

2013.  “The Role of Conspiracist Ideation and World -

views in Predicting Rejection of Science.”  Plos one 

8(10): e75637. 

Li, H., and Aral, S. 2025.  “Human Trust in AI 

Search: A Large-Scale Experiment.”  arXiv preprint 

arXiv:2504.06435 .

Li, Y., Liu, K., Satapathy, R., Wang, S., and Cambria, 

E. 2024.  “Recent Developments in Recommender Sys -

tems: A Survey [Review Article].”  IEEE Computational 

Intelligence Magazine  19(2): 78–95. 

Lippens, L. 2024.  “Computer Says ‘No’: Exploring 

Systemic Bias in ChatGPT Using an Audit Approach.” 

Computers in Human Behavior: Artificial Humans  2(1): 

100054. 

Llanes-Ortiz, G. 2023.  Digital Initiatives for Indigenous 

Languages.  UNESCO and Global Voices. 

Lorenz-Spreen, P., Oswald, L., Lewandowsky, S., and 

Hertwig, R. 2023.  “A Systematic Review of Worldwide 

Causal and Correlational Evidence on Digital Media 

and Democracy.”  Nature Human Behaviour  7(1): 74–101. 

Lucidity Insights. 2024.  “Global AI Investment Flows 

in 2024.” 

Lukoff, K., Lyngs, U., Zade, H., Liao, J. V., Choi, J., 

Fan, K., Munson, S. A., and Hiniker, A. 2021.  “How the 

Design of Youtube Influences User Sense of Agency.” 

Proceedings of the 2021 CHI Conference on Human 

Factors in Computing Systems.  Yokohama, Japan: As -

sociation for Computing Machinery. 

Lundstedt, M., Wiebrecht, F., Boese-Schlosser, V., 

Morrison, K., Natsika, N., Nord, M., Papada, E., and 

others. 2022.  “Case for Democracy Report.” V-Dem 

Institute. 

Macro Polo. 2024.  “The Global AI Talent Tracker 2.0.” 

https://archivemacropolo.org/interactive/digital-proj -

ects/the-global-ai-talent-tracker/. Accessed April 2025. 

Matz, S., Teeny, J., Vaid, S. S., Peters, H., Harari, G., 

and Cerf, M. 2024.  “The Potential of Generative AI for 

Personalized Persuasion at Scale.”  Scientific Reports 

14(1): 4692. 

McKay, S., and Tenove, C. 2021.  “Disinformation as a 

Threat to Deliberative Democracy.”  Political Research 

Quarterly  74(3): 703–717. 

McKinsey Analytics. 2021.  “The State of AI in 2021.” 

Mckinsey & Company. 

Methnani, L., Chiou, M., Dignum, V., and Theodorou, 

A. 2024.  “Who’s in Charge Here? A Survey on Trust -

worthy AI in Variable Autonomy Robotic Systems.”  ACM 

Computing Surveys  56(7): Article 184. 

Mitchell, S., Potash, E., Barocas, S., D’Amour, A., and 

Lum, K. 2021.  “Algorithmic Fairness: Choices, Assump -

tions, and Definitions.”  Annual Review of Statistics and 

Its Application  8: 141–163. REFERENCES  2 5 5 

Mittelstadt, B., Russell, C., and Wachter, S. 2019.  “Ex -

plaining Explanations in AI.”  Proceedings of the Confer -

ence on Fairness, Accountability, and Transparency. 

Atlanta, GA: Association for Computing Machinery. 

Nadeem, M., Bethke, A., and Reddy, S. 2020.  “Ste -

reoset: Measuring Stereotypical Bias in Pretrained Lan -

guage Models.”  arXiv preprint arXiv:2004.09456 .

Narayanan, A. 2023.  “Understanding Social Media 

Recommendation Algorithms.” Knight First Amendment 

Institute at Columbia University. 

Narayanan, A., and Kapoor, S. 2024.  AI Snake Oil: 

What Artificial Intelligence Can Do, What It Can’t, and 

How to Tell the Difference.  Princeton, NJ: Princeton 

University Press. 

Narayanan, D. 2019.  “Technology and Political Will Can 

Create Better Governance.”  The Economist , 22 March. 

https://www.economist.com/open-future/2019/03/22/ 

technology-and-political-will-can-create-better-gover -

nance. 

New York Times. 2025.  “What Deepseek? Big Tech 

Keeps Its AI Building Boom Alive.” 8 February. 

Nussberger, A.-M., Luo, L., Celis, L. E., and Crockett, 

M. J. 2022.  “Public Attitudes Value Interpretability but 

Prioritize Accuracy in Artificial Intelligence.”  Nature 

Communications  13(1): 5821. 

OECD (Organisation for Economic Co-operation and 

Development). 2025a.  OECD AI Policy Observatory .

Paris: OECD Publishing. 

OECD (Organisation for Economic Co-operation and 

Development). 2025b.  Policies, Data and Analysis 

for Trustworthy Artificial Intelligence.  OECD AI Policy 

Observatory. 

OECD (Organisation for Economic Co-operation and 

Development). 2025.  “OECD AI Principles.” https:// 

oecd.ai/en/ai-principles. Accessed 17 March 2025. 

Open A.I. 2025.  “Announcing the Star -

g a t e P r o j e c t .” h t t p s : / / o p e n a i . c o m / i n d ex / 

announcing-the-stargate-project/. 

Ovadya, A. 2023.  “Meta Ran a Giant Experiment in 

Governance. Now It’s Turning to AI.” https://www.wired. 

com/story/meta-ran-a-giant-experiment-in-gover -

nance-now-its-turning-to-ai/. 

Oxford Insights. 2023.  Government AI Readiness In -

dex 2023.  Oxford Insights. 

Pan, B., Hembrooke, H., Joachims, T., Lorigo, L., Gay, 

G., and Granka, L. 2007.  “In Google We Trust: Users’ 

Decisions on Rank, Position, and Relevance.”  Journal 

of Computer-Mediated Communication  12(3): 801–823. 

Pansardi, P., and Bindi, M. L. 2021.  “The New Con -

cepts of Power? Power-over, Power-to and Power-

With.”  Journal of Political Power  14: 51–71. 

Parli, V. 2025.  How Disruptive Is Deepseek? Stanford 

HAI Faculty Discuss China’s New Model.  Stanford Re -

port  [Online]. Available from: https://news.stanford.edu/ 

stories/2025/02/how-disruptive-is-deepseek. 

Participedia. 2025.  https://participedia.net/. Accessed 

13 April 2025. 

Paul, A., Yu, C. L., Susanto, E. A., Lau, N. W. L., and 

Meadows, G. I. 2024.  “Agentpeertalk: Empowering 

Students through Agentic-Ai-Driven Discernment of 

Bullying and Joking in Peer Interactions in Schools.” 

arXiv preprint arXiv:2408.01459 .

Pentland, A., and Tsai, L. 2024.  “Toward Building De -

liberative Digital Media: From Subversion to Consen -

sus.”  PNAS Nexus  3(10). 

Personal Data Protection Commission. 2025. 

“Personal Data Protection Act,.” https://www. 

p d p c . g o v. s g / h e l p - a n d - r e s o u r c e s / 2 0 2 0 / 0 1 / 

model-ai-governance-framework. 

Perspective. 2025.  “Build with Perspective API.” https:// 

developers.perspectiveapi.com/s/?language=en_US. 

Accessed 17 March 2025. 

Phan, L., Gatti, A., Han, Z., Li, N., Hu, J., Zhang, H., 

Shi, S., and others. 2025.  “Humanity’s Last Exam.” 

arXiv preprint arXiv:2501.14249 .

PIB Delhi. 2025.  “India’s AI Revolution: A Roadmap to 

Viksit Bharat.” Ministry of Electronics & IT. 

Piir, R. 2023.  “Finland’s ChatGPT Equivalent Begins to 

Think in Estonian as Well.”  ERR News.  Accessed 5 July 

2024. 

Pinhanez, C. S., Cavalin, P. R., Vasconcelos, M., and 

Nogima, J. 2023.  “Balancing Social Impact, Opportuni -

ties, and Ethical Constraints of Using AI in the Docu -

mentation and Vitalization of Indigenous Languages.” 

Proceedings of the 32nd International Joint Confer -

ence on Artificial Intelligence (IJCAI-23),  6174–6182. 

Prat, A. 2018.  “Media Power.”  Journal of Political Econ -

omy  126(4): 1747–1783. 

Prat, A., and Valletti, T. 2022.  “Attention Oligopoly.” 

American Economic Journal: Microeconomics  14(3): 

530–57. 

Qi, Y., Schölkopf, B., and Jin, Z. 2024.  “Causal Re -

sponsibility Attribution for Human-AI Collaboration.” 

arXiv preprint arXiv:2411.03275 .

Rahman, R., Owen, D., and You, J. 2024.  “Tracking 

Large-Scale AI Models.” EpochAI. https://epoch.ai/blog/ 

tracking-large-scale-ai-models. 

Rekker, R. 2021.  “The Nature and Origins of Political 

Polarization over Science.”  Public Understanding of 

Science  30(4): 352–368. 

Rich, M. D. 2018.  Truth Decay: An Initial Exploration of 

the Diminishing Role of Facts and Analysis in American 

Public Life.  Rand Corporation. 

Rita Gonçalves, A., Costa Pinto, D., Gonzalez-

Jimenez, H., Dalmoro, M., and Mattila, A. S. 2025. 

“Me, Myself, and My AI: How Artificial Intelligence Clas -

sification Failures Threaten Consumers’ Self-Expres -

sion.”  Journal of Business Research  186: 114974. 

Rozado, D. 2024.  “The Political Preferences of LLMs.” 

Plos one  19(7): e0306621. 

Rudin, C. 2019.  “Stop Explaining Black Box Machine 

Learning Models for High Stakes Decisions and Use 

Interpretable Models Instead.”  Nature Machine Intel -

ligence  1(5): 206–215. 

Rueda, J., Rodríguez, J. D., Jounou, I. P., Hortal-Car -

mona, J., Ausín, T., and Rodríguez-Arias, D. 2024. 

““Just” Accuracy? Procedural Fairness Demands Ex -

plainability in AI-Based Medical Resource Allocations.” 

AI & Society  39(3): 1411–1422. 

Russell, S. 2019.  Human-Compatible: Artificial Intelli -

gence and the Problem of Control.  Viking. 

Sadek, M., Kallina, E., Bohné, T., Mougenot, C., Cal -

vo, R. A., and Cave, S. 2024.  “Challenges of Responsi -

ble AI in Practice: Scoping Review and Recommended 

Actions.”  AI & Society .

Sadowski, J., Viljoen, S., and Whittaker, M. 2021. 

“Everyone Should Decide How Their Digital Data Are 

Used—Not Just Tech Companies.”  Nature  595(7866): 

169–171. 

Salinas, A., Haim, A., and Nyarko, J. 2024.  “What’s 

in a Name? Auditing Large Language Models for Race 

and Gender Bias.”  arXiv preprint arXiv:2402.14875 .

Saltz, E., Jalan, Z., and Acosta, T. 2024.  “Re-Ranking 

News Comments by Constructiveness and Curiosity 

Significantly Increases Perceived Respect, Trustworthi -

ness, and Interest.”  arXiv preprint arXiv:2404.05429 .

Saura García, C. 2024.  “Datafeudalism: The Domina -

tion of Modern Societies by Big Tech Companies.”  Phi -

losophy & Technology  37(3): 90. 

Savage, N. 2020.  “The Race to the Top among the 

World’s Leaders in Artificial Intelligence.”  Nature 

588(7837): S102–S102. 

Schaake, M. 2024.  The Tech Coup: How to Save De -

mocracy from Silicon Valley.  Princeton, NJ: Princeton 

University Press. 

Schmid, S., Lambach, D., Diehl, C., and Reuter, C. 

2025.  “Arms Race or Innovation Race? Geopolitical AI 

Development.”  Geopolitics : 1–30. 

Schuster, N., and Lazar, S. 2025.  “Attention, Moral 

Skill, and Algorithmic Recommendation.”  Philosophical 

Studies  182(1): 159–184. 

Sen, A. 1973.  “Behaviour and the Concept of Prefer -

ence.”  Economica  40(159): 241–259. 

Sen, A. 1985.  “Well-Being, Agency and Freedom: The 

Dewey Lectures 1984.”  The Journal of Philosophy 

82(4): 169–221. 

Sen, A. 1997.  “Maximization and the Act of Choice.” 

Econometrica  65(4): 745–779. 

Sen, A. K. 1977.  “Rational Fools: A Critique of the Be -

havioral Foundations of Economic Theory.”  Philosophy 

& Public Affairs  6(4): 317–344. 

Sharma, M., Tong, M., Korbak, T., Duvenaud, D., 

Askell, A., Bowman, S. R., Cheng, N., and others. 

2023.  “Towards Understanding Sycophancy in Lan -

guage Models.”  arXiv preprint arXiv:2310.13548 .

Shen, H., Knearem, T., Ghosh, R., Alkiek, K., Krishna, 

K., Liu, Y., Ma, Z., and others. 2024.  “Towards Bidi -

rectional Human-AI Alignment: A Systematic Review for 

Clarifications, Framework, and Future Directions.”  arXiv 

preprint arXiv:2406.09264 .25 6 HUMAN DEVELOPMENT REPORT 2025 

Siegel, A. A. 2020.  “Online Hate Speech.”  Social Me -

dia and Democracy: The State of the Field, Prospects 

for Reform : 56–88. 

Simchon, A., Edwards, M., and Lewandowsky, S. 

2024.  “The Persuasive Effects of Political Microtar -

geting in the Age of Generative Artificial Intelligence.” 

PNAS Nexus  3(2): pgae035. 

Simon, H. A. 1971.  “Designing Organizations for an 

Information-Rich World.” In Greeenbeger, M., (ed.)  Com -

puters, Communications, and the Public Interest.  Balti -

more, MD: The Johns Hopkins Press. 

Singh, A., and Joachims, T. 2018.  Fairness of Expo -

sure in Rankings.  Proceedings of the 24th ACM SIGKDD 

International Conference on Knowledge Discovery & 

Data Mining.  London, United Kingdom: Association for 

Computing Machinery. 

Smith, G. 2009.  Democratic Innovations: Designing 

Institutions for Citizen Participation.  Cambridge Univer -

sity Press. 

Stagnaro, M. N., Tappin, B. M., and Rand, D. G. 2023. 

“No Association between Numerical Ability and Po -

litically Motivated Reasoning in a Large US Probability 

Sample.”  Proceedings of the National Academy of Sci -

ences  120(32): e2301491120. 

Stanger, A., Kraus, J., Lim, W., Millman-Perlah, G., 

and Schroeder, M. 2024.  “Terra Incognita: The Gov -

ernance of Artificial Intelligence in Global Perspective.” 

Annual Review of Political Science  27. 

Statistica. 2024.  “Worldwide Data Centers.” 

Stefanija, A. P., and Pierson, J. 2023.  “Algorithmic 

Governmentality, Digital Sovereignty, and Agency Af -

fordances: Extending the Possible Fields of Action.” 

Weizenbaum Journal of the Digital Society  3(2). 

Stewart, A. J., Arechar, A. A., Rand, D. G., and Plot -

kin, J. B. 2024.  “The Distorting Effects of Producer 

Strategies: Why Engagement Does Not Reveal Con -

sumer Preferences for Misinformation.”  Proceedings of 

the National Academy of Sciences  121(10): e2315195121. 

Stobierski, T. 2020.  “What Are Network Effects?” 

Harvard Business School Online. https://online.hbs. 

edu/blog/post/what-are-network-effects. 

Stray, J. 2020.  “Aligning AI Optimization to Community 

Well-Being.”  International Journal of Community Well-

Being  3(4): 443–463. 

Stray, J., Halevy, A., Assar, P., Hadfield-Menell, D., 

Boutilier, C., Ashar, A., Bakalar, C., and others. 2024. 

“Building Human Values into Recommender Systems: 

An Interdisciplinary Synthesis.”  ACM Computing Sur -

veys  2(3): Article 20. 

Strömbäck, J., Boomgaarden, H., Broda, E., Dams -

tra, A., Lindgren, E., Tsfati, Y., and Vliegenthart, R. 

2022.  “From Low-Choice to High-Choice Media En -

vironments: Implications for Knowledge Resistance.” 

Knowledge Resistance in High-Choice Information En -

vironments.  Routledge. 

Summerfield, C., Argyle, L., Bakker, M., Collins, T., 

Durmus, E., Eloundou, T., Gabriel, I., and others. 

2024.  “How Will Advanced AI Systems Impact Democ -

racy?”  arXiv preprint arXiv:2409.06729 .

Tang, A. 2024.  “Democracy in the Age of AI.”  RSA 

Journal . https://www.thersa.org/rsa-journal/2024/ 

issue-2/democracy-in-the-age-of-ai. 

Tappin, B. M., Pennycook, G., and Rand, D. G. 2021. 

“Rethinking the Link between Cognitive Sophistication 

and Politically Motivated Reasoning.”  Journal of Experi -

mental Psychology: General  150(6): 1095. 

Tappin, B. M., Wittenberg, C., Hewitt, L. B., Berinsky, 

A. J., and Rand, D. G. 2023.  “Quantifying the Poten -

tial Persuasive Returns to Political Microtargeting.” 

Proceedings of the National Academy of Sciences 

120(25): e2216261120. 

Te Hiku Media. 2025.  “Te Hiku Media.” Kaitaia. https:// 

tehiku.nz/. 

Tessler, M. H., Bakker, M. A., Jarrett, D., Sheahan, 

H., Chadwick, M. J., Koster, R., Evans, G., and oth -

ers. 2024.  “AI Can Help Humans Find Common 

Ground in Democratic Deliberation.”  science  386(6719): 

eadq2852. 

The Computational Democracy Project. 2025.  “Po -

lis.” https://pol.is/home. 

The Stanford Institute for Human-Centered AI. 

2025.  “The Global AI Vibrancy Tool 2024.” Stanford, 

CA: The Stanford Institute for Human-Centered AI. 

Tirole, J. 2023.  “Competition and the Industrial Chal -

lenge for the Digital Age.”  Annual Review of Economics 

15(Volume 15, 2023): 573–605. 

Tortoise Media. 2025.  “The Global AI Index.” Tortoise 

Media. 

Touvron, H., Martin, L., Stone, K., Albert, P., Alma -

hairi, A., Babaei, Y., Bashlykov, N., and others. 2023. 

“Llama 2: Open Foundation and Fine-Tuned Chat Mod -

els.”  arXiv preprint arXiv:2307.09288 .

Tsado, A. 2024.  “Only Five Percent of Africa’s AI Tal -

ent Has the Compute Power It Needs.” Available from: 

https://www.undp.org/digital/blog/only-five-percent-

africas-ai-talent-has-compute-power-it-needs. 

UNDP (United Nations Development Programme). 

2024.  Human Development Report 2023/24. Breaking 

the Gridlock: Reimagining Cooperation in a Polarized 

World . New York: UNDP. 

UNESCO (United Nations Educational, Scientific 

and Cultural Organization). 2021.  “Recommendation 

on the Ethics of Artificial Intelligence.” Paris: UNESCO. 

V-Dem Institute. 2025.  https://www.v-dem.net/. Ac -

cessed 28 April 2025. 

Vafa, K., Chen, J., Rambachan, A., Kleinberg, J., and 

Mullainathan, S. 2024.  “Evaluating the World Model 

Implicit in a Generative Model.”  Advances in Neural In -

formation Processing Systems  37: 26941–26975. 

Varoquaux, G., Luccioni, A. S., and Whittaker, 

M. 2024.  “Hype, Sustainability, and the Price of 

the Bigger-Is-Better Paradigm in AI.”  arXiv preprint 

arXiv:2409.14160 .

Veale, M., Matus, K., and Gorwa, R. 2023.  “AI and 

Global Governance: Modalities, Rationales, Ten -

sions.”  Annual Review of Law and Social Science  19(1): 

255–275. 

Vélez, N., Christian, B., Hardy, M., Thompson, B. D., 

and Griffiths, T. L. 2023.  “How Do Humans Overcome 

Individual Computational Limitations by Working To -

gether?”  Cognitive Science  47(1): e13232. 

Véliz, C. 2019.  “Three Things Digital Ethics Can Learn 

from Medical Ethics.”  Nature Electronics  2(8): 316–318. 

Véliz, C. 2021.  “Moral Zombies: Why Algorithms Are 

Not Moral Agents.”  AI & Society  36(2): 487–497. 

Villalobos, P., Ho, A., Sevilla, J., Besiroglu, T., Heim, 

L., and Hobbhahn, M. 2024.  “Will We Run out of Data? 

Limits of Llm Scaling Based on Human-Generated 

Data.”  arXiv preprint arXiv:2211.04325 .

Vipra, J., and West, S. M. 2023.  “Computational Pow -

er and AI.” AI Now Institute. 

Voigt, P., and Von dem Bussche, A. 2017.  The EU 

General Data Protection Regulation (GDPR): A Practi -

cal Guide, 1st Ed.  Cham, Switzerland: Springer Interna -

tional Publishing. 

Volenik, A. 2024.  “A Handful of Big Tech Companies 

Surged by $8 Trillion in Market Value since ChatGPT’s 

Launch—Marking a New Era.”  Yahoo Finance , 29 

December. 

Wachter, S., Mittelstadt, B., and Russell, C. 2024.  “Do 

Large Language Models Have a Legal Duty to Tell the 

Truth?”  Royal Society Open Science  11(8): 240197. 

Wagner, C., Strohmaier, M., Olteanu, A., Kıcıman, E., 

Contractor, N., and Eliassi-Rad, T. 2021.  “Measuring 

Algorithmically Infused Societies.”  Nature  595(7866): 

197–204. 

Wang, W., Ma, Z., Wang, Z., Wu, C., Chen, W., Li, X., 

and Yuan, Y. 2025.  “A Survey of LLM-Based Agents in 

Medicine: How Far Are We from Baymax?”  arXiv pre -

print arXiv:2502.11211 .

Wang, Y., Ma, W., Zhang, M., Liu, Y., and Ma, S. 2023. 

“A Survey on the Fairness of Recommender Systems.” 

ACM Computing Surveys  41(3): 1–43. 

Wendler, C., Veselovsky, V., Monea, G., and West, 

R. 2024.  “Do Llamas Work in English? On the Latent 

Language of Multilingual Transformers.”  Proceedings 

of the 62nd Annual Meeting of the Association for 

Computational Linguistics (Volume 1: Long Papers) ,

15366–15394. 

Westberg, P. 2024.  “ASML: Architect -

ing Earth’s Most Complex Machines.” https:// 

q u a r t r . c o m / i n s i g h t s / c o m p a n y - r e s e a r c h / 

asml-architecting-earths-most-complex-machines. 

Whitt, R. S. 2024.  “Rise of the KnowMeBots: Promot -

ing the Two Dimensions of AI Agency.” SSRN. 

Whittlestone, J., Nyrup, R., Alexandrova, A., and 

Cave, S. 2019.  “The Role and Limits of Principles in 

AI Ethics: Towards a Focus on Tensions.”  Proceed -

ings of the 2019 AAAI/ACM Conference on AI, Ethics, 

and Society.  Honolulu, HI: Association for Computing 

Machinery. 

Widder, D. G., Whittaker, M., and West, S. M. 2024. 

“Why ‘Open’ AI Systems Are Actually Closed, and Why 

This Matters.”  Nature  635(8040): 827–833. REFERENCES  2 5 7 

Wikforss, Å., Kendeou, P., and Robinson, D. 2019. 

“Critical Thinking in the Post-Truth Era.”  Misinformation 

and Fake News in Education  279. 

Winner, L. 1980.  “Do Artifacts Have Politics?”  Daedalus 

109(1): 121–136. 

Wölflein, G., Ferber, D., Truhn, D., Arandjelović, O., 

and Kather, J. N. 2025.  “LLM Agents Making Agent 

Tools.”  arXiv preprint arXiv:2502.11705 .

Woolston, C. 2022.  “Is Big Tech Draining AI Talent 

from Academia?”  Nature Index .

World Bank. 2017.  World Development Report 2017: 

Governance and the Law.  Washington, DC: World 

Bank. 

Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., 

Zhang, M., and others. 2023.  “The Rise and Potential 

of Large Language Model Based Agents: A Survey.” 

arXiv preprint arXiv:2309.07864 .

Yao, B., Cai, Z., Chuang, Y.-S., Yang, S., Jiang, M., 

Yang, D., and Hu, J. 2024.  “No Preference Left Be -

hind: Group Distributional Preference Optimization.” 

arXiv preprint arXiv:2412.20299 .

Yuan, J., Di, Z., Zhao, S., and Naseem, U. 2024.  “Cul -

tural Palette: Pluralising Culture Alignment Via Multi-

Agent Palette.”  arXiv preprint arXiv:2412.11167 .

Zhao, Z., Fan, W., Li, J., Liu, Y., Mei, X., Wang, Y., Wen, 

Z., and others. 2024.  “Recommender Systems in the 

Era of Large Language Models (LLMs).”  IEEE Trans -

actions on Knowledge and Data Engineering  36(11): 

6889–6907. 

Zheng, J., and Meister, M. 2025.  “The Unbearable 

Slowness of Being: Why Do We Live at 10 Bits/S?” 

Neuron .

Zhi-Xuan, T., Carroll, M., Franklin, M., and Ashton, 

H. 2024.  “Beyond Preferences in AI Alignment.”  Philo -

sophical Studies .

Zhuravskaya, E., Petrova, M., and Enikolopov, R. 

2020.  “Political Effects of the Internet and Social Me -

dia.”  Annual Review of Economics  12(1): 415–438. 

Zuboff, S. 2019.  The Age of Surveillance Capitalism: 

The Fight for a Human Future at the New Frontier of 

Power.  PublicAffairs. 

CHAPTER 6 

AAAI (Association for the Advancement of Artificial 

Intelligence). 2025.  “AAAI 2025 Presidential Panel 

on the Future of AI Research.”  Association for the Ad -

vancement of Artificial Intelligence (AAAI) .

Abbas Khan, M., Khan, H., Omer, M. F., Ullah, I., and 

Yasir, M. 2024.  “Impact of Artificial Intelligence on the 

Global Economy and Technology Advancements.”  Arti -

ficial General Intelligence (Agi) Security: Smart Applica -

tions and Sustainable Technologies.  Springer. 

Abduljabbar, R., Dia, H., Liyanage, S., and Bagloee, 

S. A. 2019.  “Applications of Artificial Intelligence in 

Transport: An Overview.”  Sustainability  11(1): 189. 

Abdurahman, S., Atari, M., Karimi-Malekabadi, F., 

Xue, M. J., Trager, J., Park, P. S., Golazizian, P., Omra -

ni, A., and Dehghani, M. 2024.  “Perils and Opportuni -

ties in Using Large Language Models in Psychological 

Research.”  PNAS Nexus  3(7). 

Abolghasemi, M., Ganbold, O., and Rotaru, K. 2025. 

“Humans Vs. Large Language Models: Judgmental 

Forecasting in an Era of Advanced AI.”  International 

Journal of Forecasting  forthcoming. 

Acemoglu, D. 2024.  “Harms of AI.” In Bullock, J. B., 

Chen, Y.-C., Himmelreich, J., Hudson, V. M., Korinek, A., 

Young, M. M. and Zhang, B., (eds.),  The Oxford Hand -

book of AI Governance.  Oxford University Press. 

Acemoglu, D., and Restrepo, P. 2019.  “Automation 

and New Tasks: How Technology Displaces and Rein -

states Labor.”  Journal of Economic Perspectives  33(2): 

3–30. 

Acemoglu, D., and Restrepo, P. 2019.  2020. ““The 

Wrong Kind of AI? Artificial Intelligence and the Future 

of Labour Demand.”  Cambridge Journal of Regions, 

Economy and Society  13(1): 25–35. 

Adams, J. 2025.  “How Stripe ‘Teaches’ Tech to Beat 

the Payments Fraud Exam.”  American Banker .

Adapa, K., Gupta, A., Singh, S., Kaur, H., Trikha, A., 

Sharma, A., and Rahul, K. 2025.  “A Real World Evalu -

ation of an Innovative Artificial Intelligence Tool for 

Population-Level Breast Cancer Screening.”  NPJ Digital 

Medicine  8(1): 2. 

Afroogh, S., Akbari, A., Malone, E., Kargar, M., and 

Alambeigi, H. 2024.  “Trust in AI: Progress, Challenges, 

and Future Directions.”  Humanities and Social Scienc -

es Communications  11(1): 1568. 

Agarwal, N., Huang, R., Moehring, A., Rajpurkar, P., 

Salz, T., and Yu, F. 2024.  “Comparative Advantage of 

Humans Versus AI in the Long Tail.”  AEA Papers and 

Proceedings  114: 618–22. 

Agarwal, N., Moehring, A., Rajpurkar, P., and Salz, 

T. 2023.  “Combining Human Expertise with Artificial 

Intelligence: Experimental Evidence from Radiology.” 

Working Paper 31422, National Bureau of Economic 

Research, Cambridge, MA. 

Agrawal, A., McHale, J., and Oettl, A. 2024.  “Artificial 

Intelligence and Scientific Discovery: A Model of Priori -

tized Search.”  Research Policy  53(5): 104989. 

Ahuja, N. J., Dutt, S., Choudhary, S. L., and Kumar, 

M. 2025.  “Intelligent Tutoring System in Education for 

Disabled Learners Using Human–Computer Interaction 

and Augmented Reality.”  International Journal of Hu -

man–Computer Interaction  41(3): 1804–1816. 

AI Sweden. n.d.  “Om AI Sweden.” https://www.ai.se/sv/ 

om-ai-sweden. Accessed 1 April 2025. 

Aiken, E., Bellue, S., Karlan, D., Udry, C., and Blumen -

stock, J. E. 2022.  “Machine Learning and Phone Data 

Can Improve Targeting of Humanitarian Aid.”  Nature 

603(7903): 864–870. 

Aitken, J. M., Veres, S. M., Shaukat, A., Gao, Y., 

Cucco, E., Dennis, L. A., Fisher, M., and others. 2018. 

“Autonomous Nuclear Waste Management.”  IEEE Intel -

ligent Systems  33(6): 47–55. 

Ajunwa, I. 2023.  The Quantified Worker: Law and 

Technology in the Modern Workplace.  Cambridge Uni -

versity Press. 

Akcigit, U., Baslandze, S., and Lotti, F. 2023.  “Con -

necting to Power: Political Connections, Innovation, 

and Firm Dynamics.”  Econometrica  91(2): 529–564. 

Al-Kharusi, Y., Khan, A., Rizwan, M., and Bait-Su -

wailam, M. M. 2024.  “Open-Source Artificial Intel -

ligence Privacy and Security: A Review.”  Computers 

13(12): 311. 

Alan, S., and Mumcu, I. 2024.  “Nurturing Childhood 

Curiosity to Enhance Learning: Evidence from a Ran -

domized Pedagogical Intervention.”  American Eco -

nomic Review  114(4): 1173–1210. 

Alcazer, V., Le Meur, G., Roccon, M., Barriere, S., 

Le Calvez, B., Badaoui, B., Spaeth, A., and others. 

2024.  “Evaluation of a Machine-Learning Model Based 

on Laboratory Parameters for the Prediction of Acute 

Leukaemia Subtypes: A Multicentre Model Develop -

ment and Validation Study in France.”  The Lancet Digi -

tal Health  6(5): e323–e333. 

Alcott, B. 2005.  “Jevons’ Paradox.”  Ecological Eco -

nomics  54(1): 9–21. 

Aldridge, G., Tomaselli, A., Nowell, C., Reupert, A., 

Jorm, A., and Yap, M. B. H. 2024.  “Engaging Parents 

in Technology-Assisted Interventions for Childhood Ad -

versity: Systematic Review.”  Journal of Medical Internet 

Research  26: e43994. 

Ali, S. S., and Choi, B. J. 2020.  “State-of-the-Art Artifi -

cial Intelligence Techniques for Distributed Smart Grids: 

A Review.”  Electronics  9(6): 1030. 

Allen, M., Babiker, M., Chen, Y., de Coninck, H. C., 

and de Kleijne, K. 2018.  “IPCC SR15: Summary for 

Policymakers.”  IPCC Special Report Global Warming 

of 1.5  ºC.  Intergovernmental Panel on Climate Change. 

Aloisi, A., and De Stefano, V. 2022.  “Your Boss Is 

an Algorithm: Artificial Intelligence, Platform Work and 

Labour.” Bloomsbury Publishing. 

AlphaFold. n.d.  “Alphafold Protein Structure Data -

base.” https://www.alphafold.ebi.ac.uk/. Accessed 20 

January 2025. 

Ameh, B. 2024.  “Digital Tools and AI: Using Technol -

ogy to Monitor Carbon Emissions and Waste at Each 

Stage of the Supply Chain, Enabling Real-Time Ad -

justments for Sustainability Improvements.”  Interna -

tional Journal of Science and Research Archive  13(1): 

2741–2754. 

Andreas, J., Beguš, G., Bronstein, M. M., Diamant, 

R., Delaney, D., Gero, S., Goldwasser, S., and others. 

2022.  “Toward Understanding the Communication in 

Sperm Whales.”  iScience  25(6). 

Angrist, N., Ainomugisha, M., Bathena, S. P., Berg -

man, P., Crossley, C., Cullen, C., Letsomo, T., and 

others. 2023.  “Building Resilient Education Systems: 

Evidence from Large-Scale Randomized Trials in Five 

Countries.” Working Paper 31208, National Bureau of 

Economic Research, Cambridge, MA. 

Angrist, N., Bergman, P., and Matsheng, M. 2022. 

“Experimental Evidence on Learning Using Low-Tech 25 8 HUMAN DEVELOPMENT REPORT 2025 

When School Is Out.”  Nature Human Behaviour  6(7): 

941–950. 

Angrist, N., and Dercon, S. 2024.  “Mind the Gap be -

tween Education Policy and Practice.”  Nature Human 

Behaviour  8(12): 2261–2263. 

Angrist, N., Evans, D. K., Filmer, D., Glennerster, R., 

Rogers, H., and Sabarwal, S. 2024.  “How to Improve 

Education Outcomes Most Efficiently? A Review of the 

Evidence Using a Unified Metric.”  Journal of Develop -

ment Economics : 103382. 

Angrist, N., and Meager, R. 2023.  Implementation 

Matters: Generalizing Treatment Effects in Education. 

SSRN. https://ssrn.com/abstract=4487496. 

Ansari, Y., Virwani, K., Yahyazadeh, S., Thompson, 

L. E., Lofano, E., Fong, A., Miller, R. D., and La, Y.-H. 

2018.  “A Highly Stable Sodium–Oxygen Battery Using 

a Mechanically Reinforced Membrane.”  Advanced En -

ergy Materials  8(36): 1802603. 

Antonietti, R., Burlina, C., and Rodriguez-Pose, A. 

2025.  “Digital Technology and Regional Income In -

equality: Are Better Institutions the Solution?”  Papers in 

Regional Science : 100079. 

Antunes, L. M., Butler, K. T., and Grau-Cres -

po, R. 2024.  “Crystal Structure Generation with 

Autoregressive Large Language Modeling.”  Nature 

Communications  15(1): 10570. 

Argyle, L. P., Busby, E. C., Fulda, N., Gubler, J. R., Ryt -

ting, C., and Wingate, D. 2023.  “Out of One, Many: 

Using Language Models to Simulate Human Samples.” 

Political Analysis  31(3): 337–351. 

Arifuzzaman, M., Aniq Gul, M., Khan, K., and Hossain, 

S. M. Z. 2021.  “Application of Artificial Intelligence (AI) 

for Sustainable Highway and Road System.”  Symmetry 

13(1): 60. 

Arntz, M., Genz, S., Gregory, T., Lehmer, F., and 

Zierahn-Weilage, U. 2024.  “De-Routinization in the 

Fourth Industrial Revolution–Firm-Level Evidence.”  ZA 

Discussion Papers  (No. 16740). 

Ash, E., and Hansen, S. 2023.  “Text Algorithms in Eco -

nomics.”  Annual Review of Economics  15(Volume 15, 

2023): 659–688. 

Ashkinaze, J., Mendelsohn, J., Qiwei, L., Budak, C., 

and Gilbert, E. 2024.  “How AI Ideas Affect the Creativ -

ity, Diversity, and Evolution of Human Ideas: Evidence 

from a Large, Dynamic Experiment.”  arXiv preprint 

arXiv:2401.13481 .

Atari, M., Xue, M. J., Park, P. S., Blasi, D. E., and Hen -

rich, J. 2025.  “Which Humans?”  PsyArXiv Preprints .

Atkinson, R. D., Brake, D., Castro, D., Cunliff, C., Ken -

nedy, J., McLaughlin, M., McQuinn, A., and New, J. 

2019.  A Policymaker’s Guide to the “Techlash”—What 

It Is and Why It’sa Threat to Growth and Progress. Infor -

mation Technology and Innovation Foundation. 

Autor, D. 2022.  “The Labor Market Impacts of Tech -

nological Change: From Unbridled Enthusiasm to 

Qualified Optimism to Vast Uncertainty.” Working Paper 

30074, National Bureau of Economic Research, Cam -

bridge, MA. 

Autor, D., Chin, C., Salomons, A., and Seegmiller, B. 

2024.  “New Frontiers: The Origins and Content of New 

Work, 1940–2018.”  The quarterly journal of economics :

qjae008. 

Autor, D., and Salomons, A. 2018.  “Is Automation 

Labor-Displacing? Productivity Growth, Employment, 

and the Labor Share.” Working Paper 24871, National 

Bureau of Economic Research, Cambridge, MA. 

Autor, D., Salomons, A., and Seegmiller, B. 2021. 

New Frontiers: The Origins and Content of New Work, 

1940–2018. MIT. 

Babina, T., Fedyk, A., He, A., and Hodson, J. 2024. 

“Artificial Intelligence, Firm Growth, and Product Innova -

tion.”  Journal of Financial Economics  151: 103745. 

Bail, C. A. 2024.  “Can Generative AI Improve Social 

Science?”  Proceedings of the National Academy of 

Sciences  121(21): e2314021121. 

Bailey, R. L., MacFarlane, A. J., Field, M. S., Tagko -

poulos, I., Baranzini, S. E., Edwards, K. M., Rose, C. 

J., and others. 2024.  “Artificial Intelligence in Food and 

Nutrition Evidence: The Challenges and Opportunities.” 

PNAS Nexus  3(12): pgae461. 

Bain, E. E., Shafner, L., Walling, D. P., Othman, A. A., 

Chuang-Stein, C., Hinkle, J., and Hanina, A. 2017. 

“Use of a Novel Artificial Intelligence Platform on Mo -

bile Devices to Assess Dosing Compliance in a Phase 

2 Clinical Trial in Subjects with Schizophrenia.”  JMIR 

mHealth and uHealth  5(2): e7030. 

Bajpai, D. A. 2024.  “Evaluating the Impact of Artificial 

Intelligence on Enhancing Tax Compliance and Finan -

cial Regulation.”  Available at SSRN 4922459 .

Ball, K. 2021.  “Electronic Monitoring and Surveillance 

in the Workplace.”  European Commission Joint Re -

search Centre .

Barzelay, A., Ng, J., and Romanoff, M. 2024.  “Govern -

ing Artificial Intelligence Responsibility in Low to Middle 

Income Countries: Enabling Pathways to Sustainable 

Development.”  California Western International Law 

Journal  54(2): 3. 

Bastani, H., Bastani, O., Sungu, A., Ge, H., Kabakcı, 

O., and Mariman, R. 2024.  “Generative AI Can Harm 

Learning.”  Available at SSRN  4895486. 

Bastani, S., and Waldenström, D. 2020.  “How Should 

Capital Be Taxed?”  Journal of Economic Surveys  34(4): 

812–846. 

Bastani, S., and Waldenström, D. 2024.  “Future Tax 

Challenges in an AI-Driven Economy.” https://cepr.org/ 

voxeu/columns/future-tax-challenges-ai-driven-econo -

my. Accessed 6 March 2025. 

Beg, S., Halim, W., Lucas, A. M., and Saif, U. 2022. 

“Engaging Teachers with Technology Increased 

Achievement, Bypassing Teachers Did Not.”  American 

Economic Journal: Economic Policy  14(2): 61–90. 

Bekbolatova, M., Mayer, J., Ong, C. W., and Toma, M. 

2024.  Transformative Potential of AI in Healthcare: Def -

initions, Applications, and Navigating the Ethical Land -

scape and Public Perspectives. Healthcare. MDPI, 125. 

Belenguer, L. 2022.  “AI Bias: Exploring Discrimina -

tory Algorithmic Decision-Making Models and the 

Application of Possible Machine-Centric Solutions 

Adapted from the Pharmaceutical Industry.”  AI and Eth -

ics  2(4): 771–787. 

Bengio, Y., Mindermann, S., Privitera, D., Besiro -

glu, T., Bommasani, R., Casper, S., Choi, Y., and 

others. 2024.  “International Scientific Report on the 

Safety of Advanced AI (Interim Report).”  arXiv preprint 

arXiv:2412.05282 .

Benítez-Rueda, M., and Parrado, E. 2024.  “Mirror, Mir -

ror on the Wall: Which Jobs Will AI Replace after All? 

A New Index of Occupational Exposure.” IDB Working 

Paper Series. 

Berg, J., and Gmyrek, P. 2024.  “Differences between 

IMF (2024) and ILO (WP96, 2023) Estimates of AI Expo -

sure Technical Analysis of Detailed Scores and Estima -

tion Methods.” Internal ILO Note, forthcoming. 

Bergerman, M., Maeta, S. M., Zhang, J., Freitas, G. 

M., Hamner, B., Singh, S., and Kantor, G. 2015.  “Ro -

bot Farmers: Autonomous Orchard Vehicles Help Tree 

Fruit Production.”  IEEE Robotics & Automation Maga -

zine  22(1): 54–63. 

Berreby, D. 2024.  “As Use of AI Soars, So Does the 

Energy and Water It Requires.” Yale Environment 360. 

Beuermann, D. W., Cristia, J., Cueto, S., Malamud, O., 

and Cruz-Aguayo, Y. 2015.  “One Laptop Per Child at 

Home: Short-Term Impacts from a Randomized Experi -

ment in Peru.”  American Economic Journal: Applied 

Economics  7(2): 53–80. 

Bewersdorff, A., Hartmann, C., Hornberger, M., 

Seßler, K., Bannert, M., Kasneci, E., Kasneci, G., Zhai, 

X., and Nerdel, C. 2025.  “Taking the Next Step with 

Generative Artificial Intelligence: The Transformative 

Role of Multimodal Large Language Models in Science 

Education.”  Learning and Individual Differences  118: 

102601. 

Bhorat, H., Hill, R., Köhler, T., Monnakgotla, J., and 

Steenkamp, F. 2023.  Who Are the Robots Coming 

For? The Evolving Task Content of Employment in 

South Africa. SARChI Industrial Development Working 

Paper Series WP 2023-06. SARChI …. 

Bilalić, M., Graf, M., and Vaci, N. 2025.  “Computers 

and Chess Masters: The Role of AI In transforming Elite 

Human Performance.”  British Journal of Psychology 

Forthcoming. 

Binz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, 

C. T., Allen, C., Schad, D., and others. 2025.  “How 

Should the Advancement of Large Language Models 

Affect the Practice of Science?”  Proceedings of the Na -

tional Academy of Sciences  122(5): e2401227121. 

Björkegren, D., Choi, J. H., Budihal, D., Sobhani, D., 

Garrod, O., and Atherton, P. 2025.  “Could AI Leapfrog 

the Web? Evidence from Teachers in Sierra Leone.” 

arXiv preprint arXiv:2502.12397 .

Blau, W., Cerf, V. G., Enriquez, J., Francisco, J. S., 

Gasser, U., Gray, M. L., Greaves, M., and others. 

2024.  “Protecting Scientific Integrity in an Age of Gen -

erative AI.”  Proceedings of the National Academy of 

Sciences  121(22): e2407886121. 

Blaurock, M., Büttgen, M., and Schepers, J. 2024. 

“Designing Collaborative Intelligence Systems for REFERENCES  2 5 9 

Employee-AI Service Co-Production.”  Journal of Serv -

ice Research  0(0): 10946705241238751. 

Blili-Hamelin, B., Graziul, C., Hancox-Li, L., Hazan, H., 

El-Mhamdi, E.-M., Ghosh, A., Heller, K., and others. 

2025.  “Stop Treating AGI as the North-Star Goal of AI 

Research.”  arXiv preprint arXiv:2502.03689 .

Bloom, N., Jones, C. I., Van Reenen, J., and Webb, M. 

2020.  “Are Ideas Getting Harder to Find?”  American 

Economic Review  110(4): 1104–1144. 

Blount, D., Gero, S., Van Oast, J., Parham, J., Kingen, 

C., Scheiner, B., Stere, T., and others. 2022.  “Fluke -

book: An Open-Source AI Platform for Cetacean Photo 

Identification.”  Mammalian Biology  102(3): 1005–1023. 

Boali, A., Asgari, H. R., Mohammadian Behbahani, 

A., Salmanmahiny, A., and Naimi, B. 2024.  “Remotely 

Sensed Desertification Modeling Using Ensemble of 

Machine Learning Algorithms.”  Remote Sensing Appli -

cations: Society and Environment  34: 101149. 

Boelaert, J., Coavoux, S., Ollion, E., Petev, I. D., and 

Präg, P. 2025.  “How Do Generative Language Models 

Answer Opinion Polls?”  Sociological Methods & Re -

search  0(0). https://doi.org/10.1177/00491241251330582. 

Bondi, E., Fang, F., Hamilton, M., Kar, D., Dmello, 

D., Choi, J., Hannaford, R., and others. 2018.  “Spot 

Poachers in Action: Augmenting Conservation Drones 

with Automatic Detection in near Real Time.”  Proceed -

ings of the AAAI Conference on Artificial Intelligence 

32(1). 

Boussioux, L., Lane, J. N., Zhang, M., Jacimovic, V., 

and Lakhani, K. R. 2024.  “The Crowdless Future? 

Generative AI and Creative Problem-Solving.”  Organi -

zation Science  35(5): 1589–1607. 

Brinkmann, L., Baumann, F., Bonnefon, J.-F., Derex, 

M., Müller, T. F., Nussberger, A.-M., Czaplicka, A., and 

others. 2023.  “Machine Culture.”  Nature Human Be -

haviour  7(11): 1855–1868. 

Brockway, P. E., Sorrell, S., Semieniuk, G., Heun, M. 

K., and Court, V. 2021.  “Energy Efficiency and Econo -

my-Wide Rebound Effects: A Review of the Evidence 

and Its Implications.”  Renewable and Sustainable En -

ergy Reviews  141: 110781. 

Brollo, F., Dabla-Norris, M. E., de Mooij, M. R., Garcia-

Macia, M. D., Hanappi, T., Liu, M. L., and Nguyen, A. 

D. 2024.  “Broadening the Gains from Generative AI: 

The Role of Fiscal Policies.” IMF Staff Discussion Notes 

2024/002, International Monetary Fund, Washington, 

DC. 

Brynjolfsson, E. 2022.  “The Turing Trap: The Promise 

& Peril of Human-Like Artificial Intelligence.”  Daedalus 

151(2): 272–287. 

Brynjolfsson, E., Li, D., and Raymond, L. R. 2025. 

“Generative AI at Work.”  The Quarterly Journal of Eco -

nomics  140(2): 889–942. 

Buera, F. J., Kaboski, J. P., and Townsend, R. M. 

2023.  “From Micro to Macro Development.”  Journal of 

Economic Literature  61(2): 471–503. 

Buntz, B. 2024.  “Quality Vs. Quantity: Us and China 

Chart Different Paths in Global AI Patent Race in 

2024.” R&D World. https://www.rdworldonline.com/ 

quality-vs-quantity-us-and-china-chart-different-paths-

in-global-ai-patent-race-in-2024/. Accessed 1 April 

2025. 

Burton, J. W., Lopez-Lopez, E., Hechtlinger, S., Rah -

wan, Z., Aeschbach, S., Bakker, M. A., Becker, J. A., 

and others. 2024.  “How Large Language Models Can 

Reshape Collective Intelligence.”  Nature Human Be -

haviour  8(9): 1643–1655. 

Callaway, E. 2022.  “What’s Next for the AI Protein-

Folding Revolution.”  Nature  604(7905): 234–238. 

Cao, S., Jiang, W., Wang, J., and Yang, B. 2024. 

“From Man Vs. Machine to Man+ Machine: The Art and 

AI of Stock Analyses.”  Journal of Financial Economics 

160: 103910. 

Capraro, V., Lentsch, A., Acemoglu, D., Akgun, S., 

Akhmedova, A., Bilancini, E., Bonnefon, J.-F., and 

others. 2024.  “The Impact of Generative Artificial Intel -

ligence on Socioeconomic Inequalities and Policy Mak -

ing.”  PNAS Nexus  3(6). 

Cardarelli, L. 2024.  “Pypotterylens: An Open-Source 

Deep Learning Framework for Automated Digitisation 

of Archaeological Pottery Documentation.”  arXiv pre -

print arXiv:2412.11574 .

Cavender-Bares, J., Gamon, J. A., and Townsend, P. 

A. 2020.  Remote Sensing of Plant Biodiversity.  Spring -

er Nature. 

Cazzaniga, M., Jaumotte, M. F., Li, L., Melina, M. G., 

Panton, A. J., Pizzinelli, C., Rockall, E. J., and Tavares, 

M. M. M. 2024.  “Gen-AI: Artificial Intelligence and the 

Future of Work.” IMF Staff Discussion Notes 2024/001, 

International Monetary Fund, Washington, DC. 

Celi, L. A., Cellini, J., Charpignon, M.-L., Dee, E. C., 

Dernoncourt, F., Eber, R., Mitchell, W. G., and others. 

2022.  “Sources of Bias in Artificial Intelligence That 

Perpetuate Healthcare Disparities—a Global Review.” 

PLOS Digital Health  1(3): e0000022. 

Chaix, B., Bibault, J.-E., Pienkowski, A., Delamon, G., 

Guillemassé, A., Nectoux, P., and Brouard, B. 2019. 

“When Chatbots Meet Patients: One-Year Prospective 

Study of Conversations between Patients with Breast 

Cancer and a Chatbot.”  JMIR cancer  5(1): e12856. 

Chakraborty, C., Bhattacharya, M., Lee, S.-S., Wen, 

Z.-H., and Lo, Y.-H. 2024.  “The Changing Scenario of 

Drug Discovery Using AI to Deep Learning: Recent Ad -

vancement, Success Stories, Collaborations, and Chal -

lenges.”  Molecular Therapy Nucleic Acids  35(3). 

Chan Miller, C., Roche, S., Wilzewski, J. S., Liu, X., 

Chance, K., Souri, A. H., Conway, E., and others. 

2024.  “Methane Retrieval from Methaneair Using the 

Co 2 Proxy Approach: A Demonstration for the Upcom -

ing Methanesat Mission.”  Atmospheric Measurement 

Techniques  17(18): 5429–5454. 

Chandel, N. S., Chakraborty, S. K., Rajwade, Y. A., 

Dubey, K., Tiwari, M. K., and Jat, D. 2021.  “Identifying 

Crop Water Stress Using Deep Learning Models.”  Neu -

ral Computing and Applications  33(10): 5353–5367. 

Chen, R. J., Wang, J. J., Williamson, D. F., Chen, T. 

Y., Lipkova, J., Lu, M. Y., Sahai, S., and Mahmood, F. 

2023a.  “Algorithmic Fairness in Artificial Intelligence 

for Medicine and Healthcare.”  Nature biomedical engi -

neering  7(6): 719–742. 

Chen, Y., Liu, T. X., Shan, Y., and Zhong, S. 2023b. 

“The Emergence of Economic Rationality of GPT.”  Pro -

ceedings of the National Academy of Sciences  120(51): 

e2316205120. 

Chitturi, S. R., Ramdas, A., Wu, Y., Rohr, B., Ermon, S., 

Dionne, J., Jornada, F. H. d., and others. 2024.  “Tar -

geted Materials Discovery Using Bayesian Algorithm 

Execution.”  NPJ Computational Materials  10(1): 1–12. 

Choi, S. L., Jain, R., Emami, P., Wadsack, K., Ding, F., 

Sun, H., Gruchalla, K., and others. 2024.  “eGridGPT: 

Trustworthy AI in the Control Room.” Technical Report 

NREL/TP-5D00-87440, National Renewable Energy 

Laboratory (NREL), Golden, CO. 

Cobb, P. J. 2023.  “Large Language Models and Gen -

erative AI, Oh My!: Archaeology in the Time of Chatgpt, 

Midjourney, and Beyond.”  Advances in Archaeological 

Practice  11(3): 363–369. 

Collins, K. M., Sucholutsky, I., Bhatt, U., Chandra, K., 

Wong, L., Lee, M., Zhang, C. E., and others. 2024. 

“Building Machines That Learn and Think with People.” 

Nature Human Behaviour  8(10): 1851–1863. 

Comunale, M., and Manera, A. 2024.  “The Economic 

Impacts and the Regulation of AI: A Review of the Aca -

demic Literature and Policy Actions.”  IMF Working Pa -

per No. 2024/065 .

Cordier, T., Esling, P., Lejzerowicz, F., Visco, J., Oua -

dahi, A., Martins, C., Cedhagen, T., and Pawlowski, 

J. 2017.  “Predicting the Ecological Quality Status of 

Marine Environments from Edna Metabarcoding Data 

Using Supervised Machine Learning.”  Environmental 

Science & Technology  51(16): 9118–9126. 

Cordier, T., Forster, D., Dufresne, Y., Martins, C. I. M., 

Stoeck, T., and Pawlowski, J. 2018.  “Supervised Ma -

chine Learning Outperforms Taxonomy-Based Environ -

mental DNA Metabarcoding Applied to Biomonitoring.” 

Molecular Ecology Resources  18(6): 1381–1391. 

Cornelli, G., Frost, J., and Mishra, S. 2023.  “Artificial 

Intelligence, Services Globalisation and Income In -

equality.” BIS Working Papers 1135, Bank for Interna -

tional Settlements. 

Corso, A., Moss, R., Koren, M., Lee, R., and Ko -

chenderfer, M. 2021.  “A Survey of Algorithms for Black-

Box Safety Validation of Cyber-Physical Systems.”  Jour -

nal of Artificial Intelligence Research  72: 377–428. 

Coyle, and Selvi 2024.  “Making Innovation Inclu -

sive.” Productivity Insights Paper 039, The Productivity 

Institute. 

Coyle, D. 2025.  The Measure of Progress: Counting 

What Really Matters.  Princeton, NJ: Princeton Univer -

sity Press. 

Crafts, N. 2021.  “Artificial Intelligence as a General-

Purpose Technology: An Historical Perspective.”  Ox -

ford Review of Economic Policy  37 (3): 521–536. 

Crootof, R., Kaminski, M. E., Price, W., and Nicholson, 

I. 2023.  “Humans in the Loop.”  Vand. L. Rev.  76: 429. 

Crootof, R., Kaminski, M. E., and Price, W. N. I. 2023. 

“Humans in the Loop.”  Vanderbilt Law Review  76(2): 

429–510. 2 6 0 HUMAN DEVELOPMENT REPORT 2025 

Cubaynes, H. C., and Fretwell, P. T. 2022.  “Whales 

from Space Dataset, an Annotated Satellite Image 

Dataset of Whales for Training Machine Learning Mod -

els.”  Scientific Data  9(1): 245. 

Cui, H., and Yasseri, T. 2024.  “AI-Enhanced Collective 

Intelligence.”  Patterns  5(11). 

Cui, Z., Li, N., and Zhou, H. 2024.  “Can AI Replace 

Human Subjects? A Large-Scale Replication of Psy -

chological Experiments with LLMs.”  arXiv preprint 

arXiv:2409.00128 .

Current AI. n.d.  “Building AI Together, Unlocking Op -

portunity for All.” https://www.currentai.org/. Accessed 

1 April 2025. 

d’Elia, A., Gabbay, M., Rodgers, S., Kierans, C., 

Jones, E., Durrani, I., Thomas, A., and Frith, L. 2022. 

“Artificial Intelligence and Health Inequities in Primary 

Care: A Systematic Scoping Review and Framework.” 

Family medicine and community health  10(Suppl 1). 

D’Silva, D., Filková, Z., Packer, F., and Tiwari, S. 2019. 

“The Design of Digital Financial Infrastructure: Lessons 

from India.”  BIS paper  (106). 

da Silveira, C. B. L., Strenzel, G. M. R., Maida, M., 

Gaspar, A. L. B., and Ferreira, B. P. 2021.  “Coral Reef 

Mapping with Remote Sensing and Machine Learning: 

A Nurture and Nature Analysis in Marine Protected Ar -

eas.”  Remote Sensing  13(15): 2907. 

Dae-Hyun. 2024.  “South Korea Unveils Plans for Na -

tional AI Computing Center with $1.7 Billion Investment.” 

https://koreatechtoday.com/south-korea-unveils-plans-

for-national-ai-computing-center-with-1-7-billion-invest -

ment/. Accessed 1 April 2025. 

Dauvergne, P. 2022.  “Is Artificial Intelligence Greening 

Global Supply Chains? Exposing the Political Economy 

of Environmental Costs.”  Review of International Politi -

cal Economy  29(3): 696–718. 

De Neubourg, C., Praet, S., Carrera Manzano, M., 

and Karpati, J. 2025.  “Harnessing Digital Innovations 

for Adaptive Social Protection in the Face of Climate 

Change.”  Social Policy Research Institute  (Background 

Research Paper - Next Generation of Human Develop -

ment Research (HDR 2025)). 

de Roda Husman, S., Lhermitte, S., Bolibar, J., Ize -

boud, M., Hu, Z., Shukla, S., van der Meer, M., Long, 

D., and Wouters, B. 2024.  “A High-Resolution Record 

of Surface Melt on Antarctic Ice Shelves Using Multi-

Source Remote Sensing Data and Deep Learning.”  Re -

mote Sensing of Environment  301: 113950. 

De Simone, M., Tiberti, F., Mosuro, W., Manolio, F., 

Barron, M., and Dikoru, E. 2025.  “From Chalkboards 

to Chatbots: Transforming Learning in Nigeria, One 

Promt at a Time.” World Bank blogs. https://blogs.world -

bank.org/en/education/From-chalkboards-to-chatbots-

Transforming-learning-in-Nigeria. Accessed 3 April 

2025. 

Dell, M. 2024.  “Deep Learning for Economists.” Work -

ing Paper 32768, National Bureau of Economic Re -

search, Cambridge, MA. 

Denniston, A. K., and Liu, X. 2024.  “Responsible and 

Evidence-Based AI: 5 Years On.”  The Lancet Digital 

Health  6(5): e305–e307. 

Digital Economy Working Group (G20). 2024.  Minis -

tério das Comunicações (MCOM)., International Tele -

communication Union (ITU)., and Brazilian Network 

Information Center. 2024. Universal and Meaningful 

Connectivity: A Framework for Indicators and Metrics. 

Diouf, M. A., Perez, L. P., Simione, F. F., Viseth, A., 

and Yao, J. 2024.  “A Conceptual Policy Framework for 

Leveraging Digitalization to Support Diversification in 

Sub-Saharan Africa.” Working Paper 2024/123, Interna -

tional Monetary Fund, Washington, DC. 

Doellgast, V. 2022.  Exit, Voice, and Solidarity: Con -

testing Precarity in the Us and European Telecommu -

nications Industries.  Oxford University Press. 

Doellgast, V. 2023.  “Strengthening Social Regulation 

in the Digital Economy: Comparative Findings from the 

Ict Industry.”  Labour and Industry  33(1): 22–38. 

Doellgast, V., Appalla, S., Ginzburg, D., , , Kim, J., and 

Thian, W. Forthcoming . “Global Case Studies of So -

cial Dialogue on AI and Algorithmic Management.”  ILO 

Working Paper .

Dongarra, J. J., Luszczek, P., and Petitet, A. 2003. 

“The Linpack Benchmark: Past, Present and Future.” 

Concurrency and Computation: Practice and Experi -

ence  15(9): 803–820. 

Dor, L. M. B., and Coglianese, C. 2021.  “Procurement 

as AI Governance.”  IEEE Transactions on Technology 

and Society  2(4): 192–199. 

Doshi, A. R., and Hauser, O. P. 2024.  “Generative AI 

Enhances Individual Creativity but Reduces the Col -

lective Diversity of Novel Content.”  Science Advances 

10(28): eadn5290. 

Du Boulay, B. 2016.  “Artificial Intelligence as an Ef -

fective Classroom Assistant.”  IEEE Intelligent Systems 

31(6): 76–81. 

Du, K., Zhao, Y., Mao, R., Xing, F., and Cambria, E. 

2025.  “Natural Language Processing in Finance: A Sur -

vey.”  Information Fusion  115: 102755. 

Duede, E., Dolan, W., Bauer, A., Foster, I., and Lakhani, 

K. 2024.  “Oil & Water? Diffusion of AI within and across 

Scientific Fields.”  arXiv preprint arXiv:2405.15828 .

Duporge, I., Isupova, O., Reece, S., Macdonald, D. W., 

and Wang, T. 2021.  “Using Very-High-Resolution Satel -

lite Imagery and Deep Learning to Detect and Count 

African Elephants in Heterogeneous Landscapes.” 

Remote Sensing in Ecology and Conservation  7(3): 

369–381. 

Durlik, I., Miller, T., Kostecka, E., and Tuński, T. 2024. 

“Artificial Intelligence in Maritime Transportation: A 

Comprehensive Review of Safety and Risk Manage -

ment Applications.”  Applied Sciences  14(18): 8420. 

Dychiao, R. G. K., Alberto, I. R. I., Artiaga, J. C. M., Sa -

longcay, R. P., and Celi, L. A. 2024.  “Large Language 

Model Integration in Philippine Ophthalmology: Early 

Challenges and Steps Forward.”  The Lancet Digital 

Health  6(5): e308. 

Eastwood, B. 2025.  “When Humans and AI Work 

Best Together — and When Each Is Better Alone.” MIT 

https://mitsloan.mit.edu/ideas-made-to-matter/when-

humans-and-ai-work-best-together-and-when-each-

better-alone. Accessed 16 Febryart 2025. 

Eaves, D., Mazzucato, M., and Vasconcellos, B. 

2024.  “Digital Public Infrastructure and Public Value: 

What Is ‘Public’about DPI?” 

Eaves, D., and Sandman, J. 2021.  “What Is Digital 

Public Infrastructure?” https://medium.com/iipp-blog/ 

what-is-digital-public-infrastructure-6fbfa74f2f8c. 

Eger, S., Cao, Y., D’Souza, J., Geiger, A., Greisinger, 

C., Gross, S., Hou, Y., and others. 2025.  “Transform -

ing Science with Large Language Models: A Survey 

on AI-Assisted Scientific Discovery, Experimentation, 

Content Generation, and Evaluation.”  arXiv preprint 

arXiv:2502.05151 .

Eggertsen, T. G., Travers, J. G., Hardy, E. J., Wolf, 

M. J., McKinsey, T. A., and Saucerman, J. J. 2025. 

“Logic-Based Machine Learning Predicts How Escita -

lopram Attenuates Cardiomyocyte Hypertrophy.”  Pro -

ceedings of the National Academy of Sciences  122(10): 

e2420499122. 

Eini, M., Kaboli, H. S., Rashidian, M., and Hedayat, H. 

2020.  “Hazard and Vulnerability in Urban Flood Risk 

Mapping: Machine Learning Techniques and Consider -

ing the Role of Urban Districts.”  International Journal of 

Disaster Risk Reduction  50: 101687. 

Eisfeldt, A. L., and Schubert, G. 2024.  “AI and Fi -

nance.” Working Paper 33076, National Bureau of Eco -

nomic Research, Cambridge, MA. 

Eloundou, T., Manning, S., Mishkin, P., and Rock, 

D. 2024.  “GPTs Are GPTs: An Early Look at the Labor 

Market Impact Potential of Large Language Models by 

Admin No Comments.”  Science  384: 1306–1308 

Ennaji, O., Vergütz, L., and El Allali, A. 2023.  “Ma -

chine Learning in Nutrient Management: A Review.” 

Artificial Intelligence in Agriculture  9: 1–11. 

Ernst, E., Merola, R., and Samaan, D. 2019.  “Econom -

ics of Artificial Intelligence: Implications for the Future 

of Work.”  IZA Journal of Labor Policy  9(1). 

Ertmer, P. A., and Ottenbreit-Leftwich, A. T. 2010. 

“Teacher Technology Change: How Knowledge, Con -

fidence, Beliefs, and Culture Intersect.”  Journal of Re -

search on Technology in Education  42(3): 255–284. 

Esmaeilzadeh, P. 2024.  “Challenges and Strategies 

for Wide-Scale Artificial Intelligence (AI) Deployment 

in Healthcare Practices: A Perspective for Healthcare 

Organizations.”  Artificial Intelligence in Medicine  151: 

102861. 

Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter, S. 

M., Blau, H. M., and Thrun, S. 2017.  “Dermatologist-

Level Classification of Skin Cancer with Deep Neural 

Networks.”  Nature  542(7639): 115–118. 

ETO (Emerging Technology Observatory). 2023. 

“Singapore’s AI Research Collaboration with China 

More Than Doubled between 2016 and 2021.” 

ETO (Emerging Technology Observatory). 2024. 

“The State of Global AI Research.” Emerging Technol -

ogy Observatory. 

Faber, J. M., Luyten, H., and Visscher, A. J. 2017.  “The 

Effects of a Digital Formative Assessment Tool on Math -

ematics Achievement and Student Motivation: Results 

of a Randomized Experiment.”  Computers & Education 

106: 83–96. REFERENCES  2 61 

Fallis, D. 2021.  “The Epistemic Threat of Deepfakes.” 

Philosophy & Technology  34(4): 623–643. 

Fan, J., Wang, S., Li, H., Yan, Z., Zhang, Y., Zheng, X., 

and Wang, P. 2020.  “Modeling the Ecological Status 

Response of Rivers to Multiple Stressors Using Ma -

chine Learning: A Comparison of Environmental DNA 

Metabarcoding and Morphological Data.”  Water Re -

search  183: 116004. 

Fan, Y., Tang, L., Le, H., Shen, K., Tan, S., Zhao, Y., 

Shen, Y., Li, X., and Gašević, D. 2025.  “Beware of 

Metacognitive Laziness: Effects of Generative Artificial 

Intelligence on Learning Motivation, Processes, and 

Performance.”  British Journal of Educational Technol -

ogy  56(2): 489–530. 

Farahani, M., and Ghasemi, G. 2024.  “Artificial Intel -

ligence and Inequality: Challenges and Opportunities.” 

Int. J. Innov. Educ  9: 78–99. 

Ferdousi, R., Hossain, M. A., and El Saddik, A. 2021. 

“Early-Stage Risk Prediction of Non-Communicable 

Disease Using Machine Learning in Health Cps.”  IEEE 

Access  9: 96823–96837. 

Ferrario, A., and Loi, M. How Explainability Contrib -

utes to Trust in AI. Proceedings of the 2022 ACM 

Conference on Fairness, Accountability, and Trans -

parency, 2022.  1457–1466. 

Feuerriegel, S., Maarouf, A., Bär, D., Geissler, D., 

Schweisthal, J., Pröllochs, N., Robertson, C. E., and 

others. 2025.  “Using Natural Language Processing to 

Analyse Text Data in Behavioural Science.”  Nature Re -

views Psychology .

Filippas, A., Horton, J. J., and Manning, B. S. 2024. 

Large Language Models as Simulated Economic 

Agents: What Can We Learn from Homo Silicus? Pro -

ceedings of the 25th ACM Conference on Economics 

and Computation. 614–615. 

Filippucci, F., Gal, P., Jona Lasinio, C. S., Leandro, A., 

and Nicoletti, G. 2024.  “The Impact of Artificial Intelli -

gence on Productivity, Distribution and Growth.” OECD 

Artificial Intelligence Papers 15, OECD Publishing, Paris. 

Filippucci, F., Gal, P., and Schief, M. 2024.  “Miracle 

or Myth? Assessing the Macroeconomic Productivity 

Gains from Artificial Intelligence.” OECD Artificial Intel -

ligence Papers 29, OECD Publishing, Paris. 

Frank, D.-A., Elbæk, C. T., Børsting, C. K., Mitkidis, 

P., Otterbring, T., and Borau, S. 2021.  “Drivers and 

Social Implications of Artificial Intelligence Adoption in 

Healthcare During the Covid-19 Pandemic.”  PLOS ONE 

16(11): e0259928. 

Frey, C. B., and Osborne, M. A. 2017.  “The Future of 

Employment: How Susceptible Are Jobs to Computeri -

sation?”  Technological Forecasting and Social Change 

114: 254–280. 

Fu, Y., Bin, H., Zhou, T., Wang, M., Chen, Y., Lai, Z. G. 

D. C., Wobbrock, J. O., and Hiniker, A. 2024.  “Creativ -

ity in the Age of AI: Evaluating the Impact of Generative 

AI on Design Outputs and Designers’ Creative Think -

ing.”  arXiv preprint arXiv:2411.00168 .

Fügener, A., Grahl, J., Gupta, A., and Ketter, W. 2021. 

“Will Humans-in-the-Loop Become Borgs? Merits and 

Pitfalls of Working with AI.”  Management Information 

Systems Quarterly (MISQ)-Vol  45. 

Gao, S., Fang, A., Huang, Y., Giunchiglia, V., Noori, 

A., Schwarz, J. R., Ektefaie, Y., Kondic, J., and Zitnik, 

M. 2024.  “Empowering Biomedical Discovery with AI 

Agents.”  Cell  187(22): 6125–6151. 

Garikapati, D., and Shetiya, S. S. 2024.  “Autonomous 

Vehicles: Evolution of Artificial Intelligence and the 

Current Industry Landscape.”  Big Data and Cognitive 

Computing  8(4): 42. 

Gaspar, V. J., L.; Wingender, P., 2016.  “Tax Capacity 

and Growth: Is There a Tipping Point?”  IMF Working 

Paper  16/234. 

Ge, T., Chan, X., Wang, X., Yu, D., Mi, H., and 

Yu, D. 2024.  “Scaling Synthetic Data Creation 

with 1,000,000,000 Personas.”  arXiv preprint 

arXiv:2406.20094 .

George, A. S., and Shaji, T. 2024.  “Overcoming the 

Collective Action Problem: Enacting Norms to Address 

Adolescent Technology Addiction.”  Partners Universal 

International Research Journal  3(2): 57–75. 

Ghobadpour, A., Boulon, L., Mousazadeh, H., Malva -

jerdi, A. S., and Rafiee, S. 2019.  “State of the Art of Au -

tonomous Agricultural Off-Road Vehicles Driven by Re -

newable Energy Systems.”  Energy Procedia  162: 4–13. 

Ghobadpour, A., Monsalve, G., Cardenas, A., and 

Mousazadeh, H. 2022.  “Off-Road Electric Vehicles 

and Autonomous Robots in Agricultural Sector: 

Trends, Challenges, and Opportunities.”  Vehicles  4(3): 

843–864. 

Ghosh, K., and Sadeghian, S. 2024.  “The Impact of 

AI on Perceived Job Decency and Meaningfulness: A 

Case Study.”  arXiv preprint arXiv:2406.14273 .

Giacosa, E., Alam, G. M., Culasso, F., and Crocco, E. 

2023.  “Stress-Inducing or Performance-Enhancing? 

Safety Measure or Cause of Mistrust? The Paradox of 

Digital Surveillance in the Workplace.”  Journal of Inno -

vation & Knowledge  8(2): 100357. 

Gichoya, J. W., Thomas, K., Celi, L. A., Safdar, N., Ba -

nerjee, I., Banja, J. D., Seyyed-Kalantari, L., Trivedi, 

H., and Purkayastha, S. 2023.  “AI Pitfalls and What 

Not to Do: Mitigating Bias in AI.”  The British Journal of 

Radiology  96(1150): 20230023. 

Gille, F., Jobin, A., and Ienca, M. 2020.  “What We Talk 

About When We Talk About Trust: Theory of Trust for AI 

in Healthcare.”  Intelligence-Based Medicine  1: 100001. 

Girotra, K., Meincke, L., Terwiesch, C., and Ulrich, K. 

T. 2023.  “Ideas Are Dimes a Dozen: Large Language 

Models for Idea Generation in Innovation.”  Available at 

SSRN 4526071 .

Glickman, M., and Sharot, T. 2024a.  “AI-Induced Hy -

per-Learning in Humans.”  Current Opinion in Psychol -

ogy  60: 101900. 

Glickman, M., and Sharot, T. 2024b.  “How Human–AI 

Feedback Loops Alter Human Perceptual, Emotional 

and Social Judgements.”  Nature Human Behaviour .

Gmyrek, P., Berg, J., and Bescond, D. 2023.  “Genera -

tive AI and Jobs: A Global Analysis of Potential Effects 

on Job Quantity and Quality.” ILO Working Paper 96. 

Gmyrek, P., Winkler, H., and Garganta, S. 2024.  “Buf -

fer or Bottleneck? Employment Exposure to Generative 

AI and the Digital Divide in Latin America.” Policy Re -

search Working Paper 10863, World Bank, Washington, 

DC. 

Goel, M., and Pandey, M. 2024.  “Crop Yield Prediction 

Using AI: A Review.”  2nd International Conference on 

Disruptive Technologies (ICDT) , 1547–1553. 

Goh, E., Gallo, R., Hom, J., Strong, E., Weng, Y., Ker -

man, H., Cool, J. A., and others. 2024.  “Large Lan -

guage Model Influence on Diagnostic Reasoning: A 

Randomized Clinical Trial.”  JAMA Network Open  7(10): 

e2440969–e2440969. 

Goldin, I., Koutroumpis, P., Lafond, F., and Winkler, J. 

2024.  “Why Is Productivity Slowing Down?”  Journal of 

Economic Literature  62(1): 196–268. 

Goldman Sachs. 2024.  “AI Is Poised to Drive 160% 

Increase in Data Center Power Demand.” Available 

at: https://www.goldmansachs.com/insights/articles/ 

AI-poised-to-drive-160-increase-in-power-demand. 

Google Research. 2025.  “Green Light: Reduce Traf -

fic Emissions with AI—Google Research.” Available at: 

https://sites.research.google/gr/greenlight/. 

Gould, R. K., Jimenez Naranjo, Y., and Balvanera, P. 

2025.  “Relationality Is Not Weird: The Importance of 

Relational Thinking in the Majority of the Planet’s Soci -

eties.”  Ecosystems and People  21(1): 2427810. 

Green, S. E., Rees, J. P., Stephens, P. A., Hill, R. A., 

and Giordano, A. J. 2020.  “Innovations in Camera 

Trapping Technology and Approaches: The Integration 

of Citizen Science and Artificial Intelligence.”  Animals 

10(1): 132. 

Grepperud, S., and Rasmussen, I. 2004.  “A General 

Equilibrium Assessment of Rebound Effects.”  Energy 

Economics  26(2): 261–282. 

Grossmann, I., Varnum, M. E. W., Hutcherson, C. A., 

and Mandel, D. R. 2024.  “When Expert Predictions 

Fail.”  Trends in Cognitive Sciences  28(2): 113–123. 

Gu, C., Peng, Y., Nastase, S. A., Mayer, R. E., and Li, 

P. 2024.  “Onscreen Presence of Instructors in Video 

Lectures Affects Learners’ Neural Synchrony and Vi -

sual Attention During Multimedia Learning.”  Proceed -

ings of the National Academy of Sciences  121(12): 

e2309054121. 

Gu, X., and Krenn, M. 2024.  “Interesting Scientific 

Idea Generation Using Knowledge Graphs and LLMs: 

Evaluations with 100 Research Group Leaders.”  arXiv 

preprint arXiv:2405.17044 .

Gulshan, V., Peng, L., Coram, M., Stumpe, M. C., Wu, 

D., Narayanaswamy, A., Venugopalan, S., and oth -

ers. 2016.  “Development and Validation of a Deep 

Learning Algorithm for Detection of Diabetic Retinopa -

thy in Retinal Fundus Photographs.”  JAMA  316(22): 

2402–2410. 

Guo, D., Zhu, Q., Yang, D., Xie, Z., Dong, K., Zhang, 

W., Chen, G., and others. 2024.  “Deepseek-Coder: 

When the Large Language Model Meets Program -

ming—the Rise of Code Intelligence.”  arXiv: 2401.14196. 

Guo, S., Xu, P., Miao, Q., Shao, G., Chapman, C. A., 

Chen, X., He, G., and others. 2020.  “Automatic Identi -

fication of Individual Primates with Deep Learning Tech -

niques.”  iScience  23(8): 101412. 2 6 2 HUMAN DEVELOPMENT REPORT 2025 

Gupta, P., Nguyen, T. N., Gonzalez, C., and Woolley, 

A. W. 2023.  “Fostering Collective Intelligence in Hu -

man–AI Collaboration: Laying the Groundwork for Co -

humain.”  Topics in Cognitive Science .

Gust, S., Hanushek, E. A., and Woessmann, L. 2024a. 

“Global Universal Basic Skills: Current Deficits and Im -

plications for World Development.”  Journal of Develop -

ment Economics  166: 103205. 

Gust, S., Hanushek, E. A., and Woessmann, L. A. 

2024b.  “World Unprepared: Missing Skills for Develop -

ment.”  EconPol Forum  25(2): 43–46. 

Gustafson, E. 2024.  “Probing the Limits of Figures and 

Grounds: Artificial Intelligence and Quantum Computa -

tion.”  New Explorations  4(1). 

Gyevnar, B., and Kasirzadeh, A. 2025.  “AI Safety for 

Everyone.”  arXiv preprint arXiv:2502.09288 .

Haase, J., and Pokutta, S. 2024.  “Human-AI Co-Cre -

ativity: Exploring Synergies across Levels of Creative 

Collaboration.”  arXiv preprint arXiv:2411.12527 .

Haider, J., Söderström, K. R., Ekström, B., and Rödl, 

M. 2024.  “GPT-Fabricated Scientific Papers on Google 

Scholar: Key Features, Spread, and Implications for 

Preempting Evidence Manipulation.”  Harvard Kennedy 

School Misinformation Review  5(5): 1–16. 

Ham, J., Quistorff, B., and Weinberg, B. A. 2025. 

“Recombinant Innovation, Novel Ideas, and the Start of 

Nobel Prize-Winning Work.” Working Paper 33579, Na -

tional Bureau of Economic Research, Cambridge, MA. 

Hamrani, A., Akbarzadeh, A., and Madramootoo, 

C. A. 2020.  “Machine Learning for Predicting Green -

house Gas Emissions from Agricultural Soils.”  Science 

of The Total Environment  741: 140338. 

Han, R., Acosta, J. N., Shakeri, Z., Ioannidis, J. P., 

Topol, E. J., and Rajpurkar, P. 2024.  “Randomised 

Controlled Trials Evaluating Artificial Intelligence in 

Clinical Practice: A Scoping Review.”  The Lancet Digital 

Health  6(5): e367–e373. 

Hanley, N., McGregor, P. G., Swales, J. K., and Turner, 

K. 2009.  “Do Increases in Energy Efficiency Improve 

Environmental Quality and Sustainability?”  Ecological 

Economics  68(3): 692–709. 

Hannun, A. Y., Rajpurkar, P., Haghpanahi, M., Tison, 

G. H., Bourn, C., Turakhia, M. P., and Ng, A. Y. 2019. 

“Cardiologist-Level Arrhythmia Detection and Classifi -

cation in Ambulatory Electrocardiograms Using a Deep 

Neural Network.”  Nature Medicine  25(1): 65–69. 

Hartman, V., Zhang, X., Poddar, R., McCarty, M., 

Fortenko, A., Sholle, E., Sharma, R., Campion, T., 

and Steel, P. A. 2024.  “Developing and Evaluat -

ing Large Language Model–Generated Emergency 

Medicine Handoff Notes.”  JAMA Network Open  7(12): 

e2448723–e2448723. 

Harvard Growth Lab. 2025.  “Growth Projections and 

Complexity Rankings.” Harvard Dataverse. https://doi. 

org/10.7910/DVN/XTAQMC, Accessed 1 April 2025. 

Hassan, H., Islam, A., Siddique, A., and Wang, L. 

C. 2024.  “Telementoring and Homeschooling Dur -

ing School Closures: A Randomised Experiment in 

Rural Bangladesh.”  The Economic Journal  134(662): 

2418–2438. 

Hausfather, Z. 2025.  “An Assessment of Current Pol -

icy Scenarios over the 21st Century and the Reduced 

Plausibility of High-Emissions Pathways.”  Dialogues on 

Climate Change : 29768659241304854. 

He, J., Feng, W., Min, Y., Yi, J., Tang, K., Li, S., Zhang, 

J., and others. 2023.  “Control Risk for Potential Mis -

use of Artificial Intelligence in Science.”  arXiv preprint 

arXiv:2312.06632 .

He, Y.-H. 2024.  “AI-Driven Research in Pure Mathemat -

ics and Theoretical Physics.”  Nature Reviews Physics 

6(9): 546–553. 

Heim, A. B., Bharani, T., Konstantinides, N., Pow -

ell, J. R., Srivastava, S., Cao, X. E., Agarwal, D., and 

others. 2023.  “AI in Search of Human Help.”  Science 

381(6654): 162–163. 

Helber, P., Bischke, B., Dengel, A., and Borth, D. 

2019.  “Eurosat: A Novel Dataset and Deep Learning 

Benchmark for Land Use and Land Cover Classifica -

tion.”  IEEE Journal of Selected Topics in Applied Earth 

Observations and Remote Sensing  12(7): 2217–2226. 

Henkel, O., Horne-Robinson, H., Kozhakhme -

tova, N., and Lee, A. 2024.  “Effective and Scalable 

Math Support: Evidence on the Impact of an AI-Tu -

tor on Math Achievement in Ghana.”  arXiv preprint 

arXiv:2402.09809 .

Hirvonen, J., Stenhammar, A., and Tuhkuri, J. 2022. 

“New Evidence on the Effect of Technology on Employ -

ment and Skill Demand.”  ETLA Working Papers 93, The 

Research Institute of the Finnish Economy .

HLEG (High-Level Expert Group on Artificial Intel -

ligence). 2019.  “High-Level Expert Group on Artificial 

Intelligence.”  Ethics Guidelines for Trustworthy AI  6. 

Hofman, J. M., Watts, D. J., Athey, S., Garip, F., 

Griffiths, T. L., Kleinberg, J., Margetts, H., and others. 

2021.  “Integrating Explanation and Prediction in Com -

putational Social Science.”  Nature  595(7866): 181–188. 

Holly, L., Demaio, S., and Kickbusch, I. 2024.  “Public 

Health Interventions to Address Digital Determinants 

of Children’s Health and Wellbeing.”  The Lancet Public 

Health  9(9): e700–e704. 

Hosny, A., and Sollaci, A. 2022.  Digitalization and So -

cial Protection: Macro and Micro Lessons for Vietnam. 

Working Paper 2022/185, International Monetary Fund, 

Washington, DC. 

Huggett, J. 2021.  “Algorithmic Agency and Autonomy 

in Archaeological Practice.”  Open Archaeology  7(1): 

417–434. 

Huggett, J. 2021.  Is Less More? Slow Data and Datafi -

cation in Archaeology. Critical archaeology in the digi -

tal age: Proceedings of the 12th IEMA Visiting Scholar’s 

Conference, 2022. Cotsen Institute of Archaeology 

Press, 97–110. 

Hullman, J., Holtzman, A., and Gelman, A. 2023. 

“Artificial Intelligence and Aesthetic Judgment.”  arXiv 

preprint arXiv:2309.12338 .

Hulten, C. R. 1978.  “Growth Accounting with Interme -

diate Inputs.”  The Review of Economic Studies  45(3): 

511–518. 

Humeau, E., and Deshpande, T. 2024.  “AI for Africa: 

Use Cases Delivering Impact.” London: GSMA. 

IBM. 2021.  “Accelerated Discovery of Battery Materials.” 

IBM Research. Available at https://research.ibm.com/ 

projects/accelerated-discovery-of-battery-materials. 

Ijaz, K., Bogdanovych, A., and Trescak, T. 2017.  “Vir -

tual Worlds Vs Books and Videos in History Education.” 

Interactive Learning Environments  25(7): 904–929. 

ILO (International Labour Organization). 2025. 

“Social Dialogue and Tripartism.” https://www.ilo.org/ 

topics-and-sectors/social-dialogue-and-tripartism. Ac -

cessed 11 March 2025. 

Imbs, J., and Wacziarg, R. 2003.  “Stages of Diversifi -

cation.”  American Economic Review  93(1): 63–86. 

Indraratna, P., Tardo, D., Yu, J., Delbaere, K., Brodie, 

M., Lovell, N., and Ooi, S.-Y. 2020.  “Mobile Phone 

Technologies in the Management of Ischemic Heart 

Disease, Heart Failure, and Hypertension: Systematic 

Review and Meta-Analysis.”  JMIR mHealth and uHealth 

8(7): e16695. 

Ishida, T., Ihsan, A. F., and Rudawan, R. A. 2024.  “Ad -

vancing Global South University Education with Large 

Language Models.”  arXiv preprint arXiv:2410.07139 .

ITU (International Telecommunication Union) and 

FAO (Food and Agriculture Organization). 2021. 

Digital Agriculture in Action: Artificial Intelligence for 

Agriculture . ITU and FAO. 

ITU (International Telecommunication Union). 2021. 

“ICTs & Digital Health.” https://www.itu.int/en/media -

centre/backgrounders/Pages/icts-digital-health.aspx. 

Accessed 4/11/2025 2025. 

ITU (International Telecommunication Union). 

2023a.  Cyber Risks, Threats, and Harms in the Meta -

verse . ITU Focus Group Technical Report. 

ITU (International Telecommunication Union). 

2023b.  “Digital Inclusion of All.” https://www.itu.int/ 

en/mediacentre/backgrounders/Pages/digital-inclu -

sion-of-all.aspx#:~:text=Overview&text=ITU’s%20mis -

sion%20is%20to%20guarantee,island%20develop -

ing%20states%20(SIDS). Accessed 11 April 2025. 

ITU (International Telecommunication Union). 

2023c.  “ITU’s Inputs to the Global Digital Compact.” 

Available at: https://www.un.org/digital-emerging-

technologies/sites/www.un.org.techenvoy/files/GDC-

submission_ITU.pdf. 

ITU (International Telecommunication Union). 

2024a.  “The Digital Sector’s Environmental Dilemma.” 

https://www.itu.int/hub/2024/11/the-digital-sectors-envi -

ronmental-dilemma/. Accessed 4/11/2025. 

ITU (International Telecommunication Union). 

2024b.  “Measuring Digital Development: Facts and 

Figures 2024.” International Telecommunication Union 

(ITU). 

ITU (International Telecommunication Union). n.d. 

“The UMC Project.” https://www.itu.int/itu-d/sites/pro -

jectumc/home/the-umc-project/. Accessed 11 March 

2025. 

J-PAL (Abdul Latif Jameel Poverty Action Lab). 2023. 

“Vocational and Skills Training Programs to Improve REFERENCES  2 6 3 

Labor Market Outcomes.” https://www.povertyaction -

lab.org/policy-insight/vocational-and-skills-training-

programs-improve-labor-market-outcomes. Accessed 

2 February 2025. 

Jain, P., Coogan, S. C. P., Subramanian, S. G., Crow -

ley, M., Taylor, S., and Flannigan, M. D. 2020.  “A Re -

view of Machine Learning Applications in Wildfire Sci -

ence and Management.”  Environmental Reviews  28(4): 

478–505. 

Jamali, H., Dascalu, S. M., and Harris, F. C. 2024. 

AI-Driven Analysis and Prediction of Energy Consump -

tion in Nyc’s Municipal Buildings. 2024 IEEE/ACIS 22nd 

International Conference on Software Engineering Re -

search, Management and Applications (SERA), 2024-

05. 277–283. 

Jarrahi, M. H., Möhlmann, M., and Lee, M. K. 2023. 

“Algorithmic Management: The Role of AI in Managing 

Workforces.”  MIT Sloan Management Review  64(3): 

1–5. 

Javidan, N., Kavian, A., Pourghasemi, H. R., Cono -

scenti, C., Jafarian, Z., and Rodrigo-Comino, J. 2021. 

“Evaluation of Multi-Hazard Map Produced Using Max -

ent Machine Learning Technique.”  Scientific Reports 

11(1): 6496. 

Jensen, T., Seerup Hass, F., Seam Akbar, M., Holm 

Petersen, P., and Jokar Arsanjani, J. 2020.  “Employ -

ing Machine Learning for Detection of Invasive Species 

Using Sentinel-2 and Aviris Data: The Case of Kudzu in 

the United States.”  Sustainability  12(9): 3544. 

Jiang, J., Zou, X., Mitchell, R. N., Zhang, Y., Zhao, 

Y., Yin, Q.-Z., Yang, W., and others. 2024.  “Sediment 

Subduction in Hadean Revealed by Machine Learning.” 

Proceedings of the National Academy of Sciences 

121(30): e2405160121. 

Jindal, S. 2023.  “Valuing Data Enrichment Workers: 

The Case for a Human-Centric Approach to AI Devel -

opment.” https://www.un.org/en/un-chronicle/valuing-

data-enrichment-workers-case-human-centric-appro -

ach-ai-development. 

Johnson, S., and Acemoglu, D. 2023.  Power and 

Progress: Our Thousand-Year Struggle over Technol -

ogy and Prosperity.  Hachette UK. 

Jordan, K., Myers, C., Damani, K., Khagame, P., 

Mumbi, A., and Njuguna, L. 2024.  “Supporting Equi -

table Access to Learning Via Sms in Kenya: Impact on 

Engagement and Learning Outcomes.”  British Journal 

of Educational Technology .

Kahl, S., Wood, C. M., Eibl, M., and Klinck, H. 2021. 

“Birdnet: A Deep Learning Solution for Avian Diversity 

Monitoring.”  Ecological Informatics  61: 101236. 

Kamminga, J., Ayele, E., Meratnia, N., and Havinga, 

P. 2018.  “Poaching Detection Technologies—a Survey.” 

Sensors  18(5): 1474. 

Kapari, M., Sibanda, M., Magidi, J., Mabhaudhi, T., 

Nhamo, L., and Mpandeli, S. 2024.  “Comparing Ma -

chine Learning Algorithms for Estimating the Maize 

Crop Water Stress Index (Cwsi) Using UAV-Acquired 

Remotely Sensed Data in Smallholder Croplands.” 

Drones  8(2): 61. 

Kapoor, S., Cantrell, E. M., Peng, K., Pham, T. H., Bail, 

C. A., Gundersen, O. E., Hofman, J. M., and others. 

2024.  “Reforms: Consensus-Based Recommendations 

for Machine-Learning-Based Science.”  Science Ad -

vances  10(18): eadk3452. 

Kapoor, S., and Narayanan, A. 2023.  “Leakage and 

the Reproducibility Crisis in Machine-Learning-Based 

Science.”  Patterns  4(9): 100804. 

Karger, E., Bastani, H., Yueh-Han, C., Jacobs, Z., Ha -

lawi, D., Zhang, F., and Tetlock, P. E. 2024.  “Forecast -

bench: A Dynamic Benchmark of AI Forecasting Capa -

bilities.”  arXiv preprint arXiv:2409.19839 .

Ke, L., Tong, S., Cheng, P., and Peng, K. 2024.  “Ex -

ploring the Frontiers of LLMs in Psychological Ap -

plications: A Comprehensive Review.”  arXiv preprint 

arXiv:2401.01519 .

Keller, B., and Willke, T. 2019.  “Snotbot: A Whale of a 

Deep-Learning Project.”  IEEE Spectrum  56(12): 41–53. 

Kelling, S., Gerbracht, J., Fink, D., Lagoze, C., Wong, 

W.-K., Yu, J. Y., Damoulas, T., and Gomes, C. 2012. 

“Ebird: A Human/Computer Learning Network for Bio -

diversity Conservation and Research.”  Proceedings of 

the AAAI Conference on Artificial Intelligence  26(2): 

2229–2236. 

Kemene, E., Valkhof, B., and Greene-Dewasmes, 

G. 2024.  “AI and Energy: Will AI Reduce Emissions 

or Increase Demand?” World Economic Forum. Avail -

able at: https://www.weforum.org/stories/2024/07/ 

generative-ai-energy-emissions/. 

Khajeh Naeeni, S., and Nouhi, N. 2024.  “The Envi -

ronmental Impacts of AI and Digital Technologies.”  AI 

and Tech in Behavioral and Social Sciences  1(4): 11–18. 

Khan, C., Blount, D., Parham, J., Holmberg, J., Ham -

ilton, P., Charlton, C., Christiansen, F., and others. 

2022a.  “Artificial Intelligence for Right Whale Photo 

Identification: From Data Science Competition to 

Worldwide Collaboration.”  Mammalian Biology  102(3): 

1025–1042. 

Khan, M., Khurshid, M., Vatsa, M., Singh, R., Dug -

gal, M., and Singh, K. 2022b.  “On AI Approaches for 

Promoting Maternal and Neonatal Health in Low Re -

source Settings: A Review.”  Frontiers in Public Health 

10: 880034. 

Khan, S. 2024.  Brave New Words: How AI Will Revo -

lutionize Education (and Why That’s a Good Thing). 

Penguin. 

Kim, A., Muhn, M., and Nikolaev, V. 2024.  “Financial 

Statement Analysis with Large Language Models.”  arX -

iv preprint arXiv:2407.17866 .

Kim Eun-jin. 2025.  “South Korea to Launch AI Comput -

ing Center with Significant Public-Private Investment.” 

https://www.businesskorea.co.kr/news/articleView. 

html?idxno=234159. Accessed 1 April 2025. 

Kim, H., Karaman, B. K., Zhao, Q., Wang, A. Q., Sabun -

cu, M. R., and Initiative, A. s. D. N. 2025.  “Learning-

Based Inference of Longitudinal Image Changes: Appli -

cations in Embryo Development, Wound Healing, and 

Aging Brain.”  Proceedings of the National Academy of 

Sciences  122(8): e2411492122. 

Kim, H. Y., Cho, G. J., and Kwon, H. S. 2022.  “Applica -

tions of Artificial Intelligence in Obstetrics.”  Ultrasonog -

raphy  42(1): 2. 

Kim, J. 2023.  “Four Ways AI Is Making the Power Grid 

Faster and More Resilient.”  MIT Techonolgy Review .

Kirkpatrick, M., Rivera, G., and Akers, J. 2022.  “Sys -

tematic Review of Behavioral Interventions Using 

Digital Technology to Reduce Problem Behavior in the 

Classroom.”  Journal of Behavioral Education : 1–25. 

Knayer, T., and Kryvinska, N. 2022.  “An Analysis of 

Smart Meter Technologies for Efficient Energy Man -

agement in Households and Organizations.”  Energy 

Reports  8: 4022–4040. 

Koch, P., Stojkoski, V., and A. Hidalgo, C. 2024.  “Aug -

menting the Availability of Historical GDP Per Capita Es -

timates through Machine Learning.”  Proceedings of the 

National Academy of Sciences  121(39): e2402060121. 

Kochkov, D., Yuval, J., Langmore, I., Norgaard, P., 

Smith, J., Mooers, G., Klöwer, M., and others. 2024. 

“Neural General Circulation Models for Weather and 

Climate.”  Nature .

Koedinger, K. R., Corbett, A. T., and Perfetti, C. 2012. 

“The Knowledge-Learning-Instruction Framework: 

Bridging the Science-Practice Chasm to Enhance 

Robust Student Learning.”  Cognitive Science  36(5): 

757–798. 

Kolata, G. 2024.  “Chatbots Defeated Doctors at Di -

agnosing Illness.”  NY Times. Available online: https:// 

www.nytimes.com/2024/11/17/health/chatgpt-ai-doc -

tors-diagnosis.html (accessed on 23 November 2024) .

Korinek, A. 2023a.  “Generative AI for Economic Re -

search: Use Cases and Implications for Economists.” 

Journal of Economic Literature  61(4): 1281–1317. 

Korinek, A. 2023b.  “Generative AI for Economic Re -

search: Use Cases and Implications for Economists.” 

Journal of Economic Literature  61(4): 1281–1317. 

Korinek, A. 2024a.  “LLMs Learn to Collaborate and 

Reason: December 2024 Update to “Generative AI for 

Economic Research: Use Cases and Implications for 

Economists,” Published in the Journal of Economic.” 

Journal of Economic Literature  61(4). 

Korinek, A. 2024b.  “LLMs Level up—Better, Faster, 

Cheaper: June 2024 Update to Section 3 of “Genera -

tive AI for Economic Research: Use Cases and Impli -

cations for Economists,” Published in The.”  Journal of 

Economic Literature  61(4): 1–38. 

Korinek, A., and Stiglitz, J. E. 2018.  “Artificial Intelli -

gence and Its Implications for Income Distribution and 

Unemployment.”  The Economics of Artificial Intelli -

gence: An Agenda.  University of Chicago Press. 

Kovacev, R. 2020.  “A Taxing Dilemma: Robot Taxes 

and the Challenges of Effective Taxation of AI, Automa -

tion and Robotics in the Fourth Industrial Revolution.” 

Ohio St. Tech. LJ  16: 182. 

Kraemer, M. U. G., Tsui, J. L. H., Chang, S. Y., Lytras, 

S., Khurana, M. P., Vanderslott, S., Bajaj, S., and oth -

ers. 2025.  “Artificial Intelligence for Modelling Infec -

tious Disease Epidemics.”  Nature  638(8051): 623–635. 

Krämer, C., and Cazes, S. 2022.  “Shaping the Transi -

tion: Artificial Intelligence and Social Dialogue.” OECD 

Social, Employment and Migration Working Papers 279, 

OECD Publishing, Paris. 2 6 4 HUMAN DEVELOPMENT REPORT 2025 

Krzywdzinski, M., Gerst, D., and Butollo, F. 2023. 

“Promoting Human-Centred AI in the Workplace. Trade 

Unions and Their Strategies for Regulating the Use of 

AI in Germany.”  Transfer: European Review of Labour 

and Research  29(1): 53–70. 

Kuenzel, R., Teizer, J., Mueller, M., and Blickle, A. 

2016.  “Smartsite: Intelligent and Autonomous Envi -

ronments, Machinery, and Processes to Realize Smart 

Road Construction Projects.”  Automation in Construc -

tion  71: 21–33. 

Kutz, J. N., Brunton, S. L., Manohar, K., Lipson, H., 

and Li, N. 2024.  “AI Institute in Dynamic Systems: De -

veloping Machine Learning and AI Tools for Scientific 

Discovery, Engineering Design, and Data-Driven Con -

trol.”  AI Magazine  45(1): 48–53. 

Kwon, K., Lee, S., and Kim, S. 2022.  “AI-Based Home 

Energy Management System Considering Energy Ef -

ficiency and Resident Satisfaction.”  IEEE Internet of 

Things Journal  9(2): 1608–1621. 

Labadze, L., Grigolia, M., and Machaidze, L. 2023. 

“Role of AI Chatbots in Education: Systematic Literature 

Review.”  International Journal of Educational Technol -

ogy in Higher Education  20(1): 56. 

Lacity, M., and Willcocks, L. P. 2017.  Robotic Process 

Automation and Risk Mitigation: The Definitive Guide. 

SB Publishing. 

Landers, R. N., and Marin, S. 2021.  “Redesigning Job 

Tasks and Work Itself through Workplace Gamification: 

A Review, Research Agenda, and Recommendations 

for Practice.”  Organizational Gamification : 63–89. 

Lara-Cinisomo, S., Ramirez Olarte, A., Rosales, M., 

and Barrera, A. Z. 2021.  “A Systematic Review of 

Technology-Based Prevention and Treatment Interven -

tions for Perinatal Depression and Anxiety in Latina and 

African American Women.”  Maternal and child health 

journal  25: 268–281. 

Lee, J. T., and Callaway, D. S. 2018.  “The Cost of Re -

liability in Decentralized Solar Power Systems in Sub-

Saharan Africa.”  Nature Energy  3(11): 960–968. 

Lee, K., Miguel, E., and Wolfram, C. 2020.  “Experi -

mental Evidence on the Economics of Rural Electrifica -

tion.”  Journal of Political Economy  128(4): 1523–1565. 

Lehdonvirta, V., Wú, B., and Hawkins, Z. 2024.  Com -

pute North Vs. Compute South: The Uneven Possi -

bilities of Compute-Based AI Governance around the 

Globe. Proceedings of the AAAI/ACM Conference on 

AI, Ethics, and Society. 828–838. 

Lenharo, M. 2024.  “The Testing of AI in Medicine 

Is a Mess. Here’s How It Should Be Done.”  Nature 

632(8026): 722–724. 

Lenton, T. M., Abrams, J. F., Bartsch, A., Bathiany, S., 

Boulton, C. A., Buxton, J. E., Conversi, A., and others. 

2024.  “Remotely Sensing Potential Climate Change 

Tipping Points across Scales.”  Nature Communications 

15(1): 343. 

Leonard, N. E., and Levin, S. A. 2022.  “Collective In -

telligence as a Public Good.”  Collective Intelligence  1(1): 

26339137221083293. 

Li, K., Rubungo, A. N., Lei, X., Persaud, D., Choudhary, 

K., DeCost, B., Dieng, A. B., and Hattrick-Simpers, J. 

2025.  “Probing out-of-Distribution Generalization in 

Machine Learning for Materials.”  Communications Ma -

terials  6(1): 9. 

Li, X., Ren, A., and Li, Q. 2022.  “Exploring Patterns of 

Transportation-Related Co2 Emissions Using Machine 

Learning Methods.”  Sustainability  14(8): 4588. 

Licht, H. 2023.  “Cross-Lingual Classification of Political 

Texts Using Multilingual Sentence Embeddings.”  Politi -

cal Analysis  31(3): 366–379. 

Lin, H., Li, R., Liu, Z., Chen, J., Yang, Y., Chen, H., Lin, 

Z., and others. 2019.  “Diagnostic Efficacy and Thera -

peutic Decision-Making Capacity of an Artificial Intel -

ligence Platform for Childhood Cataracts in Eye Clinics: 

A Multicentre Randomized Controlled Trial.”  EClini -

calMedicine  9: 52–59. 

Lipowski, C., Salomons, A., and Zierahn-Weilage, 

U. 2024.  “Expertise at Work: New Technologies, New 

Skills, and Worker Impacts.”  ZEW Discussion Papers  24. 

Liu, C.-F., Huang, C.-C., Wang, J.-J., Kuo, K.-M., and 

Chen, C.-J. 2021.  “The Critical Factors Affecting the 

Deployment and Scaling of Healthcare AI: Viewpoint 

from an Experienced Medical Center. Healthcare.” 

MDPI , 685. 

Liu, H., Ding, N., Li, X., Chen, Y., Sun, H., Huang, 

Y., Liu, C., and others. 2024a.  “Artificial Intelligence 

and Radiologist Burnout.”  JAMA Network Open  7(11): 

e2448714–e2448714. 

Liu, L., Zhou, W., Guan, K., Peng, B., Xu, S., Tang, 

J., Zhu, Q., and others. 2024b.  “Knowledge-Guided 

Machine Learning Can Improve Carbon Cycle Quanti -

fication in Agroecosystems.”  Nature Communications 

15(1): 357. 

Liu, X., Liu, H., Yang, G., Jiang, Z., Cui, S., Zhang, Z., 

Wang, H., and others. 2025.  “A Generalist Medical 

Language Model for Disease Diagnosis Assistance.” 

Nature Medicine .

Liu, Y., Wang, H., and Zhenwhei Qiang, C. 2024. 

“Who on Earth Is Using Generative AI?” https://blogs. 

worldbank.org/en/digital-development/who-on-earth-

is-using-generative-ai-. Accessed 11 March 2025. 

Liu, Z., Wang, Y., Vaidya, S., Ruehle, F., Halverson, 

J., Soljačić, M., Hou, T. Y., and Tegmark, M. 2024c. 

“Kan: Kolmogorov-Arnold Networks.”  arXiv preprint 

arXiv:2404.19756 .

Loeckx, J. 2016.  “Blurring Boundaries in Education: 

Context and Impact of Moocs.”  International Review 

of Research in Open and Distributed Learning  17(3): 

92–121. 

Luccioni, A. S., Strubell, E., and Crawford, K. 2025. 

“From Efficiency Gains to Rebound Effects: The Prob -

lem of Jevons’ Paradox in AI’s Polarized Environmental 

Debate.” 

Ludwig, J., and Mullainathan, S. 2024.  “Machine 

Learning as a Tool for Hypothesis Generation.”  The 

Quarterly Journal of Economics  139(2): 751–827. 

Ludwig, J., Mullainathan, S., and Rambachan, A. 

2024.  “The Unreasonable Effectiveness of Algorithms.” 

AEA Papers and Proceedings  114: 623–27. 

Luo, X., Rechardt, A., Sun, G., Nejad, K. K., Yáñez, 

F., Yilmaz, B., Lee, K., and others. 2024.  “Large Lan -

guage Models Surpass Human Experts in Predicting 

Neuroscience Results.”  Nature Human Behaviour .

Lutz, W., Reiter, C., Özdemir, C., Yildiz, D., Guima -

raes, R., and Goujon, A. 2021.  “Skills-Adjusted Human 

Capital Shows Rising Global Gap.”  Proceedings of the 

National Academy of Sciences  118(7): e2015826118. 

M. Bran, A., Cox, S., Schilter, O., Baldassari, C., 

White, A. D., and Schwaller, P. 2024.  “Augmenting 

Large Language Models with Chemistry Tools.”  Nature 

Machine Intelligence  6(5): 525–535. 

Ma, Z., Jiang, G., Hu, Y., and Chen, J. 2025.  “A Review 

of Physics-Informed Machine Learning for Building En -

ergy Modeling.”  Applied Energy  381: 125169. 

Madhavaram, C. R., Sunkara, J. R., Kuraku, C., Galla, 

E. P., and Gollangi, H. K. 2024.  “The Future of Auto -

motive Manufacturing: Integrating AI, Ml, and Genera -

tive AI for Next-Gen Automatic Cars.”  IMRJR  1(1). 

Magesh, S. 2025.  “A Convolutional Neural Network 

Model and Algorithm Driven Prototype for Sustainable 

Tilling and Fertilizer Optimization.”  NPJ Sustainable Ag -

riculture  3(1): 1–15. 

Magnani, M., and Clindaniel, J. 2023.  “Artificial Intel -

ligence and Archaeological Illustration.”  Advances in 

Archaeological Practice  11(4): 452–460. 

Malashin, I., Tynchenko, V., Gantimurov, A., Nelyub, 

V., Borodulin, A., and Tynchenko, Y. 2024.  “Predict -

ing Sustainable Crop Yields: Deep Learning and Ex -

plainable AI Tools.”  Sustainability  16(21): 9437. 

Manning, B. S., Zhu, K., and Horton, J. J. 2024.  “Au -

tomated Social Science: Language Models as Scientist 

and Subjects.” Working Paper 32381, National Bureau 

of Economic Research, Cambridge, MA. 

Manyika, J., and Spence, M. 2023.  “The Coming AI 

Economic Revolution: Can Artificial Intelligence Re -

verse the Productivity Slowdown?”  Foreign Aff.  102: 70. 

Markowitz, D. M. 2024.  “From Complexity to Clarity: 

How AI Enhances Perceptions of Scientists and the 

Public’s Understanding of Science.”  PNAS Nexus  3(9). 

Marsh, E., Vallejos, E. P., and Spence, A. 2022.  “The 

Digital Workplace and Its Dark Side: An Integrative Re -

view.”  Computers in Human Behavior  128: 107118. 

Martin, A. J., Wellen, J. M., and Grimmer, M. R. 2016. 

“An Eye on Your Work: How Empowerment Affects 

the Relationship between Electronic Surveillance and 

Counterproductive Work Behaviours.”  The Interna -

tional Journal of Human Resource Management  27(21): 

2635–2651. 

Marwala, T. 2024.  “Avoidable and Unavoidable AI Al -

gorithmic Bias.”  The Balancing Problem in the Gover -

nance of Artificial Intelligence.  Springer. 

Mashhadi Rajabi, M. 2022.  “Dilemmas of Energy Ef -

ficiency: A Systematic Review of the Rebound Effect 

and Attempts to Curb Energy Consumption.”  Energy 

Research & Social Science  89: 102661. 

Mayer, R. E., and DaPra, C. S. 2012.  “An Embodiment 

Effect in Computer-Based Learning with Animated REFERENCES  2 6 5 

Pedagogical Agents.”  Journal of Experimental Psychol -

ogy: Applied  18(3): 239. 

Mayfield, H., Smith, C., Gallagher, M., and Hockings, 

M. 2017.  “Use of Freely Available Datasets and Ma -

chine Learning Methods in Predicting Deforestation.” 

Environmental Modelling & Software  87: 17–28. 

McClure, E. C., Sievers, M., Brown, C. J., Buelow, C. 

A., Ditria, E. M., Hayes, M. A., Pearson, R. M., and 

others. 2020.  “Artificial Intelligence Meets Citizen Sci -

ence to Supercharge Ecological Monitoring.”  Patterns 

1(7). 

McCowan, B., Hubbard, J., Walker, L., Sharpe, F., Fre -

diani, J., and Doyle, L. 2023.  “Interactive Bioacoustic 

Playback as a Tool for Detecting and Exploring Nonhu -

man Intelligence: “Conversing” with an Alaskan Hump -

back Whale.”  PeerJ  11: e16349. 

McGreivy, N., and Hakim, A. 2024.  “Weak Baselines 

and Reporting Biases Lead to Overoptimism in Machine 

Learning for Fluid-Related Partial Differential Equa -

tions.”  Nature Machine Intelligence  6(10): 1256–1269. 

Mehandru, N., Hall, A. K., Melnichenko, O., Dubinina, 

Y., Tsirulnikov, D., Bamman, D., Alaa, A., Saponas, 

S., and Malladi, V. S. 2025.  “Bioagents: Democratiz -

ing Bioinformatics Analysis with Multi-Agent Systems.” 

arXiv preprint arXiv:2501.06314 .

Mejia, D. G., J. D.,. 2025.  “Artificial Intelligence (AI) at 

the Service of Financial Inclusion.” https://www.caf.com/ 

en/blog/artificial-intelligence-ai-at-the-service-of-finan -

cial-inclusion/. Accessed 2 April 2025. 

Melumad, S., and Yun, J. H. 2025.  “Experimental Evi -

dence of the Effects of Large Language Models Versus 

Web Search on Depth of Learning.”  Available at SSRN 

5104064 .

Meng, X.-L. 2024.  “AI Has Won Nobel Prizes in Hard 

Science: Can Humans Be Smarter—and Softer on Each 

Other?”  Harvard Data Science Review  6(4). 

Merchant, A., Batzner, S., Schoenholz, S. S., Aykol, 

M., Cheon, G., and Cubuk, E. D. 2023.  “Scaling Deep 

Learning for Materials Discovery.”  Nature  624(7990): 

80–85. 

Merola, R. 2022.  “Inclusive Growth in the Era of Auto -

mation and AI: How Can Taxation Help?”  Frontiers in 

Artificial Intelligence  5: 867832. 

Messeri, L., and Crockett, M. J. 2024.  “Artificial Intel -

ligence and Illusions of Understanding in Scientific Re -

search.”  Nature  627(8002): 49–58. 

Meza-Cordero, J. A. 2017.  “Learn to Play and Play to 

Learn: Evaluation of the One Laptop Per Child Program 

in Costa Rica.”  Journal of International Development 

29(1): 3–31. 

Mienye, I. D., Swart, T. G., and Obaido, G. 2024.  “Fair -

ness Metrics in AI Healthcare Applications: A Review.” 

2024 IEEE International Conference on Information 

Reuse and Integration for Data Science (IRI) , 284–289. 

Miri, B., David, B.-C., and Uri, Z. 2007.  “Purposely 

Teaching for the Promotion of Higher-Order Thinking 

Skills: A Case of Critical Thinking.”  Research in Science 

Education  37: 353–369. 

Mishra, S., Koopman, R., De Prato, G., Rao, A., Oso -

rio-Rodarte, I., Kim, J., Spatafora, N., Strier, K., and 

Zaccaria, A. 2023.  “AI Specialization for Pathways 

of Economic Diversification.”  Scientific Reports  13(1): 

19475. 

Molenaar, I. 2022.  “Towards Hybrid Human-AI Learn -

ing Technologies.”  European Journal of Education 

57(4): 632–645. 

Mollick, E., and Mollick, L. 2023.  “Assigning AI: Seven 

Approaches for Students, with Prompts.”  arXiv preprint 

arXiv:2306.10052 .

Mollick, E., Mollick, L., Bach, N., Ciccarelli, L., 

Przystanski, B., and Ravipinto, D. 2024.  “AI Agents 

and Education: Simulated Practice at Scale.”  arXiv pre -

print arXiv:2407.12796 .

Morice, C. P., Kennedy, J. J., Rayner, N. A., Winn, J. 

P., Hogan, E., Killick, R. E., Dunn, R. J. H., and others. 

2021.  “An Updated Assessment of near-Surface Tem -

perature Change from 1850: The Hadcrut5 Data Set.” 

Journal of Geophysical Research: Atmospheres  126(3): 

e2019JD032361. 

Mortazavi, B. 2025.  “Recent Advances in Machine 

Learning-Assisted Multiscale Design of Energy Materi -

als.”  Advanced Energy Materials  forthcoming. 

Mou, C., Liang, A., Hu, C., Meng, F., Han, B., and Xu, 

F. 2023.  “Monitoring Endangered and Rare Wildlife in 

the Field: A Foundation Deep Learning Model Integrat -

ing Human Knowledge for Incremental Recognition 

with Few Data and Low Cost.”  Animals  13(20): 3168. 

Moundridou, M., Matzakos, N., and Doukakis, S. 

2024.  “Generative AI Tools as Educators’ Assistants: 

Designing and Implementing Inquiry-Based Lesson 

Plans.”  Computers and Education: Artificial Intelligence 

7: 100277. 

Moura, L., Jones, D. T., Sheikh, I. S., Murphy, S., Kal -

fin, M., Kummer, B. R., Weathers, A. L., and others. 

2024.  “Implications of Large Language Models for 

Quality and Efficiency of Neurologic Care: Emerging Is -

sues in Neurology.”  Neurology  102(11): e209497. 

Moyer, C. A., Abedini, N. C., Youngblood, J., Talib, 

Z., Jayaraman, T., Manzoor, M., Larson, H. J., and 

others. 2018.  “Advancing Women Leaders in Global 

Health: Getting to Solutions.”  Annals of Global Health 

84(4): 743. 

Muldoon, J., Graham, M., and Cant, C. 2024.  Feeding 

the Machine: The Hidden Human Labour Powering AI. 

Canongate Books. 

Mullainathan, S., and Rambachan, A. 2024.  “From 

Predictive Algorithms to Automatic Generation of 

Anomalies.” Working Paper 32422, National Bureau of 

Economic Research, Cambridge, MA. 

Munusamy, N., and Vairavasundaram, I. 2024.  “AI 

and Machine Learning in V2g Technology: A Review 

of Bi-Directional Converters, Charging Systems, and 

Control Strategies for Smart Grid Integration.”  e-Prime 

- Advances in Electrical Engineering, Electronics and 

Energy  10: 100856. 

Muralidharan, K., Singh, A., and Ganimian, A. J. 

2019.  “Disrupting Education? Experimental Evidence 

on Technology-Aided Instruction in India.”  American 

Economic Review  109(4): 1426–1460. 

Muro, J., Linstädter, A., Magdon, P., Wöllauer, S., 

Männer, F. A., Schwarz, L.-M., Ghazaryan, G., and 

others. 2022.  “Predicting Plant Biomass and Species 

Richness in Temperate Grasslands across Regions, 

Time, and Land Management with Remote Sensing 

and Deep Learning.”  Remote Sensing of Environment 

282: 113262. 

Muthukrishna, M. 2025.  “AI Can Revolutionize Educa -

tion but Technology Is Not Enough and Most Countries 

Are Not Ready.” HDRO background paper available on 

request. 

Nagapurkar, P., and Smith, J. D. 2019.  “Techno-Eco -

nomic Optimization and Social Costs Assessment of 

Microgrid-Conventional Grid Integration Using Genetic 

Algorithm and Artificial Neural Networks: A Case Study 

for Two Us Cities.”  Journal of Cleaner Production  229: 

552–569. 

Narayanan, A., and Kapoor, S. 2024.  AI Snake Oil: 

What Artificial Intelligence Can Do, What It Can’t, and 

How to Tell the Difference.  Princeton University Press. 

National Academies of Sciences, E., and Medicine 

2022.  Human-AI Teaming: State-of-the-Art and Re -

search Needs.  Washington, DC: The National Acad -

emies Press. 

National Academies of Sciences Engineering and 

Medicine. 2024.  “Artificial Intelligence and the Future 

of Work.” 

Newlands, G. 2021.  “Lifting the Curtain: Strategic Vis -

ibility of Human Labour in AI-as-a-Service.”  Big Data & 

Society  8(1): 20539517211016026. 

Nguyen, E., Poli, M., Durrant, M. G., Kang, B., Katrek -

ar, D., Li, D. B., Bartie, L. J., and others. 2024.  “Se -

quence Modeling and Design from Molecular to Ge -

nome Scale with Evo.”  Science  386(6723): eado9336. 

Ni, J., Wu, T., Zhu, X., Hu, G., Zou, D., Wu, X., Li, R., 

and others. 2021.  “Simulation of the Present and Fu -

ture Projection of Permafrost on the Qinghai-Tibet 

Plateau with Statistical and Machine Learning Models.” 

Journal of Geophysical Research: Atmospheres  126(2): 

e2020JD033402. 

Normile, I. H. 2025.  “A Model for Understanding and 

Expanding the Scope of Critical Thinking.”  Studies in 

Philosophy and Education : 1–21. 

Norori, N., Hu, Q., Aellen, F. M., Faraci, F. D., and Tz -

ovara, A. 2021.  “Addressing Bias in Big Data and AI for 

Health Care: A Call for Open Science.”  Patterns  2(10). 

Novy-Marx, R., and Velikov, M. Z. 2025.  “AI-Powered 

(Finance) Scholarship.” Working Paper 33363, National 

Bureau of Economic Research, Cambridge, MA. 

Noy, S., and Zhang, W. 2023.  “Experimental Evidence 

on the Productivity Effects of Generative Artificial Intel -

ligence.”  Science  381(6654): 187–192. 

Nweje, U., Amaka, N. S., and Makai, C. C. 2025. 

“Women in Stem: Breaking Barriers and Building the 

Future.”  International Journal of Science and Research 

Archive  14(1) 

Obi, C. L., Olowoyo, J. O., Malevu, T. D., Mugivhisa, 

L. L., Hungwe, T., Ogunrombi, M. O., and Mkolo, N. 

M. 2024.  “Impact of Artificial Intelligence and Digital 

Technology-Based Diagnostic Tools for Communicable 2 6 6 HUMAN DEVELOPMENT REPORT 2025 

and Non-Communicable Diseases in Africa.”  African 

Journal of Laboratory Medicine  13(1): 2516. 

OECD (Organisation for Economic Co-operation and 

Development). 2023a.  “Health at a Glance 2023.” 

Paris: OECD Publishing. 

OECD (Organisation for Economic Co-operation and 

Development). 2024c.  Job Creation and Local Eco -

nomic Development 2024 the Geography of Genera -

tive AI . Paris: OECD Publishing. 

OECD (Organisation for Economic Cooperation and 

Development). 2023b.  PISA 2022 Results (Volume I) .

Paris: OECD Publishing. 

OECD (Organisation for Economic Co-operation and 

Development). 2024a.  “Managing Screentime.”  PISA 

in Focus  124, OECD Publishing, Paris. 

OECD (Organisation for Economic Co-operation and 

Development). 2024b.  PISA 2022 Results: Creative 

Minds, Creative Schools.  Paris: OECD Publishing. 

OECD (Organisation for Economic Co-operation and 

Development). n.d.  “Skills for Jobs Database.” https:// 

www.oecdskillsforjobsdatabase.org/#FR/_. Accessed 

11 March 2025. 

Olson, P., and Prince, R. 2025.  “Paul Mccartney’s 

AI Battle Should Spark a Copyright Revolution.” 

Bloomberg , https://www.bloomberg.com/opinion/arti -

cles/2025-02-28/paul-mccartney-s-ai-battle-in-the-uk-

should-spark-a-copyright-revolution. 

Osnabrügge, M., Ash, E., and Morelli, M. 2023. 

“Cross-Domain Topic Classification for Political Texts.” 

Political Analysis  31(1): 59–80. 

Oxford Insights. 2024.  Government AI Readiness In -

dex 2024. Oxford: Oxford Insights.,. 

Pagliari, M., Chambon, V., and Berberian, B. 2022. 

“What Is New with Artificial Intelligence? Human–Agent 

Interactions through the Lens of Social Agency.”  Fron -

tiers in Psychology  13: 954444. 

PAI (The Partnership on AI). 2024.  “The Partnership 

on AI.” https://partnershiponai.org/. Accessed 4 May 

2025. 

Palmer, K., Marengoni, A., Forjaz, M. J., Jureviciene, 

E., Laatikainen, T., Mammarella, F., Muth, C., and oth -

ers. 2018.  “Multimorbidity Care Model: Recommenda -

tions from the Consensus Meeting of the Joint Action 

on Chronic Diseases and Promoting Healthy Ageing 

across the Life Cycle (Ja-Chrodis).”  Health Policy  122(1): 

4–11. 

Pannone, A., Raj, A., Ravichandran, H., Das, S., Chen, 

Z., Price, C. A., Sultana, M., and Das, S. 2024.  “Ro -

bust Chemical Analysis with Graphene Chemosensors 

and Machine Learning.”  Nature  634(8034): 572–578. 

Park, H., Li, Z., and Walsh, A. 2024.  “Has Generative 

Artificial Intelligence Solved Inverse Materials Design?” 

Matter  7(7): 2355–2367. 

Park, M., Leahey, E., and Funk, R. J. 2023.  “Papers 

and Patents Are Becoming Less Disruptive over Time.” 

Nature  613(7942): 138–144. 

Park, S., Im, J., Jang, E., and Rhee, J. 2016.  “Drought 

Assessment and Monitoring through Blending of 

Multi-Sensor Indices Using Machine Learning Ap -

proaches for Different Climate Regions.”  Agricultural 

and Forest Meteorology  216: 157–169. 

Park, T., Mahmud, T. I., Lee, J., Hong, S., Park, J. Y., 

Ji, Y., Chang, T., and others. 2024.  “A Machine-Learn -

ing-Enabled Smart Neckband for Monitoring Dietary 

Intake.”  PNAS Nexus  3(5). 

Parsa, A. D., Hakkim, S., Vinnakota, D., Mahmud, I., 

Bulsari, S., Dehghani, L., Pulikkottil, A.-T., Sivasubra -

manian, M., and Kabir, R. 2023.  “Artificial Intelligence 

for Global Healthcare.”  Artificial Intelligence in Medical 

Virology.  Springer. 

Paudel, D., Boogaard, H., de Wit, A., Janssen, S., 

Osinga, S., Pylianidis, C., and Athanasiadis, I. N. 

2021.  “Machine Learning for Large-Scale Crop Yield 

Forecasting.”  Agricultural Systems  187: 103016. 

Pawlowski, J., Bonin, A., Boyer, F., Cordier, T., and 

Taberlet, P. 2021.  “Environmental DNA for Biomonitor -

ing.”  Molecular Ecology  30(13): 2931–2936. 

Pedreschi, D., Pappalardo, L., Ferragina, E., Baeza-

Yates, R., Barabási, A.-L., Dignum, F., Dignum, V., 

and others. 2025.  “Human-AI Coevolution.”  Artificial 

Intelligence  339: 104244. 

Peeters, M. M. M., van Diggelen, J., van den Bosch, 

K., Bronkhorst, A., Neerincx, M. A., Schraagen, J. M., 

and Raaijmakers, S. 2021.  “Hybrid Collective Intel -

ligence in a Human–AI Society.”  AI & SOCIETY  36(1): 

217–238. 

Peng, K., Garg, N., and Kleinberg, J. 2024.  “A No Free 

Lunch Theorem for Human-AI Collaboration.”  arXiv pre -

print arXiv:2411.15230 .

Peng, S., Kalliamvakou, E., Cihon, P., and Demirer, 

M. 2023.  “The Impact of AI on Developer Produc -

tivity: Evidence from Github Copilot.”  arXiv preprint 

arXiv:2302.06590 .

Peters, H., and Matz, S. C. 2024.  “Large Language 

Models Can Infer Psychological Dispositions of Social 

Media Users.”  PNAS Nexus  3(6). 

Pham, A.-D., Ngo, N.-T., Ha Truong, T. T., Huynh, N.-

T., and Truong, N.-S. 2020.  “Predicting Energy Con -

sumption in Multiple Buildings Using Machine Learn -

ing for Improving Energy Efficiency and Sustainability.” 

Journal of Cleaner Production  260: 121082. 

Pham, T. D., Yokoya, N., Nguyen, T. T. T., Le, N. N., Ha, 

N. T., Xia, J., Takeuchi, W., and Pham, T. D. 2021.  “Im -

provement of Mangrove Soil Carbon Stocks Estimation 

in North Vietnam Using Sentinel-2 Data and Machine 

Learning Approach.”  GIScience & Remote Sensing 

58(1): 68–87. 

Phillips, M., Marsden, H., Jaffe, W., Matin, R. N., Wali, 

G. N., Greenhalgh, J., McGrath, E., and others. 2019. 

“Assessment of Accuracy of an Artificial Intelligence 

Algorithm to Detect Melanoma in Images of Skin Le -

sions.”  JAMA Network Open  2(10): e1913436–e1913436. 

Piaggi, P. M., Weis, J., Panagiotopoulos, A. Z., De -

benedetti, P. G., and Car, R. 2022.  “Homogeneous 

Ice Nucleation in an Ab Initio Machine-Learning Model 

of Water.”  Proceedings of the National Academy of Sci -

ences  119(33): e2207294119. 

Piao, J., Lu, Z., Gao, C., Xu, F., Santos, F. P., Li, Y., 

and Evans, J. 2025.  “Emergence of Human-Like Po -

larization among Large Language Model Agents.”  arXiv 

preprint arXiv:2501.05171 .

Pichai, S. 2024.  “Q3 Earnings Call: Ceo’s Remarks.” 

https://blog.google/inside-google/message-ceo/al -

phabet-earnings-q3-2024/#search Accessed 5 March 

2025 

Pierson, E., Shanmugam, D., Movva, R., Kleinberg, 

J., Agrawal, M., Dredze, M., Ferryman, K., and oth -

ers. 2025.  “Using Large Language Models to Promote 

Health Equity.”  NEJM AI  2(2): AIp2400889. 

Pittro, C., Lazdins, J., Bulger, C., Prateek, J., Qi, R., 

and Ananthan, V. 2024.  “Automotive Component De -

sign at Nifco Using Generative AI and Diffusion Models 

| Aws Hpc Blog.” 

Plathottam, S. J., Rzonca, A., Lakhnori, R., and Il -

oeje, C. O. 2023.  “A Review of Artificial Intelligence 

Applications in Manufacturing Operations.”  Journal of 

Advanced Manufacturing and Processing  5(3): e10159. 

Platt, J., Nong, P., Carmona, G., and Kardia, S. 2024. 

“Public Attitudes toward Notification of Use of Artificial 

Intelligence in Health Care.”  JAMA Network Open  7(12): 

e2450102–e2450102. 

Pollock, L. J., Kitzes, J., Beery, S., Gaynor, K. M., Jar -

zyna, M. A., Mac Aodha, O., Meyer, B., and others. 

2025.  “Harnessing Artificial Intelligence to Fill Global 

Shortfalls in Biodiversity Knowledge.”  Nature Reviews 

Biodiversity  1(3): 166–182. 

Pratap Singh, A., Kumar, Y., Sawle, Y., Alotaibi, M. 

A., Malik, H., and Pedro García Márquez, F. 2024. 

“Development of Artificial Intelligence-Based Adaptive 

Vehicle to Grid and Grid to Vehicle Controller for Elec -

tric Vehicle Charging Station.”  Ain Shams Engineering 

Journal  15(10): 102937. 

Praticò, S., Solano, F., Di Fazio, S., and Modica, G. 

2021.  “Machine Learning Classification of Mediterra -

nean Forest Habitats in Google Earth Engine Based 

on Seasonal Sentinel-2 Time-Series and Input Image 

Composition Optimisation.”  Remote Sensing  13(4): 586. 

Price, I., Sanchez-Gonzalez, A., Alet, F., Andersson, 

T. R., El-Kadi, A., Masters, D., Ewalds, T., and others. 

2024.  “Probabilistic Weather Forecasting with Machine 

Learning.”  Nature .

Pritchett, L. 2024.  “Investing in Human Capital in Af -

rica: A Framework for Research.”  International Journal 

of Educational Development  107: 103048. 

Prodhan, F. A., Zhang, J., Hasan, S. S., Pangali 

Sharma, T. P., and Mohana, H. P. 2022.  “A Review of 

Machine Learning Methods for Drought Hazard Moni -

toring and Forecasting: Current Research Trends, Chal -

lenges, and Future Research Directions.”  Environmen -

tal Modelling & Software  149: 105327. 

Puja, S. S., Neha, N. N., Alif, O. R., Sultan, T. J., Hus -

na, M. G. Z. A., Jahan, I., and Noor, J. 2024.  “Explor -

ing the Barriers to Feminine Healthcare Access among 

Marginalized Women in Bangladesh and Facilitating 

Access through a Voice Bot.”  Heliyon  10(14). 

Purves, D. 2019.  “What Does AI’s Success Play -

ing Complex Board Games Tell Brain Scientists?” REFERENCES  2 6 7 

Proceedings of the National Academy of Sciences 

116(30): 14785–14787. 

Pyzer-Knapp, E. O., Pitera, J. W., Staar, P. W., Takeda, 

S., Laino, T., Sanders, D. P., Sexton, J., Smith, J. R., 

and Curioni, A. 2022a.  “Accelerating Materials Dis -

covery Using Artificial Intelligence, High Performance 

Computing and Robotics.”  NPJ Computational Materi -

als  8(1): 84. 

Pyzer-Knapp, E. O., Pitera, J. W., Staar, P. W. J., Take -

da, S., Laino, T., Sanders, D. P., Sexton, J., Smith, J. 

R., and Curioni, A. 2022b.  “Accelerating Materials Dis -

covery Using Artificial Intelligence, High Performance 

Computing and Robotics.”  NPJ Computational Materi -

als  8(1): 84. 

Qiu, H., Xia, D., and Yetman, J. 2025.  “The Role of 

Geopolitics in International Trade.” BIS Working Papers 

1249, Bank for International Settlements,  Basel. 

Rahwan, I., Cebrian, M., Obradovich, N., Bongard, 

J., Bonnefon, J.-F., Breazeal, C., Crandall, J. W., and 

others. 2019.  “Machine Behaviour.”  Nature  568(7753): 

477–486. 

Raihan, A. 2023.  “Artificial Intelligence and Machine 

Learning Applications in Forest Management and Bio -

diversity Conservation.”  Natural Resources Conserva -

tion and Research  6(2): 3825. 

Rajpurkar, P., Chen, E., Banerjee, O., and Topol, E. 

J. 2022.  “AI in Health and Medicine.”  Nature Medicine 

28(1): 31–38. 

Rajpurkar, P., Irvin, J., Ball, R. L., Zhu, K., Yang, B., 

Mehta, H., Duan, T., and others. 2018.  “Deep Learn -

ing for Chest Radiograph Diagnosis: A Retrospective 

Comparison of the Chexnext Algorithm to Practicing 

Radiologists.”  PLoS Medicine  15(11): e1002686. 

Rani, U., Pesole, A., and Vázquez, I. G. 2024.  Algo -

rithmic Management Practices in Regular Workplaces: 

Case Studies in Logistics and Healthcare.  Publications 

Office of the European Union Luxembourg. 

Rani, U., and Williams, M. 2025.  “From Taylorism to 

Algorithmic Management: Emerging Trends across 

Sectors in Regular Workplaces.” ILO Working Paper. 

Rathje, S., Mirea, D.-M., Sucholutsky, I., Marjieh, R., 

Robertson, C. E., and Van Bavel, J. J. 2024.  “GPT 

Is an Effective Tool for Multilingual Psychological Text 

Analysis.”  Proceedings of the National Academy of Sci -

ences  121(34): e2308950121. 

Reckling, W., Mitasova, H., Wegmann, K., Kauffman, 

G., and Reid, R. 2021.  “Efficient Drone-Based Rare 

Plant Monitoring Using a Species Distribution Model 

and AI-Based Object Detection.”  Drones  5(4): 110. 

Republic of Korea Ministry of Science and ICT. 2024. 

“The National AI Research Hub Launched.” https:// 

www.korea.net/Government/Briefing-Room/Press-Re -

leases/view?articleId=7667&type=O&insttCode=. Ac -

cessed 1 April 2025. 

Resnik, D. B., Hosseini, M., Kim, J. J. H., Epiphaniou, 

G., and Maple, C. 2025.  “Genai Synthetic Data Create 

Ethical Challenges for Scientists. Here’s How to Ad -

dress Them.”  Proceedings of the National Academy of 

Sciences  122(9): e2409182122. 

Reynolds, S. A., Beery, S., Burgess, N., Burgman, 

M., Butchart, S. H. M., Cooke, S. J., Coomes, D., and 

others. 2025a.  “The Potential for AI to Revolutionize 

Conservation: A Horizon Scan.”  Trends in Ecology & 

Evolution .

Reynolds, S. A., Beery, S., Burgess, N., Burgman, 

M., Butchart, S. H. M., Cooke, S. J., Coomes, D., and 

others. 2025b.  “The Potential for AI to Revolutionize 

Conservation: A Horizon Scan.”  Trends in Ecology & 

Evolution  40(2): 191–207. 

Rhizome. 2023.  “Rhizome Raises $2.5 Million, Launch -

es to Ensure a Resilient Grid.” https://www.rhizomedata. 

com/news/rhizome-raises-2-5-million-launches-to-en -

sure-resilient-grid. Accessed 4 May 2025. 

Riedl, C., Kim, Y. J., Gupta, P., Malone, T. W., and 

Woolley, A. W. 2021.  “Quantifying Collective Intelli -

gence in Human Groups.”  Proceedings of the National 

Academy of Sciences  118(21): e2005737118. 

Rigas, S., Papachristou, M., Papadopoulos, T., Anag -

nostopoulos, F., and Alexandridis, G. 2024.  “Adap -

tive Training of Grid-Dependent Physics-Informed 

Kolmogorov-Arnold Networks.”  IEEE Access  12: 

176982–176998. 

Rikap, C. 2024.  “Dynamics of Corporate Governance 

Beyond Ownership in AI.” https://www.common-wealth. 

org/publications/dynamics-of-corporate-governance-

beyond-ownership-in-ai 

Riyadh, M. 2024.  “Transforming the Shipping Indus -

try with Autonomous Ships and Artificial Intelligence.” 

Journal of Maritime Technology and Society .

Robbins, R., and Brodwin, E. 2020.  “Artificial Intelli -

gence Systems Are Learning to Identify Patients Who 

Need Extra Care. But Hospitals Are Falling Short in 

Explaining How It Works.” STAT. https://www.statnews. 

com/2020/07/15/artificial-intelligence-patient-consent-

hospitals/. 2024. 

Robertson, N., Sanders, D., Seymour, P., and Thom -

as, R. 1997.  “The Four-Colour Theorem.”  Journal of 

Combinatorial Theory, Series B  70(1): 2–44. 

Rodrik, D. 2016.  “Premature Deindustrialization.”  Jour -

nal of Economic Growth  21: 1–33. 

Rodrik, D., and Sandhu, R. 2024.  “Servicing Devel -

opment: Productive Upgrading of Labor-Absorbing 

Services in Developing Economies.” Working Paper 

32738, National Bureau of Economic Research, Cam -

bridge, MA. 

Rolf, E., Proctor, J., Carleton, T., Bolliger, I., Shankar, 

V., Ishihara, M., Recht, B., and Hsiang, S. 2021.  “A 

Generalizable and Accessible Approach to Machine 

Learning with Global Satellite Imagery.”  Nature Com -

munications  12(1): 4392. 

Rollend, D., Foster, K., Kott, T. M., Mocharla, R., Mu -

ñoz, R., Fendley, N., Ashcraft, C., and others. 2023. 

“Machine Learning for Activity-Based Road Transpor -

tation Emissions Estimation.”  Environmental Data Sci -

ence  2: e38. 

Rolnick, D., Donti, P. L., Kaack, L. H., Kochanski, K., 

Lacoste, A., Sankaran, K., Ross, A. S., and others. 

2022.  “Tackling Climate Change with Machine Learn -

ing.”  ACM Comput. Surv.  55(2): 42:1–42:96. 

Romer, P. M. 1990.  “Endogenous Technological 

Change.”  Journal of political Economy  98(5, Part 2): 

S71–S102. 

Romer, P. M. 1994.  “The Origins of Endogenous 

Growth.”  Journal of Economic Perspectives  8(1): 3–22. 

Romera-Paredes, B., Barekatain, M., Novikov, A., 

Balog, M., Kumar, M. P., Dupont, E., Ruiz, F. J. R., 

and others. 2024.  “Mathematical Discoveries from 

Program Search with Large Language Models.”  Nature 

625(7995): 468–475. 

Roopaei, M., Horst, J., Klaas, E., Foster, G., Salmon-

Stephens, T. J., and Grunow, J. 2021.  “Women in AI: 

Barriers and Solutions.”  2021 IEEE World AI IoT Con -

gress (AIIoT) , 0497–0503. 

Rosenbacke, R., Melhus, Å., McKee, M., and Stuckler, 

D. 2024.  “How Explainable Artificial Intelligence Can 

Increase or Decrease Clinicians’ Trust in AI Applica -

tions in Health Care: Systematic Review.”  JMIR AI  3: 

e53207. 

Rosenblatt, M., Tejavibulya, L., Jiang, R., Noble, S., 

and Scheinost, D. 2024.  “Data Leakage Inflates Pre -

diction Performance in Connectome-Based Machine 

Learning Models.”  Nature Communications  15(1): 1829. 

Rotenstein, L. S., and Wachter, R. M. 2024.  “Are Ar -

tificial Intelligence–Generated Replies the Answer to 

the Electronic Health Record Inbox Problem?”  JAMA 

Network Open  7(10): e2438528–e2438528. 

Rozado, D. 2024.  “The Political Preferences of LLMs.” 

PLOS ONE  19(7): e0306621. 

Rudolph, E., Seer, H., Mothes, C., and Albrecht, J. 

2024.  Automated Feedback Generation in an Intelli -

gent Tutoring System for Counselor Education. 2024 

19th Conference on Computer Science and Intelli -

gence Systems (FedCSIS). IEEE, 501–512. 

Rupp, K. 2022.  Transistors Per Microprocessor.  Tran -

sistors per microprocessor.  processed by Our World in 

Data. 

Russell, S., and Norvig, P. 2021.  “Artificial Intelli -

gence: A Modern Approach, 4th Us Ed.”  aima: сайт. 

URL: https://aima.\cs. berkeley.edu/(дата обращения: 

26.02. 2023) .

SaberiKamarposhti, M., Ng, K.-W., Yadollahi, M., Ka -

myab, H., Cheng, J., and Khorami, M. 2024.  “Cultivat -

ing a Sustainable Future in the Artificial Intelligence Era: 

A Comprehensive Assessment of Greenhouse Gas 

Emissions and Removals in Agriculture.”  Environmental 

Research  250: 118528. 

Sabzehgar, R., Amirhosseini, D. Z., and Rasouli, M. 

2020.  “Solar Power Forecast for a Residential Smart 

Microgrid Based on Numerical Weather Predictions Us -

ing Artificial Intelligence Methods.”  Journal of Building 

Engineering  32: 101629. 

Sagona, M., Dai, T., Macis, M., and Darden, M. 2025. 

“Trust in AI-Assisted Health Systems and AI’s Trust in 

Humans.”  NPJ Health Systems  2(1): 10. 

Sakai, M., Sakurai, A., Lu, S., Olano, J., Albrecht, C. 

M., Hamann, H. F., and Freitag, M. 2024.  “AI-Accel -

erated Nazca Survey Nearly Doubles the Number of 

Known Figurative Geoglyphs and Sheds Light on Their 2 6 8 HUMAN DEVELOPMENT REPORT 2025 

Purpose.”  Proceedings of the National Academy of Sci -

ences  121(40): e2407652121. 

Salah, M., Alhalbusi, H., Ismail, M. M., and Abdel -

fattah, F. 2024.  “Chatting with Chatgpt: Decoding 

the Mind of Chatbot Users and Unveiling the Intricate 

Connections between User Perception, Trust and Ste -

reotype Perception on Self-Esteem and Psychological 

Well-Being.”  Current Psychology  43(9): 7843–7858. 

Saliba, V., Legido-Quigley, H., Hallik, R., Aaviksoo, 

A., Car, J., and McKee, M. 2012.  “Telemedicine across 

Borders: A Systematic Review of Factors That Hinder 

or Support Implementation.”  International Journal of 

Medical Informatics  81(12): 793–809. 

Salmon, F. 2025.  “The Paradox at the Heart of the AI 

Debate.” https://www.msn.com/en-us/money/markets/ 

the-paradox-at-the-heart-of-the-ai-debate/ar-AA1y3jI4. 

Accessed 4 May 2025. 

Samuthira Pandian, A., Medina, P. A. I., Yahyazadeh, 

S., Nguyen, K. V., Miller, R., Aetukuri, N. P., and La, 

Y.-H. 2020.  “Flexible, Synergistic Ceramic–Polymer 

Hybrid Solid-State Electrolyte for Secondary Lithium 

Metal Batteries.”  ACS Applied Energy Materials  3(12): 

12709–12715. 

Sandoval-Almazan, R., Millan-Vargas, A. O., and Gar -

cia-Contreras, R. 2024.  “Examining Public Managers’ 

Competencies of Artificial Intelligence Implementation 

in Local Government: A Quantitative Study.”  Govern -

ment Information Quarterly  41(4): 101986. 

Sarkar, R., Samuel, D., Dunbar, L., and Monnerat, G. 

2024.  “5 Years of the Lancet Digital Health.”  The Lan -

cet Digital Health  6(5): e299. 

Scharre, P. 2016.  “Autonomous Weapons and Opera -

tional Risk.” Center for a New American Security. 

Schewel, L., Co, S., Willoughby, C., Yan, L., Clarke, N., 

Wergin, J., and Data, S. 2021.  “Non-Traditional Meth -

ods to Obtain Annual Average Daily Traffic (AADT).” 

Publication FHWA-PL-21- 031, United States Depart -

ment of Transportation. 

Schneider, T., Behera, S., Boccaletti, G., Deser, C., 

Emanuel, K., Ferrari, R., Leung, L. R., and others. 

2023.  “Harnessing AI and Computing to Advance 

Climate Modelling and Prediction.”  Nature Climate 

Change  13(9): 887–889. 

Schoenegger, P., Park, P. S., Karger, E., Trott, S., and 

Tetlock, P. E. 2024a.  “AI-Augmented Predictions: LLM 

Assistants Improve Human Forecasting Accuracy.” 

ACM Trans. Interact. Intell. Syst. 

Schoenegger, P., Tuminauskaite, I., Park, P. S., Bas -

tos, R. V. S., and Tetlock, P. E. 2024b.  “Wisdom of 

the Silicon Crowd: LLM Ensemble Prediction Capabili -

ties Rival Human Crowd Accuracy.”  Science Advances 

10(45): eadp1528. 

Scott Kruse, C., Karem, P., Shifflett, K., Vegi, L., Ravi, 

K., and Brooks, M. 2018.  “Evaluating Barriers to Adopt -

ing Telemedicine Worldwide: A Systematic Review.” 

Journal of telemedicine and telecare  24(1): 4–12. 

Sedek, S. S. S. 2021.  “Innovative Solutions for Aware -

ness Campaign of Social Media Addiction and Its Con -

sequences.”  International Design Journal  11(2): 131–156. 

Seldon, A., Abidoye, O., and Metcalf, T. 2020.  The 

Fourth Education Revolution Reconsidered: Will Artifi -

cial Intelligence Enrich or Diminish Humanity?  : Legend 

Press Ltd. 

Selwyn, N. 2019.  Should Robots Replace Teachers? AI 

and the Future of Education.  John Wiley & Sons. 

Seo, J., Kim, S., Jalalvand, A., Conlin, R., Rothstein, 

A., Abbate, J., Erickson, K., and others. 2024.  “Avoid -

ing Fusion Plasma Tearing Instability with Deep Re -

inforcement Learning.”  Nature  626(8000): 746–751. 

Seydl, J., and Linden, J. 2024.  “How AI Can Boost Pro -

ductivity and Jump Start Growth.” https://privatebank. 

jpmorgan.com/nam/en/insights/markets-and-investing/ 

ideas-and-insights/how-ai-can-boost-productivity-and-

jump-start-growth. Accessed 15 January 2025. 

Seyyed-Kalantari, L., Zhang, H., McDermott, M. B., 

Chen, I. Y., and Ghassemi, M. 2021.  “Underdiagno -

sis Bias of Artificial Intelligence Algorithms Applied to 

Chest Radiographs in under-Served Patient Popula -

tions.”  Nature Medicine  27(12): 2176–2182. 

Shandhi, M. M. H., Singh, K., Janson, N., Ashar, P., 

Singh, G., Lu, B., Hillygus, D. S., Maddocks, J. M., and 

Dunn, J. P. 2024.  “Assessment of Ownership of Smart 

Devices and the Acceptability of Digital Health Data 

Sharing.”  NPJ Digital Medicine  7(1): 44. 

Sharma, P., Gero, S., Payne, R., Gruber, D. F., Rus, D., 

Torralba, A., and Andreas, J. 2024.  “Contextual and 

Combinatorial Structure in Sperm Whale Vocalisations.” 

Nature Communications  15(1): 3617. 

Sharma, R. 2024.  “How Public-Private Partnerships 

Can Ensure Ethical, Sustainable and Inclusive AI De -

velopment.”  WEF .

Shevtsova, D., Ahmed, A., Boot, I. W., Sanges, C., 

Hudecek, M., Jacobs, J. J., Hort, S., and Vrijhoef, H. J. 

2024.  “Trust in and Acceptance of Artificial Intelligence 

Applications in Medicine: Mixed Methods Study.”  JMIR 

Human Factors  11(1): e47031. 

Shi, F., and Evans, J. 2023.  “Surprising Combinations 

of Research Contents and Contexts Are Related to Im -

pact and Emerge with Scientific Outsiders from Distant 

Disciplines.”  Nature Communications  14(1): 1641. 

Shiferaw, H., Bewket, W., and Eckert, S. 2019.  “Per -

formances of Machine Learning Algorithms for Map -

ping Fractional Cover of an Invasive Plant Species in 

a Dryland Ecosystem.”  Ecology and Evolution  9(5): 

2562–2574. 

Shin, M., Kim, J., van Opheusden, B., and Griffiths, 

T. L. 2023.  “Superhuman Artificial Intelligence Can Im -

prove Human Decision-Making by Increasing Novelty.” 

Proceedings of the National Academy of Sciences 

120(12): e2214840120. 

Shivaprakash, K. N., Swami, N., Mysorekar, S., Arora, 

R., Gangadharan, A., Vohra, K., Jadeyegowda, M., 

and Kiesecker, J. M. 2022.  “Potential for Artificial Intel -

ligence (AI) and Machine Learning (Ml) Applications in 

Biodiversity Conservation, Managing Forests, and Re -

lated Services in India.”  Sustainability  14(12): 7154. 

Si, C., Yang, D., and Hashimoto, T. 2024.  “Can LLMs 

Generate Novel Research Ideas? A Large-Scale Hu -

man Study with 100+ Nlp Researchers.”  arXiv preprint 

arXiv:2409.04109 .

Siewert, M. B. 2018.  “High-Resolution Digital Mapping 

of Soil Organic Carbon in Permafrost Terrain Using Ma -

chine Learning: A Case Study in a Sub-Arctic Peatland 

Environment.”  Biogeosciences  15(6): 1663–1682. 

Silvestro, D., Goria, S., Sterner, T., and Antonelli, A. 

2022.  “Improving Biodiversity Protection through Arti -

ficial Intelligence.”  Nature Sustainability  5(5): 415–424. 

Singh, S., Kaur, N., and Gehlot, A. 2024.  “Applica -

tion of Artificial Intelligence in Drug Design: A Review.” 

Computers in Biology and Medicine  179: 108810. 

Singh, T., and Johnston, A. 2019.  “How Much Is Too 

Much: Employee Monitoring, Surveillance, and Strain.” 

ICIS 2019 Proceedings , 31. 

Singh, V. 2024.  “AI, Women’s Health Care, and Trust: 

Problems and Prospects.”  Artificial Intelligence and 

Machine Learning for Women’s Health Issues.  Elsevier. 

Sinha, A., Virk, V., Chakraborty, D., and Sreeja, P. 

2025.  “Arxeval: Evaluating Retrieval and Generation in 

Language Models for Scientific Literature.”  arXiv pre -

print arXiv:2501.10483 .

Sinka, M. E., Zilli, D., Li, Y., Kiskin, I., Msaky, D., Ki -

honda, J., Mkandawile, G., and others. 2021.  “Hum -

bug – an Acoustic Mosquito Monitoring Tool for Use on 

Budget Smartphones.”  Methods in Ecology and Evolu -

tion  12(10): 1848–1859. 

Sjoding, M. W., Dickson, R. P., Iwashyna, T. J., Gay, S. 

E., and Valley, T. S. 2020.  “Racial Bias in Pulse Oxim -

etry Measurement.”  New England Journal of Medicine 

383(25): 2477–2478. 

Slawomirski, L., Lindner, L., de Bienassis, K., Hay -

wood, P., Hashiguchi, T. C. O., Steentjes, M., and 

Oderkirk, J. 2023.  “Progress on Implementing and Us -

ing Electronic Health Record Systems: Developments 

in OECD Countries as of 2021.” 

Smart Nation and Digital Government Office. n.d. 

“Smart Nation and Digital Government Office.” Govern -

ment of Singapore. https://www.smartnation.gov.sg/. 

Accessed 1 April 2025. 

Smith, P. K., and Livingstone, S. 2017.  “Child Users 

of Online and Mobile Technologies–Risks, Harms and 

Intervention.”  Child psychology and psychiatry: Frame -

works for clinical training and practice : 141–148. 

Sobotkova, A., Kristensen-McLachlan, R. D., Mallon, 

O., and Ross, S. A. 2024.  “Validating Predictions of 

Burial Mounds with Field Data: The Promise and Reality 

of Machine Learning.”  Journal of Documentation  80(5): 

1167–1189. 

Solow, R. 1987.  “We’d Better Watch Out.”  New York Re -

view of Books, July  12: 36. 

Solow, R. M. 1956.  “A Contribution to the Theory of 

Economic Growth.”  The quarterly journal of economics 

70(1): 65–94. 

Song, X., Basheer, C., Xu, J., and Zare, R. N. 2024. 

“Onsite Ammonia Synthesis from Water Vapor and Ni -

trogen in the Air.”  Science Advances  10(50): eads4443. 

Sonwani, E., Bansal, U., Alroobaea, R., Baqasah, A. 

M., and Hedabou, M. 2022.  “An Artificial Intelligence 

Approach toward Food Spoilage Detection and Analy -

sis.”  Frontiers in Public Health  9: 816226. REFERENCES  2 6 9 

Soto, M., Martinez-Gutierrez, J., Momany, M., Ca -

purro, D., Spode, F. C., Cea, E., Mergudich, T., and 

Puschel, K. 2018.  “Preferences of Underserved Chil -

ean Women on a Mobile Technology Intervention for 

Cervical Cancer Screening: Qualitative Study.”  JMIR 

mHealth and uHealth  6(11): e9494. 

Spada, C., Piccirelli, S., Hassan, C., Ferrari, C., Toth, 

E., González-Suárez, B., Keuchel, M., and others. 

2024.  “AI-Assisted Capsule Endoscopy Reading in Sus -

pected Small Bowel Bleeding: A Multicentre Prospec -

tive Study.”  The Lancet Digital Health  6(5): e345–e353. 

Spence, M. 2024.  “AI’s Promise for the Global Econo -

my.” Finance & Development, IMF. 

Sperling, K., Stenliden, L., Nissen, J., and Heintz, F. 

2022.  “Still W(AI)ting for the Automation of Teaching: 

An Exploration of Machine Learning in Swedish Primary 

Education Using Actor-Network Theory.”  European 

Journal of Education  57(4): 584–600. 

Strezoski, L., Padullaparti, H., Ding, F., and Baggu, 

M. 2022.  “Integration of Utility Distributed Energy 

Resource Management System and Aggregators 

for Evolving Distribution System Operators.”  Journal 

of Modern Power Systems and Clean Energy  10(2): 

277–285. 

Sui, P., Duede, E., Wu, S., and So, R. J. 2024.  “Con -

fabulation: The Surprising Value of Large Language 

Model Hallucinations.”  arXiv preprint arXiv:2406.04175 .

Sun, Y., Huang, J., Ao, Z., Lao, D., and Xin, Q. 2019. 

“Deep Learning Approaches for the Mapping of Tree 

Species Diversity in a Tropical Wetland Using Airborne 

Lidar and High-Spatial-Resolution Remote Sensing Im -

ages.”  Forests  10(11): 1047. 

Svanberg, M., Li, W., Fleming, M., Goehring, B., and 

Thompson, N. 2024.  “Beyond AI Exposure: Which 

Tasks Are Cost-Effective to Automate with Computer 

Vision?”  Available at SSRN 4700751 .

Szatmári, G., Pásztor, L., and Heuvelink, G. B. M. 

2021.  “Estimating Soil Organic Carbon Stock Change 

at Multiple Scales Using Machine Learning and Multi -

variate Geostatistics.”  Geoderma  403: 115356. 

Szymanski, N. J., Rendy, B., Fei, Y., Kumar, R. E., He, 

T., Milsted, D., McDermott, M. J., and others. 2023. 

“An Autonomous Laboratory for the Accelerated Syn -

thesis of Novel Materials.”  Nature  624(7990): 86–91. 

Takita, H., Kabata, D., Walston, S. L., Tatekawa, H., 

Saito, K., Tsujimoto, Y., Miki, Y., and Ueda, D. 2025. 

“A Systematic Review and Meta-Analysis of Diagnostic 

Performance Comparison between Generative AI and 

Physicians.”  NPJ Digital Medicine  8(1): 175. 

Tan, S. C., Wijekumar, K., Hong, H., Olmanson, 

J., Twomey, R., and Sinha, T. 2024.  “Guest Edito -

rial Education in the World of Chatgpt and Generative 

AI.”  IEEE Transactions on Learning Technologies  17: 

2062–2064. 

Tanaka, T. S. T., Heuvelink, G. B. M., Mieno, T., and 

Bullock, D. S. 2024.  “Can Machine Learning Models 

Provide Accurate Fertilizer Recommendations?”  Preci -

sion Agriculture  25(4): 1839–1856. 

Tang, C., Yi, W., Xu, M., Jin, Y., Zhang, Z., Chen, X., 

Liao, C., and others. 2025.  “A Deep Learning–Enabled 

Smart Garment for Accurate and Versatile Monitoring 

of Sleep Conditions in Daily Life.”  Proceedings of the 

National Academy of Sciences  122(7): e2420498122. 

Taylor, A. 2018.  “The Automation Charade.” https://log -

icmag.io/failure/the-automation-charade/. Accessed 11 

March 2025. 

Tejani, A. S., Ng, Y. S., Xi, Y., and Rayan, J. C. 2024. 

“Understanding and Mitigating Bias in Imaging Artificial 

Intelligence.”  RadioGraphics  44(5): e230067. 

The Materials Project. 2024.  “Materials Project.” 

https://next-gen.materialsproject.org/. Accessed 11 

March 2205. 

Theopilus, Y., Al Mahmud, A., Davis, H., and Octa -

via, J. R. 2024.  “Preventive Interventions for Internet 

Addiction in Young Children: Systematic Review.”  JMIR 

Mental Health  11(1): e56896. 

Thornhill, J. 2025.  “Help Is Coming in the AI Copyright 

Wars.”  Financial Times , 27 February. https://www.ft.com/ 

content/b98979ba-6ae7-4490-97a9-127381440b1f. 

Tien, P. W., Wei, S., Darkwa, J., Wood, C., and Calau -

tit, J. K. 2022.  “Machine Learning and Deep Learning 

Methods for Enhancing Building Energy Efficiency and 

Indoor Environmental Quality – a Review.”  Energy and 

AI  10: 100198. 

Toner-Rodgers, A. 2024.  “Artificial Intelligence, Scien -

tific Discovery, and Product Innovation.”  arXiv preprint 

arXiv:2412.17866 .

Tonja, A. L., Dossou, B. F., Ojo, J., Rajab, J., Thior, 

F., Wairagala, E. P., Aremu, A., and others. 2024. 

“Inkubalm: A Small Language Model for Low-Resource 

African Languages.”  arXiv preprint arXiv:2408.17024 .

Topol, E. J. 2023.  “As Artificial Intelligence Goes 

Multimodal, Medical Applications Multiply.”  Science 

381(6663): eadk6139. 

Topol, E. J. 2024.  “Medical Forecasting.”  Science 

384(6698): eadp7977. 

Touzet, C. 2023.  “Using AI to Support People with Dis -

ability in the Labour Market: Opportunities and Chal -

lenges.”  OECD Artificial Intelligence Papers 7 .

Towfek, S., and Elkanzi, M. 2024.  “A Review on the 

Role of Machine Learning in Predicting the Spread of 

Infectious Diseases.”  Metaheuristic Optimization Re -

view (MOR)  2(1): 14–27. 

Tranchero, M., Brenninkmeijer, C.-F., Murugan, A., 

and Nagaraj, A. 2024.  Theorizing with Large Lan -

guage Models. National Bureau of Economic Research. 

Tsvetkova, M., Yasseri, T., Pescetelli, N., and Werner, 

T. 2024.  “A New Sociology of Humans and Machines.” 

Nature Human Behaviour  8(10): 1864–1876. 

Tubaro, P. 2021.  “Disembedded or Deeply Embed -

ded? A Multi-Level Network Analysis of Online Labour 

Platforms.”  Sociology  55(5): 927–944. 

Tuia, D., Kellenberger, B., Beery, S., Costelloe, B. R., 

Zuffi, S., Risse, B., Mathis, A., and others. 2022.  “Per -

spectives in Machine Learning for Wildlife Conserva -

tion.”  Nature Communications  13(1): 792. 

Tuomi, I. 2019.  “The Impact of Artificial Intelligence 

on Learning, Teaching, and Education: Policies for 

the Future. JRC Science for Policy Report.”  European 

Commission .

Turki, A. T., Engelke, M., and Sobas, M. 2024.  “Ad -

vances in Decision Support for Diagnosis and Early 

Management of Acute Leukaemia.”  The Lancet Digital 

Health  6(5): e300–e301. 

Ueda, D., Kakinuma, T., Fujita, S., Kamagata, K., 

Fushimi, Y., Ito, R., Matsui, Y., and others. 2024. 

“Fairness of Artificial Intelligence in Healthcare: Review 

and Recommendations.”  Japanese Journal of Radiol -

ogy  42(1): 3–15. 

Ugander, J., and Epstein, Z. 2024.  “The Art of Ran -

domness: Sampling and Chance in the Age of Algorith -

mic Reproduction.”  Harvard Data Science Review  6(4). 

UN (United Nations). 2024.  “A Global Digital Com -

pact - an Open, Free, and Secure Digital Future for All.” 

https://www.un.org/sites/un2.un.org/files/our-common-

agenda-policy-brief-gobal-digi-compact-en.pdf. Ac -

cessed 11 March 2025. 

UN (United Nations)., and ILO (International Labour 

Organization) 2024.  Mind the AI Divide: Shaping a 

Global Perspective on the Future of Work. Geneva. 

UN (United Nations)., and ILO (International Labour 

Organization). 2024.  “Mind the AI Divide: Shaping a 

Global Perspective on the Future of Work.” 

UNCTAD (United Nations Conference on Trade and 

Development). 2023.  State of Commodity Depen -

dence 2023 . Geneva: UNCTAD. 

UNCTAD (United Nations Conference on Trade and 

Development). 2025.  Technology and Innovation Re -

port 2025: Inclusive Artificial Intelligence for Develop -

ment. Geneva. 

UNDESA (United Nations Department of Economic 

and Social Affairs). 2024a.  “The Sustainable Develop -

ment Goals Report 2024.” 

UNDESA (United Nations Department of Economic 

and Social Affairs). 2024b.  “World Population Pros -

pects 2024 Summary of Results.” 

UNDP (United Nations Development Programme) 

2024.  Human Development Report 2023–24: Break -

ing the Gridlock: Reimagining Cooperation in a Polar -

ized World. New York. 

UNDP (United Nations Development Programme). 

2019.  Human Development Report 2019 Beyond In -

come, Beyond Averages, Beyond Today: Inequalities 

in Human Development in the 21st Century. New York. 

UNESCO (United Nations Educational, Scientific and 

Cultural Organization). 2024.  “Global Education Mon -

itoring Report, 2024/5, Leadership in Education: Lead 

for Learning.” Paris: UNESCO. 

Urbán, J. F., Stefanou, P., and Pons, J. A. 2025.  “Un -

veiling the Optimization Process of Physics Informed 

Neural Networks: How Accurate and Competitive Can 

Pinns Be?”  Journal of Computational Physics  523: 

113656. 

Urbina, F., Lentzos, F., Invernizzi, C., and Ekins, S. 

2022.  “Dual Use of Artificial-Intelligence-Powered 

Drug Discovery.”  Nature Machine Intelligence  4(3): 

189–191. 2 70 HUMAN DEVELOPMENT REPORT 2025 

Uzokov, J., Alyavi, A., Alyavi, B., and Abdullaev, A. 

2024.  How Artificial Intelligence Can Assist with Isch -

aemic Heart Disease. Oxford University Press UK. 

Vaccaro, M., Almaatouq, A., and Malone, T. 2024. 

“When Combinations of Humans and AI Are Useful: A 

Systematic Review and Meta-Analysis.”  Nature Human 

Behaviour  8(12): 2293–2303. 

van Klink, R., August, T., Bas, Y., Bodesheim, P., 

Bonn, A., Fossøy, F., Høye, T. T., and others. 2022. 

“Emerging Technologies Revolutionise Insect Ecology 

and Monitoring.”  Trends in Ecology & Evolution  37(10): 

872–885. 

Varnum, M. E. W., Baumard, N., Atari, M., and Gray, 

K. 2024.  “Large Language Models Based on Historical 

Text Could Offer Informative Tools for Behavioral Sci -

ence.”  Proceedings of the National Academy of Sci -

ences  121(42): e2407639121. 

Verhoef, L. A., Budde, B. W., Chockalingam, C., 

García Nodar, B., and van Wijk, A. J. M. 2018.  “The 

Effect of Additive Manufacturing on Global Energy De -

mand: An Assessment Using a Bottom-up Approach.” 

Energy Policy  112: 349–360. 

Virnodkar, S. S., Pachghare, V. K., Patil, V. C., and 

Jha, S. K. 2020.  “Remote Sensing and Machine Learn -

ing for Crop Water Stress Determination in Various 

Crops: A Critical Review.”  Precision Agriculture  21(5): 

1121–1155. 

Volokh, E. 2023.  “Large Libel Models? Liability for AI 

Output.”  J. Free Speech L.  3: 489. 

von Eschenbach, W. J. 2021.  “Transparency and the 

Black Box Problem: Why We Do Not Trust AI.”  Philoso -

phy & Technology  34(4): 1607–1622. 

Wachter, R. M., and Brynjolfsson, E. 2024.  “Will Gen -

erative Artificial Intelligence Deliver on Its Promise in 

Health Care?”  JAMA  331(1): 65–69. 

Wang, A., Hertzmann, A., and Russakovsky, O. 2024. 

“Benchmark Suites Instead of Leaderboards for Evalu -

ating AI Fairness.”  Patterns  5(11). 

Wang, F., and Preininger, A. 2019.  “AI in Health: State 

of the Art, Challenges, and Future Directions.”  Year -

book of medical informatics  28(01): 016–026. 

Wang, X. Q., Chen, P., Chow, C. L., and Lau, D. 2023. 

“Artificial-Intelligence-Led Revolution of Construction 

Materials: From Molecules to Industry 4.0.”  Matter  6(6): 

1831–1859. 

Washington, J. 2023.  “Combating Misinformation and 

Fake News: The Potential of AI and Media Literacy Edu -

cation.”  Available at SSRN 4580385 .

Wei, Q., Mease, P. J., Chiorean, M., Iles-Shih, L., 

Matos, W. F., Baumgartner, A., Molani, S., and oth -

ers. 2024.  “Machine Learning to Understand Risks for 

Severe Covid-19 Outcomes: A Retrospective Cohort 

Study of Immune-Mediated Inflammatory Diseases, 

Immunomodulatory Medications, and Comorbidities 

in a Large Us Health-Care System.”  The Lancet Digital 

Health  6(5): e309–e322. 

Wenger, E., and Kenett, Y. 2025.  “We’re Different, 

We’re the Same: Creative Homogeneity across LLMs.” 

arXiv preprint arXiv:2501.19361 .

WHO (World Health Organization). 2021.  “World 

Health Statistics 2021: Monitoring Health for the SDGs, 

Sustainable Development Goals.” Geneva: WHO. 

WHO (World Health Organization). 2022.  “Value 

Gender and Equity in the Global Health Workforce.” 

https://www.who.int/activities/value-gender-and-equi -

ty-in-the-global-health-workforce. Accessed 11 March 

2025. 

WHO (World Health Organization). 2024.  “World 

Health Statistics 2024 Monitoring Health for the SDGs, 

Sustainable Development Goals.” Geneva: WHO. 

Wilhelm, C., Steckelberg, A., and Rebitschek, F. G. 

2025.  “Benefits and Harms Associated with the Use 

of AI-Related Algorithmic Decision-Making Systems by 

Healthcare Professionals: A Systematic Review.”  The 

Lancet Regional Health–Europe  48. 

Wizeline. 2023.  “Tec De Monterrey and Wizeline Pres -

ent G.AI.L, the First Generative Artificial Intelligence 

Laboratory in Latin America.” https://www.globenews -

wire.com/en/news-release/2023/10/12/2759626/0/en/ 

Tec-de-Monterrey-and-Wizeline-present-G-AI-L-the-

first-Generative-Artificial-Intelligence-Laboratory-in-

Latin-America.html. Accessed 11 March 2025. 

WMO (World Meteorological Organization). 2025. 

“WMO Confirms 2024 as Warmest Year on Record at 

About 1.55°C above Pre-Industrial Level.” 

Wolfe, S. 2024-05-10 2024.  Ohmconnect Combines 

with Google’s Nest Renew to Form Virtual Power Plant 

Firm.  Renewable Energy World  [Online]. 

Woolley, A. W., and Gupta, P. 2024.  “Understanding 

Collective Intelligence: Investigating the Role of Col -

lective Memory, Attention, and Reasoning Processes.” 

Perspectives on Psychological Science  19(2): 344–354. 

World Bank 2024.  Digital Progress and Trends Report 

2023 . Washington, DC: World Bank. 

World Bank. 2025.  “World Development Indicators 

(Employment in Services (% of Total Employment) (Mod -

eled ILO Estimate)).” https://data.worldbank.org/indica -

tor/SL.SRV.EMPL.ZS. Accessed 10 March 2025. 

WTO (World Trade Organization) 2025.  Trading with 

Intelligence How AI Shapes and Is Shaped by Interna -

tional Trade . Geneva: WTO. 

Xiao, G., Yang, D., Xu, L., Li, J., and Jiang, Z. 2024. 

“The Application of Artificial Intelligence Technology in 

Shipping: A Bibliometric Review.”  Journal of Marine Sci -

ence and Engineering  12(4): 624. 

Xiao, J., Chevallier, F., Gomez, C., Guanter, L., Hicke, 

J. A., Huete, A. R., Ichii, K., and others. 2019.  “Remote 

Sensing of the Terrestrial Carbon Cycle: A Review of 

Advances over 50 Years.”  Remote Sensing of Environ -

ment  233: 111383. 

Xie, Y., Pan, Y., Xu, H., and Mei, Q. 2024.  “Bridg -

ing AI and Science: Implications from a Large-Scale 

Literature Analysis of AI4science.”  arXiv preprint 

arXiv:2412.09628 .

Yan, L., Greiff, S., Teuber, Z., and Gašević, D. 2024. 

“Promises and Challenges of Generative Artificial Intel -

ligence for Human Learning.”  Nature Human Behaviour 

8(10): 1839–1850. 

Yang, Y., Zhang, Y., Wu, M., Zhang, K., Zhang, Y., Yu, 

H., Hu, Y., and Wang, B. 2025.  “Twinmarket: A Scal -

able Behavioral and Socialsimulation for Financial Mar -

kets.”  arXiv preprint arXiv:2502.01506 .

Yin, C., and Imms, P., and Chowdhury, N. F., and 

Chaudhari, N. N., and Ping, H., and Wang, H., and 

Bogdan, P., and others. 2025.  “Deep Learning to 

Quantify the Pace of Brain Aging in Relation to Neuro -

cognitive Changes.”  Proceedings of the National Acad -

emy of Sciences  122(10): e2413442122. 

Yu, Y., and Romero, D. M. 2024.  “Does the Use of Un -

usual Combinations of Datasets Contribute to Greater 

Scientific Impact?”  Proceedings of the National Acad -

emy of Sciences  121(41): e2402802121. 

Zanatto, D., Chattington, M., and Noyes, J. 2021. 

Sense of Agency in Human-Machine Interaction. Ad -

vances in Neuroergonomics and Cognitive Engineer -

ing: Proceedings of the AHFE 2021 Virtual Conferenc -

es on Neuroergonomics and Cognitive Engineering, 

Industrial Cognitive Ergonomics and Engineering 

Psychology, and Cognitive Computing and Internet of 

Things, July 25–29, 2021, USA. Springer, 353–360. 

Zarifhonarvar, A. 2024.  “Economics of Chatgpt: A 

Labor Market View on the Occupational Impact of Ar -

tificial Intelligence.”  Journal of Electronic Business & 

Digital Economics  3(2): 100–116. 

Zeni, C., Pinsler, R., Zügner, D., Fowler, A., Horton, 

M., Fu, X., Wang, Z., and others. 2025.  “A Generative 

Model for Inorganic Materials Design.”  Nature .

Zhang, K., Zhou, R., Adhikarla, E., Yan, Z., Liu, Y., Yu, 

J., Liu, Z., and others. 2024a.  “A Generalist Vision– 

Language Foundation Model for Diverse Biomedical 

Tasks.”  Nature Medicine  30(11): 3129–3141. 

Zhang, Y., Liu, C., Liu, M., Liu, T., Lin, H., Huang, C.-B., 

and Ning, L. 2024b.  “Attention Is All You Need: Utiliz -

ing Attention in AI-Enabled Drug Discovery.”  Briefings 

in Bioinformatics  25(1). 

Zhang, Y., Zhu, J., Xie, H., and He, Y. 2025.  “Physics-

Informed Deep Learning for Stochastic Particle Dynam -

ics Estimation.”  Proceedings of the National Academy 

of Sciences  122(9): e2418643122. 

Zhong, T., Yang, Z., Liu, Z., Zhang, R., Liu, Y., Sun, H., 

Pan, Y., and others. 2024.  “Opportunities and Chal -

lenges of Large Language Models for Low-Resource 

Languages in Humanities Research.”  arXiv preprint 

arXiv:2412.04497 .

Zhou, Y., Zheng, S., and Hensen, J. L. M. 2024.  “Ma -

chine Learning-Based Digital District Heating/Cooling 

with Renewable Integrations and Advanced Low-Car -

bon Transition.”  Renewable and Sustainable Energy 

Reviews  199: 114466. 

Zhu, Z., Zheng, W., Tang, N., and Zhong, W. 2024. 

“Review of Manpower Management in Healthcare Sys -

tem: Strategies, Challenges, and Innovations.”  Journal 

of Multidisciplinary Healthcare : 5341–5351. 

Zysman, J., and Nitzberg, M. 2024.  “Generative AI 

and the Future of Work: Augmentation or Automation?” 

Available at SSRN 4811728 .Statistical 

# annex Statistical annex 

READERS GUIDE  273 

HUMAN DEVELOPMENT COMPOSITE INDICES 

1 Human Development Index and its components  278 

2 Human Development Index trends, 1990–2023  283 

3 Inequality-adjusted Human Development Index  287 

4 Gender Development Index  292 

5 Gender Inequality Index  297 

6 Multidimensional Poverty Index: developing countries  302 

7 Planetary pressures-adjusted Human Development Index  305 

DEVELOPING REGIONS  310 

STATISTICAL REFERENCES  311 

2 7 2 HUMAN DEVELOPMENT REPORT 2025 The tables provide an overview of key aspects of human 

development. The seven tables contain the family of 

composite human development indices and their com -

ponents estimated by the Human Development Report 

Office (HDRO). The sixth table, on multidimensional 

poverty, is produced in partnership with the Oxford 

Poverty and Human Development Initiative. 

Tables 1–7 are part of the 2025 Human Development 

Report. The full set of seven statistical tables is 

available for download at  https://hdr.undp.org/en/ 

human-development-report-2025 . Unless otherwise 

noted, tables use data available to the HDRO as of 

1 November 2024. All indices and indicators, along 

with technical notes on the calculation of composite 

indices and additional source information, are availa -

ble at  https://hdr.undp.org/data-center .

Countries and territories are ranked by 2023 

Human Development Index (HDI) value. Robustness 

and reliability analysis has shown that for most coun -

tries differences in HDI are not statistically significant 

at the fourth decimal place. For this reason countries 

with the same HDI value at three decimal places are 

listed with tied ranks. 

## Sources and definitions 

Unless otherwise noted, the HDRO uses data from in -

ternational data agencies with the mandate, resourc -

es and expertise to collect national data on specific 

indicators. 

Definitions of indicators and sources for original 

data components are given at the end of each table, 

with full source details in  Statistical references .

## Gross national income per capita 

## in purchasing power parity terms 

In comparing standard of living across countries, the 

income component of the HDI uses gross national 

income (GNI) per capita converted into purchasing 

power parity (PPP) terms to eliminate differences in 

national price levels. 

The 2021 cycle of the International Comparison 

Programme survey, which is the world’s largest sta -

tistical initiative and coordinated by the World Bank, 

produced internationally comparable price level in -

dices and estimates of PPP-based gross domestic 

product and its major expenditure components in 

aggregate and per capita terms for 176 participating 

economies. The 2025 Human Development Report 

uses GNI per capita in constant 2021 PPP terms. 

## Methodology updates 

The 2025 Report retains all the composite indices 

from the family of human development indices  —

the HDI, the Inequality-adjusted Human Develop -

ment Index (IHDI), the Gender Development Index 

(GDI), the Gender Inequality Index (GII), the Multi -

dimensional Poverty Index (MPI) and the Planetary 

pressures-adjusted Human Development Index (PH -

DI). The methodology used to compute the indices 

is the same as the one used in the 2023/2024 Human 

Development Report. For details, see  Technical notes 

1–6  at  https://hdr.undp.org/sites/default/files/2025_ 

HDR/hdr2025_technical_notes.pdf .

## Comparisons over time 

## and across editions 

Because national and international agencies continu -

ally improve their data series, the data —including the 

HDI values and ranks —presented in this report are 

not comparable to those published in earlier editions. 

For HDI comparability across years and countries, 

see table 2, which presents trends using consistent da -

ta, or  https://hdr.undp.org/data-center , which pres -

ents interpolated consistent data. 

# Readers guide READERS GUIDE 

> 2 7 3

## Discrepancies between national 

## and international estimates 

National and international data can differ because 

international agencies harmonize national data us -

ing a consistent methodology and occasionally pro -

duce estimates of missing data to allow comparability 

across countries. In other cases international agen -

cies might not have access to the most recent national 

data. When HDRO becomes aware of discrepancies, 

it brings them to the attention of national and inter -

national data authorities. 

## Country groupings and aggregates 

The tables present weighted aggregates for several 

country groupings. In general, an aggregate is shown 

only when data are available for at least half the coun -

tries and represent at least two-thirds of the popula -

tion in that grouping. Aggregates for each grouping 

cover only the countries for which data are available. 

Human development classification 

HDI classifications are based on HDI fixed cutoff 

points, which are derived from the quartiles of dis -

tributions of the component indicators. The cutoff 

points are HDI of less than 0.550 for low human de -

velopment, 0.550–0.699 for medium human develop -

ment, 0.700–0.799 for high human development and 

0.800 or greater for very high human development. 

Regional groupings 

Regional groupings are based on United Nations De -

velopment Programme regional classifications. Least 

Developed Countries and Small Island Developing 

States are defined according to UN classifications 

(see  https://www.un.org/ohrlls/ ). 

Developing countries 

The aggregates for developing countries are based on 

information from all developing countries that are in -

cluded in a regional grouping. 

Organisation for Economic 

Co‑operation and Development 

Of the 38 Organisation for Economic Co- operation 

and Development members, 33 are considered de -

veloped countries and 5 (Costa Rica, Chile, Colom -

bia, Mexico and Türkiye) are considered developing 

countries. Aggregates refer to all countries from the 

group for which data are available. 

## Country notes 

Data for China do not include Hong Kong Special 

Administrative Region of China, Macao Special Ad -

ministrative Region of China or Taiwan Province of 

China. 

As of 2 May 2016, Czechia is the short name to be 

used for the Czech Republic. 

As of 1 June 2018, the Kingdom of Eswatini is the 

name of the country formerly known as Swaziland. 

As of 14 February 2019, the Republic of North 

Macedonia (short form: North Macedonia) is the 

name of the country formerly known as the former 

Yugoslav Republic of Macedonia. 

As of 1 June 2022, Türkiye is the name of the coun -

try formerly known as Turkey. 

> 2 74 HUMAN DEVELOPMENT REPORT 2025

## Symbols 

A dash between two years, as in 2010–2023, indicates 

that the data are from the most recent year available 

during the period specified. Growth rates are usually 

average annual rates of growth between the first and 

last years of the period shown. 

The following symbols are used in the tables: 

..  Not available 

0 or 0.0  Nil or negligible 

— Not applicable 

## Statistical acknowledgements 

The Report’s composite indices and other statis -

tical resources draw on a wide variety of the most 

respected international data providers in their spe -

cialized fields. HDRO is particularly grateful to 

Eurostat; the Global Carbon Project; ICF Macro; the 

International Labour Organization; the Internation -

al Monetary Fund; the Inter-Parliamentary Union; 

the Luxembourg Income Study; the Organisation 

for Economic Co- operation and Development; the 

Socio-Economic Database for Latin America and 

the Caribbean; the United Nations Children’s Fund; 

the United Nations Department of Economic and 

Social Affairs; the United Nations Educational, Sci -

entific and Cultural Organization Institute for Statis -

tics; the United Nations Environment Programme; 

the United Nations Statistics Division; the United 

Nations University World Institute for Develop -

ment Economics Research; the World Bank; the 

World Health Organization; and the World Inequal -

ity Database. The international education database 

maintained by Robert Barro (Harvard University) 

and Jong-Wha Lee (Korea University) was another 

invaluable source for the calculation of the Report’s 

indices. 

## Statistical tables 

The seven tables relate to the six composite human 

development indices and their components. Since 

the 2010 Human Development Report, four compos -

ite human development indices —the HDI, the IHDI, 

the GII and the MPI for developing countries —have 

been calculated. The 2014 Report introduced the 

GDI, which compares the HDI calculated separately 

for women and men. The 2020 Report introduced the 

PHDI, which adjusts the HDI for the excessive hu -

man pressure on the planet. 

For indicators that are global Sustainable 

Development Goals indicators or can be used in 

monitoring progress towards specific goals, the table 

headers include the relevant goals and targets. 

Table 1, Human Development Index and its 

components,  ranks countries by 2023 HDI value and 

details the values of the three HDI components: lon -

gevity, education (with two indicators) and income 

per capita. The table also presents the difference in 

rankings by HDI value and gross national income per 

capita, as well as the rank on the 2022 HDI, calculated 

using the most recently revised historical data availa -

ble in 2024. 

Table 2, Human Development Index trends, 

1990–2023, provides a time series of HDI values al -

lowing 2023 HDI values to be compared with those 

for previous years. The table uses the most recent -

ly revised historical data available in 2024 and the 

same methodology applied to compute 2023 HDI val -

ues. The table also includes the change in HDI rank 

over the last eight years and the average annual HDI 

growth rate across four time intervals: 1990–2000, 

2000–2010, 2010–2023 and 1990–2023. 

Table 3, Inequality-adjusted Human Devel -

opment Index,  contains two related measures of 

inequality —the IHDI and the overall loss in HDI due READERS GUIDE 

> 2 7 5

to inequality. The IHDI looks beyond the average 

achievements of a country in longevity, education 

and income to show how these achievements are dis -

tributed among its residents. The IHDI value can be 

interpreted as the level of human development when 

inequality is accounted for. The relative difference be -

tween IHDI and HDI values is the loss due to inequal -

ity in distribution of the HDI within the country. The 

table presents the coefficient of human inequality, 

which is the unweighted average of inequalities in the 

three dimensions. In addition, the table shows each 

country’s difference in rank on the HDI and the IHDI. 

A negative value means that taking inequality into ac -

count lowers a country’s rank on the HDI. The table 

also presents the income shares of the poorest 40 per -

cent, the richest 10 percent and the richest 1 percent 

of the population, as well as the Gini coefficient. 

Table 4, Gender Development Index,  meas -

ures disparities on the HDI by gender. The table con -

tains HDI values estimated separately for women and 

men, the ratio of which is the GDI value. The closer 

the ratio is to 1, the smaller the gap between women 

and men. Values for the three HDI components  —

longevity, education (with two indicators) and in -

come per capita —are also presented by gender. The 

table includes five country groupings by absolute de -

viation from gender parity in HDI values. 

Table 5, Gender Inequality Index,  presents a 

composite measure of gender inequality using three 

dimensions: reproductive health, empowerment and 

the labour market. The reproductive health indica -

tors are maternal mortality ratio and adolescent birth 

rate. The empowerment indicators are the percentage 

of parliamentary seats held by women and the per -

centage of population with at least some secondary 

education by gender. The labour market indicator is 

participation in the labour force by gender. A low GII 

value indicates low inequality between women and 

men, and vice-versa. 

Table 6, Multidimensional Poverty Index,  cap -

tures the multiple deprivations that people in devel -

oping countries face in their health, education and 

standard of living. The MPI shows both the incidence 

of nonincome multidimensional poverty (a headcount 

of those in multidimensional poverty) and its intensity 

(the average deprivation score experienced by multi -

dimensionally poor people). Based on deprivation score 

thresholds, people are classified as multidimensionally 

poor, in severe multidimensional poverty or vulnerable 

to multidimensional poverty. The table includes the 

contribution of deprivation in each dimension to over -

all multidimensional poverty. It also presents measures 

of income poverty —population living below the nation -

al poverty line and population living on less than $2.15 

in purchasing power parity terms per day. 

Table 7, Planetary pressures-adjusted Human 

Development Index,  adjusts the HDI for planetary 

pressures in the Anthropocene to reflect a concern for 

intergenerational inequality, similar to the Inequality-

adjusted HDI adjustment, which is motivated by a 

concern for intragenerational inequality. The PHDI 

value can be interpreted as the level of human de -

velopment adjusted by carbon dioxide emissions per 

person (production-based) and material footprint per 

capita to account for the excessive human pressure on 

the planet. The table presents the relative difference 

between PHDI and HDI values as well as each coun -

try’s difference in rank on the HDI and the PHDI. A 

negative value means that taking planetary pressures 

into account lowers a country’s rank on the HDI. 

> 2 76 HUMAN DEVELOPMENT REPORT 2025

# Human development 

# composite indices TABLE 1 

# Human Development Index and its components 

HDI RANK 

SDG 3  SDG 4.3  SDG 4.4  SDG 8.5 

Human Development 

Index (HDI) 

Life expectancy 

at birth 

Expected years 

of schooling 

Mean years of 

schooling 

Gross national income 

(GNI) per capita 

GNI per capita rank 

minus HDI rank 

HDI 

rank 

Value  (years)  (years)  (years)  (2021 PPP $) 

2023  2023  2023 a 2023 a 2023  2023 b 2022 

Very high human development 

1 Iceland  0.972  82.7  18.9  c 13.9  d 69,117  12  3

2 Norway  0.970  83.3  18.8  c 13.1  e 112,710  f 0 1

2 Switzerland  0.970  84.0  16.7  13.9  e 81,949  f 5 2

4 Denmark  0.962  81.9  18.7  c 13.0  e 76,008  f 4 4

5 Germany  0.959  81.4  17.3  14.3  e 64,053  13  6

5 Sweden  0.959  83.3  19.0  c 12.7  e 66,102  10  4

7 Australia  0.958  83.9  20.7  c 12.9  58,277  14  8

8 Hong Kong, China (SAR)  0.955  85.5  g 16.9  12.4  69,436  4 9

8 Netherlands  0.955  82.2  18.6  c 12.7  e 68,344  6 7

10  Belgium  0.951  82.1  19.0  c 12.7  e 63,582  9 13 

11  Ireland  0.949  82.4  19.2  c 11.7  e 90,885  f –6  10 

12  Finland  0.948  81.9  19.5  c 13.0  e 57,068  10  11 

13  Singapore  0.946  83.7  16.7  12.0  111,239  f –10  14 

13  United Kingdom  0.946  81.3  17.8  13.5  54,372  13  11 

15  United Arab Emirates  0.940  82.9  15.6  13.0  71,142  –4  23 

16  Canada  0.939  82.6  15.9  13.9  54,688  9 16 

17  Liechtenstein  0.938  83.6  15.4  12.4  h 166,812  f,i  –16  15 

17  New Zealand  0.938  82.1  19.3  c 12.9  e 47,260  17  17 

17  United States  0.938  79.3  15.9  13.9  73,650  –7  18 

20  Korea (Republic of)  0.937  84.3  16.6  12.7  e 49,726  11  19 

21  Slovenia  0.931  81.6  17.5  13.0  e 46,361  15  21 

22  Austria  0.930  82.0  16.3  12.4  e 63,479  –2  20 

23  Japan  0.925  84.7  15.5  12.7  e 47,775  10  23 

24  Malta  0.924  83.3  15.9  12.4  e 52,155  5 26 

25  Luxembourg  0.922  82.2  14.4  12.6  d 85,461  f –19  22 

26  France  0.920  83.3  16.1  11.8  e 55,060  –2  27 

27  Israel  0.919  82.4  14.9  13.5  e 48,050  5 23 

28  Spain  0.918  83.7  17.8  10.8  e 46,008  9 28 

29  Czechia  0.915  79.8  16.8  13.0  e 45,889  9 28 

29  Italy  0.915  83.7  16.7  10.8  e 52,389  –1  32 

29  San Marino  0.915  85.7  g 14.6  e 11.4  64,706  –13  30 

32  Andorra  0.913  84.0  14.5  11.6  64,631  –15  37 

32  Cyprus  0.913  81.6  16.2  12.6  e 45,394  7 31 

34  Greece  0.908  81.9  20.8  c 11.6  e 35,761  17  36 

35  Poland  0.906  78.6  16.7  13.2  e 42,218  5 33 

36  Estonia  0.905  79.2  16.0  13.6  e 40,881  8 33 

37  Saudi Arabia  0.900  78.7  16.9  11.6  e 50,299  –7  37 

38  Bahrain  0.899  81.3  15.9  11.1  52,819  –11  33 

39  Lithuania  0.895  76.0  16.5  13.6  e 41,916  2 39 

40  Portugal  0.890  82.4  17.5  9.7  e 41,064  3 41 

41  Croatia  0.889  78.6  16.3  12.1  j 41,380  1 40 

41  Latvia  0.889  76.2  16.5  13.4  e 37,998  6 43 

43  Qatar  0.886  82.4  13.1  10.8  105,353  f –39  41 

44  Slovakia  0.880  78.3  14.9  13.1  e 36,793  5 44 

45  Chile  0.878  81.2  16.9  11.3  e 28,047  16  45 

46  Hungary  0.870  77.0  15.5  12.3  e 37,236  2 46 

47  Argentina  0.865  77.4  18.8  c 11.2  e 25,876  20  47 

48  Montenegro  0.862  77.1  15.5  12.8  e 28,026  14  48 

48  Uruguay  0.862  78.1  17.5  10.5  28,650  12  50 

50  Oman  0.858  80.0  13.4  11.9  36,096  0 52 

51  Türkiye  0.853  77.2  19.8  c 9.0  e 34,507  1 48 

52  Kuwait  0.852  80.4  15.9  e 7.6  e 56,612  –29  53 

53  Antigua and Barbuda  0.851  77.6  15.5  e 11.6  27,387  10  51 

54  Seychelles  0.848  72.9  18.2  c 11.2  29,195  4 56 

55  Bulgaria  0.845  75.6  15.3  11.5  e 32,175  0 57 

55  Romania  0.845  75.9  14.1  11.6  39,374  –10  54 

57  Georgia  0.844  74.5  16.8  12.7  20,753  18  55 

58  Saint Kitts and Nevis  0.840  72.1  18.4  b,k  10.8  l 29,105  1 60 

59  Panama  0.839  79.6  13.3  e 10.8  e 34,385  –6  57 

60  Brunei Darussalam  0.837  75.3  13.7  m 9.3  75,827  f –51  63 

60  Kazakhstan  0.837  74.4  14.0  12.5  e 30,989  –4  59 

62  Costa Rica  0.833  80.8  16.3  e 8.8  e 23,417  6 65 

Continued → 

2 7 8 HUMAN DEVELOPMENT REPORT 2025 HDI RANK 

SDG 3  SDG 4.3  SDG 4.4  SDG 8.5 

Human Development 

Index (HDI) 

Life expectancy 

at birth 

Expected years 

of schooling 

Mean years of 

schooling 

Gross national income 

(GNI) per capita 

GNI per capita rank 

minus HDI rank 

HDI 

rank 

Value  (years)  (years)  (years)  (2021 PPP $) 

2023  2023  2023 a 2023 a 2023  2023 b 2022 

62  Serbia  0.833  76.8  15.0  11.6  e 23,115  7 61 

64  Russian Federation  0.832  73.2  13.2  12.4  39,222  –18  61 

65  Belarus  0.824  74.4  13.7  12.3  e 26,725  1 64 

66  Bahamas  0.820  74.6  11.9  n 12.8  e 30,975  –9  66 

67  Malaysia  0.819  76.7  12.7  11.1  32,553  –13  68 

68  North Macedonia  0.815  77.4  14.8  10.2  m 22,128  2 67 

69  Armenia  0.811  75.7  14.4  11.3  d 20,221  9 72 

69  Barbados  0.811  76.2  16.6  e 9.9  d 17,328  20  69 

71  Albania  0.810  79.6  14.5  10.2  d 17,627  16  70 

72  Trinidad and Tobago  0.807  73.5  14.2  o 10.8  27,000  –7  71 

73  Mauritius  0.806  74.9  14.2  e 10.1  d 27,280  –9  75 

74  Bosnia and Herzegovina  0.804  77.9  13.2  11.0  19,827  6 73 

High human development 

75  Iran (Islamic Republic of)  0.799  77.7  14.0  e 10.8  e 16,096  19  77 

76  Saint Vincent and the Grenadines  0.798  71.2  16.3  n 11.3  p 17,247  14  75 

76  Thailand  0.798  76.4  15.4  e 9.0  20,570  1 78 

78  China  0.797  78.0  15.5  e 8.0  e 22,029  –7  74 

79  Peru  0.794  77.7  14.9  e 10.2  e 14,339  23  79 

80  Grenada  0.791  75.2  16.6  e 9.4  q 14,349  21  80 

81  Azerbaijan  0.789  74.4  12.9  11.1  20,668  –5  82 

81  Mexico  0.789  75.1  14.5  9.3  e 21,813  –8  84 

83  Colombia  0.788  77.7  14.3  9.0  e 18,666  1 85 

84  Brazil  0.786  75.8  15.8  8.4  e 18,011  1 86 

84  Palau  0.786  69.3  14.1  13.3  p 16,035  11  81 

86  Moldova (Republic of)  0.785  71.2  14.6  e 11.8  15,867  11  82 

87  Ukraine  0.779  73.4  13.3  11.1  d 16,933  5 90 

88  Ecuador  0.777  77.4  14.9  9.0  13,986  15  89 

89  Dominican Republic  0.776  73.7  13.6  9.4  e 22,024  –17  87 

89  Guyana  0.776  70.2  13.0  o 8.7  d 46,959  –54  95 

89  Sri Lanka  0.776  77.5  13.1  10.8  12,616  22  88 

92  Tonga  0.769  72.9  17.8  e 10.9  d 7,438  38  91 

93  Maldives  0.766  81.0  12.8  7.4  d 19,317  –11  91 

93  Viet Nam  0.766  74.6  15.5  9.0  13,033  14  91 

95  Turkmenistan  0.764  70.1  13.2  11.2  e 17,716  –9  96 

96  Algeria  0.763  76.3  15.5  7.4  e 15,114  3 96 

97  Cuba  0.762  78.1  13.9  10.6  d 8,415  r 30  91 

98  Dominica  0.761  71.1  14.2  e 10.1  16,001  –2  98 

99  Paraguay  0.756  73.8  14.0  e 8.9  e 15,252  –1  102 

100  Egypt  0.754  71.6  13.1  e 10.1  e 16,218  –7  100 

100  Jordan  0.754  77.8  13.1  10.2  9,222  22  100 

102  Lebanon  0.752  77.8  11.7  10.4  s 11,299  13  99 

103  Saint Lucia  0.748  72.7  12.7  8.6  e 20,900  –29  102 

104  Mongolia  0.747  71.7  13.6  9.4  m 14,787  –4  105 

105  Tunisia  0.746  76.5  14.7  e 7.6  12,011  9 104 

106  South Africa  0.741  66.1  13.8  11.6  13,694  0 107 

107  Uzbekistan  0.740  72.4  12.5  11.9  8,826  17  107 

108  Bolivia (Plurinational State of)  0.733  68.6  15.6  e 10.0  e 9,445  13  113 

108  Gabon  0.733  68.3  12.5  e 9.7  18,854  –25  111 

108  Marshall Islands  0.733  66.9  16.4  11.6  p 7,224  23  110 

111  Botswana  0.731  69.2  11.4  10.5  16,984  –20  112 

111  Fiji  0.731  67.3  13.8  10.4  12,843  –3  114 

113  Indonesia  0.728  71.1  13.3  8.7  e 13,700  –8  114 

114  Suriname  0.722  73.6  11.0  8.4  e 17,344  –26  116 

115  Belize  0.721  73.6  12.0  8.8  12,343  –2  118 

115  Libya  0.721  69.3  12.9  q 7.8  l 19,831  –36  106 

117  Jamaica  0.720  71.5  12.4  e 10.0  10,057  t 2 117 

117  Kyrgyzstan  0.720  71.7  12.7  12.1  e 6,078  24  118 

117  Philippines  0.720  69.8  12.8  e 10.0  10,731  0 120 

120  Morocco  0.710  75.3  15.1  6.2  8,653  5 122 

121  Venezuela (Bolivarian Republic of)  0.709  72.5  13.0  p 9.7  p 7,157  u 11  121 

122  Samoa  0.708  71.7  12.4  11.3  e 5,952  21  123 

123  Nicaragua  0.706  74.9  11.5  9.9  6,881  11  124 

124  Nauru  0.703  62.1  12.8  q 9.4  q 19,642  –43  125 

TABLE 1 

Continued → 

2 7 9 TABLE 1 / HUMAN DEVELOPMENT INDEX AND ITS COMPONENTS TABLE 1 

HDI RANK 

SDG 3  SDG 4.3  SDG 4.4  SDG 8.5 

Human Development 

Index (HDI) 

Life expectancy 

at birth 

Expected years 

of schooling 

Mean years of 

schooling 

Gross national income 

(GNI) per capita 

GNI per capita rank 

minus HDI rank 

HDI 

rank 

Value  (years)  (years)  (years)  (2021 PPP $) 

2023  2023  2023 a 2023 a 2023  2023 b 2022 

Medium human development 

125  Bhutan  0.698  73.0  13.2  e 5.8  l 13,843  –21  126 

126  Eswatini (Kingdom of)  0.695  64.1  15.2  e 8.7  9,919  –6  126 

126  Iraq  0.695  72.3  12.4  v 6.8  o 12,654  –16  126 

128  Tajikistan  0.691  71.8  10.8  e 11.3  d 5,747  17  129 

129  Tuvalu  0.689  67.1  12.4  w 10.8  e 7,006  4 130 

130  Bangladesh  0.685  74.7  12.3  6.8  8,498  –4  131 

130  India  0.685  72.0  13.0  6.9  9,047  –7  133 

132  El Salvador  0.678  72.1  11.1  7.3  10,595  –14  134 

133  Equatorial Guinea  0.674  63.7  12.5  q 8.3  l 12,762  –24  132 

133  Palestine, State of  0.674  65.2  13.0  10.1  6,547  5 109 

135  Cabo Verde  0.668  76.1  11.4  e 6.1  l 8,165  –7  135 

136  Namibia  0.665  67.4  11.8  x 7.3  d 10,917  –20  137 

137  Guatemala  0.662  72.6  10.7  5.8  12,459  –25  136 

138  Congo  0.649  65.8  12.7  e 8.3  d 5,903  6 138 

139  Honduras  0.645  72.9  10.2  e 7.5  e 6,065  3 139 

140  Kiribati  0.644  66.5  11.9  y 9.1  l 4,947  11  140 

141  Sao Tome and Principe  0.637  69.7  12.9  o 6.0  e 5,583  6 141 

142  Timor-Leste  0.634  67.7  13.3  x 6.2  x 5,435  8 142 

143  Ghana  0.628  65.5  11.4  7.1  6,846  –8  144 

143  Kenya  0.628  63.6  11.5  x 8.6  5,608  3 143 

145  Nepal  0.622  70.4  13.8  4.5  4,726  10  150 

146  Vanuatu  0.621  71.5  11.8  e 7.2  l 3,404  20  145 

147  Lao People's Democratic Republic  0.617  69.0  9.6  6.1  d 8,106  –18  147 

148  Angola  0.616  64.6  12.2  6.0  x 6,631  –11  146 

149  Micronesia (Federated States of)  0.615  67.2  11.5  q 7.3  l 4,246  7 147 

150  Myanmar  0.609  66.9  11.5  s 6.4  z 4,919  aa  3 149 

151  Cambodia  0.606  70.7  11.2  5.2  4,931  1 151 

152  Comoros  0.603  66.8  13.3  e 6.0  3,481  12  151 

153  Zimbabwe  0.598  62.8  11.1  e 8.9  e 3,511  9 153 

154  Zambia  0.595  66.3  11.0  ab  7.4  d 3,447  11  154 

155  Cameroon  0.588  63.7  10.8  6.6  d 4,746  –1  156 

156  Solomon Islands  0.584  70.5  11.3  q 5.9  l 2,777  18  155 

157  Côte d'Ivoire  0.582  61.9  11.4  4.9  6,735  –21  162 

157  Uganda  0.582  68.3  11.6  x 6.3  e 2,736  18  157 

159  Rwanda  0.578  67.8  12.6  4.9  2,971  9 160 

160  Papua New Guinea  0.576  66.1  11.5  x 5.0  d 3,971  –2  158 

161  Togo  0.571  62.7  13.1  e 5.9  e 2,856  9 161 

162  Syrian Arab Republic  0.564  72.1  7.4  n 5.9  p 3,918  –3  159 

163  Mauritania  0.563  68.5  7.9  e 4.9  d 6,267  –23  163 

164  Nigeria  0.560  54.5  10.5  7.6  5,569  –16  164 

165  Tanzania (United Republic of)  0.555  67.0  8.6  6.1  3,515  –4  165 

166  Haiti  0.554  64.9  10.9  q 5.4  ac  2,935  3 166 

167  Lesotho  0.550  57.4  11.0  e 7.7  e 3,029  0 167 

Low human development 

168  Pakistan  0.544  67.6  7.9  e 4.3  e 5,501  –19  168 

169  Senegal  0.530  68.7  9.1  2.9  e 4,202  –12  169 

170  Gambia  0.524  65.9  9.0  x 4.7  x 2,812  1 170 

171  Congo (Democratic Republic of the)  0.522  61.9  10.9  e 7.4  d 1,431  17  172 

172  Malawi  0.517  67.4  9.9  5.2  m 1,634  12  173 

173  Benin  0.515  60.8  10.4  3.2  3,806  –13  174 

174  Guinea-Bissau  0.514  64.1  10.6  o 3.7  2,403  2 175 

175  Djibouti  0.513  66.0  6.2  e 4.0  p 6,368  –36  176 

176  Sudan  0.511  66.3  8.6  e 4.0  2,810  –4  171 

177  Liberia  0.510  62.2  10.5  6.2  e 1,538  9 177 

178  Eritrea  0.503  68.6  7.3  e 5.1  l 2,029  1 178 

179  Guinea  0.500  60.7  10.4  e 2.5  e 3,494  –16  179 

180  Ethiopia  0.497  67.3  9.2  x 2.4  e 2,796  –7  181 

181  Afghanistan  0.496  66.0  10.8  e 2.5  1,972  –1  180 

182  Mozambique  0.493  63.6  10.8  e 4.6  1,356  7 182 

183  Madagascar  0.487  63.6  9.1  e 4.6  1,656  0 183 

184  Yemen  0.470  69.3  7.5  p 5.5  1,018  7 184 

185  Sierra Leone  0.467  61.8  9.1  o 3.5  e 1,714  –3  185 

Continued → 

2 8 0 HUMAN DEVELOPMENT REPORT 2025 TABLE 1              

> HDI RANK
> SDG 3 SDG 4.3 SDG 4.4 SDG 8.5
> Human Development
> Index (HDI)
> Life expectancy
> at birth
> Expected years
> of schooling
> Mean years of
> schooling
> Gross national income
> (GNI) per capita
> GNI per capita rank
> minus HDI rank
> HDI
> rank
> Value (years) (years) (years) (2021 PPP $)
> 2023 2023 2023 a2023 a2023 2023 b2022

186  Burkina Faso  0.459  61.1  8.7  2.3  2,391  –9  186 

187  Burundi  0.439  63.7  9.8  e 3.5  e 859  5 187 

188  Mali  0.419  60.4  7.0  e 1.6  m 2,342  –10  188 

188  Niger  0.419  61.2  8.3  e 1.4  d 1,590  –3  189 

190  Chad  0.416  55.1  8.3  e 2.3  e 1,748  –9  189 

191  Central African Republic  0.414  57.4  7.4  e 4.0  d 1,100  –1  .. 

192  Somalia  0.404  58.8  7.5  q 1.9  1,475  –5  192 

193  South Sudan  0.388  57.6  5.6  e 5.7  ad  688  0 191 

Other countries or territories 

Korea (Democratic People's Rep. of)  ..  73.6  12.2  e ..  ..  ..  .. 

Monaco  ..  86.4  g 21.7  c ..  ..  ..  .. 

Human development groups 

Very high human development  0.914  80.0  16.4  12.5  53,014  — —

High human development  0.777  75.7  14.6  8.7  18,405  — —

Medium human development  0.656  69.3  12.1  6.8  7,822  — —

Low human development  0.515  65.0  8.9  4.0  3,007  — —

Developing countries  0.712  72.0  12.7  7.8  13,301  — —

Regions 

Arab States  0.719  72.5  12.0  8.1  15,825  — —

East Asia and the Pacific  0.775  75.9  14.6  8.3  19,520  — —

Europe and Central Asia  0.818  74.8  15.6  10.7  23,171  — —

Latin America and the Caribbean  0.783  75.6  14.8  9.1  18,048  — —

South Asia  0.672  71.9  12.1  6.8  8,722  — —

Sub-Saharan Africa  0.568  62.5  10.3  6.2  4,352  — —

Least developed countries  0.560  66.5  10.2  5.1  3,637  — —

Small island developing states  0.739  71.9  12.6  8.6  19,343  — —

Organisation for Economic Co -operation 

and Development  0.916  80.6  16.5  12.3  52,698  — —

World  0.756  73.4  13.0  8.8  20,327  — —

2 8 1 TABLE 1 / HUMAN DEVELOPMENT INDEX AND ITS COMPONENTS Notes 

a Data refer to 2023 or the most recent year available. 

b Based on countries for which a Human Development 

Index (HDI) value is calculated. 

c In calculating the HDI value, expected years of schooling 

is capped at 18 years. 

d Updated by HDRO based on data from Barro and Lee 

(2018) and UNESCO Institute for Statistics (2024). 

e Updated by HDRO based on data from UNESCO 

Institute for Statistics (2024). 

f In calculating the HDI value, GNI per capita is capped at 

$75,000. 

g In calculating the HDI value, life expectancy is capped at 

85 years. 

h Updated by HDRO using the mean years of schooling 

trend of Austria and data from UNESCO Institute for 

Statistics (2024). 

i Estimated using the purchasing power parity (PPP) rate 

and projected growth rate of Switzerland. 

j Updated by HDRO based on data from Eurostat (2024) 

and UNESCO Institute for Statistics (2024). 

k Refers to 2015 based on UNESCO Institute for Statistics 

(2024). 

l HDRO estimate based on data from Robert Barro and 

Jong-Wha Lee, ICF Macro Demographic and Health Sur -

veys, the Organisation for Economic Co-operation and 

Development, United Nations Children’s Fund ( UNICEF) 

Multiple Indicator Cluster Surveys and the United Na -

tions Educational, Scientific and Cultural Organization 

(UNESCO) Institute for Statistics. 

m Refers to 2020 based on UNESCO Institute for Statistics 

(2024). 

n HDRO estimate based on data from the Center for 

Distributive, Labor and Social Studies and the World 

Bank’s Socio-Economic Database for Latin America and 

the Caribbean, ICF Macro Demographic and Health 

Surveys, the UNESCO Institute for Statistics and UNICEF 

Multiple Indicator Cluster Surveys. 

o Updated by HDRO based on data from UNICEF Multiple 

Indicator Cluster Surveys for various years and UNESCO 

Institute for Statistics (2024). 

p Updated by HDRO based on data from UNESCO Institute 

for Statistics (2024) and estimates using cross-country 

regression. 

q Based on HDRO estimates using cross-country regression. 

r HDRO estimate calculated based on United Nations 

Statistics Division (2025) and World Bank (2024a). 

s Refers to 2018 based on UNESCO Institute for Statistics 

(2024). 

t HDRO estimate based on data from IMF (2024) and 

World Bank (2024a). 

u IMF 2024. 

v Updated by HDRO based on data from UNICEF Multiple 

Indicator Cluster Surveys for various years. 

w HDRO estimate based on data from ICF Macro Demo -

graphic and Health Surveys, the UNESCO Institute for 

Statistics and UNICEF Multiple Indicator Cluster Surveys. 

x Updated by HDRO based on data from ICF Macro 

Demographic and Health Surveys for various years and 

UNESCO Institute for Statistics (2024). 

y Updated by HDRO based on data from UNICEF Multiple 

Indicator Cluster Surveys for various years and estimates 

using cross-country regression. 

z Refers to 2019 based on UNESCO Institute for Statistics 

(2024). 

aa  HDRO estimate based on data from IMF (2024), United 

Nations Statistics Division (2025) and World Bank (2024a). 

ab  Updated by HDRO based on data from ICF Macro De -

mographic and Health Surveys for various years. 

ac  Refers to 2017 based on UNESCO Institute for Statistics 

(2024). 

ad  Refers to 2008 based on UNESCO Institute for Statistics 

(2024). 

Definitions 

Human Development Index (HDI):  A composite index 

measuring average achievement in three basic dimensions of 

human development—a long and healthy life, knowledge and 

a decent standard of living. See  Technical note 1  at  https://hdr. 

undp.org/sites/default/files/2025_HDR/hdr2025_technical_ 

notes.pdf  for details on how the HDI is calculated. 

Life expectancy at birth:  Number of years a newborn infant 

could expect to live if prevailing patterns of age-specific 

mortality rates at the time of birth stay the same throughout 

the infant’s life. 

Expected years of schooling:  Number of years of schooling 

that a child of school entrance age can expect to receive if 

prevailing patterns of age-specific enrolment rates persist 

throughout the child’s life. 

Mean years of schooling:  Average number of years of education 

received by people ages 25 and older, converted from education 

attainment levels using official durations of each level. 

Gross national income (GNI) per capita:  Aggregate income 

of an economy generated by its production and its ownership 

of factors of production, less the incomes paid for the use of 

factors of production owned by the rest of the world, converted 

to international dollars using PPP rates, divided by midyear 

population. 

GNI per capita rank minus HDI rank:  Difference in ranking by 

GNI per capita and by HDI value. A negative value means that 

the country is better ranked by GNI than by HDI value. 

HDI rank for 2022:  Ranking by HDI value for 2022, calculated 

using the same most recently revised data available that were 

used to calculate HDI values for 2023. 

Main data sources 

Columns 1 and 7:  HDRO calculations based on data from 

Barro and Lee (2018), IMF (2024), UNDESA (2024a), UNESCO 

Institute for Statistics (2024), United Nations Statistics Division 

(2025) and World Bank (2024a). 

Column 2:  UNDESA 2024a. 

Column 3:  ICF Macro Demographic and Health Surveys, 

UNESCO Institute for Statistics 2024 and UNICEF Multiple 

Indicator Cluster Surveys. 

Column 4:  Barro and Lee 2018, Eurostat 2024, ICF Macro De -

mographic and Health Surveys, UNESCO Institute for Statistics 

2024 and UNICEF Multiple Indicator Cluster Surveys. 

Column 5:  IMF 2024, United Nations Statistics Division 2025 

and World Bank 2024a. 

Column 6:  Calculated based on data in columns 1 and 5. 

TABLE 1 

2 8 2 HUMAN DEVELOPMENT REPORT 2025 HDI RANK 

Human Development Index (HDI) 

Change in 

HDI rank  Average annual HDI growth 

Value  (%) 

1990  2000  2010  2015  2020  2021  2022  2023  2015–2023 a 1990–2000  2000–2010  2010–2023  1990–2023 

Very high human development 

1 Iceland  0.841  0.902  0.935  0.956  0.965  0.967  0.964  0.972  2 0.70  0.36  0.30  0.44 

2 Norway  0.856  0.924  0.947  0.959  0.969  0.969  0.967  0.970  –1  0.77  0.25  0.18  0.38 

2 Switzerland  0.858  0.892  0.945  0.957  0.963  0.968  0.966  0.970  0 0.39  0.58  0.20  0.37 

4 Denmark  0.844  0.896  0.920  0.943  0.954  0.958  0.959  0.962  2 0.60  0.26  0.34  0.40 

5 Germany  0.834  0.897  0.936  0.948  0.955  0.958  0.955  0.959  –1  0.73  0.43  0.19  0.42 

5 Sweden  0.818  0.912  0.918  0.945  0.951  0.958  0.959  0.959  0 1.09  0.07  0.34  0.48 

7 Australia  0.867  0.897  0.929  0.938  0.950  0.954  0.952  0.958  1 0.34  0.35  0.24  0.30 

8 Hong Kong, China (SAR)  0.755  0.839  0.912  0.937  0.950  0.961  0.950  0.955  2 1.06  0.84  0.36  0.71 

8 Netherlands  0.855  0.900  0.925  0.940  0.945  0.951  0.953  0.955  –1  0.51  0.27  0.25  0.34 

10  Belgium  0.824  0.894  0.921  0.933  0.939  0.948  0.945  0.951  3 0.82  0.30  0.25  0.44 

11  Ireland  0.776  0.869  0.915  0.931  0.948  0.946  0.947  0.949  4 1.14  0.52  0.28  0.61 

12  Finland  0.823  0.898  0.920  0.938  0.947  0.949  0.946  0.948  –4  0.88  0.24  0.23  0.43 

13  Singapore  0.819  0.882  0.932  0.935  0.944  0.948  0.942  0.946  –2  0.74  0.55  0.11  0.44 

13  United Kingdom  0.812  0.870  0.921  0.931  0.930  0.941  0.946  0.946  2 0.69  0.57  0.21  0.46 

15  United Arab Emirates  0.713  0.790  0.835  0.857  0.909  0.903  0.921  0.940  27  1.03  0.56  0.92  0.84 

16  Canada  0.865  0.894  0.918  0.932  0.931  0.937  0.935  0.939  –2  0.33  0.27  0.17  0.25 

17  Liechtenstein  ..  0.882  0.914  0.925  0.929  0.933  0.936  0.938  1 ..  0.36  0.20  .. 

17  New Zealand  0.811  0.896  0.926  0.934  0.940  0.939  0.933  0.938  –5  1.00  0.33  0.10  0.44 

17  United States  0.878  0.895  0.919  0.928  0.925  0.921  0.930  0.938  0 0.19  0.26  0.16  0.20 

20  Korea (Republic of)  0.738  0.830  0.894  0.914  0.928  0.933  0.928  0.937  1 1.18  0.75  0.36  0.73 

21  Slovenia  0.734  0.829  0.896  0.909  0.918  0.924  0.926  0.931  2 1.22  0.78  0.30  0.72 

22  Austria  0.832  0.879  0.912  0.919  0.925  0.930  0.927  0.930  –3  0.55  0.37  0.15  0.34 

23  Japan  0.853  0.889  0.907  0.917  0.922  0.922  0.921  0.925  –3  0.41  0.20  0.15  0.25 

24  Malta  0.735  0.790  0.867  0.892  0.903  0.914  0.917  0.924  5 0.72  0.93  0.49  0.70 

25  Luxembourg  0.787  0.861  0.909  0.913  0.916  0.918  0.922  0.922  –3  0.90  0.54  0.11  0.48 

26  France  0.798  0.852  0.888  0.901  0.909  0.915  0.916  0.920  –1  0.66  0.41  0.27  0.43 

27  Israel  0.787  0.839  0.889  0.902  0.912  0.918  0.921  0.919  –3  0.64  0.58  0.26  0.47 

28  Spain  0.766  0.833  0.875  0.895  0.901  0.912  0.911  0.918  0 0.84  0.49  0.37  0.55 

29  Czechia  0.753  0.817  0.880  0.900  0.898  0.901  0.911  0.915  –3  0.82  0.75  0.30  0.59 

29  Italy  0.787  0.849  0.887  0.889  0.899  0.908  0.905  0.915  1 0.76  0.44  0.24  0.46 

29  San Marino  ..  0.881  0.905  0.896  0.895  0.903  0.910  0.915  –2  ..  0.27  0.08  .. 

32  Andorra  ..  0.825  0.870  0.869  0.851  0.871  0.893  0.913  3 ..  0.53  0.37  .. 

32  Cyprus  0.749  0.808  0.869  0.882  0.905  0.907  0.908  0.913  1 0.76  0.73  0.38  0.60 

34  Greece  0.770  0.828  0.876  0.888  0.896  0.897  0.897  0.908  –3  0.73  0.57  0.28  0.50 

35  Poland  0.722  0.801  0.852  0.879  0.880  0.884  0.902  0.906  –1  1.04  0.62  0.47  0.69 

36  Estonia  0.738  0.793  0.868  0.888  0.901  0.899  0.902  0.905  –5  0.72  0.91  0.32  0.62 

37  Saudi Arabia  0.670  0.737  0.801  0.851  0.875  0.878  0.893  0.900  9 0.96  0.84  0.90  0.90 

38  Bahrain  0.734  0.775  0.810  0.868  0.885  0.885  0.902  0.899  –1  0.55  0.44  0.81  0.62 

39  Lithuania  0.745  0.778  0.854  0.869  0.888  0.887  0.888  0.895  –4  0.43  0.94  0.36  0.56 

40  Portugal  0.707  0.797  0.836  0.857  0.870  0.876  0.883  0.890  2 1.21  0.48  0.48  0.70 

41  Croatia  ..  0.769  0.831  0.852  0.867  0.876  0.886  0.889  4 ..  0.78  0.52  .. 

41  Latvia  0.736  0.764  0.833  0.859  0.879  0.871  0.881  0.889  –1  0.37  0.87  0.50  0.57 

43  Qatar  0.767  0.795  0.834  0.860  0.872  0.866  0.883  0.886  –4  0.36  0.48  0.47  0.44 

44  Slovakia  0.698  0.774  0.851  0.861  0.867  0.859  0.873  0.880  –6  1.04  0.95  0.26  0.70 

45  Chile  0.718  0.771  0.823  0.855  0.856  0.865  0.869  0.878  –1  0.71  0.65  0.50  0.61 

46  Hungary  0.730  0.781  0.838  0.847  0.857  0.852  0.867  0.870  1 0.68  0.71  0.29  0.53 

47  Argentina  0.733  0.789  0.844  0.859  0.851  0.847  0.858  0.865  –7  0.74  0.68  0.19  0.50 

48  Montenegro  ..  ..  0.815  0.839  0.841  0.840  0.853  0.862  0 ..  ..  0.43  .. 

48  Uruguay  0.713  0.764  0.796  0.818  0.837  0.837  0.852  0.862  13  0.69  0.41  0.61  0.58 

50  Oman  ..  0.707  0.804  0.838  0.843  0.834  0.846  0.858  1 ..  1.29  0.50  .. 

51  Türkiye  0.598  0.669  0.750  0.821  0.838  0.841  0.853  0.853  7 1.13  1.15  0.99  1.08 

52  Kuwait  0.698  0.778  0.812  0.832  0.837  0.839  0.845  0.852  1 1.09  0.43  0.37  0.61 

53  Antigua and Barbuda  ..  ..  0.828  0.839  0.840  0.843  0.848  0.851  –5  ..  ..  0.21  .. 

54  Seychelles  ..  ..  0.758  0.819  0.853  0.838  0.836  0.848  5 ..  ..  0.87  .. 

55  Bulgaria  0.706  0.733  0.799  0.824  0.826  0.817  0.835  0.845  1 0.38  0.87  0.43  0.55 

55  Romania  0.719  0.730  0.822  0.823  0.832  0.829  0.840  0.845  2 0.15  1.19  0.21  0.49 

57  Georgia  ..  0.705  0.770  0.807  0.822  0.819  0.838  0.844  6 ..  0.89  0.71  .. 

58  Saint Kitts and Nevis  ..  ..  0.791  0.830  0.828  0.818  0.829  0.840  –4  ..  ..  0.46  .. 

59  Panama  0.672  0.718  0.775  0.803  0.808  0.819  0.835  0.839  6 0.66  0.77  0.61  0.67 

60  Brunei Darussalam  0.781  0.792  0.830  0.839  0.836  0.835  0.825  0.837  –12  0.14  0.47  0.06  0.21 

60  Kazakhstan  0.689  0.692  0.781  0.819  0.826  0.816  0.831  0.837  –1  0.04  1.22  0.53  0.59 

62  Costa Rica  0.677  0.720  0.776  0.803  0.819  0.817  0.823  0.833  3 0.62  0.75  0.55  0.63 

TABLE 2 

# Human Development Index trends, 1990–2023 

Continued → 

2 8 3 TABLE 2 / HUMAN DEVELOPMENT INDEX TRENDS, 1990–2023 HDI RANK               

> Human Development Index (HDI)
> Change in
> HDI rank Average annual HDI growth
> Value (%)
> 1990 2000 2010 2015 2020 2021 2022 2023 2015–2023 a1990–2000 2000–2010 2010–2023 1990–2023

62  Serbia  ..  0.701  0.775  0.802  0.809  0.807  0.826  0.833  5 ..  1.01  0.56  .. 

64  Russian Federation  0.762  0.750  0.808  0.833  0.818  0.813  0.826  0.832  –12  –0.16  0.75  0.23  0.27 

65  Belarus  ..  0.724  0.803  0.825  0.815  0.817  0.824  0.824  –10  ..  1.04  0.20  .. 

66  Bahamas  0.762  0.787  0.801  0.807  0.797  0.794  0.818  0.820  –3  0.32  0.18  0.18  0.22 

67  Malaysia  0.653  0.733  0.779  0.800  0.810  0.802  0.810  0.819  2 1.16  0.61  0.39  0.69 

68  North Macedonia  0.644  0.686  0.765  0.795  0.783  0.781  0.811  0.815  4 0.63  1.10  0.49  0.72 

69  Armenia  0.663  0.667  0.747  0.777  0.761  0.786  0.801  0.811  9 0.06  1.14  0.63  0.61 

69  Barbados  0.730  0.762  0.797  0.800  0.803  0.803  0.807  0.811  0 0.43  0.45  0.13  0.32 

71  Albania  0.654  0.682  0.769  0.797  0.794  0.794  0.806  0.810  0 0.42  1.21  0.40  0.65 

72  Trinidad and Tobago  0.661  0.714  0.789  0.808  0.800  0.796  0.805  0.807  –10  0.77  1.00  0.17  0.61 

73  Mauritius  0.627  0.683  0.755  0.792  0.795  0.789  0.794  0.806  0 0.86  1.01  0.50  0.76 

74  Bosnia and Herzegovina  ..  0.674  0.725  0.769  0.783  0.783  0.799  0.804  7 ..  0.73  0.80  .. 

High human development 

75  Iran (Islamic Republic of)  0.626  0.710  0.778  0.788  0.775  0.777  0.793  0.799  –1  1.27  0.92  0.21  0.74 

76  Saint Vincent and the Grenadines  ..  0.700  0.746  0.765  0.781  0.781  0.794  0.798  11  ..  0.64  0.52  .. 

76  Thailand  0.584  0.657  0.742  0.788  0.798  0.800  0.792  0.798  –2  1.18  1.22  0.56  0.95 

78  China  0.491  0.598  0.710  0.750  0.786  0.794  0.796  0.797  16  1.99  1.73  0.89  1.48 

79  Peru  0.625  0.682  0.731  0.768  0.769  0.764  0.790  0.794  5 0.88  0.70  0.64  0.73 

80  Grenada  ..  ..  0.771  0.782  0.782  0.782  0.789  0.791  –4  ..  ..  0.20  .. 

81  Azerbaijan  ..  0.652  0.744  0.771  0.757  0.765  0.784  0.789  –1  ..  1.33  0.45  .. 

81  Mexico  0.668  0.712  0.751  0.773  0.763  0.761  0.783  0.789  –2  0.64  0.53  0.38  0.51 

83  Colombia  0.623  0.679  0.741  0.767  0.764  0.762  0.782  0.788  3 0.86  0.88  0.47  0.71 

84  Brazil  0.641  0.690  0.748  0.764  0.770  0.768  0.780  0.786  4 0.74  0.81  0.38  0.62 

84  Palau  ..  0.736  0.779  0.802  0.799  0.789  0.786  0.786  –17  ..  0.57  0.07  .. 

86  Moldova (Republic of)  ..  ..  0.739  0.759  0.770  0.773  0.784  0.785  5 ..  ..  0.47  .. 

87  Ukraine  0.750  0.716  0.782  0.778  0.783  0.772  0.772  0.779  –10  –0.46  0.89  –0.03  0.12 

88  Ecuador  0.646  0.683  0.737  0.764  0.740  0.753  0.773  0.777  0 0.56  0.76  0.41  0.56 

89  Dominican Republic  0.589  0.658  0.715  0.747  0.767  0.762  0.778  0.776  6 1.11  0.83  0.63  0.84 

89  Guyana  0.494  0.567  0.647  0.683  0.722  0.713  0.763  0.776  33  1.39  1.33  1.41  1.38 

89  Sri Lanka  0.638  0.702  0.748  0.769  0.780  0.777  0.777  0.776  –8  0.96  0.64  0.28  0.60 

92  Tonga  0.641  0.688  0.724  0.743  0.765  0.763  0.764  0.769  4 0.71  0.51  0.46  0.55 

93  Maldives  ..  0.639  0.689  0.725  0.730  0.745  0.764  0.766  10  ..  0.76  0.82  .. 

93  Viet Nam  0.499  0.604  0.686  0.717  0.755  0.754  0.764  0.766  16  1.93  1.28  0.85  1.31 

95  Turkmenistan  ..  ..  0.700  0.725  0.744  0.754  0.761  0.764  8 ..  ..  0.68  .. 

96  Algeria  0.595  0.651  0.718  0.737  0.742  0.755  0.761  0.763  3 0.90  0.98  0.47  0.76 

97  Cuba  0.687  0.697  0.783  0.769  0.762  0.745  0.764  0.762  –16  0.14  1.17  –0.21  0.31 

98  Dominica  ..  0.721  0.747  0.741  0.753  0.749  0.759  0.761  0 ..  0.35  0.14  .. 

99  Paraguay  0.607  0.664  0.709  0.737  0.742  0.723  0.747  0.756  0 0.90  0.66  0.49  0.67 

100  Egypt  0.572  0.639  0.677  0.706  0.736  0.738  0.751  0.754  15  1.11  0.58  0.83  0.84 

100  Jordan  0.619  0.672  0.732  0.743  0.743  0.736  0.751  0.754  –4  0.82  0.86  0.23  0.60 

102  Lebanon  ..  ..  0.750  0.763  0.750  0.733  0.755  0.752  –12  ..  ..  0.02  .. 

103  Saint Lucia  0.683  0.710  0.749  0.757  0.734  0.724  0.747  0.748  –11  0.39  0.54  –0.01  0.28 

104  Mongolia  0.593  0.611  0.714  0.753  0.741  0.727  0.742  0.747  –11  0.30  1.57  0.35  0.70 

105  Tunisia  0.569  0.654  0.717  0.728  0.733  0.728  0.745  0.746  –4  1.40  0.92  0.31  0.82 

106  South Africa  0.633  0.618  0.669  0.722  0.724  0.721  0.737  0.741  –1  –0.24  0.80  0.79  0.48 

107  Uzbekistan  ..  0.603  0.681  0.707  0.723  0.727  0.737  0.740  7 ..  1.22  0.64  .. 

108  Bolivia (Plurinational State of)  0.552  0.630  0.677  0.704  0.697  0.693  0.727  0.733  8 1.33  0.72  0.61  0.86 

108  Gabon  0.621  0.652  0.684  0.720  0.732  0.720  0.730  0.733  –1  0.49  0.48  0.53  0.50 

108  Marshall Islands  ..  ..  ..  0.691  0.722  0.723  0.732  0.733  11  ..  ..  ..  .. 

111  Botswana  0.590  0.594  0.652  0.690  0.718  0.700  0.729  0.731  9 0.07  0.94  0.88  0.65 

111  Fiji  0.629  0.668  0.697  0.715  0.718  0.705  0.726  0.731  –1  0.60  0.43  0.37  0.46 

113  Indonesia  0.531  0.600  0.670  0.701  0.710  0.707  0.726  0.728  4 1.23  1.11  0.64  0.96 

114  Suriname  ..  ..  0.707  0.718  0.714  0.697  0.719  0.722  –6  ..  ..  0.16  .. 

115  Belize  0.617  0.671  0.727  0.721  0.713  0.713  0.717  0.721  –9  0.84  0.80  –0.06  0.47 

115  Libya  0.690  0.727  0.755  0.728  0.688  0.729  0.741  0.721  –14  0.52  0.38  –0.35  0.13 

117  Jamaica  0.662  0.659  0.708  0.713  0.711  0.703  0.718  0.720  –6  –0.05  0.72  0.13  0.25 

117  Kyrgyzstan  0.649  0.627  0.668  0.695  0.700  0.704  0.717  0.720  1 –0.34  0.64  0.58  0.32 

117  Philippines  0.593  0.632  0.669  0.690  0.699  0.690  0.714  0.720  3 0.64  0.57  0.57  0.59 

120  Morocco  0.451  0.528  0.607  0.659  0.683  0.690  0.704  0.710  7 1.59  1.40  1.21  1.38 

121  Venezuela (Bolivarian Republic of)  0.658  0.703  0.764  0.768  0.699  0.696  0.706  0.709  –37  0.66  0.84  –0.57  0.23 

122  Samoa  ..  0.676  0.708  0.708  0.708  0.706  0.703  0.708  –9  ..  0.46  0.00  .. 

123  Nicaragua  0.515  0.593  0.651  0.679  0.676  0.682  0.701  0.706  0 1.42  0.94  0.63  0.96 

124  Nauru  ..  ..  0.616  0.660  0.684  0.692  0.700  0.703  2 ..  ..  1.02  .. 

Continued → 

TABLE 2 

2 8 4 HUMAN DEVELOPMENT REPORT 2025 TABLE 2               

> HDI RANK
> Human Development Index (HDI)
> Change in
> HDI rank Average annual HDI growth
> Value (%)
> 1990 2000 2010 2015 2020 2021 2022 2023 2015–2023 a1990–2000 2000–2010 2010–2023 1990–2023

Medium human development 

125  Bhutan  ..  ..  0.593  0.637  0.688  0.691  0.695  0.698  9 ..  ..  1.26  .. 

126  Eswatini (Kingdom of)  0.570  0.493  0.534  0.607  0.657  0.658  0.695  0.695  16  –1.44  0.80  2.05  0.60 

126  Iraq  0.531  0.592  0.650  0.675  0.680  0.687  0.695  0.695  –2  1.09  0.94  0.52  0.82 

128  Tajikistan  ..  0.554  0.639  0.658  0.664  0.672  0.687  0.691  0 ..  1.44  0.60  .. 

129  Tuvalu  0.566  0.610  0.636  0.658  0.681  0.681  0.686  0.689  –1  0.75  0.42  0.62  0.60 

130  Bangladesh  0.397  0.477  0.561  0.621  0.663  0.663  0.680  0.685  9 1.85  1.64  1.55  1.67 

130  India  0.446  0.501  0.590  0.633  0.652  0.647  0.676  0.685  5 1.17  1.65  1.16  1.31 

132  El Salvador  0.523  0.607  0.660  0.667  0.660  0.663  0.674  0.678  –7  1.50  0.84  0.21  0.79 

133  Equatorial Guinea  ..  0.508  0.612  0.656  0.668  0.671  0.677  0.674  –2  ..  1.88  0.75  .. 

133  Palestine, State of  ..  ..  0.691  0.712  0.718  0.718  0.733  0.674  –21  ..  ..  –0.19  .. 

135  Cabo Verde  ..  0.585  0.648  0.658  0.647  0.651  0.664  0.668  –7  ..  1.03  0.23  .. 

136  Namibia  0.597  0.561  0.591  0.630  0.647  0.631  0.649  0.665  0 –0.62  0.52  0.91  0.33 

137  Guatemala  0.499  0.563  0.623  0.638  0.645  0.639  0.655  0.662  –4  1.21  1.02  0.47  0.86 

138  Congo  0.573  0.545  0.609  0.643  0.643  0.643  0.644  0.649  –6  –0.50  1.12  0.49  0.38 

139  Honduras  0.516  0.558  0.596  0.610  0.625  0.628  0.643  0.645  1 0.79  0.66  0.61  0.68 

140  Kiribati  ..  ..  0.600  0.623  0.632  0.631  0.642  0.644  –2  ..  ..  0.55  .. 

141  Sao Tome and Principe  ..  ..  0.564  0.608  0.628  0.631  0.636  0.637  0 ..  ..  0.94  .. 

142  Timor-Leste  ..  0.507  0.645  0.628  0.650  0.644  0.633  0.634  –5  ..  2.44  –0.13  .. 

143  Ghana  0.432  0.487  0.558  0.588  0.614  0.618  0.625  0.628  4 1.21  1.37  0.91  1.14 

143  Kenya  0.485  0.500  0.552  0.583  0.600  0.608  0.626  0.628  5 0.31  0.99  1.00  0.79 

145  Nepal  0.404  0.471  0.551  0.575  0.599  0.596  0.605  0.622  5 1.55  1.58  0.94  1.32 

146  Vanuatu  ..  ..  0.582  0.599  0.617  0.615  0.621  0.621  0 ..  ..  0.50  .. 

147  Lao People's Democratic Republic  0.409  0.473  0.556  0.604  0.616  0.613  0.614  0.617  –4  1.46  1.63  0.80  1.25 

148  Angola  ..  0.391  0.528  0.603  0.610  0.609  0.615  0.616  –3  ..  3.05  1.19  .. 

149  Micronesia (Federated States of)  ..  0.596  0.603  0.604  0.609  0.611  0.614  0.615  –6  ..  0.12  0.15  .. 

150  Myanmar  0.347  0.415  0.515  0.566  0.609  0.605  0.606  0.609  3 1.81  2.18  1.30  1.72 

151  Cambodia  0.387  0.438  0.543  0.562  0.595  0.594  0.602  0.606  5 1.25  2.17  0.85  1.37 

152  Comoros  ..  0.461  0.534  0.565  0.592  0.594  0.602  0.603  2 ..  1.48  0.94  .. 

153  Zimbabwe  0.500  0.458  0.512  0.567  0.582  0.581  0.594  0.598  –1  –0.87  1.12  1.20  0.54 

154  Zambia  0.422  0.429  0.533  0.565  0.578  0.574  0.589  0.595  0 0.16  2.19  0.85  1.05 

155  Cameroon  0.448  0.439  0.529  0.575  0.579  0.574  0.581  0.588  –5  –0.20  1.88  0.82  0.83 

156  Solomon Islands  ..  0.547  0.564  0.576  0.579  0.577  0.583  0.584  –7  ..  0.31  0.27  .. 

157  Côte d'Ivoire  0.389  0.419  0.465  0.519  0.553  0.557  0.565  0.582  10  0.75  1.05  1.74  1.23 

157  Uganda  0.342  0.407  0.514  0.547  0.571  0.573  0.578  0.582  3 1.76  2.36  0.96  1.62 

159  Rwanda  ..  0.340  0.504  0.525  0.555  0.562  0.570  0.578  5 ..  4.01  1.06  .. 

160  Papua New Guinea  0.403  0.456  0.503  0.543  0.567  0.567  0.572  0.576  1 1.24  0.99  1.05  1.09 

161  Togo  0.412  0.448  0.483  0.523  0.554  0.560  0.567  0.571  4 0.84  0.76  1.30  0.99 

162  Syrian Arab Republic  0.572  0.594  0.669  0.549  0.570  0.571  0.571  0.564  –3  0.38  1.20  –1.30  –0.04 

163  Mauritania  0.396  0.468  0.525  0.551  0.554  0.553  0.562  0.563  –5  1.68  1.16  0.54  1.07 

164  Nigeria  0.379  0.435  0.502  0.530  0.547  0.554  0.557  0.560  –2  1.39  1.44  0.84  1.19 

165  Tanzania (United Republic of)  0.381  0.414  0.513  0.520  0.554  0.548  0.554  0.555  1 0.83  2.17  0.61  1.15 

166  Haiti  0.461  0.497  0.452  0.552  0.555  0.548  0.552  0.554  –9  0.75  –0.94  1.58  0.56 

167  Lesotho  0.483  0.462  0.478  0.517  0.537  0.532  0.547  0.550  1 –0.44  0.34  1.09  0.39 

Low human development 

168  Pakistan  0.396  0.436  0.500  0.527  0.536  0.537  0.544  0.544  –5  0.97  1.38  0.65  0.97 

169  Senegal  0.377  0.398  0.477  0.509  0.522  0.522  0.526  0.530  1 0.54  1.83  0.81  1.04 

170  Gambia  0.331  0.403  0.463  0.482  0.512  0.513  0.519  0.524  5 1.99  1.40  0.96  1.40 

171  Congo (Democratic Republic of the)  0.388  0.391  0.440  0.477  0.506  0.508  0.514  0.522  8 0.08  1.19  1.32  0.90 

172  Malawi  0.306  0.394  0.475  0.504  0.512  0.509  0.513  0.517  –1  2.56  1.89  0.65  1.60 

173  Benin  0.351  0.415  0.485  0.511  0.504  0.506  0.512  0.515  –4  1.69  1.57  0.46  1.17 

174  Guinea-Bissau  ..  ..  0.452  0.481  0.498  0.502  0.511  0.514  2 ..  ..  0.99  .. 

175  Djibouti  ..  0.337  0.421  0.469  0.499  0.501  0.510  0.513  6 ..  2.25  1.53  .. 

176  Sudan  ..  ..  0.479  0.498  0.513  0.512  0.516  0.511  –3  ..  ..  0.50  .. 

177  Liberia  ..  0.443  0.467  0.480  0.498  0.503  0.508  0.510  0 ..  0.53  0.68  .. 

178  Eritrea  ..  ..  0.465  0.480  0.495  0.496  0.499  0.503  –1  ..  ..  0.61  .. 

179  Guinea  0.282  0.359  0.430  0.465  0.488  0.490  0.498  0.500  3 2.44  1.82  1.17  1.75 

180  Ethiopia  ..  0.293  0.415  0.456  0.486  0.487  0.494  0.497  4 ..  3.54  1.40  .. 

181  Afghanistan  0.285  0.351  0.465  0.496  0.501  0.486  0.495  0.496  –7  2.10  2.85  0.50  1.69 

182  Mozambique  0.246  0.311  0.419  0.457  0.477  0.478  0.490  0.493  1 2.37  3.03  1.26  2.13 

183  Madagascar  ..  0.443  0.493  0.501  0.483  0.481  0.483  0.487  –11  ..  1.08  –0.09  .. 

184  Yemen  0.359  0.439  0.502  0.475  0.459  0.458  0.466  0.470  –4  2.03  1.35  –0.51  0.82 

185  Sierra Leone  0.313  0.318  0.410  0.432  0.454  0.458  0.463  0.467  0 0.16  2.57  1.01  1.22 

Continued → 

2 8 5 TABLE 2 / HUMAN DEVELOPMENT INDEX TRENDS, 1990–2023 HDI RANK               

> Human Development Index (HDI)
> Change in
> HDI rank Average annual HDI growth
> Value (%)
> 1990 2000 2010 2015 2020 2021 2022 2023 2015–2023 a1990–2000 2000–2010 2010–2023 1990–2023

186  Burkina Faso  ..  ..  0.377  0.419  0.453  0.454  0.457  0.459  1 ..  ..  1.53  .. 

187  Burundi  0.294  0.308  0.416  0.432  0.435  0.435  0.437  0.439  –2  0.47  3.05  0.41  1.22 

188  Mali  0.240  0.320  0.410  0.413  0.414  0.414  0.417  0.419  0 2.92  2.51  0.17  1.70 

188  Niger  0.215  0.266  0.339  0.374  0.404  0.413  0.414  0.419  3 2.15  2.45  1.64  2.04 

190  Chad  ..  0.303  0.375  0.396  0.408  0.408  0.414  0.416  –1  ..  2.15  0.80  .. 

191  Central African Republic  0.342  0.333  0.358  0.377  0.386  0.339  ..  0.414  –1  –0.27  0.73  1.12  0.58 

192  Somalia  ..  ..  ..  ..  ..  ..  0.385  0.404  ..  ..  ..  ..  .. 

193  South Sudan  ..  ..  0.420  0.317  0.398  0.393  0.388  0.388  0 ..  ..  –0.61  .. 

Other countries or territories 

Korea (Democratic People’s Rep. of)  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. 

Monaco  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. 

Human development groups 

Very high human development  0.797  0.838  0.879  0.898  0.901  0.903  0.908  0.914  — 0.50  0.48  0.30  0.42 

High human development  0.569  0.636  0.714  0.744  0.763  0.766  0.774  0.777  — 1.12  1.16  0.65  0.95 

Medium human development  0.439  0.491  0.573  0.611  0.631  0.629  0.649  0.656  — 1.13  1.56  1.05  1.22 

Low human development  0.346  0.393  0.467  0.491  0.507  0.507  0.512  0.515  — 1.28  1.74  0.76  1.21 

Developing countries  0.520  0.576  0.649  0.680  0.696  0.696  0.708  0.712  — 1.03  1.20  0.72  0.96 

Regions 

Arab States  0.550  0.615  0.670  0.693  0.707  0.710  0.716  0.719  — 1.12  0.86  0.54  0.82 

East Asia and the Pacific  0.514  0.604  0.699  0.735  0.764  0.768  0.773  0.775  — 1.63  1.47  0.80  1.25 

Europe and Central Asia  0.674  0.686  0.753  0.789  0.802  0.803  0.815  0.818  — 0.18  0.94  0.64  0.59 

Latin America and the Caribbean  0.648  0.697  0.747  0.767  0.764  0.762  0.778  0.783  — 0.73  0.70  0.36  0.58 

South Asia  0.454  0.508  0.590  0.627  0.645  0.641  0.665  0.672  — 1.13  1.51  1.01  1.20 

Sub-Saharan Africa  0.405  0.435  0.510  0.540  0.557  0.558  0.565  0.568  — 0.72  1.60  0.83  1.03 

Least developed countries  0.360  0.411  0.494  0.526  0.550  0.549  0.555  0.560  — 1.33  1.86  0.97  1.35 

Small island developing states  0.617  b 0.660  0.702  0.727  0.731  0.727  0.737  0.739  — 0.68  0.62  0.40  0.55 

Organisation for Economic Co -operation 

and Development  0.801  0.846  0.883  0.899  0.903  0.904  0.910  0.916  — 0.55  0.43  0.28  0.41 

World  0.608  0.651  0.707  0.731  0.742  0.742  0.752  0.756  — 0.69  0.83  0.52  0.66 

TABLE 2                   

> Notes
> For HDI values that are comparable across years and countries,
> use this table or the interpolated data at https://hdr.undp.org/
> en/data , which present trends using consistent data.
> aA positive value indicates an improvement in rank.
> bValue reported with relaxed aggregation rule. For details,
> see Reader’s guide .
> Definitions
> Human Development Index (HDI): Acomposite index
> measuring average achievement in three basic dimensions of
> human development—a long and healthy life, knowledge and
> a decent standard of living. See Technical note 1 at https://hdr.
> undp.org/sites/default/files/2025_HDR/hdr2025_technical_
> notes.pdf for details on how the HDI is calculated.
> Average annual HDI growth: A smoothed annualized growth of
> the HDI in a given period, calculated as the annual compound
> growth rate.
> Main data sources
> Columns 1–8: HDRO calculations based on data from Barro
> and Lee (2018), IMF (2024), UNDESA (2024a), UNESCO In -
> stitute for Statistics (2024), United Nations Statistics Division
> (2025) and World Bank (2024a).
> Column 9: Calculated based on data in columns 4 and 8.
> Columns 10–13: Calculated based on data in columns 1, 2, 3
> and 8.

2 8 6 HUMAN DEVELOPMENT REPORT 2025 HDI RANK 

SDG 10.1 

Human 

Development 

Index (HDI)  Inequality-adjusted HDI (IHDI) 

Coefficient 

of human 

inequality 

Inequality 

in life 

expectancy 

Inequality-

adjusted 

life 

expectancy 

index 

Inequality 

in 

education a

Inequality-

adjusted 

education 

index 

Inequality 

in income 

Inequality-

adjusted 

income 

index  Income shares held by 

Gini 

coefficient 

Value  Value 

Overall 

loss 

(%) 

Difference 

from HDI 

rank b (%)  Value  (%)  Value  (%)  Value 

(%) 

Poorest 

40  percent 

Richest 

10  percent 

Richest 

1 percent 

2023  2023  2023  2023  2023  2023 c 2023  2023 d 2023  2022 e 2022  2010–2023 f 2010–2023 f 2023  2010–2023 f

Very high human development 

1 Iceland  0.972  0.923  5.0  0 5.0  2.0  0.945  2.3  0.942  10.7  0.882  23.9  22.0  8.0  26.1 

2 Norway  0.970  0.909  6.3  0 6.2  2.4  0.950  1.8  0.921  14.3  0.857  22.9  22.4  9.3  27.7 

2 Switzerland  0.970  0.894  7.8  –2  7.5  3.1  0.953  1.8  0.912  17.7  0.823  19.7  26.4  9.8  33.7 

4 Denmark  0.962  0.909  5.5  2 5.5  3.1  0.924  2.3  0.913  11.0  0.890  23.1  23.8  12.0  28.3 

5 Germany  0.959  0.890  7.2  –3  7.1  3.2  0.914  3.7  0.922  14.3  0.836  20.6  25.0  12.8  32.4 

5 Sweden  0.959  0.886  7.6  –4  7.4  2.6  0.948  2.6  0.901  16.9  0.815  21.5  22.7  10.9  29.8 

7 Australia  0.958  0.873  8.9  –5  8.6  3.0  0.954  4.3  0.889  18.5  0.784  19.6  26.2  9.9  34.3 

8 Hong Kong, China (SAR)  0.955  0.839  12.1  –16  11.7  2.3  0.977  8.7  0.805  24.1  0.750  ..  ..  17.9  .. 

8 Netherlands  0.955  0.892  6.6  3 6.4  3.3  0.925  4.7  0.879  11.4  0.874  24.0  21.4  6.8  25.7 

10  Belgium  0.951  0.891  6.3  4 6.3  3.5  0.922  4.0  0.886  11.3  0.865  23.6  21.9  8.5  26.6 

11  Ireland  0.949  0.886  6.6  2 6.5  3.1  0.930  2.6  0.868  14.0  0.860  22.0  24.8  13.6  30.1 

12  Finland  0.948  0.891  6.0  6 5.9  2.9  0.925  2.0  0.914  12.8  0.836  23.2  22.9  11.1  27.7 

13  Singapore  0.946  0.823  13.0  –19  12.4  2.6  0.955  8.7  0.790  25.9  0.741  ..  ..  14.2  .. 

13  United Kingdom  0.946  0.869  8.1  0 7.9  3.9  0.907  3.2  0.915  16.7  0.792  20.2  24.6  13.1  32.4 

15  United Arab Emirates  0.940  0.866  7.9  –1  7.9  3.9  0.930  9.3  0.786  10.4  0.889  23.0  20.5  16.1  26.4 

16  Canada  0.939  0.867  7.7  2 7.5  4.3  0.923  2.2  0.884  16.0  0.800  20.5  24.0  11.6  31.7 

17  Liechtenstein  0.938  ..  ..  ..  ..  4.9  0.931  ..  ..  ..  ..  ..  ..  11.5  .. 

17  New Zealand  0.938  0.853  9.1  –2  8.8  4.4  0.913  4.1  0.892  18.1  0.762  ..  ..  12.1  .. 

17  United States  0.938  0.832  11.3  –12  10.7  5.5  0.862  2.7  0.882  23.9  0.759  15.6  30.2  20.7  41.3 

20  Korea (Republic of)  0.937  0.857  8.5  1 8.4  2.5  0.965  6.2  0.831  16.4  0.784  19.9  24.6  15.1  32.9 

21  Slovenia  0.931  0.885  4.9  9 4.9  2.6  0.923  2.0  0.899  10.0  0.834  24.9  20.6  8.0  24.3 

22  Austria  0.930  0.861  7.4  4 7.1  3.2  0.923  2.6  0.842  15.6  0.823  21.0  23.8  11.5  30.7 

23  Japan  0.925  0.845  8.6  2 8.5  2.5  0.970  5.8  0.805  17.1  0.772  20.8  26.1  12.7  32.9 

24  Malta  0.924  0.843  8.8  2 8.6  5.2  0.923  5.2  0.812  15.5  0.799  21.0  25.1  9.0  31.4 

25  Luxembourg  0.922  0.838  9.1  –1  8.9  4.8  0.911  5.4  0.774  16.4  0.836  19.5  24.5  13.1  32.7 

26  France  0.920  0.836  9.1  –2  9.0  3.7  0.938  5.3  0.795  17.9  0.783  20.8  24.9  12.1  31.5 

27  Israel  0.919  0.813  11.5  –11  11.0  3.6  0.926  5.3  0.820  24.0  0.709  16.6  26.6  16.8  37.9 

28  Spain  0.918  0.819  10.8  –6  10.5  2.8  0.952  9.6  0.772  19.2  0.749  18.7  24.7  12.1  33.9 

29  Czechia  0.915  0.867  5.2  14  5.1  3.0  0.893  1.2  0.888  11.1  0.823  24.1  22.2  9.7  26.2 

29  Italy  0.915  0.817  10.7  –7  10.3  2.6  0.955  7.5  0.763  20.8  0.749  18.6  26.2  12.3  34.8 

29  San Marino  0.915  ..  ..  ..  ..  1.8  0.982  4.1  0.752  ..  ..  ..  ..  11.5  .. 

32  Andorra  0.913  0.837  8.3  4 8.2  4.7  0.939  5.6  0.747  14.4  0.837  ..  ..  11.5  .. 

32  Cyprus  0.913  0.841  7.9  8 7.7  2.9  0.921  5.4  0.822  14.8  0.787  21.4  25.7  8.4  31.3 

34  Greece  0.908  0.825  9.1  1 8.9  3.3  0.921  6.7  0.826  16.8  0.739  19.6  24.8  14.3  32.9 

35  Poland  0.906  0.817  9.8  –2  9.5  3.9  0.867  4.8  0.861  19.8  0.732  22.4  22.8  15.2  28.5 

36  Estonia  0.905  0.841  7.1  12  6.8  3.0  0.883  1.6  0.881  15.7  0.766  20.4  24.3  12.8  31.8 

37  Saudi Arabia  0.900  ..  ..  ..  ..  5.1  0.857  12.8  0.748  ..  ..  ..  ..  25.2  .. 

38  Bahrain  0.899  ..  ..  ..  ..  4.7  0.898  13.2  0.706  ..  ..  ..  ..  25.5  .. 

39  Lithuania  0.895  0.812  9.3  –3  8.8  4.1  0.826  2.0  0.893  20.4  0.726  18.7  29.1  9.6  36.7 

40  Portugal  0.890  0.795  10.7  –4  10.4  3.1  0.929  9.8  0.730  18.4  0.742  19.6  27.5  9.7  34.6 

41  Croatia  0.889  0.828  6.9  7 6.7  3.6  0.869  3.0  0.832  13.5  0.787  21.8  22.3  9.0  28.9 

41  Latvia  0.889  0.812  8.7  –1  8.3  4.2  0.828  1.7  0.889  19.0  0.727  19.2  26.2  10.7  34.3 

43  Qatar  0.886  ..  ..  ..  ..  3.7  0.924  10.1  0.651  ..  ..  18.1  25.8  24.3  35.1 

44  Slovakia  0.880  0.833  5.3  11  5.3  4.6  0.857  1.5  0.839  10.0  0.803  24.3  19.1  9.2  24.1 

45  Chile  0.878  0.723  17.7  –16  16.1  4.6  0.898  6.0  0.795  37.7  0.530  15.8  34.5  22.0  43.0 

46  Hungary  0.870  0.819  5.9  8 5.9  3.7  0.845  2.5  0.819  11.3  0.793  22.2  24.1  9.8  29.2 

47  Argentina  0.865  0.761  12.0  –3  11.6  7.4  0.818  4.9  0.830  22.6  0.650  15.5  29.8  12.4  40.7 

48  Montenegro  0.862  0.771  10.6  1 10.4  3.3  0.849  7.8  0.790  19.9  0.682  18.3  24.7  9.9  34.3 

48  Uruguay  0.862  0.747  13.3  –10  12.9  5.9  0.842  7.6  0.773  25.1  0.640  15.9  30.5  14.8  40.6 

50  Oman  0.858  0.750  12.6  –6  12.3  6.6  0.862  6.5  0.720  23.7  0.679  ..  ..  19.9  .. 

51  Türkiye  0.853  0.708  17.0  –14  16.5  8.1  0.808  12.4  0.700  28.9  0.628  14.7  34.7  24.4  44.4 

52  Kuwait  0.852  ..  ..  ..  ..  5.8  0.876  22.1  0.541  ..  ..  ..  ..  17.6  .. 

53  Antigua and Barbuda  0.851  ..  ..  ..  ..  6.8  0.826  9.9  0.738  ..  ..  ..  ..  21.2  .. 

54  Seychelles  0.848  0.755  11.0  –2  10.8  9.3  0.738  6.7  0.815  16.6  0.715  19.7  23.9  20.5  32.1 

55  Bulgaria  0.845  0.748  11.5  –4  11.0  4.9  0.814  4.3  0.772  23.7  0.665  17.1  29.9  16.9  39.0 

55  Romania  0.845  0.758  10.3  2 9.8  4.9  0.818  3.7  0.746  20.9  0.714  18.4  24.0  13.4  33.9 

57  Georgia  0.844  0.754  10.7  0 10.3  6.9  0.781  2.4  0.867  21.4  0.633  19.3  25.2  18.5  33.5 

Continued → 

TABLE 3 

# Inequality ‑adjusted Human Development Index 

2 8 7 TABLE 3 / INEQUALITY-ADJUSTED HUMAN DEVELOPMENT INDEX HDI RANK                           

> SDG 10.1
> Human
> Development
> Index (HDI) Inequality-adjusted HDI (IHDI)
> Coefficient
> of human
> inequality
> Inequality
> in life
> expectancy
> Inequality-
> adjusted
> life
> expectancy
> index
> Inequality
> in
> education a
> Inequality-
> adjusted
> education
> index
> Inequality
> in income
> Inequality-
> adjusted
> income
> index Income shares held by
> Gini
> coefficient
> Value Value
> Overall
> loss
> (%)
> Difference
> from HDI
> rank b(%) Value (%) Value (%) Value
> (%)
> Poorest
> 40 percent
> Richest
> 10 percent
> Richest
> 1percent
> 2023 2023 2023 2023 2023 2023 c2023 2023 d2023 2022 e2022 2010–2023 f2010–2023 f2023 2010–2023 f

58  Saint Kitts and Nevis  0.840  ..  ..  ..  ..  9.9  0.723  ..  ..  ..  ..  ..  ..  21.2  .. 

59  Panama  0.839  0.664  20.9  –19  19.6  10.1  0.825  9.9  0.659  38.9  0.539  12.1  36.9  17.9  48.9 

60  Brunei Darussalam  0.837  0.756  9.7  4 9.7  6.9  0.792  10.1  0.620  12.1  0.879  ..  ..  13.1  .. 

60  Kazakhstan  0.837  0.766  8.5  8 8.3  7.2  0.777  3.2  0.782  14.7  0.739  22.9  24.8  14.9  29.2 

62  Costa Rica  0.833  0.678  18.6  –11  17.5  6.0  0.879  11.0  0.667  35.6  0.531  13.2  35.1  18.2  46.7 

62  Serbia  0.833  0.772  7.3  13  7.3  4.2  0.836  4.1  0.773  13.5  0.712  20.0  25.9  12.5  33.1 

64  Russian Federation  0.832  0.758  8.9  10  8.6  5.7  0.771  1.5  0.768  18.7  0.734  18.7  26.6  23.8  35.1 

65  Belarus  0.824  0.771  6.4  15  6.3  3.5  0.808  2.8  0.770  12.7  0.737  24.8  20.7  9.6  24.4 

66  Bahamas  0.820  0.670  18.3  –9  16.8  9.5  0.760  3.4  0.732  37.6  0.541  ..  ..  17.9  .. 

67  Malaysia  0.819  0.707  13.7  –2  13.3  6.1  0.819  9.0  0.657  24.8  0.658  16.1  30.9  14.9  40.7 

68  North Macedonia  0.815  0.723  11.3  4 11.0  4.3  0.845  8.4  0.689  20.5  0.649  18.1  22.9  6.9  33.5 

69  Armenia  0.811  0.743  8.4  7 8.3  6.7  0.799  2.9  0.755  15.1  0.681  22.8  23.0  15.0  27.9 

69  Barbados  0.811  0.620  23.6  –22  20.6  7.2  0.802  5.5  0.749  49.0  0.397  ..  ..  21.2  .. 

71  Albania  0.810  0.705  13.0  1 12.8  6.4  0.859  12.3  0.651  19.7  0.627  21.6  22.8  8.9  29.4 

72  Trinidad and Tobago  0.807  ..  ..  ..  ..  10.7  0.735  5.9  0.711  ..  ..  ..  ..  17.9  .. 

73  Mauritius  0.806  0.669  17.0  –5  16.2  9.8  0.762  7.4  0.676  31.4  0.581  18.8  29.9  15.9  36.8 

74  Bosnia and Herzegovina  0.804  0.689  14.3  2 13.8  4.7  0.848  10.1  0.657  26.5  0.587  19.8  25.1  9.3  33.0 

High human development 

75  Iran (Islamic Republic of)  0.799  0.643  19.5  –8  19.1  7.9  0.817  21.9  0.586  27.5  0.556  19.1  26.8  18.3  34.8 

76  Saint Vincent and the Grenadines  0.798  ..  ..  ..  ..  10.3  0.707  6.1  0.778  ..  ..  ..  ..  21.2  .. 

76  Thailand  0.798  0.677  15.2  1 15.0  7.3  0.804  16.0  0.612  21.7  0.630  19.1  27.1  19.8  34.9 

78  China  0.797  0.670  15.9  1 15.2  5.1  0.846  10.3  0.626  30.3  0.568  18.8  28.2  15.8  35.7 

79  Peru  0.794  0.633  20.3  –10  19.9  9.7  0.802  19.3  0.608  30.6  0.520  16.2  30.7  26.9  40.3 

80  Grenada  0.791  ..  ..  ..  ..  10.1  0.763  7.0  0.721  ..  ..  15.2  33.7  21.2  43.8 

81  Azerbaijan  0.789  0.735  6.8  15  6.8  10.4  0.750  4.3  0.696  5.7  0.759  ..  ..  14.0  .. 

81  Mexico  0.789  0.646  18.1  –3  17.8  9.0  0.771  16.0  0.600  28.4  0.582  15.4  34.4  21.6  43.5 

83  Colombia  0.788  0.593  24.7  –24  23.1  8.3  0.815  17.0  0.579  44.0  0.442  10.3  43.5  17.9  54.8 

84  Brazil  0.786  0.594  24.4  –21  22.8  9.5  0.777  15.1  0.611  43.7  0.441  11.3  41.0  21.1  52.0 

84  Palau  0.786  0.616  21.6  –11  20.1  13.6  0.655  5.8  0.786  40.9  0.453  ..  ..  16.1  .. 

86  Moldova (Republic of)  0.785  0.719  8.4  17  8.3  9.1  0.716  2.2  0.783  13.6  0.662  24.3  22.1  10.4  25.7 

87  Ukraine  0.779  0.715  8.2  17  8.1  7.3  0.762  3.6  0.714  13.3  0.672  24.3  21.7  9.3  25.6 

88  Ecuador  0.777  0.640  17.6  1 17.0  8.4  0.809  12.1  0.625  30.6  0.518  14.0  33.2  14.0  44.6 

89  Dominican Republic  0.776  0.634  18.3  0 18.2  17.0  0.686  14.6  0.592  22.9  0.628  17.9  28.3  15.2  37.0 

89  Guyana  0.776  ..  ..  ..  ..  14.9  0.657  10.4  0.584  ..  ..  ..  ..  17.9  .. 

89  Sri Lanka  0.776  0.630  18.8  –2  17.5  4.7  0.842  11.3  0.642  36.6  0.463  18.5  30.8  20.5  37.7 

92  Tonga  0.769  0.682  11.3  16  11.0  7.9  0.749  4.3  0.821  20.7  0.516  23.1  22.0  16.1  27.1 

93  Maldives  0.766  0.602  21.4  –7  20.5  3.7  0.904  29.3  0.425  28.6  0.568  22.1  23.3  13.1  29.3 

93  Viet Nam  0.766  0.641  16.3  6 16.3  12.7  0.733  15.3  0.618  21.1  0.581  18.6  28.1  15.7  36.1 

95  Turkmenistan  0.764  ..  ..  ..  ..  19.3  0.622  2.9  0.720  ..  ..  ..  ..  19.5  .. 

96  Algeria  0.763  0.601  21.2  –6  20.7  11.9  0.763  33.3  0.452  16.8  0.631  23.1  22.9  23.3  27.6 

97  Cuba  0.762  ..  ..  ..  ..  4.8  0.851  9.1  0.673  ..  ..  ..  ..  13.7  .. 

98  Dominica  0.761  ..  ..  ..  ..  17.3  0.651  16.2  0.612  ..  ..  ..  ..  21.2  .. 

99  Paraguay  0.756  0.599  20.8  –6  20.0  10.6  0.740  14.7  0.585  34.6  0.497  14.5  35.4  17.9  45.1 

100  Egypt  0.754  0.582  22.8  –13  22.0  10.4  0.711  36.9  0.443  18.7  0.625  21.8  27.5  19.1  31.9 

100  Jordan  0.754  0.637  15.5  8 15.3  8.8  0.811  13.0  0.614  24.1  0.519  20.3  27.4  20.4  33.7 

102  Lebanon  0.752  ..  ..  ..  ..  10.9  0.792  ..  ..  20.2  0.570  20.6  24.7  21.3  31.8 

103  Saint Lucia  0.748  0.523  30.1  –20  29.1  10.6  0.725  37.4  0.401  39.2  0.491  15.1  34.1  21.2  43.7 

104  Mongolia  0.747  0.647  13.4  16  13.3  8.8  0.726  11.9  0.610  19.2  0.610  20.8  24.6  16.1  31.4 

105  Tunisia  0.746  0.595  20.2  –4  19.7  7.2  0.807  29.1  0.469  22.9  0.558  20.0  27.0  22.6  33.7 

106  South Africa  0.741  0.476  35.8  –29  32.4  19.8  0.569  17.3  0.637  59.9  0.298  7.2  50.5  19.4  63.0 

107  Uzbekistan  0.740  ..  ..  ..  ..  8.9  0.735  1.8  0.730  ..  ..  20.4  23.2  16.7  31.2 

108  Bolivia (Plurinational State of)  0.733  0.578  21.1  –8  21.0  21.0  0.590  15.0  0.652  26.9  0.502  15.7  30.3  17.9  40.9 

108  Gabon  0.733  0.558  23.9  –10  23.7  19.0  0.602  20.6  0.531  31.4  0.543  16.8  27.7  11.0  38.0 

108  Marshall Islands  0.733  0.626  14.6  10  14.3  16.4  0.604  4.0  0.809  22.5  0.501  18.9  27.5  16.1  35.5 

111  Botswana  0.731  0.509  30.4  –16  29.3  19.2  0.611  23.3  0.511  45.5  0.423  10.9  41.5  22.7  53.3 

111  Fiji  0.731  0.626  14.4  13  14.2  15.5  0.615  8.6  0.667  18.5  0.598  21.3  24.2  16.1  30.7 

113  Indonesia  0.728  0.608  16.5  10  16.4  12.5  0.688  12.9  0.575  23.6  0.568  19.5  29.9  17.9  36.1 

114  Suriname  0.722  ..  ..  ..  ..  10.8  0.736  18.4  0.478  ..  ..  17.0  30.1  17.9  39.2 

TABLE 3 

Continued → 

2 8 8 HUMAN DEVELOPMENT REPORT 2025 HDI RANK                           

> SDG 10.1
> Human
> Development
> Index (HDI) Inequality-adjusted HDI (IHDI)
> Coefficient
> of human
> inequality
> Inequality
> in life
> expectancy
> Inequality-
> adjusted
> life
> expectancy
> index
> Inequality
> in
> education a
> Inequality-
> adjusted
> education
> index
> Inequality
> in income
> Inequality-
> adjusted
> income
> index Income shares held by
> Gini
> coefficient
> Value Value
> Overall
> loss
> (%)
> Difference
> from HDI
> rank b(%) Value (%) Value (%) Value
> (%)
> Poorest
> 40 percent
> Richest
> 10 percent
> Richest
> 1percent
> 2023 2023 2023 2023 2023 2023 c2023 2023 d2023 2022 e2022 2010–2023 f2010–2023 f2023 2010–2023 f

115  Belize  0.721  ..  ..  ..  ..  7.3  0.764  14.8  0.532  ..  ..  ..  ..  17.9  .. 

115  Libya  0.721  ..  ..  ..  ..  16.8  0.631  ..  ..  ..  ..  ..  ..  16.8  .. 

117  Jamaica  0.720  0.590  18.1  0 17.0  11.6  0.700  5.8  0.637  33.7  0.462  16.0  29.9  17.9  40.2 

117  Kyrgyzstan  0.720  0.649  9.9  26  9.7  10.3  0.713  3.4  0.730  15.3  0.525  23.8  22.0  18.1  26.4 

117  Philippines  0.720  0.597  17.1  5 16.8  15.0  0.652  12.0  0.606  23.6  0.540  16.9  32.5  16.6  40.7 

120  Morocco  0.710  0.517  27.2  –9  26.1  10.6  0.761  41.9  0.364  25.9  0.499  17.4  31.9  13.4  39.5 

121  Venezuela (Bolivarian Republic of)  0.709  0.605  14.7  14  14.5  12.6  0.706  9.7  0.616  21.1  0.509  ..  ..  17.9  .. 

122  Samoa  0.708  0.609  14.0  17  13.7  10.3  0.713  7.0  0.672  23.7  0.471  17.8  31.3  16.1  38.7 

123  Nicaragua  0.706  0.535  24.2  –1  23.5  9.4  0.766  25.8  0.483  35.3  0.414  14.3  37.2  17.9  46.2 

124  Nauru  0.703  0.599  14.8  14  14.7  16.8  0.539  8.7  0.613  18.5  0.650  20.5  25.3  16.1  32.4 

Medium human development 

125  Bhutan  0.698  0.478  31.5  –10  30.0  13.1  0.708  48.2  0.290  28.6  0.532  22.3  22.7  14.0  28.5 

126  Eswatini (Kingdom of)  0.695  0.431  38.0  –21  35.1  23.7  0.518  21.0  0.564  60.5  0.274  10.5  42.7  19.3  54.6 

126  Iraq  0.695  0.534  23.2  0 22.8  13.3  0.698  29.7  0.400  25.5  0.545  21.9  23.7  15.7  29.5 

128  Tajikistan  0.691  0.594  14.0  14  13.9  15.7  0.671  6.0  0.636  19.9  0.490  19.4  26.4  14.5  34.0 

129  Tuvalu  0.689  0.578  16.1  10  15.8  13.1  0.630  9.2  0.638  25.1  0.480  17.4  30.8  16.1  39.1 

130  Bangladesh  0.685  0.482  29.6  –3  29.0  15.8  0.709  35.3  0.368  35.9  0.430  20.4  27.4  16.2  33.4 

130  India  0.685  0.475  30.7  –10  29.9  15.5  0.676  36.9  0.372  37.4  0.426  20.2  25.5  23.1  32.8 

132  El Salvador  0.678  0.555  18.1  10  17.8  8.9  0.730  21.3  0.435  23.3  0.540  16.6  28.7  12.8  38.8 

133  Equatorial Guinea  0.674  ..  ..  ..  ..  28.9  0.478  ..  ..  ..  ..  ..  ..  18.9  .. 

133  Palestine, State of  0.674  0.538  20.2  10  19.7  18.2  0.569  9.5  0.632  31.4  0.433  19.2  25.2  18.2  33.7 

135  Cabo Verde  0.668  0.478  28.4  –1  26.8  7.6  0.797  27.4  0.377  45.4  0.363  15.4  32.3  13.9  42.4 

136  Namibia  0.665  0.438  34.1  –10  32.4  19.2  0.589  25.0  0.427  53.0  0.333  8.6  47.2  21.6  59.1 

137  Guatemala  0.662  0.479  27.6  2 26.9  13.0  0.704  35.0  0.320  32.8  0.490  13.1  38.0  17.9  48.3 

138  Congo  0.649  0.426  34.4  –11  32.0  20.1  0.563  20.9  0.498  55.1  0.276  12.4  37.9  20.5  48.9 

139  Honduras  0.645  0.496  23.1  7 22.4  9.9  0.733  21.6  0.418  35.6  0.400  11.6  34.6  17.9  48.2 

140  Kiribati  0.644  0.535  16.9  15  16.6  24.7  0.538  9.6  0.573  15.5  0.498  23.0  22.8  16.1  27.8 

141  Sao Tome and Principe  0.637  0.478  25.0  5 23.6  9.9  0.689  18.7  0.453  42.4  0.350  16.8  32.8  16.0  40.7 

142  Timor-Leste  0.634  0.451  28.9  –2  27.7  22.2  0.571  44.9  0.317  16.1  0.507  22.8  24.0  15.2  28.7 

143  Ghana  0.628  0.399  36.5  –10  35.4  22.1  0.545  33.0  0.371  51.0  0.313  14.3  32.2  15.2  43.5 

143  Kenya  0.628  0.456  27.4  0 26.7  20.9  0.531  19.7  0.487  39.6  0.367  18.2  31.8  15.9  38.7 

145  Nepal  0.622  0.437  29.7  –2  28.9  15.0  0.659  39.8  0.320  31.9  0.397  21.8  24.2  13.7  30.0 

146  Vanuatu  0.621  0.521  16.1  17  16.0  11.1  0.704  17.9  0.466  19.1  0.431  20.0  24.7  16.1  32.3 

147  Lao People's Democratic Republic  0.617  0.462  25.1  5 24.9  19.7  0.605  31.3  0.322  23.6  0.507  17.8  31.2  19.7  38.8 

148  Angola  0.616  0.360  41.6  –15  39.9  27.4  0.498  34.2  0.353  58.1  0.266  11.5  39.6  26.0  51.3 

149  Micronesia (Federated States of)  0.615  ..  ..  ..  ..  14.4  0.622  ..  ..  25.8  0.420  16.2  29.7  16.1  40.1 

150  Myanmar  0.609  0.477  21.7  10  21.6  20.5  0.574  26.9  0.389  17.6  0.485  21.9  25.5  16.7  30.7 

151  Cambodia  0.606  0.444  26.7  5 26.3  14.9  0.663  28.1  0.348  35.8  0.378  ..  ..  18.1  .. 

152  Comoros  0.603  0.356  41.0  –14  39.7  22.2  0.560  44.4  0.317  52.4  0.255  13.6  33.6  14.2  45.3 

153  Zimbabwe  0.598  0.406  32.1  1 29.9  22.3  0.511  14.6  0.517  52.9  0.253  15.1  34.8  17.5  50.3 

154  Zambia  0.595  0.361  39.3  –8  35.7  23.4  0.546  20.4  0.440  63.4  0.196  11.2  39.1  18.0  51.5 

155  Cameroon  0.588  0.361  38.6  –7  37.5  27.9  0.484  31.7  0.354  52.9  0.275  15.0  31.1  13.3  42.2 

156  Solomon Islands  0.584  0.483  17.3  22  17.2  11.8  0.686  17.4  0.422  22.5  0.389  18.4  29.2  16.1  37.1 

157  Côte d'Ivoire  0.582  0.350  39.9  –10  39.4  28.5  0.461  46.1  0.258  43.4  0.360  19.2  27.8  21.0  35.3 

157  Uganda  0.582  0.400  31.3  4 30.6  20.1  0.593  27.9  0.384  43.6  0.282  16.1  34.5  21.4  42.7 

159  Rwanda  0.578  0.399  31.0  5 30.2  18.9  0.596  27.4  0.372  44.3  0.285  15.8  35.6  19.9  43.7 

160  Papua New Guinea  0.576  0.423  26.6  9 26.5  20.2  0.566  32.1  0.329  27.2  0.405  ..  ..  16.4  .. 

161  Togo  0.571  0.363  36.4  0 36.1  26.5  0.483  37.7  0.348  44.1  0.283  17.8  29.6  14.1  37.9 

162  Syrian Arab Republic  0.564  ..  ..  ..  ..  13.3  0.695  ..  ..  ..  ..  23.2  21.1  21.6  26.6 

163  Mauritania  0.563  0.374  33.6  4 32.8  19.3  0.602  44.0  0.214  35.0  0.406  20.3  24.6  10.0  32.0 

164  Nigeria  0.560  0.379  32.3  6 31.7  38.6  0.325  37.8  0.339  18.6  0.494  18.7  26.7  11.6  35.1 

165  Tanzania (United Republic of)  0.555  0.391  29.5  8 29.1  19.9  0.579  26.2  0.325  41.1  0.317  17.4  33.1  18.1  40.5 

166  Haiti  0.554  0.337  39.2  –6  38.2  25.3  0.516  37.3  0.302  52.1  0.245  15.8  31.2  17.9  41.1 

167  Lesotho  0.550  0.357  35.1  1 33.7  30.0  0.403  19.6  0.453  51.4  0.250  13.5  32.9  14.5  44.9 

Low human development 

168  Pakistan  0.544  0.364  33.1  7 32.6  26.0  0.542  43.5  0.205  28.2  0.435  22.7  25.5  16.7  29.6 

169  Senegal  0.530  0.340  35.8  –2  34.8  18.0  0.614  47.0  0.186  39.3  0.343  18.8  28.8  13.0  36.2 

170  Gambia  0.524  0.329  37.2  –4  36.4  22.2  0.549  47.0  0.215  40.1  0.302  17.5  30.5  15.9  38.8 

TABLE 3 

Continued → 

2 8 9 TABLE 3 / INEQUALITY-ADJUSTED HUMAN DEVELOPMENT INDEX TABLE 3                           

> HDI RANK
> SDG 10.1
> Human
> Development
> Index (HDI) Inequality-adjusted HDI (IHDI)
> Coefficient
> of human
> inequality
> Inequality
> in life
> expectancy
> Inequality-
> adjusted
> life
> expectancy
> index
> Inequality
> in
> education a
> Inequality-
> adjusted
> education
> index
> Inequality
> in income
> Inequality-
> adjusted
> income
> index Income shares held by
> Gini
> coefficient
> Value Value
> Overall
> loss
> (%)
> Difference
> from HDI
> rank b(%) Value (%) Value (%) Value
> (%)
> Poorest
> 40 percent
> Richest
> 10 percent
> Richest
> 1percent
> 2023 2023 2023 2023 2023 2023 c2023 2023 d2023 2022 e2022 2010–2023 f2010–2023 f2023 2010–2023 f

171  Congo (Democratic Republic of the)  0.522  0.341  34.7  2 34.1  30.8  0.446  26.8  0.402  44.8  0.222  15.1  35.7  19.4  44.7 

172  Malawi  0.517  0.365  29.4  12  29.0  19.8  0.584  28.0  0.324  39.3  0.256  18.0  31.0  15.2  38.5 

173  Benin  0.515  0.316  38.6  –8  38.5  32.1  0.426  44.0  0.222  39.3  0.334  19.5  27.2  12.8  34.4 

174  Guinea-Bissau  0.514  0.331  35.6  1 35.3  28.6  0.484  42.1  0.242  35.3  0.311  19.8  26.1  11.0  33.4 

175  Djibouti  0.513  0.341  33.5  6 32.9  24.2  0.536  45.8  0.165  28.7  0.447  15.8  32.3  15.9  41.6 

176  Sudan  0.511  0.328  35.8  1 35.3  24.1  0.541  42.5  0.214  39.3  0.306  19.9  27.8  15.4  34.2 

177  Liberia  0.510  0.326  36.1  1 35.9  29.2  0.459  42.1  0.287  36.4  0.262  18.8  27.1  12.2  35.3 

178  Eritrea  0.503  ..  ..  ..  ..  19.4  0.603  ..  ..  ..  ..  ..  ..  13.8  .. 

179  Guinea  0.500  0.302  39.6  –4  39.0  35.4  0.405  50.1  0.185  31.6  0.367  21.6  23.1  8.7  29.6 

180  Ethiopia  0.497  0.326  34.4  3 33.9  22.4  0.565  42.8  0.192  36.5  0.320  19.4  28.5  13.8  35.0 

181  Afghanistan  0.496  0.321  35.3  1 34.4  25.2  0.530  48.8  0.196  29.2  0.319  ..  ..  15.1  .. 

182  Mozambique  0.493  0.297  39.8  –2  38.7  27.3  0.488  34.3  0.298  54.4  0.180  12.9  41.1  24.8  50.3 

183  Madagascar  0.487  0.319  34.5  2 33.9  28.6  0.480  28.3  0.290  44.9  0.234  15.8  33.5  15.2  42.6 

184  Yemen  0.470  0.325  30.9  5 29.8  19.7  0.609  46.4  0.209  23.2  0.269  18.8  29.4  25.0  36.7 

185  Sierra Leone  0.467  0.281  39.8  –1  39.5  35.1  0.417  47.5  0.194  35.9  0.275  19.6  29.4  15.0  35.7 

186  Burkina Faso  0.459  0.273  40.5  –2  40.2  31.1  0.436  46.1  0.172  43.4  0.271  18.5  30.2  14.7  37.4 

187  Burundi  0.439  0.286  34.9  2 34.6  24.8  0.505  39.5  0.235  39.5  0.196  18.3  29.9  14.5  37.5 

188  Mali  0.419  0.281  32.9  2 32.5  34.0  0.410  40.6  0.148  23.0  0.367  19.1  28.3  12.1  35.7 

188  Niger  0.419  0.265  36.8  –1  36.7  37.7  0.395  35.0  0.181  37.4  0.262  21.1  27.8  14.1  32.9 

190  Chad  0.416  0.252  39.4  –1  39.5  37.4  0.338  42.9  0.177  38.2  0.267  17.9  29.5  12.8  37.4 

191  Central African Republic  0.414  0.253  38.9  1 38.5  35.0  0.374  35.2  0.220  45.5  0.198  15.3  33.1  15.6  43.0 

192  Somalia  0.404  0.229  43.3  0 43.1  37.2  0.375  44.6  0.150  47.4  0.214  ..  ..  16.2  .. 

193  South Sudan  0.388  0.226  41.8  0 41.7  36.7  0.367  39.6  0.210  48.9  0.149  14.5  33.0  15.4  44.1 

Other countries or territories 

..  Korea (Democratic People’s Rep. of)  ..  ..  ..  ..  ..  11.5  0.731  6.7  ..  ..  ..  ..  ..  14.8  .. 

..  Monaco  ..  ..  ..  ..  ..  3.7  0.963  2.2  ..  ..  ..  ..  ..  11.5  .. 

Human development groups 

Very high human development  0.914  0.821  10.2  — 9.9  4.6  0.881  5.0  0.829  20.1  0.757  18.6  27.2  16.5  —

High human development  0.777  0.640  17.6  — 17.2  8.3  0.786  13.9  0.599  29.3  0.557  17.9  30.3  17.3  —

Medium human development  0.656  0.457  30.3  — 29.9  18.8  0.616  34.8  0.368  36.1  0.421  19.4  27.1  20.2  —

Low human development  0.515  0.336  34.8  — 34.4  27.1  0.505  40.4  0.228  35.8  0.330  19.3  29.3  16.3  —

Developing countries  0.712  0.539  24.3  — 24.0  14.6  0.684  24.8  0.459  32.5  0.498  18.6  29.0  18.3  —

Regions 

Arab States  0.719  0.544  24.3  — 23.9  13.7  0.697  33.6  0.399  24.6  0.577  20.9  26.5  19.3  —

East Asia and the Pacific  0.775  0.649  16.3  — 15.8  7.8  0.793  11.8  0.600  27.9  0.575  18.8  28.6  16.2  —

Europe and Central Asia  0.818  0.719  12.1  — 11.9  8.4  0.772  6.6  0.736  20.6  0.653  19.4  27.5  17.3  —

Latin America and the Caribbean  0.783  0.619  20.9  — 20.1  9.8  0.772  15.3  0.606  35.3  0.508  13.4  36.7  19.6  —

South Asia  0.672  0.469  30.2  — 29.6  16.5  0.666  36.9  0.356  35.4  0.436  20.5  25.8  21.2  —

Sub-Saharan Africa  0.568  0.377  33.6  — 33.6  28.0  0.471  33.4  0.328  39.4  0.346  16.7  32.2  16.0  —

Least developed countries  0.560  0.374  33.2  — 32.8  23.9  0.545  35.9  0.289  38.6  0.333  18.1  30.7  16.9  —

Small island developing states  0.739  0.567  23.3  — 22.9  15.1  0.677  21.0  0.503  32.7  0.535  ..  ..  15.7  —

Organisation for Economic Co -operation 

and Development  0.916  0.812  11.4  — 11.0  4.8  0.887  6.4  0.815  21.8  0.740  18.0  28.5  16.4  —

World  0.756  0.590  22.0  — 21.6  12.9  0.715  21.5  0.514  30.4  0.559  18.7  28.6  17.9  —

2 9 0 HUMAN DEVELOPMENT REPORT 2025 TABLE 3 

Notes 

a See  https://hdr.undp.org/en/composite/IHDI  for the list 

of surveys used to estimate inequalities. 

b Based on countries for which an IHDI value is calculated. 

c Calculated by HDRO from period life tables from UNDESA 

(2024a). 

d Data refer to 2023 or the most recent year available. 

e Data refer to 2022 or the most recent year available. 

f Data refer to the most recent year available during the 

period specified. 

Definitions 

Human Development Index (HDI):  A composite index measur -

ing average achievement in three basic dimensions of human 

development—a long and healthy life, knowledge and a decent 

standard of living. See  Technical note 1  at  https://hdr.undp.org/ 

sites/default/files/2025_HDR/hdr2025_technical_notes.pdf  for 

details on how the HDI is calculated. 

Inequality ‑adjusted HDI (IHDI):  HDI value adjusted for inequal -

ities in the three basic dimensions of human development. 

See  Technical note 2 at  https://hdr.undp.org/sites/default/ 

files/2025_HDR/hdr2025_technical_notes.pdf  for details on 

how the IHDI is calculated. 

Overall loss:  Percentage difference between the IHDI value 

and the HDI value. 

Difference from HDI rank:  Difference in ranks on the IHDI and 

the HDI, calculated only for countries for which an IHDI value 

is calculated. 

Coefficient of human inequality:  Average inequality in the 

three basic dimensions of human development. 

Inequality in life expectancy:  Inequality in distribution of ex -

pected length of life based on data from life tables estimated 

using the Atkinson inequality index. 

Inequality ‑adjusted life expectancy index:  HDI life expectancy 

index value adjusted for inequality in distribution of expected 

length of life based on data from life tables listed in  Main data 

sources .

Inequality in education:  Inequality in distribution of years of 

schooling based on data from household surveys estimated us -

ing the Atkinson inequality index. 

Inequality ‑adjusted education index:  HDI education index value 

adjusted for inequality in distribution of years of schooling based 

on data from household surveys listed in  Main data sources .

Inequality in income:  Inequality in income distribution based 

on data from household surveys estimated using the Atkinson 

inequality index. 

Inequality ‑adjusted income index:  HDI income index value ad -

justed for inequality in income distribution based on data listed 

in  Main data sources .

Income shares:  Percentage share of income (or consumption) 

that accrues to the indicated population subgroups. 

Income share held by richest 1%:  Share of pretax national in -

come held by the richest 1 percent of the population. Pretax 

national income is the sum of all pretax personal income flows 

accruing to the owners of the production factors, labour and 

capital, before the tax/transfer system is taken into account and 

after the pension system is taken into account. 

Gini coefficient:  Measure of the deviation of the distribution of 

income among individuals or households in a country from a 

perfectly equal distribution. A value of 0 represents absolute 

equality, a value of 100 absolute inequality. 

Main data sources 

Column 1:  HDRO calculations based on data from Barro and 

Lee (2018), IMF (2024), UNDESA (2024a), UNESCO Institute for 

Statistics (2024), United Nations Statistics Division (2025) and 

World Bank (2024a). 

Column 2:  Calculated as the geometric mean of the values 

in the inequality-adjusted life expectancy index, inequality-

adjusted education index and inequality-adjusted income in -

dex using the methodology in  Technical note 2  (available at 

https://hdr.undp.org/sites/default/files/2025_HDR/hdr2025_ 

technical_notes.pdf ). 

Column 3:  Calculated based on data in columns 1 and 2. 

Column 4:  Calculated based on IHDI ranks and recalculated 

HDI ranks for countries for which an IHDI value is calculated. 

Column 5:  Calculated as the arithmetic mean of the values in 

inequality in life expectancy, inequality in education and in -

equality in income using the methodology in  Technical note 2 

(available at  https://hdr.undp.org/sites/default/files/2025_HDR/ 

hdr2025_technical_notes.pdf ). 

Column 6:  Calculated based on complete life tables from 

UNDESA (2024a). 

Column 7:  Calculated based on inequality in life expectancy 

and the HDI life expectancy index. 

Column 8:  Calculated based on data from the Center for Dis -

tributive, Labor and Social Studies and the World Bank’s Socio-

Economic Database for Latin America and the Caribbean, 

Eurostat’s European Union Statistics on Income and Living 

Conditions, ICF Macro Demographic and Health Surveys, the 

Luxembourg Income Study database, United Nations Children’s 

Fund Multiple Indicator Cluster Surveys and the United Nations 

Educational Scientific and Cultural Organization Institute for 

Statistics using the methodology in  Technical note 2  (available 

at  https://hdr.undp.org/sites/default/files/2025_HDR/hdr2025_ 

technical_notes.pdf ). 

Column 9:  Calculated based on inequality in education and the 

HDI education index. 

Column 10:  UNU-WIDER 2023. 

Column 11:  Calculated based on inequality in income and the 

HDI income index. 

Columns 12, 13 and 15:  World Bank 2024a. 

Column 14:  World Inequality Database 2023. 

2 9 1 TABLE 3 / INEQUALITY-ADJUSTED HUMAN DEVELOPMENT INDEX TABLE 4 

# Gender Development Index 

HDI RANK 

SDG 3  SDG 4.3  SDG 4.4  SDG 8.5 

Gender Development Index  Human Development Index  Life expectancy at birth  Expected years of schooling  Mean years of schooling 

Estimated gross national 

income per capita a

Value  (years)  (years)  (years)  (2021 PPP $) 

Value  Group b Female  Male  Female  Male  Female  Male  Female  Male  Female  Male 

2023  2023  2023  2023  2023  2023  2023 c 2023 c 2023 c 2023 c 2023  2023 

Very high human development 

1 Iceland  0.983  1 0.959  0.975  84.5  81.0  20.2  d 17.6  14.0  e 13.8  e 56,441  81,199  f

2 Norway  0.995  1 0.967  0.972  84.8  81.7  19.7  d 17.9  13.3  g 13.0  g 94,569  h 130,573  f

2 Switzerland  0.977  1 0.954  0.976  85.8  82.0  16.8  16.5  13.6  g 14.3  g 60,385  103,808  f

4 Denmark  0.990  1 0.953  0.963  83.9  80.0  19.3  d 18.1  d 13.2  g 12.8  g 63,412  88,753  f

5 Germany  0.975  1 0.946  0.970  83.8  79.0  17.4  17.3  14.0  g 14.6  g 52,189  76,218  f

5 Sweden  0.988  1 0.950  0.961  85.1  81.4  20.7  d 17.4  12.9  g 12.6  g 55,665  76,391  f

7 Australia  0.977  1 0.946  0.968  85.7  82.1  21.5  d 19.8  d 12.9  12.8  48,588  68,116 

8 Hong Kong, China (SAR)  0.976  1 0.941  0.964  88.1  i 82.8  j 16.9  16.9  12.0  12.8  56,528  85,162  f

8 Netherlands  0.971  2 0.938  0.966  83.7  80.5  18.9  d 18.2  d 12.5  g 12.9  g 56,539  80,307  f

10  Belgium  0.979  1 0.940  0.960  84.3  79.9  20.1  d 18.0  12.7  g 12.7  g 51,965  75,533  f

11  Ireland  1.001  1 0.950  0.949  84.5  80.4  19.6  d 18.8  d 11.9  g 11.5  g 74,819  107,271  f

12  Finland  0.992  1 0.943  0.951  84.7  79.2  20.7  d 18.4  d 13.2  g 12.8  g 48,533  65,803 

13  Singapore  0.994  1 0.944  0.950  86.2  81.2  16.9  16.6  11.7  12.3  96,100  h 125,389  f

13  United Kingdom  0.979  1 0.933  0.953  83.2  79.4  18.4  d 17.2  13.6  13.4  42,538  66,576 

15  United Arab Emirates  0.957  2 0.908  0.949  84.2  82.0  16.1  15.3  12.8  13.1  39,172  89,116  f

16  Canada  0.991  1 0.934  0.943  84.8  80.4  16.5  15.3  13.9  13.8  45,016  64,494 

17  Liechtenstein  0.964  2 0.919  0.954  85.3  81.8  14.4  16.4  12.2  k 12.6  k 130,593  h 203,518  f

17  New Zealand  0.973  2 0.925  0.950  83.8  80.4  19.7  d 18.9  d 12.9  g 12.9  g 39,338  55,285 

17  United States  1.009  1 0.938  0.929  81.8  76.9  16.8  15.1  14.0  13.8  60,085  87,081  f

20  Korea (Republic of)  0.959  2 0.915  0.954  87.2  81.2  16.3  16.9  12.1  g 13.3  g 38,370  61,120 

21  Slovenia  0.997  1 0.927  0.930  84.3  78.9  18.4  d 16.7  13.0  g 12.9  g 37,398  55,248 

22  Austria  0.985  1 0.921  0.936  84.3  79.5  16.8  15.8  12.1  g 12.6  g 51,929  75,395 

23  Japan  0.970  2 0.909  0.938  87.7  i 81.7  15.5  15.5  12.4  g 13.0  g 37,017  59,059 

24  Malta  0.977  1 0.911  0.932  85.3  81.3  16.6  15.3  12.2  g 12.6  g 38,808  64,528 

25  Luxembourg  0.996  1 0.919  0.922  83.8  80.6  14.5  14.2  12.8  e 12.4  e 70,537  100,195  f

26  France  0.993  1 0.916  0.923  86.1  80.4  16.6  15.6  11.6  g 11.9  g 46,383  64,286 

27  Israel  0.994  1 0.915  0.921  84.6  80.2  15.5  14.4  13.6  g 13.5  g 41,075  55,089 

28  Spain  0.989  1 0.910  0.920  86.3  81.0  18.5  d 17.2  10.7  g 10.8  g 37,689  54,633 

29  Czechia  0.987  1 0.908  0.919  82.6  77.0  17.5  16.2  12.8  g 13.1  g 35,089  56,992 

29  Italy  0.975  1 0.901  0.925  85.7  81.6  17.3  16.2  10.7  g 11.0  g 38,437  67,001 

29  San Marino  0.991  1 0.910  0.918  87.1  84.2  j 14.8  g 14.4  g 11.3  11.4  57,818  71,829 

32  Andorra  ..  ..  ..  ..  86.1  82.1  14.8  14.3  11.5  11.7  ..  .. 

32  Cyprus  0.996  1 0.911  0.915  83.7  79.6  16.9  15.5  12.6  g 12.6  g 39,336  51,361 

34  Greece  0.963  2 0.889  0.923  84.3  79.3  21.0  d 20.7  d 11.2  g 11.9  g 27,068  45,015 

35  Poland  1.012  1 0.910  0.899  82.4  74.9  17.6  15.8  13.4  g 13.0  g 33,206  51,802 

36  Estonia  1.023  1 0.913  0.893  83.0  74.9  16.9  15.1  13.7  g 13.3  g 34,599  47,825 

37  Saudi Arabia  0.931  3 0.855  0.918  81.2  77.1  17.9  16.4  11.0  g 12.0  g 20,287  69,767 

38  Bahrain  0.957  2 0.870  0.909  82.0  80.7  16.6  15.4  12.1  10.6  24,461  70,143 

39  Lithuania  1.022  1 0.903  0.884  80.7  71.2  17.0  15.9  13.7  g 13.5  g 35,072  49,587 

40  Portugal  1.000  1 0.890  0.890  85.1  79.4  17.9  17.1  9.7  g 9.7  g 36,435  46,152 

41  Croatia  0.999  1 0.888  0.889  81.7  75.4  17.3  15.4  11.9  l 12.3  l 33,291  50,066 

41  Latvia  1.026  2 0.899  0.876  80.5  71.6  17.3  15.7  13.7  g 13.1  g 31,383  45,664 

43  Qatar  1.036  2 0.909  0.877  83.4  81.6  15.1  12.3  12.7  10.2  54,169  125,739  f

44  Slovakia  0.999  1 0.879  0.880  81.6  75.0  15.5  14.4  13.1  g 13.1  g 29,901  44,016 

45  Chile  0.967  2 0.862  0.891  83.1  79.2  17.2  16.6  11.2  g 11.4  g 21,087  35,091 

46  Hungary  0.989  1 0.864  0.874  80.2  73.7  15.8  15.1  12.2  g 12.5  g 29,682  45,425 

47  Argentina  0.988  1 0.853  0.863  79.9  74.8  20.8  d 17.0  11.5  g 10.9  g 19,464  32,386 

48  Montenegro  0.984  1 0.855  0.868  80.3  73.7  16.2  14.9  12.2  g 13.3  g 22,325  34,173 

48  Uruguay  1.017  1 0.863  0.848  81.9  74.2  18.9  d 16.1  10.8  10.3  22,306  35,387 

50  Oman  0.945  3 0.822  0.870  81.9  78.5  14.1  13.0  12.3  11.7  15,311  48,793 

51  Türkiye  0.938  3 0.822  0.876  79.9  74.5  19.7  d 19.9  d 8.3  g 9.7  g 21,513  47,535 

52  Kuwait  1.011  1 0.849  0.840  81.8  79.3  18.2  d,g  13.9  g 8.4  g 7.1  g 29,510  73,825 

53  Antigua and Barbuda  1.031  2 0.862  0.836  80.3  74.5  16.8  g 14.3  g 12.2  11.1  23,694  31,453 

54  Seychelles  1.004  1 0.842  0.838  76.5  69.9  20.8  d 16.3  11.0  m 11.4  m 23,994  33,419 

55  Bulgaria  1.000  1 0.844  0.844  79.2  72.2  15.7  14.9  11.6  g 11.4  g 25,852  38,916 

55  Romania  0.986  1 0.837  0.849  79.6  72.4  14.6  13.5  11.3  11.8  28,345  51,116 

57  Georgia  1.009  1 0.846  0.838  79.1  69.6  17.1  16.5  12.8  12.6  16,596  25,515 

58  Saint Kitts and Nevis  ..  ..  ..  ..  76.0  68.6  19.7  d,n  17.0  n 11.1  o 10.6  o ..  .. 

59  Panama  1.014  1 0.844  0.833  82.6  76.7  14.0  g 12.7  g 11.1  g 10.5  g 29,598  39,169 

Continued → 

2 92 HUMAN DEVELOPMENT REPORT 2025 HDI RANK 

SDG 3  SDG 4.3  SDG 4.4  SDG 8.5 

Gender Development Index  Human Development Index  Life expectancy at birth  Expected years of schooling  Mean years of schooling 

Estimated gross national 

income per capita a

Value  (years)  (years)  (years)  (2021 PPP $) 

Value  Group b Female  Male  Female  Male  Female  Male  Female  Male  Female  Male 

2023  2023  2023  2023  2023  2023  2023 c 2023 c 2023 c 2023 c 2023  2023 

60  Brunei Darussalam  0.993  1 0.829  0.835  77.6  73.3  14.2  p 13.3  p 9.3  m 9.3  56,315  93,032  f

60  Kazakhstan  1.004  1 0.837  0.833  78.4  70.1  14.2  13.9  12.6  g 12.5  g 25,774  36,485 

62  Costa Rica  0.975  1 0.818  0.840  83.4  78.1  16.9  g 15.8  g 8.9  g 8.7  g 15,436  31,586 

62  Serbia  0.987  1 0.827  0.838  80.0  73.5  15.7  14.4  11.4  g 12.0  g 17,781  29,012 

64  Russian Federation  1.023  1 0.840  0.821  79.0  67.3  13.2  13.1  12.5  12.3  31,728  47,866 

65  Belarus  1.009  1 0.826  0.820  79.1  69.5  13.8  13.7  12.4  g 12.3  g 22,205  31,904 

66  Bahamas  1.015  1 0.826  0.814  78.2  70.9  12.2  q 11.6  q 12.9  g 12.8  g 28,999  33,132 

67  Malaysia  0.973  2 0.805  0.828  79.4  74.3  13.1  12.2  11.0  11.2  22,512  41,670 

68  North Macedonia  0.955  2 0.794  0.831  79.6  75.1  15.3  14.3  9.6  p 10.8  p 15,663  28,957 

69  Armenia  1.006  1 0.812  0.807  79.5  71.4  14.9  13.9  11.4  e 11.3  e 16,566  24,445 

69  Barbados  1.035  2 0.819  0.791  78.6  73.6  18.4  d,g  14.8  g 10.4  e 9.1  e 14,577  20,313 

71  Albania  0.963  2 0.794  0.824  81.4  77.7  14.7  14.3  9.9  e 10.5  e 14,123  21,211 

72  Trinidad and Tobago  0.990  1 0.801  0.809  76.7  70.4  14.6  r 13.9  r 10.9  10.6  20,212  33,937 

73  Mauritius  0.971  2 0.790  0.813  78.2  71.9  14.7  g 13.6  g 10.0  e 10.1  e 16,738  37,829 

74  Bosnia and Herzegovina  0.967  2 0.789  0.816  80.9  74.4  13.7  12.6  10.3  11.7  14,574  25,622 

High human development 

75  Iran (Islamic Republic of)  0.875  5 0.724  0.828  79.6  75.8  14.1  g 13.9  g 10.9  g 10.8  g 4,433  27,375 

76  Saint Vincent and the Grenadines  ..  ..  ..  ..  74.3  68.7  16.4  q 16.1  q 11.4  s 11.2  s ..  .. 

76  Thailand  1.008  1 0.802  0.795  80.9  72.2  15.5  g 15.2  g 8.9  9.2  18,717  22,519 

78  China  0.976  1 0.786  0.806  80.9  75.2  16.0  g 15.1  g 7.8  g 8.3  g 16,257  27,580 

79  Peru  0.959  2 0.777  0.810  80.1  75.4  15.0  g 14.8  g 9.6  g 10.7  g 11,653  17,053 

80  Grenada  0.984  1 0.783  0.796  78.4  72.4  17.2  g 16.0  g 9.3  t 9.6  t 11,030  17,645 

81  Azerbaijan  0.983  1 0.781  0.795  77.1  71.6  12.9  12.9  11.0  11.2  17,656  23,803 

81  Mexico  0.976  1 0.777  0.797  77.8  72.2  15.0  13.9  9.2  g 9.5  g 15,410  28,611 

83  Colombia  0.992  1 0.784  0.790  80.5  75.0  14.5  14.0  9.2  g 8.9  g 15,384  22,035 

84  Brazil  1.002  1 0.785  0.783  79.0  72.8  16.5  15.1  8.6  g 8.2  g 13,886  22,268 

84  Palau  0.992  1 0.781  0.788  71.8  67.2  15.1  13.1  13.3  m 13.3  m 12,385  19,156 

86  Moldova (Republic of)  1.029  2 0.795  0.773  75.5  66.6  15.0  g 14.3  g 11.9  11.7  15,025  16,853 

87  Ukraine  1.038  2 0.792  0.763  80.2  66.9  13.5  13.1  11.4  e 10.7  e 13,295  21,120 

88  Ecuador  0.998  1 0.776  0.777  80.1  74.7  15.4  14.4  8.9  9.0  12,333  15,649 

89  Dominican Republic  1.024  1 0.783  0.765  77.0  70.5  14.6  12.6  9.9  g 9.0  g 17,368  26,730 

89  Guyana  0.992  1 0.771  0.777  73.9  66.5  13.3  r 12.7  r 8.8  e 8.6  e 32,865  61,804 

89  Sri Lanka  0.951  2 0.750  0.789  80.6  74.2  13.6  12.6  10.7  10.8  6,970  18,637 

92  Tonga  0.998  1 0.763  0.764  76.4  69.4  19.0  d,g  16.6  g 11.0  e 10.8  e 5,957  9,081 

93  Maldives  0.986  1 0.755  0.766  82.8  79.7  14.1  11.6  7.4  e 7.4  e 12,134  23,702 

93  Viet Nam  0.997  1 0.765  0.767  79.3  69.9  15.5  u 15.4  8.5  9.5  11,422  14,711 

95  Turkmenistan  ..  ..  ..  ..  72.8  66.9  13.2  13.2  10.9  g 11.5  g ..  .. 

96  Algeria  0.887  5 0.702  0.791  77.7  74.9  16.2  14.8  6.9  g 7.9  g 5,284  24,554 

97  Cuba  0.975  1 0.750  0.769  80.5  75.7  14.6  13.2  10.7  e 10.5  e 5,994  10,900 

98  Dominica  ..  ..  ..  ..  74.5  68.2  15.0  g 13.3  g 10.0  10.2  ..  .. 

99  Paraguay  0.988  1 0.750  0.759  77.0  70.9  14.4  g 13.6  g 8.9  g 8.9  g 11,930  18,555 

100  Egypt  0.895  5 0.695  0.777  73.8  69.5  13.0  g 13.2  g 10.7  g 9.7  g 5,077  27,143 

100  Jordan  0.861  5 0.677  0.787  80.2  75.7  13.6  12.7  9.7  10.9  2,745  15,296 

102  Lebanon  0.992  1 0.749  0.755  79.7  75.7  12.1  u 11.4  u 13.1  v 9.1  v 6,068  16,829 

103  Saint Lucia  1.016  1 0.754  0.742  76.3  69.3  13.4  12.1  8.9  g 8.4  g 16,790  25,106 

104  Mongolia  1.030  2 0.757  0.735  76.4  67.2  14.4  13.1  9.9  p 8.9  p 11,204  18,386 

105  Tunisia  0.931  3 0.712  0.765  79.1  73.9  15.6  g 13.8  g 7.0  8.2  6,063  18,092 

106  South Africa  0.996  1 0.738  0.741  69.6  62.6  14.4  13.2  11.5  11.7  10,794  16,755 

107  Uzbekistan  0.951  2 0.718  0.755  75.4  69.5  12.5  12.4  11.8  12.1  5,840  11,759 

108  Bolivia (Plurinational State of)  0.961  2 0.718  0.748  71.1  66.1  15.7  g 15.5  g 9.4  g 10.7  g 8,010  10,874 

108  Gabon  0.994  1 0.728  0.733  71.1  65.9  12.6  q 12.3  q 10.5  8.9  13,264  24,269 

108  Marshall Islands  0.960  2 0.716  0.746  69.3  64.9  17.0  15.8  11.5  m 11.8  m 5,186  9,161 

111  Botswana  0.997  1 0.730  0.732  71.7  66.7  11.8  11.1  10.4  10.5  15,531  18,444 

111  Fiji  0.948  3 0.706  0.745  69.4  65.3  14.4  13.3  10.4  10.3  7,531  18,235 

113  Indonesia  0.945  3 0.704  0.745  73.3  69.0  13.6  13.1  8.4  g 9.0  g 9,073  18,284 

114  Suriname  0.993  1 0.717  0.722  76.8  70.5  11.3  10.6  8.6  g 8.2  g 12,734  21,958 

115  Belize  0.981  1 0.713  0.727  76.5  70.9  12.3  11.6  8.8  8.8  9,453  15,179 

115  Libya  0.955  2 0.700  0.733  70.4  68.3  13.0  t 12.8  t 8.4  o 7.2  o 12,125  27,282 

117  Jamaica  1.013  1 0.723  0.713  74.0  69.0  13.5  g 11.3  g 10.2  9.6  8,153  12,002 

117  Kyrgyzstan  0.959  2 0.701  0.731  75.2  68.2  12.8  12.6  12.0  g 12.2  g 4,120  8,080 

TABLE 4 

Continued → 

2 9 3 TABLE 4 / GENDER DEVELOPMENT INDEX TABLE 4 

HDI RANK 

SDG 3  SDG 4.3  SDG 4.4  SDG 8.5 

Gender Development Index  Human Development Index  Life expectancy at birth  Expected years of schooling  Mean years of schooling 

Estimated gross national 

income per capita a

Value  (years)  (years)  (years)  (2021 PPP $) 

Value  Group b Female  Male  Female  Male  Female  Male  Female  Male  Female  Male 

2023  2023  2023  2023  2023  2023  2023 c 2023 c 2023 c 2023 c 2023  2023 

117  Philippines  0.984  1 0.709  0.721  72.8  66.9  13.1  12.1  10.2  9.8  7,744  13,732 

120  Morocco  0.859  5 0.642  0.748  77.6  73.2  15.1  15.1  5.3  7.1  3,221  13,990 

121  Venezuela (Bolivarian Republic of)  0.993  1 0.699  0.704  76.5  68.7  13.0  s 11.6  s 10.0  m 9.7  s 5,040  9,323 

122  Samoa  0.955  2 0.687  0.719  73.7  69.9  13.0  11.9  11.8  g 10.9  g 3,724  8,150 

123  Nicaragua  0.952  2 0.685  0.719  77.4  72.3  11.7  11.3  9.9  10.0  4,676  9,161 

124  Nauru  0.955  2 0.689  0.722  64.0  60.3  13.1  t 12.6  u 9.3  t 10.2  t 15,192  23,930 

Medium human development 

125  Bhutan  0.958  2 0.681  0.711  75.0  71.3  13.7  g 12.6  g 5.2  o 6.3  o 10,750  16,531 

126  Eswatini (Kingdom of)  0.964  2 0.682  0.708  67.0  61.2  14.7  g 15.8  g 8.5  8.9  8,446  11,447 

126  Iraq  0.793  5 0.592  0.747  74.1  70.4  11.8  w 12.9  w 5.6  r 8.0  r 2,909  22,332 

128  Tajikistan  0.926  3 0.662  0.715  74.0  69.6  10.5  g 11.2  g 10.9  e 11.6  e 4,051  7,504 

129  Tuvalu  0.969  2 0.675  0.697  70.7  63.8  12.6  t 12.1  t 10.6  g 10.9  g 4,963  8,957 

130  Bangladesh  0.918  4 0.650  0.708  76.4  73.0  12.4  11.9  6.2  7.3  5,280  11,820 

130  India  0.874  5 0.631  0.722  73.6  70.5  13.0  12.9  5.8  8.0  4,543  13,273 

132  El Salvador  0.983  1 0.670  0.682  76.3  67.5  11.5  10.7  7.0  7.6  7,699  13,795 

133  Equatorial Guinea  ..  ..  ..  ..  65.7  62.0  12.1  u 12.9  t ..  ..  ..  .. 

133  Palestine, State of  0.945  3 0.638  0.676  71.5  59.7  13.8  12.2  10.2  10.0  2,339  10,806 

135  Cabo Verde  0.964  2 0.653  0.677  79.2  72.9  11.6  g 11.1  g 5.8  o 6.3  o 5,998  10,259 

136  Namibia  1.011  1 0.668  0.661  71.3  63.3  11.8  x 11.8  x 7.5  e 7.0  e 9,353  12,555 

137  Guatemala  0.934  3 0.638  0.683  74.9  70.3  10.8  10.5  5.3  6.5  8,528  16,454 

138  Congo  0.924  4 0.622  0.673  67.5  64.1  13.4  g 12.1  g 7.3  e 9.4  e 4,214  7,591 

139  Honduras  0.964  2 0.633  0.657  75.5  70.3  10.6  g 9.7  g 7.0  g 8.1  g 4,914  7,199 

140  Kiribati  0.976  1 0.634  0.650  68.2  64.6  12.4  y 11.3  y 9.3  o 9.0  o 3,949  6,009 

141  Sao Tome and Principe  0.980  1 0.633  0.646  73.7  66.2  13.2  r 12.7  r 5.4  g 6.8  g 4,982  6,192 

142  Timor-Leste  0.939  3 0.613  0.653  69.4  66.1  13.5  x 13.0  x 5.8  x 6.8  x 4,188  6,661 

143  Ghana  0.933  3 0.607  0.651  67.9  63.1  11.3  11.5  6.1  8.3  5,958  7,736 

143  Kenya  0.944  3 0.610  0.646  65.9  61.5  11.5  x 11.5  x 8.0  9.3  4,641  6,586 

145  Nepal  0.858  5 0.567  0.661  71.8  68.8  12.4  14.0  3.5  5.8  3,185  6,390 

146  Vanuatu  0.952  2 0.604  0.635  73.9  69.4  11.9  g 11.7  g 6.6  o 7.5  o 2,857  3,940 

147  Lao People's Democratic Republic  0.911  4 0.583  0.640  71.3  66.8  8.8  9.7  5.1  e 7.0  e 6,691  9,507 

148  Angola  0.906  4 0.584  0.645  67.1  62.1  11.5  12.9  4.5  x 7.3  x 5,854  7,425 

149  Micronesia (Federated States of)  0.953  2 0.598  0.628  71.1  63.5  11.5  t 11.6  u 6.9  o 7.8  o 3,157  5,348 

150  Myanmar  0.947  3 0.589  0.622  70.2  63.8  12.0  v 11.1  v 6.1  z 6.7  z 3,122  6,731 

151  Cambodia  0.939  3 0.586  0.625  73.2  68.0  11.4  10.9  4.4  6.2  4,067  5,832 

152  Comoros  0.929  3 0.581  0.625  68.9  64.8  13.7  g 12.9  g 5.2  6.9  2,657  4,295 

153  Zimbabwe  0.944  3 0.581  0.616  65.0  60.2  10.7  g 11.4  g 8.3  g 9.7  g 3,145  3,915 

154  Zambia  0.949  3 0.580  0.611  68.7  63.9  11.2  aa  10.9  aa  6.6  e 8.4  e 3,132  3,768 

155  Cameroon  0.898  5 0.556  0.619  65.9  61.5  10.2  11.4  5.7  e 7.6  e 3,629  5,870 

156  Solomon Islands  0.927  3 0.565  0.610  72.0  69.2  11.0  t 11.6  u 5.5  o 6.8  o 2,469  3,072 

157  Côte d'Ivoire  0.910  4 0.553  0.607  64.1  60.0  11.1  11.7  4.0  5.6  5,161  8,253 

157  Uganda  0.908  4 0.556  0.612  71.1  65.3  11.2  x 12.0  x 5.2  g 7.9  g 2,280  3,201 

159  Rwanda  0.922  4 0.552  0.599  69.9  65.5  12.5  12.6  4.5  5.3  2,159  3,824 

160  Papua New Guinea  0.926  3 0.554  0.599  69.1  63.7  10.9  x 12.1  x 4.3  e 5.7  e 3,436  4,475 

161  Togo  0.865  5 0.535  0.618  62.9  62.5  12.9  g 14.5  g 4.5  g 7.4  g 2,470  3,237 

162  Syrian Arab Republic  0.787  5 0.477  0.607  74.4  69.8  7.2  q 7.7  q 5.1  m 6.7  m 1,149  6,688 

163  Mauritania  0.886  5 0.528  0.595  70.5  66.5  8.1  g 7.8  g 4.2  e 5.9  e 3,604  9,038 

164  Nigeria  0.892  5 0.528  0.592  54.7  54.2  10.2  10.8  6.6  8.7  5,001  6,126 

165  Tanzania (United Republic of)  0.951  2 0.542  0.569  69.8  64.2  8.7  8.5  5.5  6.7  2,977  4,062 

166  Haiti  0.932  3 0.534  0.573  68.3  61.7  10.8  t 11.0  t 4.8  ab  6.1  ab  2,256  3,627 

167  Lesotho  1.006  1 0.550  0.547  60.0  54.6  11.3  g 10.7  g 8.4  g 7.0  g 2,495  3,592 

Low human development 

168  Pakistan  0.838  5 0.485  0.579  70.2  65.3  7.3  8.6  4.0  g 4.6  g 2,173  8,724 

169  Senegal  0.924  4 0.509  0.550  70.8  66.8  9.9  8.4  2.5  g 3.8  g 2,665  5,686 

170  Gambia  0.959  2 0.515  0.537  67.5  64.2  9.9  x 8.1  x 3.9  x 5.8  x 2,561  3,065 

171  Congo (Democratic Republic of the)  0.886  5 0.491  0.554  64.0  59.8  10.4  g 11.5  g 6.1  e 9.0  e 1,215  1,650 

172  Malawi  0.925  3 0.497  0.537  70.6  64.1  10.0  9.8  4.3  p 6.4  p 1,356  1,925 

173  Benin  0.866  5 0.479  0.553  62.2  59.3  9.8  11.1  2.0  4.6  3,329  4,279 

174  Guinea-Bissau  0.878  5 0.485  0.553  66.4  61.7  10.5  w 11.7  w 2.5  5.1  1,996  2,820 

175  Djibouti  0.814  5 0.453  0.556  68.5  63.5  5.8  g 6.6  g 2.7  s 5.1  s 3,101  9,690 

176  Sudan  0.813  5 0.441  0.542  69.6  63.3  8.4  g 8.8  g 3.6  4.3  909  4,742 

Continued → 

2 9 4 HUMAN DEVELOPMENT REPORT 2025 TABLE 4 

HDI RANK 

SDG 3  SDG 4.3  SDG 4.4  SDG 8.5 

Gender Development Index  Human Development Index  Life expectancy at birth  Expected years of schooling  Mean years of schooling 

Estimated gross national 

income per capita a

Value  (years)  (years)  (years)  (2021 PPP $) 

Value  Group b Female  Male  Female  Male  Female  Male  Female  Male  Female  Male 

2023  2023  2023  2023  2023  2023  2023 c 2023 c 2023 c 2023 c 2023  2023 

177  Liberia  0.865  5 0.473  0.547  63.4  60.9  10.1  10.8  4.7  g 7.8  g 1,279  1,798 

178  Eritrea  ..  ..  ..  ..  70.7  66.5  6.9  g 7.8  g 4.0  o 5.7  o ..  .. 

179  Guinea  0.828  5 0.451  0.545  61.9  59.5  9.4  g 11.4  g 1.5  g 3.6  g 2,550  4,460 

180  Ethiopia  0.886  5 0.465  0.525  70.7  64.1  8.6  x 9.7  x 1.7  g 3.2  g 2,056  3,531 

181  Afghanistan  0.660  5 0.379  0.575  67.5  64.5  8.1  g 13.4  g 1.2  3.9  721  3,198 

182  Mozambique  0.920  4 0.473  0.514  66.5  60.3  10.5  g 11.2  g 3.7  5.7  1,198  1,523 

183  Madagascar  0.934  3 0.469  0.502  65.4  61.9  9.2  g 8.9  g 4.3  4.9  1,345  1,965 

184  Yemen  0.407  5 0.221  0.543  71.4  67.2  6.5  s 8.1  s 3.6  7.5  137  1,877 

185  Sierra Leone  0.830  5 0.423  0.510  63.5  60.1  7.8  u 10.3  u 2.5  g 4.8  g 1,437  1,992 

186  Burkina Faso  0.881  5 0.428  0.486  63.2  58.9  8.8  8.7  1.6  3.1  1,634  3,153 

187  Burundi  0.932  3 0.424  0.456  65.7  61.6  10.1  g 9.6  g 2.8  g 4.3  g 764  955 

188  Mali  0.812  5 0.372  0.459  61.9  59.0  6.3  g 7.7  g 1.1  p 2.2  p 1,409  3,257 

188  Niger  0.855  5 0.385  0.451  62.1  60.3  7.5  g 9.1  g 1.0  e 1.8  e 1,276  1,895 

190  Chad  0.787  5 0.365  0.464  57.0  53.2  7.0  g 9.6  g 1.3  g 3.5  g 1,248  2,245 

191  Central African Republic  ..  ..  ..  ..  59.3  55.3  6.2  g 8.6  g 2.7  e 5.4  e ..  .. 

192  Somalia  0.793  5 0.354  0.447  61.4  56.4  7.5  t 8.1  t 0.9  2.9  790  2,156 

193  South Sudan  ..  ..  ..  ..  60.6  54.6  4.5  g 6.7  g 4.8  ac  6.2  ac  ..  .. 

Other countries or territories 

Korea (Democratic People’s Rep. of)  ..  ..  ..  ..  75.7  71.5  11.9  g 12.5  g ..  ..  ..  .. 

Monaco  ..  ..  ..  ..  88.5  i 84.4  j 22.3  d 21.1  d ..  ..  ..  .. 

Human development groups 

Very high human development  0.989  — 0.908  0.918  82.9  77.2  16.9  15.9  12.4  12.6  41,543  64,643 

High human development  0.971  — 0.764  0.786  78.6  72.9  15.0  14.2  8.6  8.8  13,044  23,717 

Medium human development  0.883  — 0.610  0.691  71.0  67.7  12.0  12.2  5.9  7.8  4,456  11,072 

Low human development  0.836  — 0.463  0.554  67.4  62.7  8.4  9.5  3.3  4.8  1,618  4,475 

Developing countries  0.934  — 0.685  0.733  74.4  69.8  12.6  12.6  7.3  8.3  8,845  17,725 

Regions 

Arab States  0.871  — 0.655  0.752  74.5  70.6  11.9  12.0  7.5  8.6  5,493  25,449 

East Asia and the Pacific  0.973  — 0.763  0.785  78.9  73.1  14.9  14.2  8.0  8.5  14,435  24,478 

Europe and Central Asia  0.970  — 0.803  0.829  78.4  71.2  15.6  15.5  10.5  10.9  16,367  30,624 

Latin America and the Caribbean  0.989  — 0.777  0.785  78.5  72.7  15.3  14.1  9.2  9.1  13,703  22,526 

South Asia  0.872  — 0.618  0.709  73.6  70.2  12.0  12.3  5.9  7.7  4,246  12,996 

Sub-Saharan Africa  0.916  — 0.544  0.594  64.6  60.4  10.1  10.7  5.4  7.1  3,623  5,173 

Least developed countries  0.889  — 0.525  0.591  68.9  64.2  9.8  10.5  4.3  5.9  2,549  4,832 

Small island developing states  0.979  — 0.731  0.747  74.7  69.2  12.8  12.4  8.5  8.8  15,508  23,151 

Organisation for Economic Co -operation 

and Development  0.986  — 0.908  0.921  83.1  78.0  17.0  16.0  12.2  12.5  41,745  63,915 

World  0.955  — 0.737  0.772  75.9  71.0  13.1  13.0  8.4  9.2  14,943  25,751 

2 9 5 TABLE 4 / GENDER DEVELOPMENT INDEX TABLE 4 

Notes 

a Because disaggregated income data are not available, 

data are crudely estimated. See  Definitions  and  Technical 

note 3 at  https://hdr.undp.org/sites/default/files/2025_ 

HDR/hdr2025_technical_notes.pdf  for details on how 

the Gender Development Index is calculated. 

b Countries are divided into five groups by absolute 

deviation from gender parity in HDI values. 

c Data refer to 2023 or the most recent year available. 

d In calculating the HDI value, expected years of schooling 

is capped at 18 years. 

e Updated by HDRO based on data from Barro and Lee 

(2018) and UNESCO Institute for Statistics (2024). 

f In calculating the male HDI value, estimated gross 

national income per capita is capped at $75,000. 

g Updated by HDRO based on data from UNESCO 

Institute for Statistics (2024). 

h In calculating the female HDI value, estimated gross 

national income per capita is capped at $75,000. 

i In calculating the female HDI value, life expectancy at 

birth is capped at 87.5 years. 

j In calculating the male HDI value, life expectancy at birth 

is capped at 82.5 years. 

k Updated by HDRO using the mean years of schooling 

trend of Austria and data from UNESCO Institute for 

Statistics (2024). 

l Updated by HDRO based on data from Eurostat (2024) 

and UNESCO Institute for Statistics (2024). 

m HDRO estimate based on data from Robert Barro and 

Jong-Wha Lee, Eurostat’s EU Statistics on Income and 

Living Conditions, ICF Macro Demographic and Health 

Surveys, the United Nations Educational, Scientific and 

Cultural Organization (UNESCO) Institute for Statistics 

and United Nations Children’s Fund (UNICEF) Multiple 

Indicator Cluster Surveys. 

n Refers to 2015 based on UNESCO Institute for Statistics 

(2024). 

o HDRO estimate based on data from Robert Barro and 

Jong-Wha Lee, ICF Macro Demographic and Health 

Surveys, the Organisation for Economic Co-operation 

and Development, the UNESCO Institute for Statistics 

and UNICEF Multiple Indicator Cluster Surveys. 

p Refers to 2020 based on UNESCO Institute for Statistics 

(2024). 

q HDRO estimate based on data from the Center for 

Distributive, Labor and Social Studies and the World 

Bank’s Socio-Economic Database for Latin America and 

the Caribbean, ICF Macro Demographic and Health 

Surveys, the UNESCO Institute for Statistics and UNICEF 

Multiple Indicator Cluster Surveys. 

r Updated by HDRO based on data from UNESCO 

Institute for Statistics (2024) and UNICEF Multiple 

Indicator Cluster Surveys for various years. 

s Updated by HDRO based on data from UNESCO 

Institute for Statistics (2024) and estimates using cross-

country regression. 

t Based on HDRO estimates using cross-country 

regression. 

u HDRO estimate based on data from ICF Macro Demo -

graphic and Health Surveys, the UNESCO Institute for 

Statistics and UNICEF Multiple Indicator Cluster Surveys. 

v Refers to 2018 based on UNESCO Institute for Statistics 

(2024). 

w Updated by HDRO based on data from UNICEF Multiple 

Indicator Cluster Surveys for various years. 

x Updated by HDRO based on data from ICF Macro 

Demographic and Health Surveys for various years and 

UNESCO Institute for Statistics (2024). 

y Updated by HDRO based on data from UNICEF Multiple 

Indicator Cluster Surveys for various years and estimates 

using cross-country regression. 

z Refers to 2019 based on UNESCO Institute for Statistics 

(2024). 

aa  Updated by HDRO based on data from ICF Macro 

Demographic and Health Surveys for various years. 

ab  Refers to 2017 based on UNESCO Institute for Statistics 

(2024). 

ac  Refers to 2008 based on UNESCO Institute for Statistics 

(2024). 

Definitions 

Gender Development Index:  Ratio of female to male HDI val -

ues. See  Technical note 3  at  https://hdr.undp.org/sites/default/ 

files/2025_HDR/hdr2025_technical_notes.pdf  for details on 

how the Gender Development Index is calculated. 

Gender Development Index groups:  Countries are divided into 

five groups by absolute deviation from gender parity in HDI 

values. Group 1 comprises countries with high equality in HDI 

achievements between women and men (absolute deviation of 

less than 2.5 percent), group 2 comprises countries with me -

dium to high equality in HDI achievements between women and 

men (absolute deviation of 2.5–5 percent), group 3 comprises 

countries with medium equality in HDI achievements between 

women and men (absolute deviation of 5–7.5 percent), group 

4 comprises countries with medium to low equality in HDI 

achievements between women and men (absolute deviation 

of 7.5–10 percent) and group 5 comprises countries with low 

equality in HDI achievements between women and men (abso -

lute deviation from gender parity of more than 10 percent). 

Human Development Index (HDI):  A composite index measur -

ing average achievement in three basic dimensions of human 

development—a long and healthy life, knowledge and a decent 

standard of living. See  Technical note 1  at  https://hdr.undp.org/ 

sites/default/files/2025_HDR/hdr2025_technical_notes.pdf  for 

details on how the HDI is calculated. 

Life expectancy at birth:  Number of years a newborn infant 

could expect to live if prevailing patterns of age-specific mortality 

rates at the time of birth stay the same throughout the infant’s life. 

Expected years of schooling:  Number of years of schooling 

that a child of school entrance age can expect to receive if 

prevailing patterns of age-specific enrolment rates persist 

throughout the child’s life. 

Mean years of schooling:  Average number of years of 

education received by people ages 25 and older, converted 

from educational attainment levels using official durations of 

each level. 

Estimated gross national income per capita:  Derived from 

the ratio of female to male wages, female and male shares of 

economically active population and gross national income (in 

2021 purchasing power parity terms). See  Technical note 3  at 

https://hdr.undp.org/sites/default/files/2025_HDR/hdr2025_ 

technical_notes.pdf  for details. 

Main data sources 

Column 1:  Calculated based on data in columns 3 and 4. 

Column 2:  Calculated based on data in column 1. 

Columns 3 and 4:  HDRO calculations based on data from 

Barro and Lee (2018), IMF (2024), UNDESA (2024a), UNESCO 

Institute for Statistics (2024), United Nations Statistics Division 

(2025) and World Bank (2024a). 

Columns 5 and 6:  UNDESA 2024a. 

Columns 7 and 8:  ICF Macro Demographic and Health Surveys, 

UNESCO Institute for Statistics 2024 and UNICEF Multiple 

Indicator Cluster Surveys. 

Columns 9 and 10:  Barro and Lee 2018, Eurostat 2024, ICF 

Macro Demographic and Health Surveys, UNESCO Institute for 

Statistics 2024 and UNICEF Multiple Indicator Cluster Surveys. 

Columns 11 and 12:  HDRO calculations based on ILO (2024), 

IMF (2024), UNDESA (2024a), United Nations Statistics Division 

(2025) and World Bank (2024a). 

2 9 6 HUMAN DEVELOPMENT REPORT 2025 HDI RANK 

SDG 3.1  SDG 3.7  SDG 5.5  SDG 4.4 

Gender Inequality Index 

Maternal 

mortality ratio 

Adolescent 

birth rate 

Share of seats 

in parliament 

Population with at least some 

secondary education  Labour force participation rate a

Value  Rank 

(deaths per 

100,000 live births) 

(births per 1,000 

women ages 15–19) 

(% held 

by  women) 

(% ages 25 and older)  (% ages 15 and older) 

Female  Male  Female  Male 

2023  2023  2020  2023  2023  2023 b 2023 b 2023  2023 

Very high human development 

1 Iceland  0.024  7 3 3.4  47.6  99.9  99.6  70.5  79.3 

2 Norway  0.004  2 2 1.4  46.2  95.9  98.5  62.1  69.2 

2 Switzerland  0.010  4 7 1.5  37.8  98.0  98.3  62.6  72.9 

4 Denmark  0.003  1 5 1.1  43.6  91.0  92.5  59.7  67.7 

5 Germany  0.057  21  4 5.5  35.3  93.6  94.3  56.4  66.7 

5 Sweden  0.007  3 5 1.8  46.4  94.9  94.1  64.4  70.6 

7 Australia  0.056  20  3 6.7  44.5  92.3  93.5  62.8  71.7 

8 Hong Kong, China (SAR)  ..  ..  ..  1.1  ..  77.9  84.1  52.2  63.6 

8 Netherlands  0.013  5 4 1.9  39.1  91.1  92.7  64.1  73.1 

10  Belgium  0.031  8 5 3.7  43.5  88.3  91.0  50.7  59.5 

11  Ireland  0.054  19  5 4.1  27.4  90.4  89.9  60.4  70.8 

12  Finland  0.021  6 8 3.1  46.0  91.6  91.6  58.5  63.8 

13  Singapore  0.031  8 7 2.2  29.1  82.9  87.8  62.6  74.9 

13  United Kingdom  0.083  31  10  8.4  31.5  99.1  99.0  58.1  66.6 

15  United Arab Emirates  0.040  13  9 3.1  50.0  83.4  87.0  54.5  90.8 

16  Canada  0.052  18  11  4.8  35.8  96.1  96.5  61.6  69.7 

17  Liechtenstein  ..  ..  ..  1.7  28.0  ..  ..  52.8  67.2 

17  New Zealand  0.082  30  7 10.9  44.3  82.9  c 82.3  c 67.6  76.7 

17  United States  0.169  45  21  13.1  28.2  97.9  97.8  57.3  68.1 

20  Korea (Republic of)  0.038  12  8 0.5  19.1  85.0  94.2  56.1  73.4 

21  Slovenia  0.042  14  5 3.5  31.5  98.3  98.9  53.8  63.2 

22  Austria  0.033  10  5 3.8  42.8  98.8  98.7  56.8  66.6 

23  Japan  0.059  22  4 1.7  15.7  98.2  d 99.1  d 54.8  71.4 

24  Malta  0.111  36  3 10.4  27.8  85.0  90.4  57.2  73.2 

25  Luxembourg  0.044  17  6 4.0  33.3  90.1  91.3  58.2  66.2 

26  France  0.034  11  8 3.5  37.2  90.5  92.8  52.8  60.1 

27  Israel  0.080  27  3 6.2  24.2  90.7  92.7  61.4  68.9 

28  Spain  0.043  15  3 4.8  43.7  81.5  85.0  53.4  63.0 

29  Czechia  0.088  32  3 6.0  23.8  99.0  99.4  51.8  68.5 

29  Italy  0.043  15  5 2.9  33.6  79.8  86.2  41.5  58.8 

29  San Marino  ..  ..  ..  1.2  33.3  87.2  88.3  70.4  70.6 

32  Andorra  ..  ..  ..  3.5  50.0  81.7  84.6  ..  .. 

32  Cyprus  0.252  64  68  7.0  14.3  84.1  87.8  60.9  70.3 

34  Greece  0.103  34  8 7.0  23.0  73.8  80.4  44.8  60.0 

35  Poland  0.081  29  2 6.2  27.5  87.5  c 91.4  c 52.0  66.3 

36  Estonia  0.061  23  5 5.0  28.7  98.7  98.7  62.0  71.6 

37  Saudi Arabia  0.228  61  16  11.1  19.9  75.7  81.5  34.6  83.6 

38  Bahrain  0.165  44  16  7.5  22.5  88.6  79.9  41.5  85.1 

39  Lithuania  0.070  24  9 5.9  28.4  96.9  98.1  58.5  68.5 

40  Portugal  0.076  26  12  7.0  36.1  64.1  65.4  55.6  63.9 

41  Croatia  0.074  25  5 6.6  31.8  93.5  97.5  47.3  57.6 

41  Latvia  0.117  38  18  7.6  32.0  97.2  98.8  55.7  67.9 

43  Qatar  0.195  52  8 5.7  4.4  86.7  70.2  61.7  95.3 

44  Slovakia  0.176  48  5 24.6  22.0  99.1  99.2  56.3  67.3 

45  Chile  0.102  33  15  6.5  32.7  86.0  88.5  52.0  71.4 

46  Hungary  0.213  54  15  17.5  14.1  98.3  99.1  54.5  68.4 

47  Argentina  0.264  70  45  26.4  43.8  74.3  e 72.2  e 53.2  72.2 

48  Montenegro  0.121  40  6 9.4  21.0  90.1  96.2  52.2  66.1 

48  Uruguay  0.218  56  19  26.2  26.9  63.2  59.3  56.5  73.4 

50  Oman  0.222  57  17  6.0  10.2  93.3  98.7  39.9  86.5 

51  Türkiye  0.227  59  17  12.1  19.8  62.0  c 80.4  c 35.8  71.2 

52  Kuwait  0.188  51  7 1.6  3.1  62.7  c 57.8  c 47.3  85.9 

53  Antigua and Barbuda  0.240  63  21  32.9  22.9  88.0  76.6  69.6  76.0 

54  Seychelles  ..  ..  3 54.5  22.9  ..  ..  61.3  65.5 

55  Bulgaria  0.208  53  7 39.1  24.2  95.7  97.1  49.8  62.2 

55  Romania  0.227  59  10  33.8  18.9  91.0  95.0  41.9  61.9 

57  Georgia  0.257  66  28  21.1  18.4  98.2  98.7  53.7  69.6 

58  Saint Kitts and Nevis  ..  ..  ..  35.2  31.3  ..  ..  ..  .. 

59  Panama  0.374  94  50  57.3  22.9  67.7  65.3  50.4  74.3 

TABLE 5 

# Gender Inequality Index 

Continued → 

2 9 7 TABLE 5 / GENDER INEQUALITY INDEX TABLE 5                   

> HDI RANK
> SDG 3.1 SDG 3.7 SDG 5.5 SDG 4.4
> Gender Inequality Index
> Maternal
> mortality ratio
> Adolescent
> birth rate
> Share of seats
> in parliament
> Population with at least some
> secondary education Labour force participation rate a
> Value Rank
> (deaths per
> 100,000 live births)
> (births per 1,000
> women ages 15–19)
> (% held
> by women)
> (% ages 25 and older) (% ages 15 and older)
> Female Male Female Male
> 2023 2023 2020 2023 2023 2023 b2023 b2023 2023

60  Brunei Darussalam  0.257  66  44  8.5  11.8  86.0  88.8  54.4  72.3 

60  Kazakhstan  0.182  50  13  18.2  19.6  100.0  c 100.0  c 63.3  74.6 

62  Costa Rica  0.217  55  22  26.3  47.4  52.1  52.9  43.9  69.7 

62  Serbia  0.117  38  10  13.7  34.8  91.2  c 96.8  c 51.5  65.5 

64  Russian Federation  0.169  45  14  13.0  17.8  99.3  99.1  56.2  70.5 

65  Belarus  0.080  27  1 8.6  34.7  99.3  c 99.9  c 65.3  74.9 

66  Bahamas  0.325  81  77  24.6  20.0  96.2  97.7  98.7  96.8 

67  Malaysia  0.172  47  21  6.0  14.7  79.0  82.1  55.8  81.9 

68  North Macedonia  0.112  37  3 13.0  42.5  68.3  76.2  42.5  61.5 

69  Armenia  0.180  49  27  13.4  35.5  99.1  99.3  61.6  76.8 

69  Barbados  0.297  76  39  45.3  32.7  95.9  e 86.4  e 54.9  62.7 

71  Albania  0.107  35  8 12.8  35.7  90.5  93.9  57.8  70.9 

72  Trinidad and Tobago  0.262  69  27  36.0  33.8  73.0  70.7  46.7  64.2 

73  Mauritius  0.352  87  84  19.8  20.0  60.4  71.3  46.9  69.7 

74  Bosnia and Herzegovina  0.157  43  6 11.2  17.5  86.2  96.2  42.2  62.1 

High human development 

75  Iran (Islamic Republic of)  0.482  123  22  26.2  5.6  59.1  69.5  13.6  67.5 

76  Saint Vincent and the Grenadines  ..  ..  62  42.3  18.2  46.3  f 41.5  f ..  .. 

76  Thailand  0.288  73  29  26.1  16.0  51.9  56.7  60.6  76.6 

78  China  0.132  41  23  5.2  26.5  68.3  c 77.9  c 54.6  75.6 

79  Peru  0.340  83  69  43.6  38.8  65.9  73.9  65.1  80.5 

80  Grenada  0.226  58  21  29.1  31.0  55.4  d 50.8  d 49.1  63.3 

81  Azerbaijan  0.315  80  41  34.8  18.6  98.0  98.4  61.9  69.6 

81  Mexico  0.358  88  59  60.1  50.1  65.3  67.0  46.2  76.4 

83  Colombia  0.393  98  75  59.5  29.4  62.2  59.8  52.0  76.5 

84  Brazil  0.390  96  72  42.7  17.7  70.0  67.6  53.1  73.1 

84  Palau  ..  ..  ..  29.9  6.9  96.2  c 92.9  c 60.5  73.7 

86  Moldova (Republic of)  0.146  42  12  23.0  38.6  98.0  98.7  70.1  71.7 

87  Ukraine  ..  ..  17  11.4  20.4  ..  ..  47.4  62.3 

88  Ecuador  0.358  88  66  55.5  43.1  54.2  54.3  52.9  77.3 

89  Dominican Republic  0.417  106  107  52.8  25.7  62.3  58.7  52.8  76.9 

89  Guyana  0.427  109  112  69.9  36.6  59.4  e 57.7  e 39.7  61.8 

89  Sri Lanka  0.367  93  29  15.1  5.3  81.1  83.1  32.0  70.5 

92  Tonga  0.444  115  126  24.8  7.1  94.2  94.1  53.3  71.4 

93  Maldives  0.309  79  57  5.4  4.6  48.6  e 47.7  e 55.4  78.8 

93  Viet Nam  0.299  78  46  34.3  30.3  61.5  70.0  67.9  76.7 

95  Turkmenistan  ..  ..  5 21.2  25.6  98.1  c 98.3  c ..  .. 

96  Algeria  0.443  114  78  8.7  6.8  47.0  c 51.3  c 17.6  65.5 

97  Cuba  0.296  75  39  48.7  55.7  78.5  c 81.6  c 57.3  84.7 

98  Dominica  ..  ..  ..  34.1  37.5  57.9  64.9  ..  .. 

99  Paraguay  0.412  104  71  70.3  23.2  57.5  56.9  59.2  82.8 

100  Egypt  0.398  101  17  41.8  22.9  62.5  e 70.2  e 15.0  69.2 

100  Jordan  0.433  111  41  18.4  13.3  73.8  85.8  13.8  60.5 

102  Lebanon  0.360  91  21  20.8  6.3  64.1  g 65.9  g 30.5  70.3 

103  Saint Lucia  0.327  82  73  27.8  24.1  50.2  c 44.2  c 62.7  75.8 

104  Mongolia  0.284  72  39  19.7  17.1  94.2  92.7  52.8  68.9 

105  Tunisia  0.238  62  37  4.3  16.2  38.9  45.5  26.7  64.9 

106  South Africa  0.388  95  127  51.6  45.7  h 77.0  78.7  49.0  61.4 

107  Uzbekistan  0.291  74  30  34.1  30.0  100.0  100.0  43.6  72.0 

108  Bolivia (Plurinational State of)  0.419  107  161  64.8  48.2  57.4  67.8  72.6  84.5 

108  Gabon  0.505  135  227  91.7  23.8  71.6  56.9  39.7  57.4 

108  Marshall Islands  ..  ..  ..  71.8  12.1  96.3  c 97.1  c 42.7  60.8 

111  Botswana  0.490  127  186  53.8  11.1  71.4  72.6  63.1  73.1 

111  Fiji  0.350  85  38  21.2  10.9  87.9  i 86.7  i 38.4  75.8 

113  Indonesia  0.423  108  173  26.4  21.6  53.5  59.9  53.4  82.2 

114  Suriname  0.391  97  96  48.0  29.4  45.5  j 42.3  j 47.8  66.8 

115  Belize  0.428  110  130  55.2  23.9  57.5  c 52.0  c 65.4  84.9 

115  Libya  0.253  65  72  5.9  16.5  62.2  k 45.3  k 33.2  60.3 

117  Jamaica  0.358  88  99  36.5  31.0  79.8  74.3  60.6  72.4 

117  Kyrgyzstan  0.340  83  50  28.3  20.0  91.2  c 93.6  c 45.9  74.7 

117  Philippines  0.351  86  78  31.9  27.5  63.6  60.0  50.2  72.5 

Continued → 

2 9 8 HUMAN DEVELOPMENT REPORT 2025 HDI RANK                   

> SDG 3.1 SDG 3.7 SDG 5.5 SDG 4.4
> Gender Inequality Index
> Maternal
> mortality ratio
> Adolescent
> birth rate
> Share of seats
> in parliament
> Population with at least some
> secondary education Labour force participation rate a
> Value Rank
> (deaths per
> 100,000 live births)
> (births per 1,000
> women ages 15–19)
> (% held
> by women)
> (% ages 25 and older) (% ages 15 and older)
> Female Male Female Male
> 2023 2023 2020 2023 2023 2023 b2023 b2023 2023

120  Morocco  0.438  113  72  25.1  21.4  33.0  38.8  19.8  69.6 

121  Venezuela (Bolivarian Republic of)  0.512  137  259  73.3  22.2  l 77.0  e 72.4  e 47.2  71.8 

122  Samoa  0.416  105  59  43.5  13.0  94.4  90.0  31.4  56.6 

123  Nicaragua  0.408  103  78  93.5  51.6  60.5  63.1  51.2  82.3 

124  Nauru  ..  ..  ..  76.2  10.5  ..  ..  56.9  72.7 

Medium human development 

125  Bhutan  0.278  71  60  9.4  15.5  26.7  k 34.3  k 56.8  72.4 

126  Eswatini (Kingdom of)  0.484  124  240  68.7  25.0  45.8  53.0  47.1  52.3 

126  Iraq  0.558  148  76  58.0  29.1  24.5  39.8  10.7  67.2 

128  Tajikistan  0.258  68  17  40.4  26.6  93.7  m 93.6  e 34.4  52.7 

129  Tuvalu  ..  ..  ..  27.5  6.3  61.1  c 60.6  c 35.2  52.4 

130  Bangladesh  0.487  125  123  73.2  20.9  43.2  48.0  43.4  80.8 

130  India  0.403  102  103  14.1  14.8  43.5  61.1  35.1  76.4 

132  El Salvador  0.362  92  43  54.2  27.4  46.4  52.8  48.8  78.1 

133  Equatorial Guinea  ..  ..  212  150.4  27.0  ..  ..  ..  .. 

133  Palestine, State of  ..  ..  20  36.0  ..  70.6  68.3  18.6  70.7 

135  Cabo Verde  0.298  77  42  38.8  41.7  30.2  f 34.8  f 44.9  61.9 

136  Namibia  0.448  116  215  66.0  35.6  73.3  c 70.7  c 55.3  60.7 

137  Guatemala  0.480  121  96  68.3  20.0  29.9  35.9  39.7  82.2 

138  Congo  0.565  151  282  109.9  20.2  32.5  e 50.6  e 44.6  65.0 

139  Honduras  0.437  112  72  82.1  27.3  30.0  28.6  40.3  75.4 

140  Kiribati  ..  ..  76  44.0  6.7  ..  ..  43.0  54.8 

141  Sao Tome and Principe  0.492  130  146  86.2  14.5  42.6  n 52.5  n 25.7  25.9 

142  Timor-Leste  0.394  99  204  27.4  36.9  35.3  40.9  40.9  52.5 

143  Ghana  0.514  138  263  58.2  14.5  45.6  65.1  62.1  65.5 

143  Kenya  0.526  143  530  56.3  24.6  60.5  70.1  62.8  72.4 

145  Nepal  0.487  125  174  67.2  33.2  26.6  43.2  33.1  56.1 

146  Vanuatu  0.556  147  94  66.2  1.9  46.6  c 48.2  c 43.1  48.8 

147  Lao People's Democratic Republic  0.475  117  126  81.7  22.0  19.3  e 31.0  e 61.5  70.8 

148  Angola  0.515  139  222  140.8  39.1  29.0  52.3  75.6  78.7 

149  Micronesia (Federated States of)  ..  ..  74  43.7  14.3  ..  ..  48.6  68.1 

150  Myanmar  0.478  118  179  33.5  15.0  l 38.5  g 47.8  g 43.6  76.7 

151  Cambodia  0.506  136  218  46.9  14.4  16.4  29.0  70.5  83.8 

152  Comoros  0.501  132  217  55.2  16.7  27.3  36.3  49.3  64.5 

153  Zimbabwe  0.519  140  357  98.1  34.0  88.8  92.9  62.1  74.4 

154  Zambia  0.524  141  135  115.9  15.0  35.5  e 52.9  e 56.4  67.8 

155  Cameroon  0.558  148  438  106.7  32.9  25.0  e 39.4  e 56.3  74.0 

156  Solomon Islands  0.478  118  122  50.4  8.0  38.2  o 47.8  o 87.1  87.7 

157  Côte d'Ivoire  0.589  159  480  92.1  16.8  20.0  32.7  59.6  75.5 

157  Uganda  0.524  141  284  107.0  33.8  24.6  c 40.4  c 74.5  85.8 

159  Rwanda  0.394  99  259  30.8  54.7  20.5  24.5  58.1  69.9 

160  Papua New Guinea  0.584  156  192  54.1  2.7  27.4  41.3  50.7  53.3 

161  Togo  0.564  150  399  77.1  19.8  14.3  c 33.3  c 69.1  72.7 

162  Syrian Arab Republic  0.490  127  30  38.9  10.8  24.1  k 32.0  k 14.7  69.8 

163  Mauritania  0.603  161  464  88.9  23.3  16.7  e 27.9  e 31.6  66.6 

164  Nigeria  0.677  171  1,047  86.4  3.6  42.4  57.8  80.7  84.5 

165  Tanzania (United Republic of)  0.504  134  238  113.2  37.4  12.6  18.3  74.9  84.0 

166  Haiti  0.618  165  350  49.8  2.7  p 27.0  i 36.0  i 50.1  65.6 

167  Lesotho  0.534  144  566  70.6  26.0  35.3  c 30.6  c 53.6  63.9 

Low human development 

168  Pakistan  0.536  145  154  41.1  20.1  27.8  48.4  25.0  81.1 

169  Senegal  0.490  127  261  60.2  46.1  15.4  24.8  39.2  68.7 

170  Gambia  0.578  154  458  58.1  8.6  35.5  49.5  45.4  50.1 

171  Congo (Democratic Republic of the)  0.604  162  547  106.9  14.8  40.8  c 66.7  c 59.7  66.0 

172  Malawi  0.581  155  381  113.6  20.7  13.4  e 26.9  e 63.8  74.9 

173  Benin  0.573  153  523  77.8  26.6  7.2  21.0  74.7  78.0 

174  Guinea-Bissau  0.632  166  725  82.0  9.8  27.3  50.6  60.1  70.2 

175  Djibouti  0.481  122  234  19.0  26.2  16.7  f 34.1  f 19.0  48.4 

176  Sudan  0.588  158  270  66.1  31.0  q 22.5  26.9  14.4  61.9 

177  Liberia  0.646  167  652  126.0  10.7  24.0  c 46.5  c 46.0  52.8 

TABLE 5 

Continued → 

2 9 9 TABLE 5 / GENDER INEQUALITY INDEX HDI RANK                   

> SDG 3.1 SDG 3.7 SDG 5.5 SDG 4.4
> Gender Inequality Index
> Maternal
> mortality ratio
> Adolescent
> birth rate
> Share of seats
> in parliament
> Population with at least some
> secondary education Labour force participation rate a
> Value Rank
> (deaths per
> 100,000 live births)
> (births per 1,000
> women ages 15–19)
> (% held
> by women)
> (% ages 25 and older) (% ages 15 and older)
> Female Male Female Male
> 2023 2023 2020 2023 2023 2023 b2023 b2023 2023

178  Eritrea  ..  ..  322  65.2  22.0  p ..  ..  ..  .. 

179  Guinea  0.609  163  553  118.6  29.6  8.1  c 21.1  c 47.0  68.2 

180  Ethiopia  0.497  131  267  69.9  38.8  7.4  c 12.7  c 55.6  78.1 

181  Afghanistan  0.661  168  620  64.1  27.2  l 7.0  24.1  24.5  88.6 

182  Mozambique  0.479  120  127  153.5  43.2  13.2  23.7  76.6  82.4 

183  Madagascar  0.584  156  392  129.8  17.2  15.9  21.2  68.9  81.6 

184  Yemen  0.838  172  183  75.3  0.3  20.7  47.2  5.9  65.7 

185  Sierra Leone  0.566  152  443  93.6  28.2  14.7  c 34.4  c 50.2  56.3 

186  Burkina Faso  0.555  146  264  87.1  16.9  7.3  13.0  41.8  54.5 

187  Burundi  0.501  132  494  53.4  38.9  8.6  c 14.5  c 77.7  79.3 

188  Mali  0.612  164  440  138.6  28.6  8.2  c 16.4  c 41.9  77.7 

188  Niger  0.591  160  441  145.3  25.9  r 6.1  11.5  73.4  87.3 

190  Chad  0.670  169  1,063  134.7  25.9  3.7  g 15.1  g 52.4  76.8 

191  Central African Republic  ..  ..  835  163.1  12.9  14.6  32.0  ..  .. 

192  Somalia  0.675  170  621  117.1  20.7  4.4  17.8  22.2  49.5 

193  South Sudan  ..  ..  1,223  97.1  32.3  26.5  s 36.4  s ..  .. 

Other countries or territories 

Korea (Democratic People’s Rep. of)  ..  ..  107  0.5  17.6  84.1  93.7  ..  .. 

Monaco  ..  ..  ..  9.7  45.8  ..  ..  39.9  56.9 

Human development groups 

Very high human development  0.125  — 14  10.1  30.2  90.8  92.7  54.1  69.3 

High human development  0.334  — 67  25.5  25.6  65.7  72.2  50.4  74.8 

Medium human development  0.513  — 291  44.8  22.5  41.1  56.5  43.4  76.6 

Low human development  0.571  — 369  81.5  25.3  19.8  34.9  41.7  75.1 

Developing countries  0.478  — 236  42.9  24.6  53.9  64.2  46.9  75.5 

Regions 

Arab States  0.539  — 133  44.2  17.8  45.8  56.9  18.4  69.8 

East Asia and the Pacific  0.315  — 78  15.5  21.7  64.6  73.2  55.0  76.4 

Europe and Central Asia  0.226  — 21  19.5  26.0  82.3  90.3  45.7  69.3 

Latin America and the Caribbean  0.384  — 85  51.4  34.2  66.2  66.1  51.8  75.1 

South Asia  0.458  — 132  26.1  17.9  42.5  58.9  33.5  76.7 

Sub-Saharan Africa  0.558  — 509  94.2  27.3  32.1  43.8  64.3  75.6 

Least developed countries  0.552  — 352  90.6  25.6  24.3  35.2  51.0  75.0 

Small island developing states  0.451  — 203  46.9  26.2  57.8  61.9  54.1  71.0 

Organisation for Economic Co -operation 

and Development  0.192  — 22  17.5  33.1  88.0  90.6  53.5  68.7 

World  0.455  — 216  39.1  26.5  62.0  70.2  48.5  74.1 

TABLE 5 

3 0 0 HUMAN DEVELOPMENT REPORT 2025 TABLE 5 

Notes 

a Updated by HDRO based on data from International 

Labour Organization (2024). 

b Data refer to 2023 or the most recent year available. 

c Updated by HDRO based on data from UNESCO Institute 

for Statistics (2024). 

d Refers to 2020 based on UNESCO Institute for Statistics 

(2024). 

e Updated by HDRO based on data from Barro and Lee 

(2018) and UNESCO Institute for Statistics (2024). 

f Updated by HDRO based on data from UNESCO Institute 

for Statistics (2024) and estimates using cross-country 

regression. 

g Refers to 2019 based on UNESCO Institute for Statistics 

(2024). 

h Excludes the 36 special rotating delegates appointed on 

an ad hoc basis. 

i Refers to 2017 based on UNESCO Institute for Statistics 

(2024). 

j Refers to 2018 based on UNESCO Institute for Statistics 

(2024). 

k HDRO estimate based on data from Robert Barro and 

Jong-Wha Lee, ICF Macro Demographic and Health 

Surveys, the Organisation for Economic Co-operation and 

Development, the United Nations Educational, Scientific 

and Cultural Organization (UNESCO) Institute for Statistics 

and United Nations Children’s Fund (UNICEF) Multiple 

Indicator Cluster Surveys. 

l Refers to 2021. 

m HDRO estimate based on data from Barro and Lee 

(2018), UNESCO Institute for Statistics (2024) and 

UNICEF Multiple Indicator Cluster Surveys. 

n Updated by HDRO based on data from UNESCO Institute 

for Statistics (2024) and UNICEF Multiple Indicator Cluster 

Surveys for various years. 

o Refers to 2013 based on UNESCO Institute for Statistics 

(2024). 

p Refers to 2019. 

q Refers to 2018. 

r Refers to 2022. 

s Refers to 2008 based on UNESCO Institute for Statistics 

(2024). 

Definitions 

Gender Inequality Index:  A composite measure reflecting in -

equality in achievement between women and men in three di -

mensions: reproductive health, empowerment and the labour 

market. See  Technical note 4  at https: //hdr.undp.org/sites/default/ 

files/2025_HDR/hdr2025_technical_notes.pdf  for details on how 

the Gender Inequality Index is calculated. 

Maternal mortality ratio:  Number of deaths due to pregnancy-

related causes per 100,000 live births. 

Adolescent birth rate:  Number of births to women ages 15–19 

per 1,000 women ages 15–19. 

Share of seats in parliament:  Proportion of seats held by 

women in the national parliament expressed as a percentage 

of total seats. For countries with a bicameral legislative system, 

the share of seats is calculated based on both houses. 

Population with at least some secondary education:  Percentage 

of the population ages 25 and older that has reached (but not 

necessarily completed) a secondary level of education. 

Labour force participation rate:  Proportion of the working-

age population (ages 15 and older) that engages in the 

labour market, either by working or actively looking for work, 

expressed as a percentage of the working-age population. 

Main data sources 

Column 1:  HDRO calculations based on data in columns 3–9. 

Column 2:  Calculated based on data in column 1. 

Column 3:  WHO, UNICEF, UNFPA, World Bank Group and 

UNDESA/Population Division 2023. 

Column 4:  UNDESA 2024a. 

Column 5:  IPU 2024. 

Columns 6 and 7:  Barro and Lee 2018, UNESCO Institute for 

Statistics 2024 and UNICEF Multiple Indicator Cluster Surveys. 

Columns 8 and 9:  ILO 2024. 

3 0 1 TABLE 5 / GENDER INEQUALITY INDEX TABLE 6 

# Multidimensional Poverty Index: developing countries 

Country 

SDG 1.2  SDG 1.2  SDG 1.1 

Multidimensional 

Poverty Index a

Population in multidimensional poverty a

Population 

vulnerable to 

multidimensional 

poverty a

Contribution of deprivation 

in dimension to overall 

multidimensional poverty a

Population living below 

monetary  poverty  line 

(%) 

Intensity of 

deprivation 

Inequality 

among 

the poor 

Population 

in severe 

multidimensional 

poverty  Health  Education 

Standard 

of living 

National 

poverty 

line 

PPP $2.15 

a day 

Headcount 

Year and 

survey b (thousands) 

2012–2023  Value  (%) 

In survey 

year  2022  (%)  Value  (%)  (%)  (%)  (%)  (%)  2012–2023 c 2012–2023 c

Estimates based on surveys for 2018–2023 

Afghanistan  2022/2023 M  0.360  d 64.9  d 26,897  d 26,329  d 55.5  d 0.020  d 39.1  d 19.9  d 24.1  d 42.5  d 33.4  d 54.5  .. 

Albania  2017/2018 D  0.003  0.7  20  20  39.1  ..  e 0.1  5.0  28.3  55.1  16.7  22.0  0.0 

Algeria  2018/2019 M  0.005  1.4  598  628  39.2  0.007  0.2  3.6  31.2  49.3  19.5  ..  .. 

Argentina  2019/2020 M  f 0.001  g 0.4  g 195  g 196  g 34.0  g ..  e 0.0  g 1.6  g 69.7  g 21.4  g 8.9  g 39.2  0.6 

Bangladesh  2019 M  0.104  24.6  40,636  41,737  42.2  0.010  6.5  18.2  17.3  37.6  45.1  18.7  5.0 

Benin  2021/2022 M  0.290  55.9  7,695  7,695  51.8  0.021  30.8  17.8  18.9  38.8  42.3  38.5  12.7 

Bhutan  2022 N  0.039  g,h  9.8  g,h  76  g,h  76  g,h  39.4  g,h  0.008  g,h  1.6  g,h  8.3  g,h  65.4  g,h  17.5  g,h  17.1  g,h  12.4  0.0 

Burkina Faso  2021 D  0.343  64.5  14,181  14,513  53.2  0.022  38.3  15.8  19.6  39.2  41.1  43.2  25.3 

Cambodia  2021/2022 D  0.070  16.6  2,863  2,863  42.3  0.009  4.1  20.5  21.5  48.0  30.5  17.7  .. 

Cameroon  2018 D  0.232  43.6  10,814  12,046  53.2  0.026  24.6  17.6  25.2  27.6  47.1  37.5  23.0 

Central African Republic  2018/2019 M  0.461  80.4  3,976  4,100  57.4  0.025  55.8  12.9  20.2  27.8  52.0  68.8  65.7 

Chad  2019 M  0.517  84.2  14,045  15,535  61.4  0.024  64.6  10.7  19.1  36.6  44.3  42.3  30.8 

Comoros  2022 M  0.084  19.2  160  160  43.9  0.013  5.7  19.4  22.7  34.4  42.9  42.4  18.6 

Congo (Democratic Republic of the)  2017/2018 M  0.331  64.5  58,097  66,064  51.3  0.020  36.8  17.4  23.1  19.9  57.0  63.9  78.9 

Costa Rica  2018 M  0.002  d,g  0.5  d,g  27  d,g  27  d,g  37.1  d,g  ..  e 0.0  d,g  2.4  d,g  40.5  d,g  41.0  d,g  18.5  d,g  25.5  0.9 

Côte d’Ivoire  2021 D  0.210  42.8  12,678  13,001  49.1  0.018  19.7  19.6  21.3  42.1  36.6  37.5  9.7 

Cuba  2019 M  0.003  g 0.7  g 79  g 78  g 38.1  g ..  e 0.1  g 2.7  g 10.1  g 39.8  g 50.1  g ..  .. 

Dominican Republic  2019 M  0.009  2.3  247  255  38.8  0.006  0.2  4.8  14.6  46.2  39.2  23.9  0.8 

Ecuador  2018 N  0.008  2.1  357  373  38.0  0.004  0.1  5.9  33.9  27.3  38.8  25.2  3.2 

Eswatini (Kingdom of)  2021/2022 M  0.033  d 7.9  d 96  d 96  d 41.3  d 0.008  d 1.3  d 19.0  d 31.1  d 28.6  d 40.3  d 58.9  36.1 

Ethiopia  2019 D  0.367  68.7  79,554  86,185  53.3  0.022  41.9  18.4  14.0  31.5  54.5  23.5  27.0 

Fiji  2021 M  0.006  1.5  14  14  38.1  ..  e 0.2  7.4  38.0  17.4  44.6  24.1  1.3 

Gabon  2019/2021 D  0.037  8.6  206  210  42.4  0.010  2.3  14.9  34.6  24.4  41.0  33.4  2.5 

Gambia  2019/2020 D  0.198  41.7  1,049  1,100  47.5  0.016  17.3  28.0  32.7  33.0  34.3  53.4  17.2 

Georgia  2018 M  0.001  g 0.3  g 13  g 13  g 36.6  g ..  e 0.0  g 2.1  g 47.1  g 23.8  g 29.1  g 15.6  5.5 

Ghana  2022 D  0.113  24.8  8,221  8,221  45.5  0.016  8.4  20.0  25.1  28.9  46.0  23.4  25.2 

Guinea  2018 D  0.373  66.2  8,412  9,306  56.4  0.025  43.5  16.4  21.4  38.4  40.3  43.7  13.8 

Guinea-Bissau  2018/2019 M  0.341  64.4  1,267  1,356  52.9  0.021  35.9  20.0  19.1  35.0  45.8  47.7  26.0 

Guyana  2019/2020 M  0.007  i 1.8  i 15  i 15  i 39.3  i 0.007  i 0.2  i 6.5  i 30.4  i 22.4  i 47.2  i ..  .. 

Honduras  2019 M  0.051  12.0  1,191  1,253  42.7  0.011  3.0  14.8  18.8  39.2  42.0  48.0  12.7 

India  2019/2021 D  0.069  16.4  231,828  233,667  42.0  0.010  4.2  18.7  32.2  28.2  39.7  ..  12.9 

Iraq  2018 M  0.033  8.6  3,477  3,806  37.9  0.005  1.3  5.2  33.1  60.9  6.0  18.9  0.1 

Jamaica  2018 N  0.011  j 2.8  j 78  j 79  j 38.9  j 0.005  j 0.2  j 5.0  j 52.2  j 20.9  j 26.9  j 19.9  0.3 

Jordan  2017/2018 D  0.002  0.4  45  49  35.4  ..  e 0.0  0.7  37.5  53.5  9.0  15.7  .. 

Kenya  2022 D  0.113  25.4  13,754  13,754  44.7  0.015  7.5  26.4  25.6  15.6  58.8  36.1  36.1 

Kiribati  2018/2019 M  0.080  19.8  25  26  40.5  0.006  3.5  30.2  30.3  12.1  57.6  21.9  1.7 

Kyrgyzstan  2018 M  0.001  0.4  25  27  36.3  ..  e 0.0  5.2  64.6  17.9  17.5  33.3  0.7 

Lesotho  2018 M  0.084  d 19.6  d 428  d 448  d 43.0  d 0.009  d 5.0  d 28.6  d 21.9  d 18.1  d 60.0  d 49.7  32.4 

Liberia  2019/2020 D  0.259  52.3  2,694  2,811  49.6  0.018  24.9  23.3  19.7  28.6  51.7  50.9  27.6 

Madagascar  2021 D  0.386  68.4  20,314  20,825  56.4  0.026  45.8  15.4  17.8  31.6  50.6  70.7  80.7 

Malawi  2019/2020 M  0.231  49.9  9,744  10,260  46.3  0.012  17.5  27.5  18.6  25.5  55.9  50.7  70.1 

Mali  2018 D  0.376  68.3  13,968  15,766  55.0  0.022  44.7  15.3  19.6  41.2  39.3  44.6  20.8 

Mauritania  2019/2021 D  0.327  58.4  2,767  2,850  56.0  0.024  38.0  12.3  17.7  42.4  39.9  31.8  5.4 

Mexico  2022 N  0.020  k,l  5.0  k,l  6,434  k,l  6,434  k,l  39.8  k,l  0.006  k,l  0.9  k,l  3.1  k,l  62.7  k,l  12.8  k,l  24.4  k,l  36.3  1.2 

Mongolia  2018 M  0.028  m 7.3  m 230  m 246  m 38.8  m 0.004  m 0.8  m 15.5  m 21.1  m 26.8  m 52.1  m 27.8  0.2 

Montenegro  2018 M  0.005  1.2  8 8 39.6  ..  e 0.1  2.9  58.5  22.3  19.2  20.3  2.0 

Morocco  2017/2018 P  0.027  n 6.4  n 2,279  n 2,374  n 42.0  n 0.012  n 1.4  n 10.9  n 24.4  n 46.8  n 28.8  n 4.8  1.4 

Mozambique  2022/2023 D  0.334  60.7  20,407  19,813  55.1  0.022  38.8  16.9  17.3  33.2  49.5  46.1  74.5 

Nepal  2022 D  0.085  20.1  5,963  5,963  42.5  0.011  5.5  20.2  28.8  30.6  40.6  ..  .. 

Nigeria  2021 M  0.175  h,o  33.0  h,o  72,211  h,o  73,738  h,o  52.9  h,o  0.027  h,o  18.1  h,o  16.6  h,o  19.5  h,o  35.5  h,o  45.0  h,o  40.1  30.9 

North Macedonia  2018/2019 M  0.001  0.4  7 7 38.2  ..  e 0.1  2.2  29.6  52.6  17.8  21.8  2.7 

Pakistan  2017/2018 D  0.198  38.3  86,987  93,416  51.7  0.023  21.5  12.9  27.6  41.3  31.1  21.9  4.9 

Palestine, State of  2019/2020 M  0.002  0.6  29  30  35.0  ..  e 0.0  1.3  62.9  31.0  6.1  29.2  0.5 

Papua New Guinea  2016/2018 D  0.263  h 56.6  h 5,320  h 5,778  h 46.5  h 0.016  h 25.8  h 25.3  h 4.6  h 30.1  h 65.3  h ..  .. 

Peru  2022 N  0.025  6.4  2,136  2,136  38.9  0.006  0.9  10.0  15.5  32.7  51.9  27.5  2.7 

Philippines  2022 D  0.016  h 3.9  h 4,429  h 4,429  h 40.6  h 0.008  h 0.7  h 5.2  h 24.6  h 32.7  h 42.7  h 18.1  3.0 

Rwanda  2019/2020 D  0.231  48.8  6,379  6,665  47.3  0.014  19.7  22.7  19.0  26.6  54.4  38.2  52.0 

Samoa  2019/2020 M  0.025  6.3  13  14  39.1  0.003  0.5  12.9  36.9  31.2  31.9  21.9  1.2 

Sao Tome and Principe  2019 M  0.048  11.7  25  27  40.9  0.007  2.1  17.0  18.7  36.6  44.6  55.5  15.7 

Senegal  2019 D  0.263  50.8  8,313  8,972  51.7  0.019  27.7  18.2  20.7  48.4  30.9  ..  9.9 

Continued → 

3 02 HUMAN DEVELOPMENT REPORT 2025 Country 

SDG 1.2  SDG 1.2  SDG 1.1 

Multidimensional 

Poverty Index a

Population in multidimensional poverty a

Population 

vulnerable to 

multidimensional 

poverty a

Contribution of deprivation 

in dimension to overall 

multidimensional poverty a

Population living below 

monetary  poverty  line 

(%) 

Intensity of 

deprivation 

Inequality 

among 

the poor 

Population 

in severe 

multidimensional 

poverty  Health  Education 

Standard 

of living 

National 

poverty 

line 

PPP $2.15 

a day 

Headcount 

Year and 

survey b (thousands) 

2012–2023  Value  (%) 

In survey 

year  2022  (%)  Value  (%)  (%)  (%)  (%)  (%)  2012–2023 c 2012–2023 c

Serbia  2019 M  0.000  g,p  0.1  g,p  8 g,p  8 g,p  38.1  g,p  ..  e 0.0  g,p  2.1  g,p  30.9  g,p  40.1  g,p  29.0  g,p  20.0  1.2 

Seychelles  2019 N  0.003  d,q  0.9  d,q  1 d,q  1 d,q  34.2  d,q  ..  e 0.0  d,q  0.4  d,q  66.8  d,q  32.1  d,q  1.1  d,q  25.3  0.5 

Sierra Leone  2019 D  0.293  59.2  4,579  4,902  49.5  0.019  28.0  21.3  23.0  24.1  53.0  56.8  26.1 

Suriname  2018 M  0.011  2.9  17  18  39.4  0.007  0.4  4.0  20.4  43.8  35.8  ..  1.1 

Tanzania (United Republic of)  2022 D  0.221  47.2  30,554  30,554  46.9  0.014  18.3  23.1  24.2  22.6  53.2  26.4  44.9 

Thailand  2022 M  0.002  g 0.5  g 352  g 352  g 37.0  g 0.003  g 0.0  g 4.7  g 31.2  g 54.0  g 14.7  g 6.3  0.0 

Tonga  2019 M  0.003  0.9  1 1 38.1  ..  e 0.0  6.4  38.2  40.7  21.1  20.6  0.0 

Trinidad and Tobago  2022 M  0.002  h 0.5  h 8 h 8 h 38.8  h 0.005  h 0.1  h 0.8  h 64.2  h 23.7  h 12.1  h ..  .. 

Tunisia  2023 M  0.003  1.0  119  118  35.2  0.002  0.0  2.8  28.1  61.8  10.1  16.6  0.3 

Turkmenistan  2019 M  0.001  d 0.2  d 17  d 18  d 34.0  d ..  e 0.0  d 0.3  d 82.4  d 15.5  d 2.1  d ..  .. 

Tuvalu  2019/2020 M  0.008  2.1  0 0 38.2  0.002  0.0  12.2  36.5  43.6  20.0  ..  .. 

Uzbekistan  2021/2022 M  0.006  h,r  1.7  h,r  604  h,r  604  h,r  35.3  h,r  0.001  h,r  0.0  h,r  0.2  h,r  94.5  h,r  0.0  h,r  5.5  h,r  14.1  2.3 

Viet Nam  2020/2021 M  0.008  h 1.9  h 1,899  h 1,913  h 40.3  h 0.010  h 0.4  h 3.5  h 22.9  h 40.7  h 36.4  h 4.3  1.0 

Yemen  2022/2023 M  0.188  s 37.4  s 14,740  s 14,303  s 50.2  s 0.019  s 17.0  s 22.5  s 28.4  s 31.7  s 39.9  s 48.6  19.8 

Zambia  2018 D  0.232  47.9  8,610  9,654  48.4  0.015  21.0  23.9  21.5  25.0  53.5  60.0  64.3 

Zimbabwe  2019 M  0.110  25.8  3,940  4,146  42.6  0.009  6.8  26.3  23.6  17.3  59.2  38.3  39.8 

Estimates based on surveys for 2012–2017 

Angola  2015/2016 D  0.282  51.1  14,914  18,211  55.3  0.024  32.5  15.5  21.2  32.1  46.8  32.3  31.1 

Armenia  2015/2016 D  0.001  t 0.2  t 6 t 5 t 36.2  t ..  e 0.0  t 2.8  t 33.1  t 36.8  t 30.1  t 24.8  0.8 

Barbados  2012 M  0.009  j 2.5  j 7 j 7 j 34.2  j ..  e 0.0  j 0.5  j 96.0  j 0.7  j 3.3  j ..  .. 

Belize  2015/2016 M  0.017  4.3  16  17  39.8  0.007  0.6  8.4  39.5  20.9  39.6  ..  .. 

Bolivia (Plurinational State of)  2016 N  0.038  9.1  1,013  1,094  41.7  0.008  1.9  12.1  18.7  31.5  49.8  36.4  2.0 

Bosnia and Herzegovina  2011/2012 M  0.008  j 2.2  j 80  j 70  j 37.9  j 0.002  j 0.1  j 4.1  j 79.7  j 7.2  j 13.1  j 16.9  .. 

Botswana  2015/2016 N  0.073  u 17.2  u 385  u 420  u 42.2  u 0.008  u 3.5  u 19.7  u 30.3  u 16.5  u 53.2  u 16.1  15.4 

Brazil  2015 N  v 0.016  g,h,v  3.8  g,h,v  7,748  g,h,v  8,080  g,h,v  42.5  g,h,v  0.008  g,h,v  0.9  g,h,v  6.2  g,h,v  49.8  g,h,v  22.9  g,h,v  27.3  g,h,v  ..  3.5 

Burundi  2016/2017 D  0.409  t 75.1  t 8,641  t 10,004  t 54.4  t 0.022  t 46.1  t 15.8  t 23.8  t 27.2  t 49.0  t 64.9  62.1 

China  2014 N  w 0.016  s,x  3.9  s,x  53,922  s,x  55,369  s,x  41.4  s,x  0.005  s,x  0.3  s,x  17.4  s,x  35.2  s,x  39.2  s,x  25.6  s,x  0.0  0.1 

Colombia  2015/2016 D  0.020  h 4.8  h 2,299  h 2,507  h 40.6  h 0.009  h 0.8  h 6.2  h 12.0  h 39.5  h 48.5  h 36.6  6.0 

Congo  2014/2015 M  0.112  24.3  1,237  1,465  46.0  0.013  9.4  21.3  23.4  20.2  56.4  ..  .. 

Egypt  2014 D  0.020  d,t  5.2  d,t  5,109  d,t  5,900  d,t  37.6  d,t  0.004  d,t  0.6  d,t  6.1  d,t  40.0  d,t  53.1  d,t  6.9  d,t  29.7  1.5 

El Salvador  2014 M  0.032  7.9  484  494  41.3  0.009  1.7  9.9  15.5  43.4  41.1  26.6  3.4 

Guatemala  2014/2015 D  0.134  28.9  4,613  5,155  46.2  0.013  11.2  21.1  26.3  35.0  38.7  59.3  9.5 

Haiti  2016/2017 D  0.200  41.3  4,464  4,747  48.4  0.019  18.5  21.8  18.5  24.6  57.0  58.5  29.2 

Indonesia  2017 D  0.014  h 3.6  h 9,675  h 10,091  h 38.7  h 0.006  h 0.4  h 4.7  h 34.7  h 26.8  h 38.5  h 9.4  1.9 

Kazakhstan  2015 M  0.002  g,t  0.5  g,t  82  g,t  91  g,t  35.6  g,t  ..  e 0.0  g,t  1.8  g,t  90.4  g,t  3.1  g,t  6.4  g,t  5.2  0.0 

Lao People’s Democratic Republic  2017 M  0.108  23.1  1,619  1,744  47.0  0.016  9.6  21.2  21.5  39.7  38.8  18.3  7.1 

Libya  2014 P  0.007  2.0  128  144  37.1  0.003  0.1  11.4  39.0  48.6  12.4  ..  .. 

Maldives  2016/2017 D  0.003  0.8  4 4 34.4  ..  e 0.0  4.8  80.7  15.1  4.2  5.4  0.0 

Moldova (Republic of)  2012 M  0.004  0.9  33  29  37.4  ..  e 0.1  3.7  9.2  42.4  48.4  31.1  0.0 

Myanmar  2015/2016 D  0.176  38.3  19,731  20,597  45.9  0.015  13.8  21.9  18.5  32.3  49.2  24.8  2.0 

Namibia  2013 D  0.185  t 40.9  t 921  t 1,181  t 45.2  t 0.013  t 13.1  t 19.2  t 31.6  t 13.9  t 54.4  t 17.4  15.6 

Nicaragua  2011/2012 D  0.074  t 16.5  t 971  t 1,108  t 45.3  t 0.013  t 5.6  t 13.4  t 11.5  t 36.2  t 52.3  t 24.9  3.9 

Niger  2012 D  0.601  t 91.0  t 16,226  t 23,027  t 66.1  t 0.026  t 76.3  t 4.9  t 21.4  t 36.7  t 41.8  t 40.8  50.6 

Paraguay  2016 M  0.019  4.5  281  304  41.9  0.013  1.0  7.2  14.3  38.9  46.8  24.7  1.3 

Saint Lucia  2012 M  0.007  j 1.9  j 3 j 3 j 37.5  j ..  e 0.0  j 1.6  j 69.5  j 7.5  j 23.0  j 0.3  0.1 

South Africa  2016 D  0.025  6.3  3,583  3,903  39.8  0.005  0.9  12.2  39.5  13.1  47.4  55.5  20.5 

Sri Lanka  2016 N  0.011  2.9  640  667  38.3  0.004  0.3  14.3  32.5  24.4  43.0  14.3  1.0 

Sudan  2014 M  0.279  52.3  20,315  25,841  53.4  0.023  30.9  17.7  21.1  29.2  49.8  ..  15.3 

Tajikistan  2017 D  0.029  7.4  676  758  39.0  0.004  0.7  20.1  47.8  26.5  25.8  22.5  6.1 

Timor-Leste  2016 D  0.222  t 48.3  t 593  t 661  t 45.9  t 0.014  t 17.4  t 26.8  t 29.3  t 23.1  t 47.6  t 41.8  24.4 

Togo  2017 M  0.180  37.6  3,030  3,419  47.8  0.016  15.2  23.8  20.9  28.1  50.9  45.5  26.6 

Uganda  2016 D  0.281  t 57.2  t 22,181  t 27,048  t 49.2  t 0.017  t 25.7  t 23.6  t 24.0  t 21.6  t 54.5  t 20.3  42.1 

Ukraine  2012 M  0.001  h,t  0.2  h,t  113  h,t  100  h,t  34.4  h,t  ..  e 0.0  h,t  0.4  h,t  60.5  h,t  28.4  h,t  11.2  h,t  1.6  0.0 

Developing countries  — 0.089  18.3  1,085,191  1,148,746  48.5  0.017  8.0  14.8  24.3  32.0  43.6  19.4  11.5 

Regions 

Arab States  — 0.072  14.7  46,840  53,193  48.9  0.018  6.5  9.2  25.7  34.6  39.7  25.9  5.8 

East Asia and the Pacific  — 0.021  5.0  100,687  104,097  42.4  0.008  0.9  14.2  28.4  36.0  35.7  3.6  0.6 

Europe and Central Asia  — 0.004  1.2  1,692  1,758  37.1  0.003  0.1  2.6  66.7  16.5  16.8  12.0  1.4 

Latin America and the Caribbean  — 0.025  5.8  32,683  34,389  42.9  0.010  1.5  6.4  34.3  27.0  38.7  36.2  3.6 

South Asia  — 0.094  20.8  393,030  401,859  45.2  0.014  7.3  17.9  28.8  33.8  37.4  23.1  11.0 

Sub-Saharan Africa  — 0.254  48.4  510,259  553,451  52.5  0.021  26.9  18.2  20.2  30.4  49.3  40.9  38.6 

TABLE 6 

3 0 3 TABLE 6 / MULTIDIMENSIONAL POVERTY INDEX: DEVELOPING COUNTRIES TABLE 6 

Notes 

a Not all indicators were available for all countries, so 

caution should be used in cross-country comparisons. 

When an indicator is missing, weights of available 

indicators are adjusted to total 100 percent. See 

Technical note 5 at  https://hdr.undp.org/sites/default/ 

files/2025_HDR/hdr2025_technical_notes.pdf .

b D indicates data from Demographic and Health Surveys, 

M indicates data from Multiple Indicator Cluster Surveys, 

N indicates data from national surveys and ˆ indicates 

data from Pan Arab Population and Family Health 

Surveys (see  https://hdr.undp.org/mpi-2024-faqs  and 

OPHI Methodological Note 58  at  https://ophi.org.uk  / 

publications/MN-58  for the list of national surveys). 

c Data refer to the most recent year available during the 

period specified. 

d Missing indicator on cooking fuel. 

e Value is not reported because it is based on a small 

number of multidimensionally poor people. 

f Urban areas only. 

g Considers child deaths that occurred at any time because 

the survey did not collect the date of child deaths. 

h Missing indicator on nutrition. 

i Revised estimate from the 2022 MPI based on the 

survey microdata update. 

j Missing indicator on child mortality. 

k Child mortality data were not used because the data 

were collected from a sample of women ages 15–49 that 

was not representative of the female population in that 

age group. 

l Anthropometric data were collected from all children 

under age 5 and from selected individuals who are age 

5 or older. Construction of the nutrition indicator was 

restricted to children under age 5 since the anthropometric 

sample is representative of the under 5 population. 

m Indicator on sanitation follows the national classification 

in which pit latrine with slab is considered unimproved. 

n Following the national report, latrines are considered an 

improved source for the sanitation indicator. 

o The analytical sample was restricted to the Multiple 

Indicator Cluster Survey sample, and its sample weight 

was used, because child mortality information was 

not collected for the National Immunization Coverage 

Survey sample. 

p Because of the high proportion of children excluded 

from nutrition indicators due to measurements not being 

taken, estimates based on the 2019 Serbia Multiple 

Indicator Cluster Survey should be interpreted with 

caution. The unweighted sample size used for the multi -

dimensional poverty calculation is 82.8 percent. 

q Missing indicator on school attendance. 

r The analytical sample was restricted to the round 2 

sample because standard of living questions were not 

collected for the round 1 sample. 

s Missing indicator on housing. 

t Revised estimate from the 2020 MPI. 

u Captures only deaths of children under age 5 who died 

in the last five years and deaths of children ages 12–18 

years who died in the last two years. 

v The methodology was adjusted to account for the 

missing indicator on nutrition and the incomplete 

indicator on child mortality (the survey did not collect the 

date of child deaths). 

w Based on the version of data accessed on 7 June 2016. 

x Given the information available in the data, child 

mortality was constructed based on deaths that 

occurred between surveys—that is, between 2012 and 

2014. Child deaths reported by an adult man in the 

household were taken into account because the date of 

death was reported. 

Definitions 

Multidimensional Poverty Index:  Proportion of the population 

that is multidimensionally poor adjusted by the intensity of the 

deprivations. 

Multidimensional poverty headcount:  Population with a

deprivation score of at least 33.3 percent. It is expressed as 

a share of the population in the survey year, the number of 

multidimensionally poor people in the survey year and the 

projected number of multidimensionally poor people in 2022. 

Intensity of deprivation of multidimensional poverty:  Average 

deprivation score experienced by people in multidimensional 

poverty. 

Inequality among the poor:  Variance of individual deprivation 

scores of poor people. It is calculated by subtracting the 

deprivation score of each multidimensionally poor person from 

the intensity, squaring the differences and dividing the sum 

of the weighted squares by the number of multidimensionally 

poor people. 

Population in severe multidimensional poverty:  Percentage 

of the population in severe multidimensional poverty—that is, 

those with a deprivation score of 50 percent or more. 

Population vulnerable to multidimensional poverty:  Percentage 

of the population at risk of suffering multiple deprivations—that 

is, those with a deprivation score of 20–33.3 percent. 

Contribution of deprivation in dimension to overall multi ‑

dimensional poverty:  Percentage of the Multidimensional 

Poverty Index attributed to deprivations in each dimension. 

Population living below national poverty line:  Percentage of 

the population living below the national poverty line, which 

is the poverty line deemed appropriate for a country by its 

authorities. National estimates are based on population-

weighted subgroup estimates from household surveys. 

Population living below PPP $2.15 a day:  Percentage of the 

population living below the international poverty line of $2.15 (in 

2017 purchasing power parity [PPP] terms) a day. 

Main data sources 

Column 1:  Refers to the year and the survey whose data were 

used to calculate the country’s Multidimensional Poverty Index 

value and its components. 

Columns 2–12:  HDRO and OPHI calculations based on data on 

household deprivations in health, education, and standard of liv -

ing from various surveys listed in column 1 using the methodol -

ogy described in  Technical note 5  at  https: //hdr.undp.org/sites/ 

default/files/2025_HDR/hdr2025_technical_notes.pdf .

Column 4 and 5:  Population data from UNDESA (2024b). 

Columns 13 and 14:  World Bank 2024b. 

3 0 4 HUMAN DEVELOPMENT REPORT 2025 HDI RANK 

Human 

Development 

Index (HDI)  Planetary pressures–adjusted HDI (PHDI) 

SDG 9.4  SDG 8.4, 12.2 

Adjustment factor 

for planetary 

pressures 

Carbon dioxide 

emissions per 

capita (production) 

Carbon dioxide 

emissions 

(production) index 

Material footprint 

per capita 

Material 

footprint index 

Difference from 

HDI value a (%) 

Difference from 

HDI rank a

Value  Value  Value  (tonnes)  Value  (tonnes)  Value 

2023  2023  2023  2023  2023  2023  2023  2023  2023 

Very high human development 

1 Iceland  0.972  0.735  24.4  –40  0.756  10.0  0.869  32.2  0.643 

2 Norway  0.970  0.723  25.5  –49  0.746  7.1  0.907  37.5  0.584 

2 Switzerland  0.970  0.732  24.5  –41  0.755  3.7  0.951  39.8  0.559 

4 Denmark  0.962  0.792  17.7  –6  0.824  4.6  0.940  26.4  0.708 

5 Germany  0.959  0.785  18.1  –9  0.819  7.2  0.907  24.3  0.730 

5 Sweden  0.959  0.810  15.5  2 0.845  3.4  0.955  24.0  0.734 

7 Australia  0.958  0.700  26.9  –59  0.731  14.5  0.811  31.5  0.651 

8 Hong Kong, China (SAR)  0.955  ..  ..  ..  ..  4.5  0.941  ..  .. 

8 Netherlands  0.955  0.740  22.5  –27  0.775  6.7  0.912  32.7  0.638 

10  Belgium  0.951  0.666  30.0  –76  0.700  7.1  0.907  45.7  0.494 

11  Ireland  0.949  0.752  20.8  –20  0.793  6.8  0.911  29.4  0.674 

12  Finland  0.948  0.748  21.1  –22  0.789  5.7  0.926  31.4  0.652 

13  Singapore  0.946  0.618  34.7  –90  0.653  8.2  0.893  53.0  0.412 

13  United Kingdom  0.946  0.827  12.6  11  0.875  4.5  0.941  17.3  0.808 

15  United Arab Emirates  0.940  0.585  37.8  –97  0.622  24.1  0.685  39.8  0.559 

16  Canada  0.939  0.643  31.5  –79  0.684  14.2  0.815  40.3  0.554 

17  Liechtenstein  0.938  ..  ..  ..  ..  4.0  0.948  ..  .. 

17  New Zealand  0.938  0.731  22.1  –28  0.779  5.8  0.925  33.1  0.634 

17  United States  0.938  0.686  26.9  –57  0.731  14.4  0.811  31.5  0.651 

20  Korea (Republic of)  0.937  0.745  20.5  –16  0.795  11.2  0.854  23.9  0.736 

21  Slovenia  0.931  0.791  15.0  7 0.850  5.3  0.930  20.8  0.769 

22  Austria  0.930  0.757  18.6  –3  0.814  6.5  0.915  25.8  0.714 

23  Japan  0.925  0.785  15.1  7 0.849  8.0  0.895  17.9  0.802 

24  Malta  0.924  0.799  13.5  14  0.864  3.4  0.956  20.5  0.773 

25  Luxembourg  0.922  0.479  48.0  –122  0.519  10.7  0.861  74.2  0.178 

26  France  0.920  0.804  12.6  20  0.874  4.2  0.945  17.7  0.804 

27  Israel  0.919  0.709  22.9  –34  0.772  6.5  0.915  33.6  0.628 

28  Spain  0.918  0.818  10.9  24  0.891  4.7  0.939  14.2  0.843 

29  Czechia  0.915  0.764  16.5  7 0.835  8.2  0.894  20.2  0.776 

29  Italy  0.915  0.801  12.5  20  0.876  5.3  0.930  16.2  0.821 

29  San Marino  0.915  ..  ..  ..  ..  ..  ..  ..  .. 

32  Andorra  0.913  ..  ..  ..  ..  5.3  0.931  ..  .. 

32  Cyprus  0.913  0.754  17.4  2 0.826  5.7  0.926  24.7  0.726 

34  Greece  0.908  0.803  11.6  24  0.884  5.3  0.930  14.6  0.838 

35  Poland  0.906  0.792  12.6  21  0.874  7.1  0.908  14.5  0.840 

36  Estonia  0.905  0.714  21.1  –23  0.789  7.6  0.901  29.1  0.677 

37  Saudi Arabia  0.900  0.666  26.0  –52  0.740  19.9  0.740  23.5  0.739 

38  Bahrain  0.899  0.632  29.7  –63  0.703  24.6  0.679  24.6  0.728 

39  Lithuania  0.895  0.751  16.1  4 0.840  4.6  0.940  23.6  0.739 

40  Portugal  0.890  0.797  10.4  27  0.896  3.6  0.953  14.5  0.839 

41  Croatia  0.889  0.787  11.5  24  0.886  4.4  0.943  15.5  0.828 

41  Latvia  0.889  0.749  15.7  5 0.843  3.6  0.954  24.2  0.732 

43  Qatar  0.886  0.276  68.8  –117  0.311  42.6  0.444  74.1  0.179 

44  Slovakia  0.880  0.770  12.5  21  0.875  5.3  0.931  16.3  0.819 

45  Chile  0.878  0.784  10.7  25  0.893  3.9  0.949  14.6  0.838 

46  Hungary  0.870  0.757  13.0  19  0.870  4.0  0.948  18.8  0.792 

47  Argentina  0.865  0.763  11.8  22  0.882  4.3  0.944  16.3  0.819 

48  Montenegro  0.862  ..  ..  ..  ..  3.7  0.951  ..  .. 

48  Uruguay  0.862  0.804  6.7  40  0.933  2.3  0.970  9.5  0.895 

50  Oman  0.858  0.581  32.3  –69  0.677  16.9  0.779  38.5  0.574 

51  Türkiye  0.853  0.729  14.5  1 0.854  5.0  0.934  20.4  0.774 

52  Kuwait  0.852  0.531  37.7  –82  0.624  23.0  0.699  40.8  0.548 

53  Antigua and Barbuda  0.851  ..  ..  ..  ..  6.8  0.911  ..  .. 

54  Seychelles  0.848  ..  ..  ..  ..  5.1  0.933  ..  .. 

55  Bulgaria  0.845  0.740  12.4  13  0.875  5.4  0.930  16.2  0.821 

55  Romania  0.845  0.739  12.5  10  0.874  3.4  0.955  18.6  0.794 

57  Georgia  0.844  0.772  8.5  32  0.915  3.2  0.959  11.6  0.871 

58  Saint Kitts and Nevis  0.840  ..  ..  ..  ..  4.9  0.936  ..  .. 

59  Panama  0.839  0.643  23.4  –43  0.766  3.1  0.959  38.5  0.573 

TABLE 7 

# Planetary pressures–adjusted Human Development Index 

Continued → 

3 0 5 TABLE 7 / PLANETARY PRESSURES–ADJUSTED HUMAN DEVELOPMENT INDEX Continued → 

TABLE 7                  

> HDI RANK
> Human
> Development
> Index (HDI) Planetary pressures–adjusted HDI (PHDI)
> SDG 9.4 SDG 8.4, 12.2
> Adjustment factor
> for planetary
> pressures
> Carbon dioxide
> emissions per
> capita (production)
> Carbon dioxide
> emissions
> (production) index
> Material footprint
> per capita
> Material
> footprint index
> Difference from
> HDI value a(%)
> Difference from
> HDI rank a
> Value Value Value (tonnes) Value (tonnes) Value
> 2023 2023 2023 2023 2023 2023 2023 2023 2023

60  Brunei Darussalam  0.837  0.600  28.3  –55  0.717  26.0  0.661  20.4  0.774 

60  Kazakhstan  0.837  0.687  17.9  –20  0.820  13.0  0.830  17.1  0.811 

62  Costa Rica  0.833  0.774  7.1  37  0.929  1.6  0.979  11.0  0.878 

62  Serbia  0.833  0.724  13.1  4 0.869  5.9  0.923  16.7  0.815 

64  Russian Federation  0.832  0.710  14.7  –2  0.853  12.6  0.836  11.7  0.871 

65  Belarus  0.824  ..  ..  ..  ..  5.9  0.922  ..  .. 

66  Bahamas  0.820  0.712  13.2  0 0.868  6.1  0.921  16.7  0.815 

67  Malaysia  0.819  0.677  17.3  –21  0.827  8.4  0.890  21.4  0.763 

68  North Macedonia  0.815  0.754  7.5  32  0.925  3.6  0.953  9.3  0.897 

69  Armenia  0.811  0.761  6.2  38  0.938  2.7  0.964  8.0  0.912 

69  Barbados  0.811  ..  ..  ..  ..  4.2  0.945  ..  .. 

71  Albania  0.810  0.755  6.8  35  0.933  1.8  0.976  10.0  0.889 

72  Trinidad and Tobago  0.807  ..  ..  ..  ..  22.4  0.708  ..  .. 

73  Mauritius  0.806  ..  ..  ..  ..  3.2  0.958  ..  .. 

74  Bosnia and Herzegovina  0.804  0.701  12.8  –3  0.872  6.3  0.918  15.7  0.826 

High human development 

75  Iran (Islamic Republic of)  0.799  0.725  9.3  14  0.907  9.2  0.880  5.9  0.934 

76  Saint Vincent and the Grenadines  0.798  ..  ..  ..  ..  2.3  0.970  ..  .. 

76  Thailand  0.798  0.726  9.0  18  0.910  3.7  0.952  11.9  0.869 

78  China  0.797  0.644  19.2  –27  0.808  8.3  0.891  24.9  0.724 

79  Peru  0.794  0.757  4.7  43  0.953  1.6  0.979  6.6  0.927 

80  Grenada  0.791  ..  ..  ..  ..  2.7  0.965  ..  .. 

81  Azerbaijan  0.789  0.737  6.6  27  0.934  4.2  0.945  6.9  0.924 

81  Mexico  0.789  0.721  8.6  14  0.914  3.8  0.951  11.2  0.876 

83  Colombia  0.788  0.740  6.1  34  0.939  2.0  0.974  8.6  0.905 

84  Brazil  0.786  0.702  10.7  7 0.893  2.2  0.971  16.6  0.816 

84  Palau  0.786  ..  ..  ..  ..  12.3  0.839  ..  .. 

86  Moldova (Republic of)  0.785  0.738  6.0  32  0.940  1.7  0.977  8.8  0.903 

87  Ukraine  0.779  0.717  8.0  18  0.920  3.7  0.952  10.0  0.889 

88  Ecuador  0.777  0.735  5.4  32  0.946  2.4  0.969  6.9  0.923 

89  Dominican Republic  0.776  0.726  6.4  28  0.936  2.8  0.963  8.3  0.908 

89  Guyana  0.776  ..  ..  ..  ..  4.4  0.943  ..  .. 

89  Sri Lanka  0.776  0.754  2.8  47  0.971  0.9  0.988  4.1  0.955 

92  Tonga  0.769  ..  ..  ..  ..  1.8  0.976  ..  .. 

93  Maldives  0.766  ..  ..  ..  ..  4.0  0.948  ..  .. 

93  Viet Nam  0.766  0.699  8.7  9 0.913  3.4  0.956  11.7  0.870 

95  Turkmenistan  0.764  0.667  12.7  –7  0.874  9.7  0.873  11.4  0.874 

96  Algeria  0.763  0.706  7.5  18  0.926  3.9  0.949  8.8  0.902 

97  Cuba  0.762  0.723  5.1  28  0.949  2.1  0.973  6.8  0.924 

98  Dominica  0.761  ..  ..  ..  ..  2.2  0.971  ..  .. 

99  Paraguay  0.756  0.689  8.9  9 0.912  1.2  0.985  14.6  0.839 

100  Egypt  0.754  0.726  3.7  35  0.963  2.4  0.969  3.9  0.956 

100  Jordan  0.754  0.714  5.3  26  0.947  1.9  0.976  7.4  0.918 

102  Lebanon  0.752  0.691  8.1  13  0.919  3.6  0.953  10.3  0.886 

103  Saint Lucia  0.748  ..  ..  ..  ..  2.8  0.963  ..  .. 

104  Mongolia  0.747  0.577  22.8  –31  0.773  13.6  0.823  25.0  0.723 

105  Tunisia  0.746  0.703  5.8  23  0.942  2.6  0.966  7.3  0.919 

106  South Africa  0.741  0.685  7.6  11  0.924  6.7  0.913  5.8  0.936 

107  Uzbekistan  0.740  0.702  5.1  24  0.949  3.5  0.954  5.1  0.944 

108  Bolivia (Plurinational State of)  0.733  0.675  7.9  8 0.921  1.9  0.975  12.1  0.866 

108  Gabon  0.733  0.704  4.0  27  0.961  2.2  0.971  4.4  0.951 

108  Marshall Islands  0.733  ..  ..  ..  ..  3.7  0.952  ..  .. 

111  Botswana  0.731  0.698  4.5  21  0.954  2.5  0.967  5.3  0.941 

111  Fiji  0.731  ..  ..  ..  ..  1.2  0.984  ..  .. 

113  Indonesia  0.728  0.684  6.0  15  0.940  2.6  0.966  7.7  0.915 

114  Suriname  0.722  ..  ..  ..  ..  4.2  0.945  ..  .. 

115  Belize  0.721  0.670  7.1  10  0.929  1.6  0.979  10.9  0.879 

115  Libya  0.721  0.629  12.8  –7  0.872  8.9  0.884  12.7  0.859 

117  Jamaica  0.720  0.686  4.7  21  0.953  2.7  0.965  5.2  0.942 

117  Kyrgyzstan  0.720  0.699  2.9  27  0.971  1.5  0.980  3.4  0.962 

3 0 6 HUMAN DEVELOPMENT REPORT 2025 Continued →                  

> HDI RANK
> Human
> Development
> Index (HDI) Planetary pressures–adjusted HDI (PHDI)
> SDG 9.4 SDG 8.4, 12.2
> Adjustment factor
> for planetary
> pressures
> Carbon dioxide
> emissions per
> capita (production)
> Carbon dioxide
> emissions
> (production) index
> Material footprint
> per capita
> Material
> footprint index
> Difference from
> HDI value a(%)
> Difference from
> HDI rank a
> Value Value Value (tonnes) Value (tonnes) Value
> 2023 2023 2023 2023 2023 2023 2023 2023 2023

117  Philippines  0.720  0.680  5.6  17  0.944  1.3  0.983  8.6  0.905 

120  Morocco  0.710  0.679  4.4  19  0.956  1.8  0.976  5.8  0.935 

121  Venezuela (Bolivarian Republic of)  0.709  0.652  8.0  7 0.920  3.5  0.955  10.4  0.885 

122  Samoa  0.708  ..  ..  ..  ..  1.1  0.985  ..  .. 

123  Nicaragua  0.706  0.668  5.4  16  0.946  0.8  0.990  8.8  0.902 

124  Nauru  0.703  ..  ..  ..  ..  4.5  0.941  ..  .. 

Medium human development 

125  Bhutan  0.698  0.593  15.0  –8  0.849  2.2  0.972  24.7  0.727 

126  Eswatini (Kingdom of)  0.695  ..  ..  ..  ..  0.9  0.988  ..  .. 

126  Iraq  0.695  0.665  4.3  13  0.957  3.9  0.949  3.2  0.964 

128  Tajikistan  0.691  0.673  2.6  21  0.974  0.9  0.988  3.6  0.960 

129  Tuvalu  0.689  ..  ..  ..  ..  1.0  0.987  ..  .. 

130  Bangladesh  0.685  0.666  2.8  18  0.972  0.7  0.991  4.3  0.952 

130  India  0.685  0.656  4.2  14  0.957  2.1  0.972  5.2  0.942 

132  El Salvador  0.678  0.638  5.9  9 0.941  1.3  0.983  9.1  0.899 

133  Equatorial Guinea  0.674  0.644  4.5  14  0.955  3.6  0.953  3.9  0.957 

133  Palestine, State of  0.674  0.653  3.1  16  0.969  0.7  0.992  4.9  0.946 

135  Cabo Verde  0.668  ..  ..  ..  ..  0.9  0.988  ..  .. 

136  Namibia  0.665  0.611  8.1  5 0.918  1.6  0.979  12.8  0.858 

137  Guatemala  0.662  0.626  5.4  9 0.946  1.1  0.985  8.5  0.906 

138  Congo  0.649  0.631  2.8  12  0.973  1.3  0.984  3.5  0.962 

139  Honduras  0.645  0.620  3.9  10  0.961  1.0  0.986  5.9  0.935 

140  Kiribati  0.644  ..  ..  ..  ..  0.5  0.993  ..  .. 

141  Sao Tome and Principe  0.637  ..  ..  ..  ..  0.7  0.991  ..  .. 

142  Timor-Leste  0.634  ..  ..  ..  ..  0.5  0.994  ..  .. 

143  Ghana  0.628  0.604  3.8  7 0.962  0.6  0.992  6.2  0.932 

143  Kenya  0.628  0.610  2.9  8 0.971  0.4  0.995  4.8  0.946 

145  Nepal  0.622  0.592  4.8  4 0.952  0.5  0.993  7.9  0.912 

146  Vanuatu  0.621  ..  ..  ..  ..  0.7  0.991  ..  .. 

147  Lao People's Democratic Republic  0.617  0.570  7.6  –3  0.923  3.2  0.958  10.0  0.889 

148  Angola  0.616  0.604  1.9  11  0.980  0.6  0.993  2.9  0.967 

149  Micronesia (Federated States of)  0.615  ..  ..  ..  ..  1.3  0.983  ..  .. 

150  Myanmar  0.609  0.593  2.6  9 0.973  0.6  0.993  4.2  0.953 

151  Cambodia  0.606  0.572  5.6  1 0.944  1.2  0.984  8.7  0.903 

152  Comoros  0.603  ..  ..  ..  ..  0.5  0.993  ..  .. 

153  Zimbabwe  0.598  0.585  2.2  8 0.978  0.7  0.991  3.1  0.965 

154  Zambia  0.595  0.585  1.7  9 0.983  0.4  0.995  2.7  0.970 

155  Cameroon  0.588  0.574  2.4  5 0.976  0.3  0.995  4.0  0.956 

156  Solomon Islands  0.584  ..  ..  ..  ..  0.4  0.995  ..  .. 

157  Côte d'Ivoire  0.582  0.537  7.7  –6  0.922  0.5  0.994  13.5  0.850 

157  Uganda  0.582  0.569  2.2  3 0.978  0.1  0.998  3.9  0.957 

159  Rwanda  0.578  0.567  1.9  4 0.980  0.1  0.999  3.4  0.962 

160  Papua New Guinea  0.576  0.566  1.7  4 0.982  0.8  0.989  2.3  0.974 

161  Togo  0.571  0.562  1.6  4 0.984  0.3  0.996  2.5  0.972 

162  Syrian Arab Republic  0.564  0.553  2.0  4 0.981  1.1  0.986  2.2  0.976 

163  Mauritania  0.563  0.542  3.7  2 0.962  0.9  0.988  5.8  0.936 

164  Nigeria  0.560  0.548  2.1  5 0.979  0.6  0.993  3.2  0.965 

165  Tanzania (United Republic of)  0.555  0.541  2.5  3 0.975  0.3  0.997  4.3  0.953 

166  Haiti  0.554  0.545  1.6  6 0.984  0.3  0.996  2.5  0.972 

167  Lesotho  0.550  ..  ..  ..  ..  1.7  0.978  ..  .. 

Low human development 

168  Pakistan  0.544  0.529  2.8  2 0.973  0.8  0.989  3.9  0.956 

169  Senegal  0.530  0.512  3.4  0 0.966  0.7  0.991  5.4  0.940 

170  Gambia  0.524  0.514  1.9  2 0.982  0.3  0.997  3.0  0.966 

171  Congo (Democratic Republic of the)  0.522  0.517  1.0  4 0.990  0.0  0.999  1.8  0.980 

172  Malawi  0.517  0.507  1.9  2 0.980  0.1  0.999  3.5  0.961 

173  Benin  0.515  0.504  2.1  1 0.978  0.4  0.995  3.5  0.961 

174  Guinea-Bissau  0.514  ..  ..  ..  ..  0.1  0.998  ..  .. 

175  Djibouti  0.513  0.480  6.4  –6  0.936  0.4  0.994  11.0  0.878 

176  Sudan  0.511  0.498  2.5  2 0.974  0.4  0.995  4.2  0.954 

TABLE 7 

3 07 TABLE 7 / PLANETARY PRESSURES–ADJUSTED HUMAN DEVELOPMENT INDEX HDI RANK                  

> Human
> Development
> Index (HDI) Planetary pressures–adjusted HDI (PHDI)
> SDG 9.4 SDG 8.4, 12.2
> Adjustment factor
> for planetary
> pressures
> Carbon dioxide
> emissions per
> capita (production)
> Carbon dioxide
> emissions
> (production) index
> Material footprint
> per capita
> Material
> footprint index
> Difference from
> HDI value a(%)
> Difference from
> HDI rank a
> Value Value Value (tonnes) Value (tonnes) Value
> 2023 2023 2023 2023 2023 2023 2023 2023 2023

177  Liberia  0.510  0.505  1.0  5 0.990  0.1  0.998  1.7  0.982 

178  Eritrea  0.503  0.496  1.4  3 0.986  0.2  0.998  2.4  0.974 

179  Guinea  0.500  0.488  2.4  2 0.975  0.3  0.996  4.1  0.955 

180  Ethiopia  0.497  0.487  2.0  2 0.980  0.1  0.998  3.5  0.962 

181  Afghanistan  0.496  0.492  0.8  5 0.991  0.3  0.997  1.2  0.986 

182  Mozambique  0.493  0.486  1.4  3 0.986  0.2  0.997  2.3  0.975 

183  Madagascar  0.487  0.481  1.2  3 0.988  0.1  0.998  2.0  0.977 

184  Yemen  0.470  0.465  1.1  1 0.989  0.3  0.996  1.6  0.982 

185  Sierra Leone  0.467  0.459  1.7  1 0.983  0.1  0.998  2.9  0.967 

186  Burkina Faso  0.459  0.453  1.3  1 0.987  0.3  0.997  2.0  0.978 

187  Burundi  0.439  0.435  0.9  1 0.991  0.1  0.999  1.6  0.982 

188  Mali  0.419  0.411  1.9  1 0.981  0.3  0.996  3.2  0.965 

188  Niger  0.419  0.410  2.1  0 0.979  0.1  0.999  3.6  0.960 

190  Chad  0.416  0.397  4.6  0 0.954  0.2  0.998  8.1  0.910 

191  Central African Republic  0.414  0.407  1.7  2 0.983  0.0  0.999  2.9  0.968 

192  Somalia  0.404  0.396  2.0  1 0.979  0.0  1.000  3.7  0.959 

193  South Sudan  0.388  0.383  1.3  1 0.986  0.1  0.998  2.3  0.974 

Other countries or territories 

..  Korea (Democratic People’s Rep. of)  ..  ..  ..  ..  0.961  2.3  0.970  4.2  0.953 

..  Monaco  ..  ..  ..  ..  ..  ..  ..  ..  .. 

Human development groups 

Very high human development  0.914  0.741  18.9  — 0.811  9.4  0.877  23.0  0.746 

High human development  0.777  0.677  12.9  — 0.871  5.6  0.926  16.6  0.816 

Medium human development  0.656  0.631  3.8  — 0.963  1.6  0.980  4.9  0.945 

Low human development  0.515  0.505  1.9  — 0.980  0.4  0.995  3.2  0.964 

Developing countries  0.712  0.653  8.3  — 0.917  3.6  0.953  10.7  0.881 

Regions 

Arab States  0.719  0.665  7.5  — 0.926  4.6  0.940  8.1  0.911 

East Asia and the Pacific  0.775  0.658  15.1  — 0.849  6.5  0.916  19.7  0.782 

Europe and Central Asia  0.818  0.731  10.6  — 0.893  5.0  0.934  13.3  0.852 

Latin America and the Caribbean  0.783  0.715  8.7  — 0.913  2.7  0.965  12.5  0.861 

South Asia  0.672  0.644  4.2  — 0.959  2.1  0.973  5.0  0.945 

Sub-Saharan Africa  0.568  0.553  2.6  — 0.974  0.7  0.991  3.8  0.958 

Least developed countries  0.560  0.548  2.1  — 0.978  0.3  0.996  3.6  0.960 

Small island developing states  0.739  ..  ..  — ..  2.7  0.965  ..  .. 

Organisation for Economic Co -operation 

and Development  0.916  0.752  17.9  — 0.821  8.2  0.893  22.6  0.750 

World  0.756  0.680  10.1  — 0.900  4.5  0.941  12.7  0.859 

TABLE 7 

3 0 8 HUMAN DEVELOPMENT REPORT 2025 TABLE 7 

Notes 

a Based on countries for which a Planetary pressures-

adjusted Human Development Index value is calculated. 

Definitions 

Human Development Index (HDI):  A composite index measur -

ing average achievement in three basic dimensions of human 

development—a long and healthy life, knowledge and a decent 

standard of living. See  Technical note 1  at 5 at  https://hdr.undp. 

org/sites/default/files/2025_HDR/hdr2025_technical_notes. 

pdf  for details on how the HDI is calculated. 

Planetary pressures ‑adjusted HDI (PHDI):  HDI value adjusted 

by the level of carbon dioxide emissions and material footprint 

per capita to account for the excessive human pressure on the 

planet. It should be seen as an incentive for transformation. 

See  Technical note 6  at 5 at  https://hdr.undp.org/sites/default/ 

files/2025_HDR/hdr2025_technical_notes.pdf  for details on 

how the PHDI is calculated. 

Difference from HDI value:  Percentage difference between 

the PHDI value and the HDI value. 

Difference from HDI rank:  Difference in ranks on the PHDI and 

the HDI, calculated only for countries for which a PHDI value 

is calculated. 

Adjustment factor for planetary pressures:  Arithmetic average 

of the carbon dioxide emissions index and the material footprint 

index, both defined below. A high value implies less pressure 

on the planet. 

Carbon dioxide emissions per capita (production):  Carbon 

dioxide emissions produced as a consequence of human 

activities (use of coal, oil and gas for combustion and industrial 

processes, gas flaring and cement manufacture), divided by 

midyear population. Values are territorial emissions, meaning 

that emissions are attributed to the country in which they 

physically occur. 

Carbon dioxide emissions (production) index:  Carbon dioxide 

emissions per capita (production-based) expressed as an 

index using a minimum value of 0 and a maximum value of 

76.61 tonnes per capita. A high value on this index implies less 

pressure on the planet. 

Material footprint per capita:  Material footprint is the 

attribution of global material extraction to a country’s domestic 

final demand. Total material footprint is the sum of the material 

footprint for biomass, fossil fuels, metal ores and nonmetal 

ores. This indicator is calculated as the raw material equivalent 

of imports plus domestic extraction minus raw material 

equivalents of exports. Material footprint per capita describes 

the average material use for final demand. 

Material footprint index:  Material footprint per capita 

expressed as an index using a minimum value of 0 and a 

maximum value of 90.27 tonnes per capita. A high value on this 

index implies less pressure on the planet. 

Main data sources 

Column 1:  HDRO calculations based on data from Barro and 

Lee (2018), IMF (2024), UNDESA (2024a), UNESCO Institute for 

Statistics (2024), United Nations Statistics Division (2025) and 

World Bank (2024a). 

Column 2:  Calculated as the product of the HDI and the 

adjustment factor presented in column 5. 

Column 3:  Calculated based on data in columns 1 and 2. 

Column 4:  Calculated based on PHDI ranks and recalculated 

HDI ranks for countries for which a PHDI value is calculated. 

Column 5:  Calculated based on data in columns 7 and 9. 

Column 6:  Global Carbon Project 2024. 

Column 7:  Calculated based on data in column 6. 

Column 8:  United Nations Environment Programme 2024. 

Column 9:  Calculated based on data in column 8. 

3 0 9 TABLE 7 / PLANETARY PRESSURES–ADJUSTED HUMAN DEVELOPMENT INDEX Developing regions 

Arab States (20 countries or territories) 

Algeria, Bahrain, Djibouti, Egypt, Iraq, Jordan, Kuwait, Lebanon, Libya, 

Morocco, State of Palestine, Oman, Qatar, Saudi Arabia, Somalia, Sudan, 

Syrian Arab Republic, Tunisia, United Arab Emirates, Yemen 

East Asia and the Pacific (26 countries) 

Brunei Darussalam, Cambodia, China, Fiji, Indonesia, Kiribati, Democratic 

People’s Republic of Korea, Lao People’s Democratic Republic, Malaysia, 

Marshall Islands, Federated States of Micronesia, Mongolia, Myanmar, Nauru, 

Palau, Papua New Guinea, Philippines, Samoa, Singapore, Solomon Islands, 

Thailand, Timor-Leste, Tonga, Tuvalu, Vanuatu, Viet Nam 

Europe and Central Asia (17 countries) 

Albania, Armenia, Azerbaijan, Belarus, Bosnia and Herzegovina, Georgia, 

Kazakhstan, Kyrgyzstan, Republic of Moldova, Montenegro, North Macedonia, 

Serbia, Tajikistan, Türkiye, Turkmenistan, Ukraine, Uzbekistan 

Latin America and the Caribbean (33 countries) 

Antigua and Barbuda, Argentina, Bahamas, Barbados, Belize, Plurinational 

State of Bolivia, Brazil, Chile, Colombia, Costa Rica, Cuba, Dominica, 

Dominican Republic, Ecuador, El Salvador, Grenada, Guatemala, Guyana, 

Haiti, Honduras, Jamaica, Mexico, Nicaragua, Panama, Paraguay, Peru, Saint 

Kitts and Nevis, Saint Lucia, Saint Vincent and the Grenadines, Suriname, 

Trinidad and Tobago, Uruguay, Bolivarian Republic of Venezuela 

South Asia (9 countries) 

Afghanistan, Bangladesh, Bhutan, India, Islamic Republic of Iran, Maldives, 

Nepal, Pakistan, Sri Lanka 

Sub-Saharan Africa (46 countries) 

Angola, Benin, Botswana, Burkina Faso, Burundi, Cabo Verde, Cameroon, 

Central African Republic, Chad, Comoros, Congo, Democratic Republic of 

the Congo, Côte d’Ivoire, Equatorial Guinea, Eritrea, Kingdom of Eswatini, 

Ethiopia, Gabon, Gambia, Ghana, Guinea, Guinea-Bissau, Kenya, Lesotho, 

Liberia, Madagascar, Malawi, Mali, Mauritania, Mauritius, Mozambique, 

Namibia, Niger, Nigeria, Rwanda, Sao Tome and Principe, Senegal, 

Seychelles, Sierra Leone, South Africa, South Sudan, United Republic of 

Tanzania, Togo, Uganda, Zambia, Zimbabwe Note:  All countries listed in developing regions are included in aggregates for developing countries. Countries  

> included in aggregates for Least Developed Countries and Small Island Developing States follow UN classi -
> fications, which are available at https://www.un.org/ohrlls/ . Countries included in aggregates for Organisation
> for Economic Co-operation and Development are listed at http:// www.oecd.org/about/membersandpartners/list
> -oecd-member-countries.htm .
> 3 1 0 HUMAN DEVELOPMENT REPORT 2025

Note:  Statistical references relate to statistical material 

presented in this  Statistical Annex  and in the full set 

of statistical tables posted at  https://hdr.undp.org/en/ 

human-development-report-2025 .

Barro, R. J., and J.‑W. Lee. 2018.  Dataset of Education -

al Attainment, June 2018 Revision.  http://www.barrolee 

.com . Accessed 4 October 2024. 

CEDLAS (Center for Distributive, Labor and Social 

Studies) and World Bank. 2024.  Socio-Economic 

Database for Latin America and the Caribbean (SED -

LAC).  https://www.cedlas.econo.unlp.edu.ar/wp/ 

en/estadisticas/sedlac/estadisticas/ . Accessed 30 

December 2024. 

Eurostat. 2024.  European Union Statistics on Income 

and Living Conditions. EU-SILC UDB 2023 – version of 

October 2024. Brussels.  https://ec.europa.eu/eurostat/ 

web/microdata/european-union-statistics-on-income-

and-living-conditions . Accessed 22 January 2025. 

Global Carbon Project. 2024.  Global Carbon At -

las.  https://globalcarbonatlas.org/emissions/carbon-

emissions/ . Accessed 7 January 2025. 

ICF Macro. Various years.  Demographic and Health 

Surveys.  https://dhsprogram.com . Accessed 30 

September 2024. 

ILO (International Labour Organization). 2024. 

ILOSTAT database.  https://ilostat.ilo.org/data/ . Ac -

cessed 10 December 2024. 

IMF (International Monetary Fund). 2024.  World Eco -

nomic Outlook database. October 2024 Edition. Wash -

ington, DC.  https://www.imf.org/en/Publications/WEO/ 

weo-database/2024/October . Accessed 5 December 

2024. 

IPU (Inter‑Parliamentary Union). 2024.  Parline da -

tabase: Monthly ranking of women in national parlia -

ments.  https://data.ipu.org/women-ranking . Accessed 

4 November 2024. 

LIS. 2024.  Luxembourg Income Study Database. 

https://www.lisdatacenter.org/data-access . Accessed 

20 December 2024. 

UNDESA (United Nations Department of Eco ‑

nomic and Social Affairs). 2024a.  World Popula -

tion Prospects: The 2024 Revision.  New York.  https:// 

population.un.org  /wpp/ . Accessed 1 August 2024. 

UNDESA (United Nations Department of Economic 

and Social Affairs). 2024b.  World Population Pros -

pects: The 2024 Revision.  New York.  https://population. 

un.org/wpp/  Accessed 14 June 2024 (embargo data). 

UNEP (United Nations Environment Programme). 

2024.  International Resource Panel’s Global material 

flows database.  https://www.resourcepanel.org/global 

-material-flows-database . Accessed 7 January 2025. 

UNESCO (United Nations Educational, Scientific 

and Cultural Organization) Institute for Statistics. 

2024.  UIS Developer Portal, Bulk Data Download Serv -

ice.  https://apiportal.uis.unesco.org/bdds . Accessed 12 

September 2024. 

UNICEF (United Nations Children’s Fund). Various 

years.  Multiple Indicator Cluster Surveys. New York. 

http://mics.unicef.org . Accessed 30 September 2024. 

United Nations Statistics Division. 2025.  National 

Accounts Main Aggregates Database.  http://unstats.un 

.org/unsd/snaama . Accessed 17 January 2025. 

UNU ‑WIDER (United Nations University World Insti ‑

tute for Development Economics Research). 2023. 

World Income Inequality Database (WIID) Companion 

dataset. Version 28 November 2023.  https://www. 

wider .unu.edu/database/world-income-inequality-

database -wiid#WIIDcomp . Accessed 3 January 2025. 

WHO (World Health Organization), UNICEF (Unit ‑

ed Nations Children’s Fund), UNFPA (United Na ‑

tions Population Fund), World Bank Group and 

UNDESA/Population Division (United Nations De ‑

partment of Economic and Social Affairs, Popula ‑

tion Division). 2023.  Trends in Maternal Mortality 

2000 to 2020: Estimates by WHO, UNICEF, UNFPA, 

World Bank Group and UNDESA/Population Divi -

sion.  Geneva: World Health Organization.  https:// 

www.who.int/publications/i/item/9789240068759 . Ac -

cessed 4 November 2024. 

World Bank. 2024a.  World Development Indicators 

database. Washington, DC.  http://data.worldbank.org .

Accessed 2 January 2025. 

World Bank. 2024b.  World Development Indicators 

database. Washington, DC.  http://data.worldbank.org .

Accessed 30 May 2024. 

World Inequality Database. 2024.  World Inequality 

Database.  http://wid.world . Accessed 2 January 2025. 

# Statistical references STATISTICAL REFERENCES 

3 1 1 Afghanistan  181 

Albania  71 

Algeria  96 

Andorra  32 

Angola  148 

Antigua and Barbuda  53 

Argentina  47 

Armenia  69 

Australia  7

Austria  22 

Azerbaijan  81 

Bahamas  66 

Bahrain  38 

Bangladesh  130 

Barbados  69 

Belarus  65 

Belgium  10 

Belize  115 

Benin  173 

Bhutan  125 

Bolivia (Plurinational State of)  108 

Bosnia and Herzegovina  74 

Botswana  111 

Brazil  84 

Brunei Darussalam  60 

Bulgaria  55 

Burkina Faso  186 

Burundi  187 

Cabo Verde  135 

Cambodia  151 

Cameroon  155 

Canada  16 

Central African Republic  191 

Chad  190 

Chile  45 

China  78 

Colombia  83 

Comoros  152 

Congo  138 

Congo 

(Democratic Republic of the)  171 

Costa Rica  62 

Côte d’Ivoire  157 

Croatia  41 

Cuba  97 

Cyprus  32 

Czechia  29 

Denmark  4

Djibouti  175 

Dominica  98 

Dominican Republic  89 

Ecuador  88 

Egypt  100 

El Salvador  132 

Equatorial Guinea  133 

Eritrea  178 

Estonia  36 

Eswatini (Kingdom of)  126 

Ethiopia  180 

Fiji  111 

Finland  12 

France  26 

Gabon  108 

Gambia  170 

Georgia  57 

Germany  5

Ghana  143 

Greece  34 

Grenada  80 

Guatemala  137 

Guinea  179 

Guinea-Bissau  174 

Guyana  89 

Haiti  166 

Honduras  139 

Hong Kong, China (SAR)  8

Hungary  46 

Iceland  1

India  130 

Indonesia  113 

Iran (Islamic Republic of)  75 

Iraq  126 

Ireland  11 

Israel  27 

Italy  29 

Jamaica  117 

Japan  23 

Jordan  100 

Kazakhstan  60 

Kenya  143 

Kiribati  140 

Korea (Democratic People’s 

Republic of) 

Korea (Republic of)  20 

Kuwait  52 

Kyrgyzstan  117 

Lao People’s 

Democratic Republic  147 

Latvia  41 

Lebanon  102 

Lesotho  167 

Liberia  177 

Libya  115 

Liechtenstein  17 

Lithuania  39 

Luxembourg  25 

Madagascar  183 

Malawi  172 

Malaysia  67 

Maldives  93 

Mali  188 

Malta  24 

Marshall Islands  108 

Mauritania  163 

Mauritius  73 

Mexico  81 

Micronesia 

(Federated States of)  149 

Moldova (Republic of)  86 

Monaco 

Mongolia  104 

Montenegro  48 

Morocco  120 

Mozambique  182 

Myanmar  150 

Namibia  136 

Nauru  124 

Nepal  145 

Netherlands  8

New Zealand  17 

Nicaragua  123 

Niger  188 

Nigeria  164 

North Macedonia  68 

Norway  2

Oman  50 

Pakistan  168 

Palau  84 

Palestine, State of  133 

Panama  59 

Papua New Guinea  160 

Paraguay  99 

Peru  79 

Philippines  117 

Poland  35 

Portugal  40 

Qatar  43 

Romania  55 

Russian Federation  64 

Rwanda  159 

Saint Kitts and Nevis  58 

Saint Lucia  103 

Saint Vincent and 

the Grenadines  76 

Samoa  122 

San Marino  29 

Sao Tome and Principe  141 

Saudi Arabia  37 

Senegal  169 

Serbia  62 

Seychelles  54 

Sierra Leone  185 

Singapore  13 

Slovakia  44 

Slovenia  21 

Solomon Islands  156 

Somalia  192 

South Africa  106 

South Sudan  193 

Spain  28 

Sri Lanka  89 

Sudan  176 

Suriname  114 

Sweden  5

Switzerland  2

Syrian Arab Republic  162 

Tajikistan  128 

Tanzania (United Republic of)  165 

Thailand  76 

Timor-Leste  142 

Togo  161 

Tonga  92 

Trinidad and Tobago  72 

Tunisia  105 

Türkiye  51 

Turkmenistan  95 

Tuvalu  129 

Uganda  157 

Ukraine  87 

United Arab Emirates  15 

United Kingdom  13 

United States  17 

Uruguay  48 

Uzbekistan  107 

Vanuatu  146 

Venezuela 

(Bolivarian Republic of)  121 

Viet Nam  93 

Yemen  184 

Zambia  154 

Zimbabwe  153 

KEY TO H U M A N D E V E LO P M E N T I N D E X R A N KS , 2023 ISBN: 9789211576092 United Nations Development Programme 

One United Nations Plaza 

New York, NY 10017 

www.undp.org
